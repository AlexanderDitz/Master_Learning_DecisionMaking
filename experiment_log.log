2025-03-18 09:40:13,764 - INFO - ================================================================================
2025-03-18 09:40:13,764 - INFO - EXPERIMENT CONFIG
2025-03-18 09:40:13,764 - INFO - ================================================================================
2025-03-18 09:40:13,764 - INFO - Number of actions: 2
2025-03-18 09:40:35,696 - INFO - ================================================================================
2025-03-18 09:40:35,697 - INFO - EXPERIMENT CONFIG
2025-03-18 09:40:35,697 - INFO - ================================================================================
2025-03-18 09:40:35,697 - INFO - Number of actions: 2
2025-03-18 09:40:35,742 - INFO - Number of participants: 128
2025-03-18 09:40:35,742 - INFO - ================================================================================
2025-03-18 09:40:35,742 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 09:40:35,742 - INFO - ================================================================================
2025-03-18 09:40:36,539 - INFO - ================================================================================
2025-03-18 09:40:36,540 - INFO - COMBINED DATASET INFORMATION
2025-03-18 09:40:36,540 - INFO - ================================================================================
2025-03-18 09:40:36,540 - INFO - Combined full dataset shape: torch.Size([128, 200, 5])
2025-03-18 09:40:36,545 - INFO - Number of participants in dataset: 128
2025-03-18 09:40:36,545 - INFO - ================================================================================
2025-03-18 09:40:36,545 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 09:40:36,545 - INFO - ================================================================================
2025-03-18 09:40:36,545 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 09:40:36,553 - INFO - Subset with 100 trials per participant:
2025-03-18 09:40:36,553 - INFO -   Dataset shape: torch.Size([128, 100, 5])
2025-03-18 09:40:36,553 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 09:40:36,553 - INFO - 
Training RNN...
2025-03-18 09:40:36,556 - INFO - RNN model trainable parameters: 1414
2025-03-18 09:40:37,281 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 09:51:19,912 - INFO - Final training loss: 0.3279311
2025-03-18 09:51:19,914 - INFO - 
Fitting SINDy...
2025-03-18 09:51:54,033 - INFO - 
Evaluating SINDy models...
2025-03-18 09:51:54,033 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127}
2025-03-18 09:51:54,034 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 09:51:54,494 - INFO - Participant 0: Log-likelihood: -1317.7810, Normalized LL: -13.1778, Raw BIC: 9147.2727, Normalized BIC: 91.4727
2025-03-18 09:51:54,494 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-18 09:51:54,896 - INFO - Participant 1: Log-likelihood: -1787.3802, Normalized LL: -17.8738, Raw BIC: 10086.4711, Normalized BIC: 100.8647
2025-03-18 09:51:54,896 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-18 09:51:55,400 - INFO - Participant 2: Log-likelihood: -556.8883, Normalized LL: -5.5689, Raw BIC: 7625.4873, Normalized BIC: 76.2549
2025-03-18 09:51:55,400 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-18 09:51:55,982 - INFO - Participant 3: Log-likelihood: -71.3130, Normalized LL: -0.7131, Raw BIC: 6654.3366, Normalized BIC: 66.5434
2025-03-18 09:51:55,982 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-18 09:51:56,481 - INFO - Participant 4: Log-likelihood: -383.8378, Normalized LL: -3.8384, Raw BIC: 7279.3862, Normalized BIC: 72.7939
2025-03-18 09:51:56,482 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-18 09:51:56,955 - INFO - Participant 5: Log-likelihood: -556.1993, Normalized LL: -5.5620, Raw BIC: 7624.1093, Normalized BIC: 76.2411
2025-03-18 09:51:56,955 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-18 09:51:57,440 - INFO - Participant 6: Log-likelihood: -587.4409, Normalized LL: -5.8744, Raw BIC: 7686.5925, Normalized BIC: 76.8659
2025-03-18 09:51:57,440 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-18 09:51:57,881 - INFO - Participant 7: Log-likelihood: -1507.6874, Normalized LL: -15.0769, Raw BIC: 9527.0854, Normalized BIC: 95.2709
2025-03-18 09:51:57,881 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-18 09:51:58,343 - INFO - Participant 8: Log-likelihood: -380.1085, Normalized LL: -3.8011, Raw BIC: 7271.9276, Normalized BIC: 72.7193
2025-03-18 09:51:58,344 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-18 09:51:58,808 - INFO - Participant 9: Log-likelihood: -605.9987, Normalized LL: -6.0600, Raw BIC: 7723.7081, Normalized BIC: 77.2371
2025-03-18 09:51:58,808 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-18 09:51:59,264 - INFO - Participant 10: Log-likelihood: -1261.1104, Normalized LL: -12.6111, Raw BIC: 9033.9313, Normalized BIC: 90.3393
2025-03-18 09:51:59,264 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-18 09:51:59,672 - INFO - Participant 11: Log-likelihood: -547.6810, Normalized LL: -5.4768, Raw BIC: 7607.0727, Normalized BIC: 76.0707
2025-03-18 09:51:59,672 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-18 09:52:00,099 - INFO - Participant 12: Log-likelihood: -1186.5131, Normalized LL: -11.8651, Raw BIC: 8884.7368, Normalized BIC: 88.8474
2025-03-18 09:52:00,099 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-18 09:52:00,506 - INFO - Participant 13: Log-likelihood: -994.4963, Normalized LL: -9.9450, Raw BIC: 8500.7032, Normalized BIC: 85.0070
2025-03-18 09:52:00,506 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-18 09:52:00,920 - INFO - Participant 14: Log-likelihood: -1458.9885, Normalized LL: -14.5899, Raw BIC: 9429.6877, Normalized BIC: 94.2969
2025-03-18 09:52:00,921 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-18 09:52:01,390 - INFO - Participant 15: Log-likelihood: -526.8915, Normalized LL: -5.2689, Raw BIC: 7565.4937, Normalized BIC: 75.6549
2025-03-18 09:52:01,390 - INFO - Evaluating participant 16 using its own SINDy model...
2025-03-18 09:52:01,844 - INFO - Participant 16: Log-likelihood: -333.6599, Normalized LL: -3.3366, Raw BIC: 7179.0305, Normalized BIC: 71.7903
2025-03-18 09:52:01,844 - INFO - Evaluating participant 17 using its own SINDy model...
2025-03-18 09:52:02,324 - INFO - Participant 17: Log-likelihood: -614.1209, Normalized LL: -6.1412, Raw BIC: 7739.9525, Normalized BIC: 77.3995
2025-03-18 09:52:02,324 - INFO - Evaluating participant 18 using its own SINDy model...
2025-03-18 09:52:02,768 - INFO - Participant 18: Log-likelihood: -548.6854, Normalized LL: -5.4869, Raw BIC: 7609.0815, Normalized BIC: 76.0908
2025-03-18 09:52:02,768 - INFO - Evaluating participant 19 using its own SINDy model...
2025-03-18 09:52:03,231 - INFO - Participant 19: Log-likelihood: -608.2886, Normalized LL: -6.0829, Raw BIC: 7728.2878, Normalized BIC: 77.2829
2025-03-18 09:52:03,231 - INFO - Evaluating participant 20 using its own SINDy model...
2025-03-18 09:52:03,654 - INFO - Participant 20: Log-likelihood: -541.0436, Normalized LL: -5.4104, Raw BIC: 7593.7979, Normalized BIC: 75.9380
2025-03-18 09:52:03,654 - INFO - Evaluating participant 21 using its own SINDy model...
2025-03-18 09:52:04,070 - INFO - Participant 21: Log-likelihood: -1987.5150, Normalized LL: -19.8752, Raw BIC: 10486.7407, Normalized BIC: 104.8674
2025-03-18 09:52:04,070 - INFO - Evaluating participant 22 using its own SINDy model...
2025-03-18 09:52:04,485 - INFO - Participant 22: Log-likelihood: -542.5718, Normalized LL: -5.4257, Raw BIC: 7596.8543, Normalized BIC: 75.9685
2025-03-18 09:52:04,485 - INFO - Evaluating participant 23 using its own SINDy model...
2025-03-18 09:52:04,937 - INFO - Participant 23: Log-likelihood: -323.6878, Normalized LL: -3.2369, Raw BIC: 7159.0862, Normalized BIC: 71.5909
2025-03-18 09:52:04,937 - INFO - Evaluating participant 24 using its own SINDy model...
2025-03-18 09:52:05,610 - INFO - Participant 24: Log-likelihood: -473.0721, Normalized LL: -4.7307, Raw BIC: 7457.8549, Normalized BIC: 74.5785
2025-03-18 09:52:05,611 - INFO - Evaluating participant 25 using its own SINDy model...
2025-03-18 09:52:06,099 - INFO - Participant 25: Log-likelihood: -1339.1688, Normalized LL: -13.3917, Raw BIC: 9190.0483, Normalized BIC: 91.9005
2025-03-18 09:52:06,099 - INFO - Evaluating participant 26 using its own SINDy model...
2025-03-18 09:52:06,605 - INFO - Participant 26: Log-likelihood: -584.7814, Normalized LL: -5.8478, Raw BIC: 7681.2735, Normalized BIC: 76.8127
2025-03-18 09:52:06,605 - INFO - Evaluating participant 27 using its own SINDy model...
2025-03-18 09:52:07,050 - INFO - Participant 27: Log-likelihood: -576.2676, Normalized LL: -5.7627, Raw BIC: 7664.2458, Normalized BIC: 76.6425
2025-03-18 09:52:07,050 - INFO - Evaluating participant 28 using its own SINDy model...
2025-03-18 09:52:07,475 - INFO - Participant 28: Log-likelihood: -65.1345, Normalized LL: -0.6513, Raw BIC: 6641.9796, Normalized BIC: 66.4198
2025-03-18 09:52:07,475 - INFO - Evaluating participant 29 using its own SINDy model...
2025-03-18 09:52:08,034 - INFO - Participant 29: Log-likelihood: -70.8265, Normalized LL: -0.7083, Raw BIC: 6653.3636, Normalized BIC: 66.5336
2025-03-18 09:52:08,034 - INFO - Evaluating participant 30 using its own SINDy model...
2025-03-18 09:52:08,718 - INFO - Participant 30: Log-likelihood: -541.4386, Normalized LL: -5.4144, Raw BIC: 7594.5878, Normalized BIC: 75.9459
2025-03-18 09:52:08,718 - INFO - Evaluating participant 31 using its own SINDy model...
2025-03-18 09:52:09,165 - INFO - Participant 31: Log-likelihood: -441.7557, Normalized LL: -4.4176, Raw BIC: 7395.2221, Normalized BIC: 73.9522
2025-03-18 09:52:09,165 - INFO - Evaluating participant 32 using its own SINDy model...
2025-03-18 09:52:09,598 - INFO - Participant 32: Log-likelihood: -561.1302, Normalized LL: -5.6113, Raw BIC: 7633.9711, Normalized BIC: 76.3397
2025-03-18 09:52:09,598 - INFO - Evaluating participant 33 using its own SINDy model...
2025-03-18 09:52:10,129 - INFO - Participant 33: Log-likelihood: -577.5921, Normalized LL: -5.7759, Raw BIC: 7666.8948, Normalized BIC: 76.6689
2025-03-18 09:52:10,129 - INFO - Evaluating participant 34 using its own SINDy model...
2025-03-18 09:52:10,628 - INFO - Participant 34: Log-likelihood: -241.8009, Normalized LL: -2.4180, Raw BIC: 6995.3124, Normalized BIC: 69.9531
2025-03-18 09:52:10,629 - INFO - Evaluating participant 35 using its own SINDy model...
2025-03-18 09:52:11,094 - INFO - Participant 35: Log-likelihood: -555.7601, Normalized LL: -5.5576, Raw BIC: 7623.2309, Normalized BIC: 76.2323
2025-03-18 09:52:11,095 - INFO - Evaluating participant 36 using its own SINDy model...
2025-03-18 09:52:11,604 - INFO - Participant 36: Log-likelihood: -318.4384, Normalized LL: -3.1844, Raw BIC: 7148.5875, Normalized BIC: 71.4859
2025-03-18 09:52:11,604 - INFO - Evaluating participant 37 using its own SINDy model...
2025-03-18 09:52:12,081 - INFO - Participant 37: Log-likelihood: -541.1919, Normalized LL: -5.4119, Raw BIC: 7594.0944, Normalized BIC: 75.9409
2025-03-18 09:52:12,082 - INFO - Evaluating participant 38 using its own SINDy model...
2025-03-18 09:52:12,568 - INFO - Participant 38: Log-likelihood: -589.4098, Normalized LL: -5.8941, Raw BIC: 7690.5302, Normalized BIC: 76.9053
2025-03-18 09:52:12,569 - INFO - Evaluating participant 39 using its own SINDy model...
2025-03-18 09:52:13,080 - INFO - Participant 39: Log-likelihood: -326.2827, Normalized LL: -3.2628, Raw BIC: 7164.2761, Normalized BIC: 71.6428
2025-03-18 09:52:13,080 - INFO - Evaluating participant 40 using its own SINDy model...
2025-03-18 09:52:13,596 - INFO - Participant 40: Log-likelihood: -498.7038, Normalized LL: -4.9870, Raw BIC: 7509.1182, Normalized BIC: 75.0912
2025-03-18 09:52:13,596 - INFO - Evaluating participant 41 using its own SINDy model...
2025-03-18 09:52:14,063 - INFO - Participant 41: Log-likelihood: -265.2649, Normalized LL: -2.6526, Raw BIC: 7042.2405, Normalized BIC: 70.4224
2025-03-18 09:52:14,064 - INFO - Evaluating participant 42 using its own SINDy model...
2025-03-18 09:52:14,523 - INFO - Participant 42: Log-likelihood: -540.7482, Normalized LL: -5.4075, Raw BIC: 7593.2071, Normalized BIC: 75.9321
2025-03-18 09:52:14,524 - INFO - Evaluating participant 43 using its own SINDy model...
2025-03-18 09:52:14,938 - INFO - Participant 43: Log-likelihood: -68.7142, Normalized LL: -0.6871, Raw BIC: 6649.1390, Normalized BIC: 66.4914
2025-03-18 09:52:14,939 - INFO - Evaluating participant 44 using its own SINDy model...
2025-03-18 09:52:15,362 - INFO - Participant 44: Log-likelihood: -2017.1294, Normalized LL: -20.1713, Raw BIC: 10545.9694, Normalized BIC: 105.4597
2025-03-18 09:52:15,363 - INFO - Evaluating participant 45 using its own SINDy model...
2025-03-18 09:52:15,768 - INFO - Participant 45: Log-likelihood: -380.2275, Normalized LL: -3.8023, Raw BIC: 7272.1656, Normalized BIC: 72.7217
2025-03-18 09:52:15,768 - INFO - Evaluating participant 46 using its own SINDy model...
2025-03-18 09:52:16,180 - INFO - Participant 46: Log-likelihood: -548.6854, Normalized LL: -5.4869, Raw BIC: 7609.0815, Normalized BIC: 76.0908
2025-03-18 09:52:16,181 - INFO - Evaluating participant 47 using its own SINDy model...
2025-03-18 09:52:16,595 - INFO - Participant 47: Log-likelihood: -534.5577, Normalized LL: -5.3456, Raw BIC: 7580.8260, Normalized BIC: 75.8083
2025-03-18 09:52:16,596 - INFO - Evaluating participant 48 using its own SINDy model...
2025-03-18 09:52:17,010 - INFO - Participant 48: Log-likelihood: -548.6854, Normalized LL: -5.4869, Raw BIC: 7609.0815, Normalized BIC: 76.0908
2025-03-18 09:52:17,011 - INFO - Evaluating participant 49 using its own SINDy model...
2025-03-18 09:52:17,425 - INFO - Participant 49: Log-likelihood: -131.3370, Normalized LL: -1.3134, Raw BIC: 6774.3847, Normalized BIC: 67.7438
2025-03-18 09:52:17,425 - INFO - Evaluating participant 50 using its own SINDy model...
2025-03-18 09:52:17,839 - INFO - Participant 50: Log-likelihood: -541.1929, Normalized LL: -5.4119, Raw BIC: 7594.0964, Normalized BIC: 75.9410
2025-03-18 09:52:17,839 - INFO - Evaluating participant 51 using its own SINDy model...
2025-03-18 09:52:18,246 - INFO - Participant 51: Log-likelihood: -338.8782, Normalized LL: -3.3888, Raw BIC: 7189.4671, Normalized BIC: 71.8947
2025-03-18 09:52:18,246 - INFO - Evaluating participant 52 using its own SINDy model...
2025-03-18 09:52:18,665 - INFO - Participant 52: Log-likelihood: -585.2675, Normalized LL: -5.8527, Raw BIC: 7682.2457, Normalized BIC: 76.8225
2025-03-18 09:52:18,665 - INFO - Evaluating participant 53 using its own SINDy model...
2025-03-18 09:52:19,074 - INFO - Participant 53: Log-likelihood: -466.0660, Normalized LL: -4.6607, Raw BIC: 7443.8427, Normalized BIC: 74.4384
2025-03-18 09:52:19,075 - INFO - Evaluating participant 54 using its own SINDy model...
2025-03-18 09:52:19,496 - INFO - Participant 54: Log-likelihood: -1261.5486, Normalized LL: -12.6155, Raw BIC: 9034.8078, Normalized BIC: 90.3481
2025-03-18 09:52:19,496 - INFO - Evaluating participant 55 using its own SINDy model...
2025-03-18 09:52:19,903 - INFO - Participant 55: Log-likelihood: -201.9486, Normalized LL: -2.0195, Raw BIC: 6915.6079, Normalized BIC: 69.1561
2025-03-18 09:52:19,903 - INFO - Evaluating participant 56 using its own SINDy model...
2025-03-18 09:52:20,325 - INFO - Participant 56: Log-likelihood: -456.2734, Normalized LL: -4.5627, Raw BIC: 7424.2575, Normalized BIC: 74.2426
2025-03-18 09:52:20,325 - INFO - Evaluating participant 57 using its own SINDy model...
2025-03-18 09:52:20,734 - INFO - Participant 57: Log-likelihood: -528.8475, Normalized LL: -5.2885, Raw BIC: 7569.4057, Normalized BIC: 75.6941
2025-03-18 09:52:20,734 - INFO - Evaluating participant 58 using its own SINDy model...
2025-03-18 09:52:21,188 - INFO - Participant 58: Log-likelihood: -541.3893, Normalized LL: -5.4139, Raw BIC: 7594.4892, Normalized BIC: 75.9449
2025-03-18 09:52:21,188 - INFO - Evaluating participant 59 using its own SINDy model...
2025-03-18 09:52:21,608 - INFO - Participant 59: Log-likelihood: -1496.3601, Normalized LL: -14.9636, Raw BIC: 9504.4309, Normalized BIC: 95.0443
2025-03-18 09:52:21,608 - INFO - Evaluating participant 60 using its own SINDy model...
2025-03-18 09:52:22,017 - INFO - Participant 60: Log-likelihood: -836.1234, Normalized LL: -8.3612, Raw BIC: 8183.9573, Normalized BIC: 81.8396
2025-03-18 09:52:22,018 - INFO - Evaluating participant 61 using its own SINDy model...
2025-03-18 09:52:22,428 - INFO - Participant 61: Log-likelihood: -70.1602, Normalized LL: -0.7016, Raw BIC: 6652.0311, Normalized BIC: 66.5203
2025-03-18 09:52:22,428 - INFO - Evaluating participant 62 using its own SINDy model...
2025-03-18 09:52:22,850 - INFO - Participant 62: Log-likelihood: -548.6854, Normalized LL: -5.4869, Raw BIC: 7609.0815, Normalized BIC: 76.0908
2025-03-18 09:52:22,851 - INFO - Evaluating participant 63 using its own SINDy model...
2025-03-18 09:52:23,261 - INFO - Participant 63: Log-likelihood: -513.9102, Normalized LL: -5.1391, Raw BIC: 7539.5311, Normalized BIC: 75.3953
2025-03-18 09:52:23,261 - INFO - Evaluating participant 64 using its own SINDy model...
2025-03-18 09:52:23,671 - INFO - Participant 64: Log-likelihood: -543.7546, Normalized LL: -5.4375, Raw BIC: 7599.2198, Normalized BIC: 75.9922
2025-03-18 09:52:23,672 - INFO - Evaluating participant 65 using its own SINDy model...
2025-03-18 09:52:24,083 - INFO - Participant 65: Log-likelihood: -540.7973, Normalized LL: -5.4080, Raw BIC: 7593.3052, Normalized BIC: 75.9331
2025-03-18 09:52:24,083 - INFO - Evaluating participant 66 using its own SINDy model...
2025-03-18 09:52:24,499 - INFO - Participant 66: Log-likelihood: -483.6483, Normalized LL: -4.8365, Raw BIC: 7479.0073, Normalized BIC: 74.7901
2025-03-18 09:52:24,499 - INFO - Evaluating participant 67 using its own SINDy model...
2025-03-18 09:52:24,910 - INFO - Participant 67: Log-likelihood: -1055.6438, Normalized LL: -10.5564, Raw BIC: 8622.9982, Normalized BIC: 86.2300
2025-03-18 09:52:24,910 - INFO - Evaluating participant 68 using its own SINDy model...
2025-03-18 09:52:25,336 - INFO - Participant 68: Log-likelihood: -410.4300, Normalized LL: -4.1043, Raw BIC: 7332.5706, Normalized BIC: 73.3257
2025-03-18 09:52:25,337 - INFO - Evaluating participant 69 using its own SINDy model...
2025-03-18 09:52:25,742 - INFO - Participant 69: Log-likelihood: -580.1064, Normalized LL: -5.8011, Raw BIC: 7671.9234, Normalized BIC: 76.7192
2025-03-18 09:52:25,742 - INFO - Evaluating participant 70 using its own SINDy model...
2025-03-18 09:52:26,160 - INFO - Participant 70: Log-likelihood: -67.8831, Normalized LL: -0.6788, Raw BIC: 6647.4769, Normalized BIC: 66.4748
2025-03-18 09:52:26,160 - INFO - Evaluating participant 71 using its own SINDy model...
2025-03-18 09:52:26,569 - INFO - Participant 71: Log-likelihood: -586.4377, Normalized LL: -5.8644, Raw BIC: 7684.5861, Normalized BIC: 76.8459
2025-03-18 09:52:26,570 - INFO - Evaluating participant 72 using its own SINDy model...
2025-03-18 09:52:26,985 - INFO - Participant 72: Log-likelihood: -548.6854, Normalized LL: -5.4869, Raw BIC: 7609.0815, Normalized BIC: 76.0908
2025-03-18 09:52:26,986 - INFO - Evaluating participant 73 using its own SINDy model...
2025-03-18 09:52:27,394 - INFO - Participant 73: Log-likelihood: -425.8177, Normalized LL: -4.2582, Raw BIC: 7363.3460, Normalized BIC: 73.6335
2025-03-18 09:52:27,394 - INFO - Evaluating participant 74 using its own SINDy model...
2025-03-18 09:52:27,800 - INFO - Participant 74: Log-likelihood: -319.1934, Normalized LL: -3.1919, Raw BIC: 7150.0975, Normalized BIC: 71.5010
2025-03-18 09:52:27,800 - INFO - Evaluating participant 75 using its own SINDy model...
2025-03-18 09:52:28,211 - INFO - Participant 75: Log-likelihood: -481.2531, Normalized LL: -4.8125, Raw BIC: 7474.2168, Normalized BIC: 74.7422
2025-03-18 09:52:28,211 - INFO - Evaluating participant 76 using its own SINDy model...
2025-03-18 09:52:28,619 - INFO - Participant 76: Log-likelihood: -153.1253, Normalized LL: -1.5313, Raw BIC: 6817.9612, Normalized BIC: 68.1796
2025-03-18 09:52:28,619 - INFO - Evaluating participant 77 using its own SINDy model...
2025-03-18 09:52:29,031 - INFO - Participant 77: Log-likelihood: -1802.9014, Normalized LL: -18.0290, Raw BIC: 10117.5134, Normalized BIC: 101.1751
2025-03-18 09:52:29,031 - INFO - Evaluating participant 78 using its own SINDy model...
2025-03-18 09:52:29,443 - INFO - Participant 78: Log-likelihood: -596.8248, Normalized LL: -5.9682, Raw BIC: 7705.3603, Normalized BIC: 77.0536
2025-03-18 09:52:29,443 - INFO - Evaluating participant 79 using its own SINDy model...
2025-03-18 09:52:29,852 - INFO - Participant 79: Log-likelihood: -282.0418, Normalized LL: -2.8204, Raw BIC: 7075.7943, Normalized BIC: 70.7579
2025-03-18 09:52:29,852 - INFO - Evaluating participant 80 using its own SINDy model...
2025-03-18 09:52:30,281 - INFO - Participant 80: Log-likelihood: -521.3209, Normalized LL: -5.2132, Raw BIC: 7554.3525, Normalized BIC: 75.5435
2025-03-18 09:52:30,281 - INFO - Evaluating participant 81 using its own SINDy model...
2025-03-18 09:52:30,695 - INFO - Participant 81: Log-likelihood: -615.1948, Normalized LL: -6.1519, Raw BIC: 7742.1003, Normalized BIC: 77.4210
2025-03-18 09:52:30,695 - INFO - Evaluating participant 82 using its own SINDy model...
2025-03-18 09:52:31,115 - INFO - Participant 82: Log-likelihood: -71.5646, Normalized LL: -0.7156, Raw BIC: 6654.8398, Normalized BIC: 66.5484
2025-03-18 09:52:31,115 - INFO - Evaluating participant 83 using its own SINDy model...
2025-03-18 09:52:31,530 - INFO - Participant 83: Log-likelihood: -76.4968, Normalized LL: -0.7650, Raw BIC: 6664.7043, Normalized BIC: 66.6470
2025-03-18 09:52:31,530 - INFO - Evaluating participant 84 using its own SINDy model...
2025-03-18 09:52:31,943 - INFO - Participant 84: Log-likelihood: -414.1253, Normalized LL: -4.1413, Raw BIC: 7339.9613, Normalized BIC: 73.3996
2025-03-18 09:52:31,943 - INFO - Evaluating participant 85 using its own SINDy model...
2025-03-18 09:52:32,354 - INFO - Participant 85: Log-likelihood: -521.6185, Normalized LL: -5.2162, Raw BIC: 7554.9477, Normalized BIC: 75.5495
2025-03-18 09:52:32,355 - INFO - Evaluating participant 86 using its own SINDy model...
2025-03-18 09:52:32,766 - INFO - Participant 86: Log-likelihood: -671.8835, Normalized LL: -6.7188, Raw BIC: 7855.4777, Normalized BIC: 78.5548
2025-03-18 09:52:32,766 - INFO - Evaluating participant 87 using its own SINDy model...
2025-03-18 09:52:33,176 - INFO - Participant 87: Log-likelihood: -1757.4109, Normalized LL: -17.5741, Raw BIC: 10026.5324, Normalized BIC: 100.2653
2025-03-18 09:52:33,176 - INFO - Evaluating participant 88 using its own SINDy model...
2025-03-18 09:52:33,599 - INFO - Participant 88: Log-likelihood: -604.7173, Normalized LL: -6.0472, Raw BIC: 7721.1453, Normalized BIC: 77.2115
2025-03-18 09:52:33,600 - INFO - Evaluating participant 89 using its own SINDy model...
2025-03-18 09:52:34,013 - INFO - Participant 89: Log-likelihood: -1708.3005, Normalized LL: -17.0830, Raw BIC: 9928.3117, Normalized BIC: 99.2831
2025-03-18 09:52:34,013 - INFO - Evaluating participant 90 using its own SINDy model...
2025-03-18 09:52:34,426 - INFO - Participant 90: Log-likelihood: -380.9921, Normalized LL: -3.8099, Raw BIC: 7273.6949, Normalized BIC: 72.7369
2025-03-18 09:52:34,426 - INFO - Evaluating participant 91 using its own SINDy model...
2025-03-18 09:52:34,839 - INFO - Participant 91: Log-likelihood: -530.8607, Normalized LL: -5.3086, Raw BIC: 7573.4320, Normalized BIC: 75.7343
2025-03-18 09:52:34,840 - INFO - Evaluating participant 92 using its own SINDy model...
2025-03-18 09:52:35,319 - INFO - Participant 92: Log-likelihood: -561.7858, Normalized LL: -5.6179, Raw BIC: 7635.2823, Normalized BIC: 76.3528
2025-03-18 09:52:35,319 - INFO - Evaluating participant 93 using its own SINDy model...
2025-03-18 09:52:35,730 - INFO - Participant 93: Log-likelihood: -309.8626, Normalized LL: -3.0986, Raw BIC: 7131.4358, Normalized BIC: 71.3144
2025-03-18 09:52:35,730 - INFO - Evaluating participant 94 using its own SINDy model...
2025-03-18 09:52:36,155 - INFO - Participant 94: Log-likelihood: -541.4394, Normalized LL: -5.4144, Raw BIC: 7594.5894, Normalized BIC: 75.9459
2025-03-18 09:52:36,155 - INFO - Evaluating participant 95 using its own SINDy model...
2025-03-18 09:52:36,566 - INFO - Participant 95: Log-likelihood: -1394.4355, Normalized LL: -13.9444, Raw BIC: 9300.5817, Normalized BIC: 93.0058
2025-03-18 09:52:36,566 - INFO - Evaluating participant 96 using its own SINDy model...
2025-03-18 09:52:36,975 - INFO - Participant 96: Log-likelihood: -563.6503, Normalized LL: -5.6365, Raw BIC: 7639.0112, Normalized BIC: 76.3901
2025-03-18 09:52:36,975 - INFO - Evaluating participant 97 using its own SINDy model...
2025-03-18 09:52:37,398 - INFO - Participant 97: Log-likelihood: -280.1650, Normalized LL: -2.8017, Raw BIC: 7072.0407, Normalized BIC: 70.7204
2025-03-18 09:52:37,398 - INFO - Evaluating participant 98 using its own SINDy model...
2025-03-18 09:52:37,809 - INFO - Participant 98: Log-likelihood: -477.3229, Normalized LL: -4.7732, Raw BIC: 7466.3565, Normalized BIC: 74.6636
2025-03-18 09:52:37,809 - INFO - Evaluating participant 99 using its own SINDy model...
2025-03-18 09:52:38,340 - INFO - Participant 99: Log-likelihood: -1526.1583, Normalized LL: -15.2616, Raw BIC: 9564.0273, Normalized BIC: 95.6403
2025-03-18 09:52:38,341 - INFO - Evaluating participant 100 using its own SINDy model...
2025-03-18 09:52:38,882 - INFO - Participant 100: Log-likelihood: -88.4260, Normalized LL: -0.8843, Raw BIC: 6688.5627, Normalized BIC: 66.8856
2025-03-18 09:52:38,883 - INFO - Evaluating participant 101 using its own SINDy model...
2025-03-18 09:52:39,458 - INFO - Participant 101: Log-likelihood: -85.7589, Normalized LL: -0.8576, Raw BIC: 6683.2284, Normalized BIC: 66.8323
2025-03-18 09:52:39,458 - INFO - Evaluating participant 102 using its own SINDy model...
2025-03-18 09:52:39,992 - INFO - Participant 102: Log-likelihood: -1770.8401, Normalized LL: -17.7084, Raw BIC: 10053.3908, Normalized BIC: 100.5339
2025-03-18 09:52:39,992 - INFO - Evaluating participant 103 using its own SINDy model...
2025-03-18 09:52:40,522 - INFO - Participant 103: Log-likelihood: -489.3280, Normalized LL: -4.8933, Raw BIC: 7490.3666, Normalized BIC: 74.9037
2025-03-18 09:52:40,522 - INFO - Evaluating participant 104 using its own SINDy model...
2025-03-18 09:52:41,072 - INFO - Participant 104: Log-likelihood: -548.6854, Normalized LL: -5.4869, Raw BIC: 7609.0815, Normalized BIC: 76.0908
2025-03-18 09:52:41,072 - INFO - Evaluating participant 105 using its own SINDy model...
2025-03-18 09:52:41,533 - INFO - Participant 105: Log-likelihood: -627.0656, Normalized LL: -6.2707, Raw BIC: 7765.8417, Normalized BIC: 77.6584
2025-03-18 09:52:41,533 - INFO - Evaluating participant 106 using its own SINDy model...
2025-03-18 09:52:41,949 - INFO - Participant 106: Log-likelihood: -1382.4348, Normalized LL: -13.8243, Raw BIC: 9276.5803, Normalized BIC: 92.7658
2025-03-18 09:52:41,949 - INFO - Evaluating participant 107 using its own SINDy model...
2025-03-18 09:52:42,362 - INFO - Participant 107: Log-likelihood: -444.2272, Normalized LL: -4.4423, Raw BIC: 7400.1650, Normalized BIC: 74.0016
2025-03-18 09:52:42,362 - INFO - Evaluating participant 108 using its own SINDy model...
2025-03-18 09:52:42,789 - INFO - Participant 108: Log-likelihood: -305.5107, Normalized LL: -3.0551, Raw BIC: 7122.7319, Normalized BIC: 71.2273
2025-03-18 09:52:42,789 - INFO - Evaluating participant 109 using its own SINDy model...
2025-03-18 11:38:51,541 - INFO - ================================================================================
2025-03-18 11:38:51,541 - INFO - EXPERIMENT CONFIG
2025-03-18 11:38:51,541 - INFO - ================================================================================
2025-03-18 11:38:51,541 - INFO - Number of actions: 2
2025-03-18 11:39:20,942 - INFO - ================================================================================
2025-03-18 11:39:20,942 - INFO - EXPERIMENT CONFIG
2025-03-18 11:39:20,951 - INFO - ================================================================================
2025-03-18 11:39:20,951 - INFO - Number of actions: 2
2025-03-18 11:39:21,053 - INFO - Number of participants: 128
2025-03-18 11:39:21,053 - INFO - ================================================================================
2025-03-18 11:39:21,053 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 11:39:21,054 - INFO - ================================================================================
2025-03-18 11:39:25,350 - INFO - ================================================================================
2025-03-18 11:39:25,351 - INFO - COMBINED DATASET INFORMATION
2025-03-18 11:39:25,351 - INFO - ================================================================================
2025-03-18 11:39:25,351 - INFO - Combined full dataset shape: torch.Size([128, 200, 5])
2025-03-18 11:39:25,352 - INFO - Number of participants in dataset: 128
2025-03-18 11:39:25,352 - INFO - ================================================================================
2025-03-18 11:39:25,353 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 11:39:25,353 - INFO - ================================================================================
2025-03-18 11:39:25,353 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 11:39:25,362 - INFO - Subset with 100 trials per participant:
2025-03-18 11:39:25,362 - INFO -   Dataset shape: torch.Size([128, 100, 5])
2025-03-18 11:39:25,362 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 11:39:25,362 - INFO - 
Training RNN...
2025-03-18 11:54:10,665 - INFO - ================================================================================
2025-03-18 11:54:10,665 - INFO - EXPERIMENT CONFIG
2025-03-18 11:54:10,665 - INFO - ================================================================================
2025-03-18 11:54:10,665 - INFO - Number of actions: 2
2025-03-18 11:54:10,763 - INFO - Number of participants: 128
2025-03-18 11:54:10,764 - INFO - ================================================================================
2025-03-18 11:54:10,764 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 11:54:10,764 - INFO - ================================================================================
2025-03-18 11:54:13,070 - INFO - ================================================================================
2025-03-18 11:54:13,070 - INFO - COMBINED DATASET INFORMATION
2025-03-18 11:54:13,070 - INFO - ================================================================================
2025-03-18 11:54:13,070 - INFO - Combined full dataset shape: torch.Size([128, 200, 5])
2025-03-18 11:54:13,073 - INFO - Number of participants in dataset: 128
2025-03-18 11:54:13,073 - INFO - ================================================================================
2025-03-18 11:54:13,073 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 11:54:13,073 - INFO - ================================================================================
2025-03-18 11:54:13,073 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 11:54:13,089 - INFO - Subset with 100 trials per participant:
2025-03-18 11:54:13,089 - INFO -   Dataset shape: torch.Size([128, 100, 5])
2025-03-18 11:54:13,090 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 11:54:13,090 - INFO - 
Training RNN...
2025-03-18 11:54:13,094 - INFO - RNN model trainable parameters: 1414
2025-03-18 11:54:14,161 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 11:54:19,455 - INFO - Final training loss: 0.3828146
2025-03-18 11:54:31,429 - INFO - 
Fitting SINDy...
2025-03-18 11:55:59,738 - INFO - ================================================================================
2025-03-18 11:55:59,738 - INFO - EXPERIMENT CONFIG
2025-03-18 11:55:59,738 - INFO - ================================================================================
2025-03-18 11:55:59,738 - INFO - Number of actions: 2
2025-03-18 11:55:59,766 - INFO - Number of participants: 16
2025-03-18 11:55:59,766 - INFO - ================================================================================
2025-03-18 11:55:59,766 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 11:55:59,766 - INFO - ================================================================================
2025-03-18 11:56:00,023 - INFO - ================================================================================
2025-03-18 11:56:00,023 - INFO - COMBINED DATASET INFORMATION
2025-03-18 11:56:00,023 - INFO - ================================================================================
2025-03-18 11:56:00,023 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 11:56:00,024 - INFO - Number of participants in dataset: 16
2025-03-18 11:56:00,024 - INFO - ================================================================================
2025-03-18 11:56:00,024 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 11:56:00,024 - INFO - ================================================================================
2025-03-18 11:56:00,024 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 11:56:00,025 - INFO - Subset with 100 trials per participant:
2025-03-18 11:56:00,025 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 11:56:00,025 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 11:56:00,025 - INFO - 
Training RNN...
2025-03-18 11:56:00,028 - INFO - RNN model trainable parameters: 518
2025-03-18 11:56:01,099 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 11:56:11,132 - INFO - Final training loss: 0.3298943
2025-03-18 11:56:11,240 - INFO - 
Fitting SINDy...
2025-03-18 11:57:38,447 - INFO - ================================================================================
2025-03-18 11:57:38,448 - INFO - EXPERIMENT CONFIG
2025-03-18 11:57:38,448 - INFO - ================================================================================
2025-03-18 11:57:38,448 - INFO - Number of actions: 2
2025-03-18 11:57:38,454 - INFO - Number of participants: 16
2025-03-18 11:57:38,454 - INFO - ================================================================================
2025-03-18 11:57:38,454 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 11:57:38,454 - INFO - ================================================================================
2025-03-18 11:57:38,532 - INFO - ================================================================================
2025-03-18 11:57:38,532 - INFO - COMBINED DATASET INFORMATION
2025-03-18 11:57:38,532 - INFO - ================================================================================
2025-03-18 11:57:38,532 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 11:57:38,532 - INFO - Number of participants in dataset: 16
2025-03-18 11:57:38,532 - INFO - ================================================================================
2025-03-18 11:57:38,532 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 11:57:38,532 - INFO - ================================================================================
2025-03-18 11:57:38,532 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 11:57:38,533 - INFO - Subset with 100 trials per participant:
2025-03-18 11:57:38,533 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 11:57:38,533 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 11:57:38,533 - INFO - 
Training RNN...
2025-03-18 11:57:38,534 - INFO - RNN model trainable parameters: 518
2025-03-18 11:57:38,928 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 11:57:44,111 - INFO - Final training loss: 0.3298943
2025-03-18 11:57:44,221 - INFO - 
Fitting SINDy...
2025-03-18 11:57:47,057 - INFO - 
Evaluating SINDy models...
2025-03-18 11:57:47,057 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-18 11:57:47,057 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 11:57:47,057 - INFO - SINDy model parameters for participant 0: 1
2025-03-18 11:57:47,057 - ERROR - Error evaluating participant 0 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,058 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,058 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-18 11:57:47,058 - INFO - SINDy model parameters for participant 1: 1
2025-03-18 11:57:47,058 - ERROR - Error evaluating participant 1 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,058 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,058 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-18 11:57:47,058 - INFO - SINDy model parameters for participant 2: 1
2025-03-18 11:57:47,058 - ERROR - Error evaluating participant 2 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,059 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,059 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-18 11:57:47,059 - INFO - SINDy model parameters for participant 3: 1
2025-03-18 11:57:47,059 - ERROR - Error evaluating participant 3 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,059 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,059 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-18 11:57:47,059 - INFO - SINDy model parameters for participant 4: 1
2025-03-18 11:57:47,059 - ERROR - Error evaluating participant 4 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,059 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,059 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-18 11:57:47,059 - INFO - SINDy model parameters for participant 5: 1
2025-03-18 11:57:47,059 - ERROR - Error evaluating participant 5 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,060 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,060 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-18 11:57:47,060 - INFO - SINDy model parameters for participant 6: 1
2025-03-18 11:57:47,060 - ERROR - Error evaluating participant 6 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,060 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,060 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-18 11:57:47,060 - INFO - SINDy model parameters for participant 7: 1
2025-03-18 11:57:47,060 - ERROR - Error evaluating participant 7 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,060 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,060 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-18 11:57:47,060 - INFO - SINDy model parameters for participant 8: 1
2025-03-18 11:57:47,060 - ERROR - Error evaluating participant 8 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,060 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,060 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-18 11:57:47,061 - INFO - SINDy model parameters for participant 9: 1
2025-03-18 11:57:47,061 - ERROR - Error evaluating participant 9 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,061 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,061 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-18 11:57:47,061 - INFO - SINDy model parameters for participant 10: 1
2025-03-18 11:57:47,061 - ERROR - Error evaluating participant 10 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,061 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,061 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-18 11:57:47,061 - INFO - SINDy model parameters for participant 11: 1
2025-03-18 11:57:47,061 - ERROR - Error evaluating participant 11 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,061 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,061 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-18 11:57:47,061 - INFO - SINDy model parameters for participant 12: 1
2025-03-18 11:57:47,061 - ERROR - Error evaluating participant 12 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,062 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,062 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-18 11:57:47,062 - INFO - SINDy model parameters for participant 13: 1
2025-03-18 11:57:47,062 - ERROR - Error evaluating participant 13 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,062 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,062 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-18 11:57:47,062 - INFO - SINDy model parameters for participant 14: 1
2025-03-18 11:57:47,062 - ERROR - Error evaluating participant 14 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,062 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,062 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-18 11:57:47,062 - INFO - SINDy model parameters for participant 15: 1
2025-03-18 11:57:47,062 - ERROR - Error evaluating participant 15 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:57:47,062 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:57:47,062 - WARNING - Could not compute average SINDy BIC due to errors
2025-03-18 11:57:47,062 - WARNING - Could not compute average Log Likelihood due to errors
2025-03-18 11:57:47,062 - INFO - 
Identified SINDy equations:
2025-03-18 11:57:47,062 - INFO - Module: x_learning_rate_reward
2025-03-18 11:57:47,072 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,072 - INFO -   Participant 0 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,072 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,074 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,074 - INFO -   Participant 1 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,074 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,075 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,075 - INFO -   Participant 2 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,075 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,077 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,077 - INFO -   Participant 3 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,077 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,078 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,078 - INFO -   Participant 4 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,078 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,079 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,080 - INFO -   Participant 5 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,080 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,081 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,081 - INFO -   Participant 6 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,081 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,083 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,083 - INFO -   Participant 7 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,083 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,084 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,084 - INFO -   Participant 8 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,084 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,086 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,086 - INFO -   Participant 9 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,086 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,087 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,088 - INFO -   Participant 10 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,088 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,089 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,089 - INFO -   Participant 11 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,089 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,091 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,091 - INFO -   Participant 12 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,091 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,092 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,092 - INFO -   Participant 13 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,092 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,094 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,094 - INFO -   Participant 14 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,094 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,095 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,096 - INFO -   Participant 15 Coefficients: [0.46509403 0.15802821 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:57:47,096 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:57:47,096 - INFO - Module: x_value_reward_not_chosen
2025-03-18 11:57:47,097 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,097 - INFO -   Participant 0 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,097 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,098 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,098 - INFO -   Participant 1 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,098 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,099 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,099 - INFO -   Participant 2 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,100 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,101 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,101 - INFO -   Participant 3 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,101 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,102 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,102 - INFO -   Participant 4 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,102 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,103 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,103 - INFO -   Participant 5 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,103 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,105 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,105 - INFO -   Participant 6 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,105 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,106 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,106 - INFO -   Participant 7 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,106 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,107 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,107 - INFO -   Participant 8 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,107 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,109 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,109 - INFO -   Participant 9 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,109 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,110 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,110 - INFO -   Participant 10 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,110 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,111 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,111 - INFO -   Participant 11 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,111 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,112 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,112 - INFO -   Participant 12 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,112 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,114 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,114 - INFO -   Participant 13 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,114 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,115 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,115 - INFO -   Participant 14 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,115 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,116 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,116 - INFO -   Participant 15 Coefficients: [-0.86221407  0.53398397  0.          0.          0.          0.        ]
2025-03-18 11:57:47,116 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:57:47,116 - INFO - Module: x_value_choice_chosen
2025-03-18 11:57:47,118 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,118 - INFO -   Participant 0 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,118 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,119 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,119 - INFO -   Participant 1 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,119 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,120 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,120 - INFO -   Participant 2 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,120 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,122 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,122 - INFO -   Participant 3 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,122 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,123 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,123 - INFO -   Participant 4 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,123 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,124 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,124 - INFO -   Participant 5 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,124 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,125 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,126 - INFO -   Participant 6 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,126 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,127 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,127 - INFO -   Participant 7 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,127 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,128 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,128 - INFO -   Participant 8 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,128 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,129 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,129 - INFO -   Participant 9 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,129 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,131 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,131 - INFO -   Participant 10 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,131 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,132 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,132 - INFO -   Participant 11 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,132 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,133 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,133 - INFO -   Participant 12 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,133 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,135 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,135 - INFO -   Participant 13 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,135 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,136 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,136 - INFO -   Participant 14 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,136 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,137 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,137 - INFO -   Participant 15 Coefficients: [0.14417009 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,137 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:57:47,137 - INFO - Module: x_value_choice_not_chosen
2025-03-18 11:57:47,139 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,139 - INFO -   Participant 0 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,139 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,140 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,140 - INFO -   Participant 1 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,140 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,141 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,141 - INFO -   Participant 2 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,141 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,143 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,143 - INFO -   Participant 3 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,143 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,144 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,144 - INFO -   Participant 4 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,144 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,145 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,145 - INFO -   Participant 5 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,145 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,147 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,147 - INFO -   Participant 6 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,147 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,148 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,148 - INFO -   Participant 7 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,148 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,149 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,149 - INFO -   Participant 8 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,149 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,151 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,151 - INFO -   Participant 9 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,151 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,152 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,152 - INFO -   Participant 10 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,152 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,153 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,153 - INFO -   Participant 11 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,153 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,155 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,155 - INFO -   Participant 12 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,155 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,156 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,156 - INFO -   Participant 13 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,156 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,157 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,157 - INFO -   Participant 14 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,157 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,158 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:57:47,159 - INFO -   Participant 15 Coefficients: [0.89472252 0.         0.         0.         0.         0.        ]
2025-03-18 11:57:47,159 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:57:47,159 - INFO - Creating dataset subset with 200 trials per participant
2025-03-18 11:57:47,160 - INFO - Subset with 200 trials per participant:
2025-03-18 11:57:47,160 - INFO -   Dataset shape: torch.Size([16, 200, 5])
2025-03-18 11:57:47,160 - INFO - 
==== Running pipeline for dataset: 200 trials per participant ====
2025-03-18 11:57:47,160 - INFO - 
Training RNN...
2025-03-18 11:57:47,161 - INFO - RNN model trainable parameters: 518
2025-03-18 11:57:47,161 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 11:57:57,881 - INFO - Final training loss: 0.3422785
2025-03-18 11:57:57,997 - INFO - 
Fitting SINDy...
2025-03-18 11:58:00,912 - INFO - 
Evaluating SINDy models...
2025-03-18 11:58:00,912 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-18 11:58:00,912 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 11:58:00,912 - INFO - SINDy model parameters for participant 0: 1
2025-03-18 11:58:00,912 - ERROR - Error evaluating participant 0 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,912 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,912 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-18 11:58:00,912 - INFO - SINDy model parameters for participant 1: 1
2025-03-18 11:58:00,913 - ERROR - Error evaluating participant 1 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,913 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,913 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-18 11:58:00,913 - INFO - SINDy model parameters for participant 2: 1
2025-03-18 11:58:00,913 - ERROR - Error evaluating participant 2 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,913 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,913 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-18 11:58:00,913 - INFO - SINDy model parameters for participant 3: 1
2025-03-18 11:58:00,913 - ERROR - Error evaluating participant 3 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,913 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,914 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-18 11:58:00,914 - INFO - SINDy model parameters for participant 4: 1
2025-03-18 11:58:00,914 - ERROR - Error evaluating participant 4 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,914 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,914 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-18 11:58:00,914 - INFO - SINDy model parameters for participant 5: 1
2025-03-18 11:58:00,914 - ERROR - Error evaluating participant 5 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,914 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,914 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-18 11:58:00,914 - INFO - SINDy model parameters for participant 6: 1
2025-03-18 11:58:00,914 - ERROR - Error evaluating participant 6 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,915 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,915 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-18 11:58:00,915 - INFO - SINDy model parameters for participant 7: 1
2025-03-18 11:58:00,915 - ERROR - Error evaluating participant 7 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,915 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,915 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-18 11:58:00,915 - INFO - SINDy model parameters for participant 8: 1
2025-03-18 11:58:00,915 - ERROR - Error evaluating participant 8 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,915 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,915 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-18 11:58:00,915 - INFO - SINDy model parameters for participant 9: 1
2025-03-18 11:58:00,915 - ERROR - Error evaluating participant 9 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,916 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,916 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-18 11:58:00,916 - INFO - SINDy model parameters for participant 10: 1
2025-03-18 11:58:00,916 - ERROR - Error evaluating participant 10 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,916 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,916 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-18 11:58:00,916 - INFO - SINDy model parameters for participant 11: 1
2025-03-18 11:58:00,916 - ERROR - Error evaluating participant 11 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,916 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,916 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-18 11:58:00,916 - INFO - SINDy model parameters for participant 12: 1
2025-03-18 11:58:00,916 - ERROR - Error evaluating participant 12 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,917 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,917 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-18 11:58:00,917 - INFO - SINDy model parameters for participant 13: 1
2025-03-18 11:58:00,917 - ERROR - Error evaluating participant 13 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,917 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,917 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-18 11:58:00,917 - INFO - SINDy model parameters for participant 14: 1
2025-03-18 11:58:00,917 - ERROR - Error evaluating participant 14 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,917 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,917 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-18 11:58:00,917 - INFO - SINDy model parameters for participant 15: 1
2025-03-18 11:58:00,917 - ERROR - Error evaluating participant 15 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 11:58:00,918 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 229, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 11:58:00,918 - WARNING - Could not compute average SINDy BIC due to errors
2025-03-18 11:58:00,918 - WARNING - Could not compute average Log Likelihood due to errors
2025-03-18 11:58:00,918 - INFO - 
Identified SINDy equations:
2025-03-18 11:58:00,918 - INFO - Module: x_learning_rate_reward
2025-03-18 11:58:00,919 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,919 - INFO -   Participant 0 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,919 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,921 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,921 - INFO -   Participant 1 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,921 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,922 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,922 - INFO -   Participant 2 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,922 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,924 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,924 - INFO -   Participant 3 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,924 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,925 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,925 - INFO -   Participant 4 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,925 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,927 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,927 - INFO -   Participant 5 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,927 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,929 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,929 - INFO -   Participant 6 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,929 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,930 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,930 - INFO -   Participant 7 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,930 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,932 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,932 - INFO -   Participant 8 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,932 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,933 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,933 - INFO -   Participant 9 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,933 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,935 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,935 - INFO -   Participant 10 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,935 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,936 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,936 - INFO -   Participant 11 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,936 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,938 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,938 - INFO -   Participant 12 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,938 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,940 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,940 - INFO -   Participant 13 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,940 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,941 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,941 - INFO -   Participant 14 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,941 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,943 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,943 - INFO -   Participant 15 Coefficients: [0.4874437  0.19646978 0.19658445 0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 11:58:00,943 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 11:58:00,943 - INFO - Module: x_value_reward_not_chosen
2025-03-18 11:58:00,944 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,944 - INFO -   Participant 0 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,944 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,945 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,945 - INFO -   Participant 1 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,945 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,947 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,947 - INFO -   Participant 2 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,947 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,948 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,948 - INFO -   Participant 3 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,948 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,949 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,949 - INFO -   Participant 4 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,949 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,950 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,950 - INFO -   Participant 5 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,951 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,952 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,952 - INFO -   Participant 6 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,952 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,953 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,953 - INFO -   Participant 7 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,953 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,954 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,954 - INFO -   Participant 8 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,954 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,956 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,956 - INFO -   Participant 9 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,956 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,957 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,957 - INFO -   Participant 10 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,957 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,958 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,958 - INFO -   Participant 11 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,958 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,959 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,960 - INFO -   Participant 12 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,960 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,961 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,961 - INFO -   Participant 13 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,961 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,962 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,962 - INFO -   Participant 14 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,962 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,963 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,963 - INFO -   Participant 15 Coefficients: [-0.11223469  0.67682141  0.          0.          0.          0.        ]
2025-03-18 11:58:00,963 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 11:58:00,963 - INFO - Module: x_value_choice_chosen
2025-03-18 11:58:00,965 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,965 - INFO -   Participant 0 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,965 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,966 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,966 - INFO -   Participant 1 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,966 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,967 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,967 - INFO -   Participant 2 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,967 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,968 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,969 - INFO -   Participant 3 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,969 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,970 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,970 - INFO -   Participant 4 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,970 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,971 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,971 - INFO -   Participant 5 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,971 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,972 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,972 - INFO -   Participant 6 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,972 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,974 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,974 - INFO -   Participant 7 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,974 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,975 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,975 - INFO -   Participant 8 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,975 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,976 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,976 - INFO -   Participant 9 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,976 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,977 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,978 - INFO -   Participant 10 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,978 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,979 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,979 - INFO -   Participant 11 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,979 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,980 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,980 - INFO -   Participant 12 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,980 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,981 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,981 - INFO -   Participant 13 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,981 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,982 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,983 - INFO -   Participant 14 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,983 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,984 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,984 - INFO -   Participant 15 Coefficients: [0.93443419 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,984 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 11:58:00,984 - INFO - Module: x_value_choice_not_chosen
2025-03-18 11:58:00,985 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,985 - INFO -   Participant 0 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,985 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:00,986 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,986 - INFO -   Participant 1 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,986 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:00,987 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,988 - INFO -   Participant 2 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,988 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:00,989 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,989 - INFO -   Participant 3 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,989 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:00,990 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,990 - INFO -   Participant 4 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,990 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:00,991 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,991 - INFO -   Participant 5 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,991 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:00,992 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,993 - INFO -   Participant 6 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,993 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:00,994 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,994 - INFO -   Participant 7 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,994 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:00,995 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,995 - INFO -   Participant 8 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,995 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:00,996 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,996 - INFO -   Participant 9 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,996 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:00,997 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,997 - INFO -   Participant 10 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,997 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:00,999 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:00,999 - INFO -   Participant 11 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:00,999 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:01,000 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:01,000 - INFO -   Participant 12 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:01,000 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:01,001 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:01,001 - INFO -   Participant 13 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:01,001 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:01,002 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:01,002 - INFO -   Participant 14 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:01,002 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:58:01,004 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 11:58:01,004 - INFO -   Participant 15 Coefficients: [0.08344289 0.         0.         0.         0.         0.        ]
2025-03-18 11:58:01,004 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 11:59:47,622 - INFO - ================================================================================
2025-03-18 11:59:47,622 - INFO - EXPERIMENT CONFIG
2025-03-18 11:59:47,622 - INFO - ================================================================================
2025-03-18 11:59:47,622 - INFO - Number of actions: 2
2025-03-18 11:59:47,631 - INFO - Number of participants: 16
2025-03-18 11:59:47,631 - INFO - ================================================================================
2025-03-18 11:59:47,631 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 11:59:47,631 - INFO - ================================================================================
2025-03-18 11:59:47,815 - INFO - ================================================================================
2025-03-18 11:59:47,815 - INFO - COMBINED DATASET INFORMATION
2025-03-18 11:59:47,815 - INFO - ================================================================================
2025-03-18 11:59:47,815 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 11:59:47,816 - INFO - Number of participants in dataset: 16
2025-03-18 11:59:47,816 - INFO - ================================================================================
2025-03-18 11:59:47,816 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 11:59:47,816 - INFO - ================================================================================
2025-03-18 11:59:47,816 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 11:59:47,817 - INFO - Subset with 100 trials per participant:
2025-03-18 11:59:47,817 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 11:59:47,817 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 11:59:47,817 - INFO - 
Training RNN...
2025-03-18 11:59:47,819 - INFO - RNN model trainable parameters: 518
2025-03-18 11:59:48,745 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 11:59:55,002 - INFO - Final training loss: 0.3298943
2025-03-18 12:01:39,117 - INFO - 
Fitting SINDy...
2025-03-18 12:19:41,909 - INFO - ================================================================================
2025-03-18 12:19:41,909 - INFO - EXPERIMENT CONFIG
2025-03-18 12:19:41,909 - INFO - ================================================================================
2025-03-18 12:19:41,909 - INFO - Number of actions: 2
2025-03-18 12:19:41,917 - INFO - Number of participants: 16
2025-03-18 12:19:41,917 - INFO - ================================================================================
2025-03-18 12:19:41,917 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 12:19:41,917 - INFO - ================================================================================
2025-03-18 12:19:42,120 - INFO - ================================================================================
2025-03-18 12:19:42,120 - INFO - COMBINED DATASET INFORMATION
2025-03-18 12:19:42,121 - INFO - ================================================================================
2025-03-18 12:19:42,121 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 12:19:42,121 - INFO - Number of participants in dataset: 16
2025-03-18 12:19:42,121 - INFO - ================================================================================
2025-03-18 12:19:42,121 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 12:19:42,121 - INFO - ================================================================================
2025-03-18 12:19:42,121 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 12:19:42,122 - INFO - Subset with 100 trials per participant:
2025-03-18 12:19:42,122 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 12:19:42,122 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 12:19:42,122 - INFO - 
Training RNN...
2025-03-18 12:19:42,124 - INFO - RNN model trainable parameters: 518
2025-03-18 12:19:43,039 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 12:19:49,186 - INFO - Final training loss: 0.3298943
2025-03-18 12:19:49,351 - INFO - 
Fitting SINDy...
2025-03-18 12:22:58,938 - INFO - ================================================================================
2025-03-18 12:22:58,939 - INFO - EXPERIMENT CONFIG
2025-03-18 12:22:58,939 - INFO - ================================================================================
2025-03-18 12:22:58,939 - INFO - Number of actions: 2
2025-03-18 12:22:58,946 - INFO - Number of participants: 16
2025-03-18 12:22:58,946 - INFO - ================================================================================
2025-03-18 12:22:58,946 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 12:22:58,946 - INFO - ================================================================================
2025-03-18 12:22:59,117 - INFO - ================================================================================
2025-03-18 12:22:59,117 - INFO - COMBINED DATASET INFORMATION
2025-03-18 12:22:59,117 - INFO - ================================================================================
2025-03-18 12:22:59,117 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 12:22:59,117 - INFO - Number of participants in dataset: 16
2025-03-18 12:22:59,117 - INFO - ================================================================================
2025-03-18 12:22:59,118 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 12:22:59,118 - INFO - ================================================================================
2025-03-18 12:22:59,118 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 12:22:59,118 - INFO - Subset with 100 trials per participant:
2025-03-18 12:22:59,118 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 12:22:59,118 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 12:22:59,118 - INFO - 
Training RNN...
2025-03-18 12:22:59,120 - INFO - RNN model trainable parameters: 518
2025-03-18 12:22:59,979 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 12:23:06,121 - INFO - Final training loss: 0.3298943
2025-03-18 12:23:06,285 - INFO - 
Fitting SINDy...
2025-03-18 12:26:46,750 - INFO - ================================================================================
2025-03-18 12:26:46,750 - INFO - EXPERIMENT CONFIG
2025-03-18 12:26:46,750 - INFO - ================================================================================
2025-03-18 12:26:46,750 - INFO - Number of actions: 2
2025-03-18 12:26:46,759 - INFO - Number of participants: 16
2025-03-18 12:26:46,759 - INFO - ================================================================================
2025-03-18 12:26:46,759 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 12:26:46,759 - INFO - ================================================================================
2025-03-18 12:26:46,944 - INFO - ================================================================================
2025-03-18 12:26:46,944 - INFO - COMBINED DATASET INFORMATION
2025-03-18 12:26:46,944 - INFO - ================================================================================
2025-03-18 12:26:46,944 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 12:26:46,944 - INFO - Number of participants in dataset: 16
2025-03-18 12:26:46,944 - INFO - ================================================================================
2025-03-18 12:26:46,944 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 12:26:46,944 - INFO - ================================================================================
2025-03-18 12:26:46,944 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 12:26:46,945 - INFO - Subset with 100 trials per participant:
2025-03-18 12:26:46,945 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 12:26:46,945 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 12:26:46,945 - INFO - 
Training RNN...
2025-03-18 12:26:46,947 - INFO - RNN model trainable parameters: 518
2025-03-18 12:26:47,888 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 12:26:54,238 - INFO - Final training loss: 0.3298943
2025-03-18 12:26:54,416 - INFO - 
Fitting SINDy...
2025-03-18 12:45:03,263 - INFO - ================================================================================
2025-03-18 12:45:03,263 - INFO - EXPERIMENT CONFIG
2025-03-18 12:45:03,263 - INFO - ================================================================================
2025-03-18 12:45:03,263 - INFO - Number of actions: 2
2025-03-18 12:45:03,271 - INFO - Number of participants: 16
2025-03-18 12:45:03,272 - INFO - ================================================================================
2025-03-18 12:45:03,272 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 12:45:03,272 - INFO - ================================================================================
2025-03-18 12:45:03,452 - INFO - ================================================================================
2025-03-18 12:45:03,452 - INFO - COMBINED DATASET INFORMATION
2025-03-18 12:45:03,452 - INFO - ================================================================================
2025-03-18 12:45:03,452 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 12:45:03,452 - INFO - Number of participants in dataset: 16
2025-03-18 12:45:03,452 - INFO - ================================================================================
2025-03-18 12:45:03,452 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 12:45:03,452 - INFO - ================================================================================
2025-03-18 12:45:03,452 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 12:45:03,453 - INFO - Subset with 100 trials per participant:
2025-03-18 12:45:03,453 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 12:45:03,453 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 12:45:03,453 - INFO - 
Training RNN...
2025-03-18 12:45:03,455 - INFO - RNN model trainable parameters: 518
2025-03-18 12:45:04,318 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 12:45:10,564 - INFO - Final training loss: 0.3298943
2025-03-18 12:45:10,565 - INFO - 
Fitting SINDy...
2025-03-18 12:47:00,281 - INFO - ================================================================================
2025-03-18 12:47:00,281 - INFO - EXPERIMENT CONFIG
2025-03-18 12:47:00,281 - INFO - ================================================================================
2025-03-18 12:47:00,281 - INFO - Number of actions: 2
2025-03-18 12:47:00,289 - INFO - Number of participants: 16
2025-03-18 12:47:00,289 - INFO - ================================================================================
2025-03-18 12:47:00,289 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 12:47:00,289 - INFO - ================================================================================
2025-03-18 12:47:00,466 - INFO - ================================================================================
2025-03-18 12:47:00,466 - INFO - COMBINED DATASET INFORMATION
2025-03-18 12:47:00,466 - INFO - ================================================================================
2025-03-18 12:47:00,466 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 12:47:00,467 - INFO - Number of participants in dataset: 16
2025-03-18 12:47:00,467 - INFO - ================================================================================
2025-03-18 12:47:00,467 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 12:47:00,467 - INFO - ================================================================================
2025-03-18 12:47:00,467 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 12:47:00,468 - INFO - Subset with 100 trials per participant:
2025-03-18 12:47:00,468 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 12:47:00,468 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 12:47:00,468 - INFO - 
Training RNN...
2025-03-18 12:47:00,470 - INFO - RNN model trainable parameters: 518
2025-03-18 12:47:01,374 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 12:47:07,505 - INFO - Final training loss: 0.3298943
2025-03-18 12:47:07,506 - INFO - 
Fitting SINDy...
2025-03-18 12:49:18,239 - INFO - ================================================================================
2025-03-18 12:49:18,239 - INFO - EXPERIMENT CONFIG
2025-03-18 12:49:18,239 - INFO - ================================================================================
2025-03-18 12:49:18,239 - INFO - Number of actions: 2
2025-03-18 12:49:18,245 - INFO - Number of participants: 16
2025-03-18 12:49:18,245 - INFO - ================================================================================
2025-03-18 12:49:18,245 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 12:49:18,245 - INFO - ================================================================================
2025-03-18 12:49:18,330 - INFO - ================================================================================
2025-03-18 12:49:18,330 - INFO - COMBINED DATASET INFORMATION
2025-03-18 12:49:18,330 - INFO - ================================================================================
2025-03-18 12:49:18,330 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 12:49:18,330 - INFO - Number of participants in dataset: 16
2025-03-18 12:49:18,330 - INFO - ================================================================================
2025-03-18 12:49:18,330 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 12:49:18,330 - INFO - ================================================================================
2025-03-18 12:49:18,330 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 12:49:18,331 - INFO - Subset with 100 trials per participant:
2025-03-18 12:49:18,331 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 12:49:18,331 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 12:49:18,331 - INFO - 
Training RNN...
2025-03-18 12:49:18,332 - INFO - RNN model trainable parameters: 518
2025-03-18 12:49:18,783 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 12:49:24,039 - INFO - Final training loss: 0.3298943
2025-03-18 12:49:24,040 - INFO - 
Fitting SINDy...
2025-03-18 12:50:12,488 - INFO - ================================================================================
2025-03-18 12:50:12,489 - INFO - EXPERIMENT CONFIG
2025-03-18 12:50:12,489 - INFO - ================================================================================
2025-03-18 12:50:12,489 - INFO - Number of actions: 2
2025-03-18 12:50:12,497 - INFO - Number of participants: 16
2025-03-18 12:50:12,497 - INFO - ================================================================================
2025-03-18 12:50:12,497 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 12:50:12,497 - INFO - ================================================================================
2025-03-18 12:50:12,677 - INFO - ================================================================================
2025-03-18 12:50:12,677 - INFO - COMBINED DATASET INFORMATION
2025-03-18 12:50:12,677 - INFO - ================================================================================
2025-03-18 12:50:12,677 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 12:50:12,678 - INFO - Number of participants in dataset: 16
2025-03-18 12:50:12,678 - INFO - ================================================================================
2025-03-18 12:50:12,678 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 12:50:12,678 - INFO - ================================================================================
2025-03-18 12:50:12,678 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 12:50:12,679 - INFO - Subset with 100 trials per participant:
2025-03-18 12:50:12,679 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 12:50:12,679 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 12:50:12,679 - INFO - 
Training RNN...
2025-03-18 12:50:12,681 - INFO - RNN model trainable parameters: 518
2025-03-18 12:50:13,576 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 12:50:19,697 - INFO - Final training loss: 0.3298943
2025-03-18 12:50:19,698 - INFO - 
Fitting SINDy...
2025-03-18 12:53:25,111 - INFO - ================================================================================
2025-03-18 12:53:25,111 - INFO - EXPERIMENT CONFIG
2025-03-18 12:53:25,111 - INFO - ================================================================================
2025-03-18 12:53:25,111 - INFO - Number of actions: 2
2025-03-18 12:53:25,117 - INFO - Number of participants: 16
2025-03-18 12:53:25,117 - INFO - ================================================================================
2025-03-18 12:53:25,117 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 12:53:25,117 - INFO - ================================================================================
2025-03-18 12:53:25,201 - INFO - ================================================================================
2025-03-18 12:53:25,201 - INFO - COMBINED DATASET INFORMATION
2025-03-18 12:53:25,201 - INFO - ================================================================================
2025-03-18 12:53:25,201 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 12:53:25,202 - INFO - Number of participants in dataset: 16
2025-03-18 12:53:25,202 - INFO - ================================================================================
2025-03-18 12:53:25,202 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 12:53:25,202 - INFO - ================================================================================
2025-03-18 12:53:25,202 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 12:53:25,202 - INFO - Subset with 100 trials per participant:
2025-03-18 12:53:25,202 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 12:53:25,202 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 12:53:25,202 - INFO - 
Training RNN...
2025-03-18 12:53:25,203 - INFO - RNN model trainable parameters: 518
2025-03-18 12:53:25,623 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 12:54:08,236 - INFO - Final training loss: 0.3166925
2025-03-18 12:54:08,236 - INFO - 
Fitting SINDy...
2025-03-18 12:54:24,059 - INFO - 
Evaluating SINDy models...
2025-03-18 12:54:24,059 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-18 12:54:24,059 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 12:54:24,060 - INFO - SINDy model parameters for participant 0: 1
2025-03-18 12:54:24,060 - ERROR - Error evaluating participant 0 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,060 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,060 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-18 12:54:24,060 - INFO - SINDy model parameters for participant 1: 2
2025-03-18 12:54:24,060 - ERROR - Error evaluating participant 1 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,061 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,061 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-18 12:54:24,061 - INFO - SINDy model parameters for participant 2: 1
2025-03-18 12:54:24,061 - ERROR - Error evaluating participant 2 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,061 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,061 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-18 12:54:24,061 - INFO - SINDy model parameters for participant 3: 3
2025-03-18 12:54:24,061 - ERROR - Error evaluating participant 3 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,061 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,061 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-18 12:54:24,061 - INFO - SINDy model parameters for participant 4: 2
2025-03-18 12:54:24,061 - ERROR - Error evaluating participant 4 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,062 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,062 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-18 12:54:24,062 - INFO - SINDy model parameters for participant 5: 3
2025-03-18 12:54:24,062 - ERROR - Error evaluating participant 5 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,062 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,062 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-18 12:54:24,062 - INFO - SINDy model parameters for participant 6: 2
2025-03-18 12:54:24,062 - ERROR - Error evaluating participant 6 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,062 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,062 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-18 12:54:24,062 - INFO - SINDy model parameters for participant 7: 2
2025-03-18 12:54:24,063 - ERROR - Error evaluating participant 7 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,063 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,063 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-18 12:54:24,063 - INFO - SINDy model parameters for participant 8: 3
2025-03-18 12:54:24,063 - ERROR - Error evaluating participant 8 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,063 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,063 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-18 12:54:24,063 - INFO - SINDy model parameters for participant 9: 0
2025-03-18 12:54:24,063 - ERROR - Error evaluating participant 9 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,063 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,063 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-18 12:54:24,063 - INFO - SINDy model parameters for participant 10: 1
2025-03-18 12:54:24,063 - ERROR - Error evaluating participant 10 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,064 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,064 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-18 12:54:24,064 - INFO - SINDy model parameters for participant 11: 3
2025-03-18 12:54:24,064 - ERROR - Error evaluating participant 11 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,064 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,064 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-18 12:54:24,064 - INFO - SINDy model parameters for participant 12: 0
2025-03-18 12:54:24,064 - ERROR - Error evaluating participant 12 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,064 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,064 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-18 12:54:24,064 - INFO - SINDy model parameters for participant 13: 2
2025-03-18 12:54:24,064 - ERROR - Error evaluating participant 13 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,065 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,065 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-18 12:54:24,065 - INFO - SINDy model parameters for participant 14: 2
2025-03-18 12:54:24,065 - ERROR - Error evaluating participant 14 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,065 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,065 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-18 12:54:24,065 - INFO - SINDy model parameters for participant 15: 3
2025-03-18 12:54:24,065 - ERROR - Error evaluating participant 15 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:54:24,065 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:54:24,065 - WARNING - Could not compute average SINDy BIC due to errors
2025-03-18 12:54:24,065 - WARNING - Could not compute average Log Likelihood due to errors
2025-03-18 12:54:24,065 - INFO - 
Identified SINDy equations:
2025-03-18 12:54:24,065 - INFO - Module: x_learning_rate_reward
2025-03-18 12:54:24,067 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,067 - INFO -   Participant 0 Coefficients: [ 0.27712132 -1.25999677  0.35849194  0.          1.94554293 -0.26338568
  0.          0.          0.          0.        ]
2025-03-18 12:54:24,068 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,069 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,069 - INFO -   Participant 1 Coefficients: [ 0.15911067  0.31919582  0.50091117 -0.29938316  0.          0.31003186
  0.          0.         -0.54586246  0.30019607]
2025-03-18 12:54:24,069 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,071 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,071 - INFO -   Participant 2 Coefficients: [ 0.92580059 -0.95760338  0.          0.          1.03436583  0.
  0.          0.          0.          0.        ]
2025-03-18 12:54:24,071 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,072 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,072 - INFO -   Participant 3 Coefficients: [  0.99968251  -0.17817922  -0.26837804   0.           0.
   0.65651887   0.           0.           5.57034859 -17.14137869]
2025-03-18 12:54:24,072 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,074 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,074 - INFO -   Participant 4 Coefficients: [0.90479781 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 12:54:24,074 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,075 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,076 - INFO -   Participant 5 Coefficients: [ 0.69485286  0.          0.34280144 -0.18207069  0.24336633  0.
 -0.13514032  0.          0.06559809  0.        ]
2025-03-18 12:54:24,076 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,077 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,077 - INFO -   Participant 6 Coefficients: [ 0.72032019  0.14671453  0.63941721 -0.30956108  0.          0.
  0.          0.         -0.08069863  0.        ]
2025-03-18 12:54:24,077 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,079 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,079 - INFO -   Participant 7 Coefficients: [ 0.86775957  0.09689589  0.55892686 -0.50379835  0.          0.
  0.          0.          0.          0.        ]
2025-03-18 12:54:24,079 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,081 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,081 - INFO -   Participant 8 Coefficients: [0.8817638  0.         0.         0.         0.05889698 0.
 0.         0.         0.         0.        ]
2025-03-18 12:54:24,081 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,082 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,082 - INFO -   Participant 9 Coefficients: [ 0.06697586  1.80815104  0.14676128  0.         -1.62708938  0.36002122
  0.          0.          0.          0.        ]
2025-03-18 12:54:24,082 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,084 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,084 - INFO -   Participant 10 Coefficients: [ 0.7164339   0.18914017  0.16605983  0.          0.         -0.1114346
  0.          0.          0.          0.        ]
2025-03-18 12:54:24,084 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,085 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,086 - INFO -   Participant 11 Coefficients: [ 0.6483072   0.24365925  1.44239912 -1.13621347  0.          0.
  0.          0.         -1.71617719  1.21396142]
2025-03-18 12:54:24,086 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,087 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,087 - INFO -   Participant 12 Coefficients: [ 0.29412203  1.37641306  0.36660898  0.         -0.76998391 -0.3770029
  0.          0.          0.          0.        ]
2025-03-18 12:54:24,087 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,089 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,089 - INFO -   Participant 13 Coefficients: [ 0.22574896  1.16903437  0.38125106  0.         -0.56995015 -0.30231461
  0.          0.          0.          0.        ]
2025-03-18 12:54:24,089 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,090 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,090 - INFO -   Participant 14 Coefficients: [ 0.37413289  1.14385154  0.38135294  0.         -0.58927593 -0.40620504
  0.          0.          0.          0.        ]
2025-03-18 12:54:24,090 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,092 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,092 - INFO -   Participant 15 Coefficients: [0.9129767 0.        0.        0.        0.        0.        0.
 0.        0.        0.       ]
2025-03-18 12:54:24,092 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:54:24,092 - INFO - Module: x_value_reward_not_chosen
2025-03-18 12:54:24,093 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,093 - INFO -   Participant 0 Coefficients: [-1.60118123  0.07198959  0.          0.          0.          0.        ]
2025-03-18 12:54:24,093 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,095 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,095 - INFO -   Participant 1 Coefficients: [0.79151464 0.40777998 0.         0.         0.         0.        ]
2025-03-18 12:54:24,095 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,096 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,096 - INFO -   Participant 2 Coefficients: [-2.92770611  0.58631972  0.          0.          0.          0.        ]
2025-03-18 12:54:24,096 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,097 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,098 - INFO -   Participant 3 Coefficients: [-1.56889744  0.09369627  0.          0.          0.          0.        ]
2025-03-18 12:54:24,098 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,099 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,099 - INFO -   Participant 4 Coefficients: [-1.54633808  0.14902092  0.          0.          0.          0.        ]
2025-03-18 12:54:24,099 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,100 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,100 - INFO -   Participant 5 Coefficients: [-1.08181889  0.44298122  0.          0.          0.          0.        ]
2025-03-18 12:54:24,100 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,102 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,102 - INFO -   Participant 6 Coefficients: [-1.491723    0.31043158  0.          0.          0.          0.        ]
2025-03-18 12:54:24,102 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,103 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,103 - INFO -   Participant 7 Coefficients: [0.94558351 0.22430297 0.         0.         0.         0.        ]
2025-03-18 12:54:24,103 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,104 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,104 - INFO -   Participant 8 Coefficients: [-1.12489764 -0.27957502  0.         -0.26309213  0.          0.        ]
2025-03-18 12:54:24,104 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,106 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,106 - INFO -   Participant 9 Coefficients: [2.30744452 0.66552653 0.         0.         0.         0.        ]
2025-03-18 12:54:24,106 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,107 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,107 - INFO -   Participant 10 Coefficients: [-0.52403984  0.27040371  0.          0.          0.          0.        ]
2025-03-18 12:54:24,107 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,108 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,109 - INFO -   Participant 11 Coefficients: [-1.71291601  0.1750234   0.          0.          0.          0.        ]
2025-03-18 12:54:24,109 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,110 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,110 - INFO -   Participant 12 Coefficients: [0.54608502 0.84094646 0.         0.         0.         0.        ]
2025-03-18 12:54:24,110 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,111 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,111 - INFO -   Participant 13 Coefficients: [0.50215543 0.36478617 0.         0.         0.         0.        ]
2025-03-18 12:54:24,111 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,113 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,113 - INFO -   Participant 14 Coefficients: [0.47792755 0.5927243  0.         0.         0.         0.        ]
2025-03-18 12:54:24,113 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,114 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,114 - INFO -   Participant 15 Coefficients: [-2.00961471  0.08861293  0.          0.          0.          0.        ]
2025-03-18 12:54:24,114 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:54:24,114 - INFO - Module: x_value_choice_chosen
2025-03-18 12:54:24,115 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,115 - INFO -   Participant 0 Coefficients: [0.7725839 0.        0.        0.        0.        0.       ]
2025-03-18 12:54:24,115 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,117 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,117 - INFO -   Participant 1 Coefficients: [0.92140685 0.         0.         0.         0.         0.        ]
2025-03-18 12:54:24,117 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,118 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,118 - INFO -   Participant 2 Coefficients: [0.7385959 0.        0.        0.        0.        0.       ]
2025-03-18 12:54:24,118 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,119 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,119 - INFO -   Participant 3 Coefficients: [0.87569006 0.         0.         0.         0.         0.        ]
2025-03-18 12:54:24,119 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,121 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,121 - INFO -   Participant 4 Coefficients: [0.89281157 0.         0.         0.         0.         0.        ]
2025-03-18 12:54:24,121 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,122 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,122 - INFO -   Participant 5 Coefficients: [0.87167392 0.         0.         0.         0.         0.        ]
2025-03-18 12:54:24,122 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,124 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,124 - INFO -   Participant 6 Coefficients: [0.87052245 0.         0.         0.         0.         0.        ]
2025-03-18 12:54:24,124 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,125 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,125 - INFO -   Participant 7 Coefficients: [0.9724798 0.        0.        0.        0.        0.       ]
2025-03-18 12:54:24,125 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,127 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,127 - INFO -   Participant 8 Coefficients: [0.87497666 0.0592956  0.         0.         0.         0.        ]
2025-03-18 12:54:24,127 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,128 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,128 - INFO -   Participant 9 Coefficients: [0.95771698 0.         0.         0.         0.         0.        ]
2025-03-18 12:54:24,128 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,129 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,129 - INFO -   Participant 10 Coefficients: [0.82530832 0.         0.         0.         0.         0.        ]
2025-03-18 12:54:24,129 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,130 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,131 - INFO -   Participant 11 Coefficients: [0.87061751 0.0514106  0.         0.         0.         0.        ]
2025-03-18 12:54:24,131 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,132 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,132 - INFO -   Participant 12 Coefficients: [0.88268091 0.07454658 0.         0.         0.         0.        ]
2025-03-18 12:54:24,132 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,133 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,133 - INFO -   Participant 13 Coefficients: [0.85495555 0.111283   0.         0.         0.         0.        ]
2025-03-18 12:54:24,133 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,135 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,135 - INFO -   Participant 14 Coefficients: [0.89340154 0.         0.         0.         0.         0.        ]
2025-03-18 12:54:24,135 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,136 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,136 - INFO -   Participant 15 Coefficients: [0.85705316 0.06589959 0.         0.         0.         0.        ]
2025-03-18 12:54:24,136 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:54:24,136 - INFO - Module: x_value_choice_not_chosen
2025-03-18 12:54:24,137 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,137 - INFO -   Participant 0 Coefficients: [0.55216533 0.         0.         0.         0.         0.        ]
2025-03-18 12:54:24,138 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,139 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,139 - INFO -   Participant 1 Coefficients: [ 0.33345211 -0.09381794  0.          0.          0.          0.        ]
2025-03-18 12:54:24,139 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,140 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,140 - INFO -   Participant 2 Coefficients: [0.92555404 0.         0.         0.         0.         0.        ]
2025-03-18 12:54:24,140 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,142 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,142 - INFO -   Participant 3 Coefficients: [ 0.74018778 -0.54170783  0.          0.10533214  0.          0.        ]
2025-03-18 12:54:24,142 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,143 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,143 - INFO -   Participant 4 Coefficients: [ 0.62101858 -0.15314399  0.          0.          0.          0.        ]
2025-03-18 12:54:24,143 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,144 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,144 - INFO -   Participant 5 Coefficients: [ 0.61968634 -0.48985603  0.          0.10132519  0.          0.        ]
2025-03-18 12:54:24,144 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,146 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,146 - INFO -   Participant 6 Coefficients: [ 0.65992197 -0.22007956  0.          0.          0.          0.        ]
2025-03-18 12:54:24,146 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,147 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,147 - INFO -   Participant 7 Coefficients: [ 0.29451518 -0.05567262  0.          0.          0.          0.        ]
2025-03-18 12:54:24,147 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,148 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,148 - INFO -   Participant 8 Coefficients: [ 0.75204348 -0.57989216  0.          0.12007304  0.          0.        ]
2025-03-18 12:54:24,148 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,150 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,150 - INFO -   Participant 9 Coefficients: [0. 0. 0. 0. 0. 0.]
2025-03-18 12:54:24,150 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,151 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,151 - INFO -   Participant 10 Coefficients: [0.20003881 0.         0.         0.         0.         0.        ]
2025-03-18 12:54:24,151 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,153 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,153 - INFO -   Participant 11 Coefficients: [ 0.77040908 -0.57348099  0.          0.11600855  0.          0.        ]
2025-03-18 12:54:24,153 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,154 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,154 - INFO -   Participant 12 Coefficients: [0. 0. 0. 0. 0. 0.]
2025-03-18 12:54:24,154 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,155 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,156 - INFO -   Participant 13 Coefficients: [ 0.14325852 -0.17584616  0.          0.          0.          0.        ]
2025-03-18 12:54:24,156 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,157 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,157 - INFO -   Participant 14 Coefficients: [ 0.12569559 -0.05136569  0.          0.          0.          0.        ]
2025-03-18 12:54:24,157 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,158 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:54:24,158 - INFO -   Participant 15 Coefficients: [ 0.70477751 -0.58144064  0.          0.13242106  0.          0.        ]
2025-03-18 12:54:24,158 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:54:24,160 - INFO - Creating dataset subset with 200 trials per participant
2025-03-18 12:54:24,160 - INFO - Subset with 200 trials per participant:
2025-03-18 12:54:24,160 - INFO -   Dataset shape: torch.Size([16, 200, 5])
2025-03-18 12:54:24,160 - INFO - 
==== Running pipeline for dataset: 200 trials per participant ====
2025-03-18 12:54:24,160 - INFO - 
Training RNN...
2025-03-18 12:54:24,161 - INFO - RNN model trainable parameters: 518
2025-03-18 12:54:24,161 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 12:55:53,426 - INFO - Final training loss: 0.3255879
2025-03-18 12:55:53,427 - INFO - 
Fitting SINDy...
2025-03-18 12:56:09,705 - INFO - 
Evaluating SINDy models...
2025-03-18 12:56:09,705 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-18 12:56:09,705 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 12:56:09,706 - INFO - SINDy model parameters for participant 0: 1
2025-03-18 12:56:09,706 - ERROR - Error evaluating participant 0 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,706 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,706 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-18 12:56:09,706 - INFO - SINDy model parameters for participant 1: 1
2025-03-18 12:56:09,706 - ERROR - Error evaluating participant 1 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,706 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,706 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-18 12:56:09,707 - INFO - SINDy model parameters for participant 2: 1
2025-03-18 12:56:09,707 - ERROR - Error evaluating participant 2 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,707 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,707 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-18 12:56:09,707 - INFO - SINDy model parameters for participant 3: 2
2025-03-18 12:56:09,707 - ERROR - Error evaluating participant 3 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,707 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,707 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-18 12:56:09,707 - INFO - SINDy model parameters for participant 4: 1
2025-03-18 12:56:09,707 - ERROR - Error evaluating participant 4 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,707 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,707 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-18 12:56:09,708 - INFO - SINDy model parameters for participant 5: 1
2025-03-18 12:56:09,708 - ERROR - Error evaluating participant 5 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,708 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,708 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-18 12:56:09,708 - INFO - SINDy model parameters for participant 6: 2
2025-03-18 12:56:09,708 - ERROR - Error evaluating participant 6 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,708 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,708 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-18 12:56:09,708 - INFO - SINDy model parameters for participant 7: 2
2025-03-18 12:56:09,708 - ERROR - Error evaluating participant 7 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,708 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,708 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-18 12:56:09,708 - INFO - SINDy model parameters for participant 8: 1
2025-03-18 12:56:09,708 - ERROR - Error evaluating participant 8 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,709 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,709 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-18 12:56:09,709 - INFO - SINDy model parameters for participant 9: 1
2025-03-18 12:56:09,709 - ERROR - Error evaluating participant 9 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,709 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,709 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-18 12:56:09,709 - INFO - SINDy model parameters for participant 10: 1
2025-03-18 12:56:09,709 - ERROR - Error evaluating participant 10 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,709 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,709 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-18 12:56:09,709 - INFO - SINDy model parameters for participant 11: 1
2025-03-18 12:56:09,709 - ERROR - Error evaluating participant 11 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,709 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,710 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-18 12:56:09,710 - INFO - SINDy model parameters for participant 12: 1
2025-03-18 12:56:09,710 - ERROR - Error evaluating participant 12 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,710 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,710 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-18 12:56:09,710 - INFO - SINDy model parameters for participant 13: 1
2025-03-18 12:56:09,710 - ERROR - Error evaluating participant 13 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,710 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,710 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-18 12:56:09,710 - INFO - SINDy model parameters for participant 14: 1
2025-03-18 12:56:09,710 - ERROR - Error evaluating participant 14 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,710 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,710 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-18 12:56:09,710 - INFO - SINDy model parameters for participant 15: 2
2025-03-18 12:56:09,710 - ERROR - Error evaluating participant 15 with SINDy model: only length-1 arrays can be converted to Python scalars
2025-03-18 12:56:09,711 - ERROR - Traceback: Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/utils/trials_impact_fixed.py", line 224, in run_training_and_evaluation
    values, probs, agent_sindy = get_update_dynamics(xs_participant, agent_sindy)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/bandits.py", line 846, in get_update_dynamics
    participant_id = int(experiment[0, -1])
                     ^^^^^^^^^^^^^^^^^^^^^^
TypeError: only length-1 arrays can be converted to Python scalars

2025-03-18 12:56:09,711 - WARNING - Could not compute average SINDy BIC due to errors
2025-03-18 12:56:09,711 - WARNING - Could not compute average Log Likelihood due to errors
2025-03-18 12:56:09,711 - INFO - 
Identified SINDy equations:
2025-03-18 12:56:09,711 - INFO - Module: x_learning_rate_reward
2025-03-18 12:56:09,712 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,712 - INFO -   Participant 0 Coefficients: [0.99166044 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 12:56:09,712 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,714 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,714 - INFO -   Participant 1 Coefficients: [ 0.67956984  0.44669356  0.11003229  1.04703819 -0.13817686 -0.29236363
  0.          0.         -0.95437106  0.59681551]
2025-03-18 12:56:09,714 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,715 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,715 - INFO -   Participant 2 Coefficients: [ 8.40303999e-01  4.12405462e-01  0.00000000e+00  3.98184639e+00
 -2.59210113e-01 -2.36970515e+01  5.68484204e+02  0.00000000e+00
 -9.56879337e-01  7.77413916e+00]
2025-03-18 12:56:09,716 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,717 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,717 - INFO -   Participant 3 Coefficients: [ 0.3665878   0.8177238   0.3402082   0.60291251 -0.21269892 -2.02111588
  4.29074818  0.          0.          0.31154896]
2025-03-18 12:56:09,717 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,718 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,719 - INFO -   Participant 4 Coefficients: [ 0.09813207  1.36470695  0.56716562  0.         -0.58305811 -0.48090795
  0.          0.          0.          0.        ]
2025-03-18 12:56:09,719 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,720 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,720 - INFO -   Participant 5 Coefficients: [ 0.37755938  1.67065104  0.36935444  0.         -1.05781563 -0.41571962
  0.          0.          0.          0.        ]
2025-03-18 12:56:09,720 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,722 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,722 - INFO -   Participant 6 Coefficients: [ 0.14386405  1.85783604  0.48126327  0.         -1.03155703 -0.51091367
  0.          0.          0.          0.        ]
2025-03-18 12:56:09,722 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,723 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,723 - INFO -   Participant 7 Coefficients: [ 0.50261455  1.12135065  0.43367568  0.         -0.63686615 -0.45799388
  0.          0.          0.          0.        ]
2025-03-18 12:56:09,723 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,725 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,725 - INFO -   Participant 8 Coefficients: [ 0.28718402  1.92289129  0.530103    0.         -1.23553399 -0.57332196
  0.          0.          0.          0.        ]
2025-03-18 12:56:09,725 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,726 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,727 - INFO -   Participant 9 Coefficients: [0.74436816 0.17448284 0.         0.         0.         0.
 0.         0.         0.05944721 0.        ]
2025-03-18 12:56:09,727 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,728 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,728 - INFO -   Participant 10 Coefficients: [ 0.1923126   0.76398187  0.45391034  0.20875781  0.         -1.32271545
  0.66240702  0.          0.          0.12800056]
2025-03-18 12:56:09,728 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,730 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,730 - INFO -   Participant 11 Coefficients: [ 0.1993733   1.87759851  0.45458552  0.         -1.11246723 -0.48895023
  0.          0.          0.          0.        ]
2025-03-18 12:56:09,730 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,731 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,731 - INFO -   Participant 12 Coefficients: [ 0.46183999  0.88137479  0.49097162  0.         -0.35731077 -0.51336501
  0.          0.          0.          0.        ]
2025-03-18 12:56:09,731 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,733 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,733 - INFO -   Participant 13 Coefficients: [ 0.34860051  0.62231575  0.59543546  0.          0.         -0.58236087
  0.          0.          0.          0.        ]
2025-03-18 12:56:09,733 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,734 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,734 - INFO -   Participant 14 Coefficients: [ 0.79851801  0.17519457  0.          4.3190157   0.         -3.12466314
 13.25775599  0.         -5.27021354  9.00054179]
2025-03-18 12:56:09,735 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,736 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,736 - INFO -   Participant 15 Coefficients: [ 0.          0.6792683   0.19503969  0.         -0.67389402  0.72899705
  0.          0.          0.          0.        ]
2025-03-18 12:56:09,736 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 12:56:09,736 - INFO - Module: x_value_reward_not_chosen
2025-03-18 12:56:09,737 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,737 - INFO -   Participant 0 Coefficients: [-2.97543788 -0.34682985  0.          0.          0.          0.        ]
2025-03-18 12:56:09,737 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,739 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,739 - INFO -   Participant 1 Coefficients: [-2.29539161 -0.80980934  0.         -0.14268344  0.          0.        ]
2025-03-18 12:56:09,739 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,740 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,740 - INFO -   Participant 2 Coefficients: [-3.45893935  0.48687383  0.          0.          0.          0.        ]
2025-03-18 12:56:09,740 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,741 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,742 - INFO -   Participant 3 Coefficients: [-2.26737745  0.90471958  0.          0.38362725  0.          0.        ]
2025-03-18 12:56:09,742 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,743 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,743 - INFO -   Participant 4 Coefficients: [-1.39011679  0.61877495  0.          0.          0.          0.        ]
2025-03-18 12:56:09,743 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,744 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,744 - INFO -   Participant 5 Coefficients: [-3.63175946  0.44285907  0.          0.          0.          0.        ]
2025-03-18 12:56:09,744 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,745 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,745 - INFO -   Participant 6 Coefficients: [-3.36963331 -0.2546096   0.         -0.10673126  0.          0.        ]
2025-03-18 12:56:09,745 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,747 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,747 - INFO -   Participant 7 Coefficients: [-1.4811872   0.40812057  0.          0.          0.          0.        ]
2025-03-18 12:56:09,747 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,748 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,748 - INFO -   Participant 8 Coefficients: [-3.39332983 -1.19474645  0.         -0.25055971  0.          0.        ]
2025-03-18 12:56:09,748 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,749 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,749 - INFO -   Participant 9 Coefficients: [2.27819944 0.07090174 0.         0.         0.         0.        ]
2025-03-18 12:56:09,749 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,751 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,751 - INFO -   Participant 10 Coefficients: [-0.92536462  0.36687357  0.          0.48278034  0.          0.        ]
2025-03-18 12:56:09,751 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,752 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,752 - INFO -   Participant 11 Coefficients: [-3.94301877 -0.92940597  0.         -0.18651582  0.          0.        ]
2025-03-18 12:56:09,752 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,753 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,753 - INFO -   Participant 12 Coefficients: [0.09427181 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,753 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,755 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,755 - INFO -   Participant 13 Coefficients: [0.56081013 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,755 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,757 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,757 - INFO -   Participant 14 Coefficients: [-1.44717329 -0.29992604  0.          0.          0.          0.        ]
2025-03-18 12:56:09,757 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,758 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,758 - INFO -   Participant 15 Coefficients: [-3.8873733  -0.6609222   0.         -0.14457793  0.          0.        ]
2025-03-18 12:56:09,758 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 12:56:09,758 - INFO - Module: x_value_choice_chosen
2025-03-18 12:56:09,759 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,759 - INFO -   Participant 0 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,759 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,761 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,761 - INFO -   Participant 1 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,761 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,762 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,762 - INFO -   Participant 2 Coefficients: [0.55376197 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,762 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,763 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,763 - INFO -   Participant 3 Coefficients: [0.56210657 0.22018261 0.         0.         0.         0.        ]
2025-03-18 12:56:09,763 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,764 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,764 - INFO -   Participant 4 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,764 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,766 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,766 - INFO -   Participant 5 Coefficients: [0.55376208 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,766 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,767 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,767 - INFO -   Participant 6 Coefficients: [0.58749934 0.1515992  0.         0.         0.         0.        ]
2025-03-18 12:56:09,767 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,768 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,768 - INFO -   Participant 7 Coefficients: [0.56037723 0.22177218 0.         0.         0.         0.        ]
2025-03-18 12:56:09,768 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,769 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,769 - INFO -   Participant 8 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,769 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,771 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,771 - INFO -   Participant 9 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,771 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,772 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,772 - INFO -   Participant 10 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,772 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,773 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,774 - INFO -   Participant 11 Coefficients: [0.55849433 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,774 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,775 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,775 - INFO -   Participant 12 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,775 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,776 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,776 - INFO -   Participant 13 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,776 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,777 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,777 - INFO -   Participant 14 Coefficients: [0.56311333 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,777 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,779 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,779 - INFO -   Participant 15 Coefficients: [0.55310953 0.24282566 0.         0.         0.         0.        ]
2025-03-18 12:56:09,779 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 12:56:09,779 - INFO - Module: x_value_choice_not_chosen
2025-03-18 12:56:09,780 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,780 - INFO -   Participant 0 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,780 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,781 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,781 - INFO -   Participant 1 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,781 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,782 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,783 - INFO -   Participant 2 Coefficients: [0.28236774 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,783 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,784 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,784 - INFO -   Participant 3 Coefficients: [0.27053916 0.24434069 0.         0.         0.         0.        ]
2025-03-18 12:56:09,784 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,785 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,785 - INFO -   Participant 4 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,785 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,786 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,786 - INFO -   Participant 5 Coefficients: [0.28236781 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,787 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,788 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,788 - INFO -   Participant 6 Coefficients: [0.29692178 0.20782833 0.         0.         0.         0.        ]
2025-03-18 12:56:09,788 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,789 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,789 - INFO -   Participant 7 Coefficients: [0.36097302 0.         0.         0.16260052 0.         0.        ]
2025-03-18 12:56:09,789 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,790 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,790 - INFO -   Participant 8 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,791 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,792 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,792 - INFO -   Participant 9 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,792 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,793 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,793 - INFO -   Participant 10 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,793 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,794 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,794 - INFO -   Participant 11 Coefficients: [0.28623112 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,794 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,796 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,796 - INFO -   Participant 12 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,796 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,797 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,797 - INFO -   Participant 13 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,797 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,798 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,798 - INFO -   Participant 14 Coefficients: [0.29004034 0.         0.         0.         0.         0.        ]
2025-03-18 12:56:09,798 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 12:56:09,799 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 12:56:09,800 - INFO -   Participant 15 Coefficients: [0.28099002 0.21325301 0.         0.         0.         0.        ]
2025-03-18 12:56:09,800 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 13:42:13,294 - INFO - ================================================================================
2025-03-18 13:42:13,294 - INFO - EXPERIMENT CONFIG
2025-03-18 13:42:13,294 - INFO - ================================================================================
2025-03-18 13:42:13,294 - INFO - Number of actions: 2
2025-03-18 13:42:13,302 - INFO - Number of participants: 16
2025-03-18 13:42:13,302 - INFO - ================================================================================
2025-03-18 13:42:13,302 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 13:42:13,302 - INFO - ================================================================================
2025-03-18 13:42:13,473 - INFO - ================================================================================
2025-03-18 13:42:13,473 - INFO - COMBINED DATASET INFORMATION
2025-03-18 13:42:13,473 - INFO - ================================================================================
2025-03-18 13:42:13,473 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 13:42:13,473 - INFO - Number of participants in dataset: 16
2025-03-18 13:42:13,473 - INFO - ================================================================================
2025-03-18 13:42:13,473 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 13:42:13,473 - INFO - ================================================================================
2025-03-18 13:42:13,473 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 13:42:13,474 - INFO - Subset with 100 trials per participant:
2025-03-18 13:42:13,474 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 13:42:13,474 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 13:42:13,474 - INFO - 
Training RNN...
2025-03-18 13:42:13,476 - INFO - RNN model trainable parameters: 518
2025-03-18 13:42:14,341 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 13:43:06,352 - INFO - Final training loss: 0.3166925
2025-03-18 13:43:06,353 - INFO - 
Fitting SINDy...
2025-03-18 13:43:35,281 - INFO - 
Evaluating SINDy models...
2025-03-18 13:43:35,281 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-18 13:43:35,281 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 13:43:35,281 - INFO - SINDy model parameters for participant 0: 1
2025-03-18 14:19:04,071 - INFO - ================================================================================
2025-03-18 14:19:04,071 - INFO - EXPERIMENT CONFIG
2025-03-18 14:19:04,071 - INFO - ================================================================================
2025-03-18 14:19:04,071 - INFO - Number of actions: 2
2025-03-18 14:19:04,078 - INFO - Number of participants: 16
2025-03-18 14:19:04,078 - INFO - ================================================================================
2025-03-18 14:19:04,078 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 14:19:04,078 - INFO - ================================================================================
2025-03-18 14:19:04,169 - INFO - ================================================================================
2025-03-18 14:19:04,169 - INFO - COMBINED DATASET INFORMATION
2025-03-18 14:19:04,169 - INFO - ================================================================================
2025-03-18 14:19:04,169 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 14:19:04,169 - INFO - Number of participants in dataset: 16
2025-03-18 14:19:04,169 - INFO - ================================================================================
2025-03-18 14:19:04,169 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 14:19:04,169 - INFO - ================================================================================
2025-03-18 14:19:04,169 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 14:19:04,170 - INFO - Subset with 100 trials per participant:
2025-03-18 14:19:04,170 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 14:19:04,170 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 14:19:04,170 - INFO - 
Training RNN...
2025-03-18 14:19:04,171 - INFO - RNN model trainable parameters: 518
2025-03-18 14:19:04,632 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 14:19:48,945 - INFO - Final training loss: 0.3166925
2025-03-18 14:19:48,946 - INFO - 
Fitting SINDy...
2025-03-18 14:20:04,649 - INFO - 
Evaluating SINDy models...
2025-03-18 14:20:04,649 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-18 14:20:04,649 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 14:20:04,649 - INFO - SINDy model parameters for participant 0: 1
2025-03-18 14:20:45,895 - INFO - ================================================================================
2025-03-18 14:20:45,895 - INFO - EXPERIMENT CONFIG
2025-03-18 14:20:45,895 - INFO - ================================================================================
2025-03-18 14:20:45,895 - INFO - Number of actions: 2
2025-03-18 14:20:45,901 - INFO - Number of participants: 16
2025-03-18 14:20:45,902 - INFO - ================================================================================
2025-03-18 14:20:45,902 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 14:20:45,902 - INFO - ================================================================================
2025-03-18 14:20:45,987 - INFO - ================================================================================
2025-03-18 14:20:45,987 - INFO - COMBINED DATASET INFORMATION
2025-03-18 14:20:45,987 - INFO - ================================================================================
2025-03-18 14:20:45,987 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 14:20:45,987 - INFO - Number of participants in dataset: 16
2025-03-18 14:20:45,987 - INFO - ================================================================================
2025-03-18 14:20:45,987 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 14:20:45,987 - INFO - ================================================================================
2025-03-18 14:20:45,987 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 14:20:45,988 - INFO - Subset with 100 trials per participant:
2025-03-18 14:20:45,988 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 14:20:45,988 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 14:20:45,988 - INFO - 
Training RNN...
2025-03-18 14:20:45,989 - INFO - RNN model trainable parameters: 518
2025-03-18 14:20:46,446 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 14:21:29,566 - INFO - Final training loss: 0.3166925
2025-03-18 14:21:29,566 - INFO - 
Fitting SINDy...
2025-03-18 14:21:45,079 - INFO - 
Evaluating SINDy models...
2025-03-18 14:21:45,079 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-18 14:21:45,079 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 14:21:45,080 - INFO - SINDy model parameters for participant 0: 1
2025-03-18 14:21:45,353 - INFO - Participant 0: Log-likelihood: -47.1440, Normalized LL: -0.4714, Raw BIC: 98.8932, Normalized BIC: 0.9889
2025-03-18 14:21:45,353 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-18 14:21:45,354 - INFO - SINDy model parameters for participant 1: 2
2025-03-18 14:21:45,632 - INFO - Participant 1: Log-likelihood: -40.5718, Normalized LL: -0.4057, Raw BIC: 90.3539, Normalized BIC: 0.9035
2025-03-18 14:21:45,632 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-18 14:21:45,632 - INFO - SINDy model parameters for participant 2: 1
2025-03-18 14:21:45,902 - INFO - Participant 2: Log-likelihood: -2.8515, Normalized LL: -0.0285, Raw BIC: 10.3082, Normalized BIC: 0.1031
2025-03-18 14:21:45,902 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-18 14:21:45,902 - INFO - SINDy model parameters for participant 3: 3
2025-03-18 14:22:19,088 - INFO - ================================================================================
2025-03-18 14:22:19,089 - INFO - EXPERIMENT CONFIG
2025-03-18 14:22:19,089 - INFO - ================================================================================
2025-03-18 14:22:19,089 - INFO - Number of actions: 2
2025-03-18 14:22:19,097 - INFO - Number of participants: 16
2025-03-18 14:22:19,097 - INFO - ================================================================================
2025-03-18 14:22:19,097 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 14:22:19,097 - INFO - ================================================================================
2025-03-18 14:22:19,270 - INFO - ================================================================================
2025-03-18 14:22:19,270 - INFO - COMBINED DATASET INFORMATION
2025-03-18 14:22:19,270 - INFO - ================================================================================
2025-03-18 14:22:19,270 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 14:22:19,271 - INFO - Number of participants in dataset: 16
2025-03-18 14:22:19,271 - INFO - ================================================================================
2025-03-18 14:22:19,271 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 14:22:19,271 - INFO - ================================================================================
2025-03-18 14:22:19,271 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 14:22:19,272 - INFO - Subset with 100 trials per participant:
2025-03-18 14:22:19,272 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 14:22:19,272 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 14:22:19,272 - INFO - 
Training RNN...
2025-03-18 14:22:19,274 - INFO - RNN model trainable parameters: 518
2025-03-18 14:22:20,130 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 14:23:10,699 - INFO - Final training loss: 0.3166925
2025-03-18 14:23:10,700 - INFO - 
Fitting SINDy...
2025-03-18 14:23:38,373 - INFO - 
Evaluating SINDy models...
2025-03-18 14:23:38,373 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-18 14:23:38,373 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 14:23:38,373 - INFO - SINDy model parameters for participant 0: 1
2025-03-18 14:23:38,935 - INFO - Participant 0: Log-likelihood: -47.1440, Normalized LL: -0.4714, Raw BIC: 98.8932, Normalized BIC: 0.9889
2025-03-18 14:23:38,935 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-18 14:23:38,936 - INFO - SINDy model parameters for participant 1: 2
2025-03-18 14:23:39,500 - INFO - Participant 1: Log-likelihood: -40.5718, Normalized LL: -0.4057, Raw BIC: 90.3539, Normalized BIC: 0.9035
2025-03-18 14:23:39,500 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-18 14:23:39,500 - INFO - SINDy model parameters for participant 2: 1
2025-03-18 14:23:40,064 - INFO - Participant 2: Log-likelihood: -2.8515, Normalized LL: -0.0285, Raw BIC: 10.3082, Normalized BIC: 0.1031
2025-03-18 14:23:40,064 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-18 14:23:40,065 - INFO - SINDy model parameters for participant 3: 3
2025-03-18 14:30:10,564 - INFO - ================================================================================
2025-03-18 14:30:10,564 - INFO - EXPERIMENT CONFIG
2025-03-18 14:30:10,564 - INFO - ================================================================================
2025-03-18 14:30:10,564 - INFO - Number of actions: 2
2025-03-18 14:30:10,570 - INFO - Number of participants: 16
2025-03-18 14:30:10,570 - INFO - ================================================================================
2025-03-18 14:30:10,570 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 14:30:10,570 - INFO - ================================================================================
2025-03-18 14:30:10,658 - INFO - ================================================================================
2025-03-18 14:30:10,658 - INFO - COMBINED DATASET INFORMATION
2025-03-18 14:30:10,658 - INFO - ================================================================================
2025-03-18 14:30:10,658 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 14:30:10,658 - INFO - Number of participants in dataset: 16
2025-03-18 14:30:10,658 - INFO - ================================================================================
2025-03-18 14:30:10,658 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 14:30:10,658 - INFO - ================================================================================
2025-03-18 14:30:10,658 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 14:30:10,659 - INFO - Subset with 100 trials per participant:
2025-03-18 14:30:10,659 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 14:30:10,659 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 14:30:10,659 - INFO - 
Training RNN...
2025-03-18 14:30:10,660 - INFO - RNN model trainable parameters: 518
2025-03-18 14:30:11,124 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 14:30:58,326 - INFO - Final training loss: 0.3166925
2025-03-18 14:30:58,327 - INFO - 
Fitting SINDy...
2025-03-18 14:31:14,341 - INFO - 
Evaluating SINDy models...
2025-03-18 14:31:14,341 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-18 14:31:14,341 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 14:31:14,342 - INFO - SINDy model parameters for participant 0: 1
2025-03-18 14:31:14,615 - INFO - Participant 0: Log-likelihood: -47.1440, Normalized LL: -0.4714, Raw BIC: 98.8932, Normalized BIC: 0.9889
2025-03-18 14:31:14,615 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-18 14:31:14,615 - INFO - SINDy model parameters for participant 1: 2
2025-03-18 14:31:14,889 - INFO - Participant 1: Log-likelihood: -40.5718, Normalized LL: -0.4057, Raw BIC: 90.3539, Normalized BIC: 0.9035
2025-03-18 14:31:14,890 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-18 14:31:14,890 - INFO - SINDy model parameters for participant 2: 1
2025-03-18 14:31:15,165 - INFO - Participant 2: Log-likelihood: -2.8515, Normalized LL: -0.0285, Raw BIC: 10.3082, Normalized BIC: 0.1031
2025-03-18 14:31:15,165 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-18 14:31:15,165 - INFO - SINDy model parameters for participant 3: 3
2025-03-18 14:31:15,447 - INFO - Participant 3: Log-likelihood: -3130.9634, Normalized LL: -31.3096, Raw BIC: 6275.7424, Normalized BIC: 62.7574
2025-03-18 14:31:15,448 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-18 14:31:15,448 - INFO - SINDy model parameters for participant 4: 2
2025-03-18 14:31:15,745 - INFO - Participant 4: Log-likelihood: -12.4799, Normalized LL: -0.1248, Raw BIC: 34.1702, Normalized BIC: 0.3417
2025-03-18 14:31:15,745 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-18 14:31:15,745 - INFO - SINDy model parameters for participant 5: 3
2025-03-18 14:31:16,060 - INFO - Participant 5: Log-likelihood: nan, Normalized LL: nan, Raw BIC: nan, Normalized BIC: nan
2025-03-18 14:31:16,060 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-18 14:31:16,060 - INFO - SINDy model parameters for participant 6: 2
2025-03-18 14:31:16,351 - INFO - Participant 6: Log-likelihood: nan, Normalized LL: nan, Raw BIC: nan, Normalized BIC: nan
2025-03-18 14:31:16,351 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-18 14:31:16,352 - INFO - SINDy model parameters for participant 7: 2
2025-03-18 14:31:16,643 - INFO - Participant 7: Log-likelihood: nan, Normalized LL: nan, Raw BIC: nan, Normalized BIC: nan
2025-03-18 14:31:16,643 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-18 14:31:16,643 - INFO - SINDy model parameters for participant 8: 3
2025-03-18 14:31:16,922 - INFO - Participant 8: Log-likelihood: -37.6847, Normalized LL: -0.3768, Raw BIC: 89.1849, Normalized BIC: 0.8918
2025-03-18 14:31:16,922 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-18 14:31:16,923 - INFO - SINDy model parameters for participant 9: 0
2025-03-18 14:31:17,198 - INFO - Participant 9: Log-likelihood: -60.8187, Normalized LL: -0.6082, Raw BIC: 121.6374, Normalized BIC: 1.2164
2025-03-18 14:31:17,198 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-18 14:31:17,198 - INFO - SINDy model parameters for participant 10: 1
2025-03-18 14:31:17,477 - INFO - Participant 10: Log-likelihood: -63.8813, Normalized LL: -0.6388, Raw BIC: 132.3678, Normalized BIC: 1.3237
2025-03-18 14:31:17,477 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-18 14:31:17,478 - INFO - SINDy model parameters for participant 11: 3
2025-03-18 14:31:17,752 - INFO - Participant 11: Log-likelihood: -954.4860, Normalized LL: -9.5449, Raw BIC: 1922.7875, Normalized BIC: 19.2279
2025-03-18 14:31:17,753 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-18 14:31:17,753 - INFO - SINDy model parameters for participant 12: 0
2025-03-18 14:31:18,030 - INFO - Participant 12: Log-likelihood: -67.8096, Normalized LL: -0.6781, Raw BIC: 135.6192, Normalized BIC: 1.3562
2025-03-18 14:31:18,030 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-18 14:31:18,030 - INFO - SINDy model parameters for participant 13: 2
2025-03-18 14:31:18,317 - INFO - Participant 13: Log-likelihood: -67.1318, Normalized LL: -0.6713, Raw BIC: 143.4739, Normalized BIC: 1.4347
2025-03-18 14:31:18,317 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-18 14:31:18,317 - INFO - SINDy model parameters for participant 14: 2
2025-03-18 14:31:18,594 - INFO - Participant 14: Log-likelihood: -51.0545, Normalized LL: -0.5105, Raw BIC: 111.3194, Normalized BIC: 1.1132
2025-03-18 14:31:18,594 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-18 14:31:18,594 - INFO - SINDy model parameters for participant 15: 3
2025-03-18 14:31:18,900 - INFO - Participant 15: Log-likelihood: -16.8531, Normalized LL: -0.1685, Raw BIC: 47.5218, Normalized BIC: 0.4752
2025-03-18 14:31:18,901 - INFO - 
Average SINDy BIC for 100 trials per participant: nan
2025-03-18 14:31:18,901 - INFO - 
Average Normalized Log Likelihood for 100 trials per participant: nan
2025-03-18 14:31:18,901 - INFO - 
Identified SINDy equations:
2025-03-18 14:31:18,901 - INFO - Module: x_learning_rate_reward
2025-03-18 14:31:18,903 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,903 - INFO -   Participant 0 Coefficients: [ 0.27712132 -1.25999677  0.35849194  0.          1.94554293 -0.26338568
  0.          0.          0.          0.        ]
2025-03-18 14:31:18,903 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,904 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,904 - INFO -   Participant 1 Coefficients: [ 0.15911067  0.31919582  0.50091117 -0.29938316  0.          0.31003186
  0.          0.         -0.54586246  0.30019607]
2025-03-18 14:31:18,904 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,906 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,906 - INFO -   Participant 2 Coefficients: [ 0.92580059 -0.95760338  0.          0.          1.03436583  0.
  0.          0.          0.          0.        ]
2025-03-18 14:31:18,906 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,908 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,908 - INFO -   Participant 3 Coefficients: [  0.99968251  -0.17817922  -0.26837804   0.           0.
   0.65651887   0.           0.           5.57034859 -17.14137869]
2025-03-18 14:31:18,908 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,909 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,909 - INFO -   Participant 4 Coefficients: [0.90479781 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 14:31:18,909 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,911 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,911 - INFO -   Participant 5 Coefficients: [ 0.69485286  0.          0.34280144 -0.18207069  0.24336633  0.
 -0.13514032  0.          0.06559809  0.        ]
2025-03-18 14:31:18,911 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,913 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,913 - INFO -   Participant 6 Coefficients: [ 0.72032019  0.14671453  0.63941721 -0.30956108  0.          0.
  0.          0.         -0.08069863  0.        ]
2025-03-18 14:31:18,913 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,914 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,914 - INFO -   Participant 7 Coefficients: [ 0.86775957  0.09689589  0.55892686 -0.50379835  0.          0.
  0.          0.          0.          0.        ]
2025-03-18 14:31:18,914 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,916 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,916 - INFO -   Participant 8 Coefficients: [0.8817638  0.         0.         0.         0.05889698 0.
 0.         0.         0.         0.        ]
2025-03-18 14:31:18,916 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,917 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,917 - INFO -   Participant 9 Coefficients: [ 0.06697586  1.80815104  0.14676128  0.         -1.62708938  0.36002122
  0.          0.          0.          0.        ]
2025-03-18 14:31:18,918 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,919 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,919 - INFO -   Participant 10 Coefficients: [ 0.7164339   0.18914017  0.16605983  0.          0.         -0.1114346
  0.          0.          0.          0.        ]
2025-03-18 14:31:18,919 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,921 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,921 - INFO -   Participant 11 Coefficients: [ 0.6483072   0.24365925  1.44239912 -1.13621347  0.          0.
  0.          0.         -1.71617719  1.21396142]
2025-03-18 14:31:18,921 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,922 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,922 - INFO -   Participant 12 Coefficients: [ 0.29412203  1.37641306  0.36660898  0.         -0.76998391 -0.3770029
  0.          0.          0.          0.        ]
2025-03-18 14:31:18,922 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,924 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,924 - INFO -   Participant 13 Coefficients: [ 0.22574896  1.16903437  0.38125106  0.         -0.56995015 -0.30231461
  0.          0.          0.          0.        ]
2025-03-18 14:31:18,924 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,926 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,926 - INFO -   Participant 14 Coefficients: [ 0.37413289  1.14385154  0.38135294  0.         -0.58927593 -0.40620504
  0.          0.          0.          0.        ]
2025-03-18 14:31:18,926 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,927 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,927 - INFO -   Participant 15 Coefficients: [0.9129767 0.        0.        0.        0.        0.        0.
 0.        0.        0.       ]
2025-03-18 14:31:18,927 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:31:18,927 - INFO - Module: x_value_reward_not_chosen
2025-03-18 14:31:18,929 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,929 - INFO -   Participant 0 Coefficients: [-1.60118123  0.07198959  0.          0.          0.          0.        ]
2025-03-18 14:31:18,929 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,930 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,930 - INFO -   Participant 1 Coefficients: [0.79151464 0.40777998 0.         0.         0.         0.        ]
2025-03-18 14:31:18,930 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,931 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,931 - INFO -   Participant 2 Coefficients: [-2.92770611  0.58631972  0.          0.          0.          0.        ]
2025-03-18 14:31:18,931 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,933 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,933 - INFO -   Participant 3 Coefficients: [-1.56889744  0.09369627  0.          0.          0.          0.        ]
2025-03-18 14:31:18,933 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,934 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,934 - INFO -   Participant 4 Coefficients: [-1.54633808  0.14902092  0.          0.          0.          0.        ]
2025-03-18 14:31:18,934 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,935 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,936 - INFO -   Participant 5 Coefficients: [-1.08181889  0.44298122  0.          0.          0.          0.        ]
2025-03-18 14:31:18,936 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,937 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,937 - INFO -   Participant 6 Coefficients: [-1.491723    0.31043158  0.          0.          0.          0.        ]
2025-03-18 14:31:18,937 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,938 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,938 - INFO -   Participant 7 Coefficients: [0.94558351 0.22430297 0.         0.         0.         0.        ]
2025-03-18 14:31:18,938 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,939 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,940 - INFO -   Participant 8 Coefficients: [-1.12489764 -0.27957502  0.         -0.26309213  0.          0.        ]
2025-03-18 14:31:18,940 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,941 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,941 - INFO -   Participant 9 Coefficients: [2.30744452 0.66552653 0.         0.         0.         0.        ]
2025-03-18 14:31:18,941 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,942 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,942 - INFO -   Participant 10 Coefficients: [-0.52403984  0.27040371  0.          0.          0.          0.        ]
2025-03-18 14:31:18,942 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,944 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,944 - INFO -   Participant 11 Coefficients: [-1.71291601  0.1750234   0.          0.          0.          0.        ]
2025-03-18 14:31:18,944 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,945 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,945 - INFO -   Participant 12 Coefficients: [0.54608502 0.84094646 0.         0.         0.         0.        ]
2025-03-18 14:31:18,945 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,946 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,946 - INFO -   Participant 13 Coefficients: [0.50215543 0.36478617 0.         0.         0.         0.        ]
2025-03-18 14:31:18,946 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,948 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,948 - INFO -   Participant 14 Coefficients: [0.47792755 0.5927243  0.         0.         0.         0.        ]
2025-03-18 14:31:18,948 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,949 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,949 - INFO -   Participant 15 Coefficients: [-2.00961471  0.08861293  0.          0.          0.          0.        ]
2025-03-18 14:31:18,949 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:31:18,949 - INFO - Module: x_value_choice_chosen
2025-03-18 14:31:18,951 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,951 - INFO -   Participant 0 Coefficients: [0.7725839 0.        0.        0.        0.        0.       ]
2025-03-18 14:31:18,951 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,952 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,952 - INFO -   Participant 1 Coefficients: [0.92140685 0.         0.         0.         0.         0.        ]
2025-03-18 14:31:18,952 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,953 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,954 - INFO -   Participant 2 Coefficients: [0.7385959 0.        0.        0.        0.        0.       ]
2025-03-18 14:31:18,954 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,955 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,955 - INFO -   Participant 3 Coefficients: [0.87569006 0.         0.         0.         0.         0.        ]
2025-03-18 14:31:18,955 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,956 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,956 - INFO -   Participant 4 Coefficients: [0.89281157 0.         0.         0.         0.         0.        ]
2025-03-18 14:31:18,956 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,957 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,958 - INFO -   Participant 5 Coefficients: [0.87167392 0.         0.         0.         0.         0.        ]
2025-03-18 14:31:18,958 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,959 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,959 - INFO -   Participant 6 Coefficients: [0.87052245 0.         0.         0.         0.         0.        ]
2025-03-18 14:31:18,959 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,960 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,960 - INFO -   Participant 7 Coefficients: [0.9724798 0.        0.        0.        0.        0.       ]
2025-03-18 14:31:18,960 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,962 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,962 - INFO -   Participant 8 Coefficients: [0.87497666 0.0592956  0.         0.         0.         0.        ]
2025-03-18 14:31:18,962 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,963 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,963 - INFO -   Participant 9 Coefficients: [0.95771698 0.         0.         0.         0.         0.        ]
2025-03-18 14:31:18,963 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,964 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,965 - INFO -   Participant 10 Coefficients: [0.82530832 0.         0.         0.         0.         0.        ]
2025-03-18 14:31:18,965 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,966 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,966 - INFO -   Participant 11 Coefficients: [0.87061751 0.0514106  0.         0.         0.         0.        ]
2025-03-18 14:31:18,966 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,967 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,967 - INFO -   Participant 12 Coefficients: [0.88268091 0.07454658 0.         0.         0.         0.        ]
2025-03-18 14:31:18,967 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,969 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,969 - INFO -   Participant 13 Coefficients: [0.85495555 0.111283   0.         0.         0.         0.        ]
2025-03-18 14:31:18,969 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,970 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,970 - INFO -   Participant 14 Coefficients: [0.89340154 0.         0.         0.         0.         0.        ]
2025-03-18 14:31:18,970 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,971 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,971 - INFO -   Participant 15 Coefficients: [0.85705316 0.06589959 0.         0.         0.         0.        ]
2025-03-18 14:31:18,971 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:31:18,972 - INFO - Module: x_value_choice_not_chosen
2025-03-18 14:31:18,973 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,973 - INFO -   Participant 0 Coefficients: [0.55216533 0.         0.         0.         0.         0.        ]
2025-03-18 14:31:18,973 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,974 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,974 - INFO -   Participant 1 Coefficients: [ 0.33345211 -0.09381794  0.          0.          0.          0.        ]
2025-03-18 14:31:18,974 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,976 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,976 - INFO -   Participant 2 Coefficients: [0.92555404 0.         0.         0.         0.         0.        ]
2025-03-18 14:31:18,976 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,977 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,977 - INFO -   Participant 3 Coefficients: [ 0.74018778 -0.54170783  0.          0.10533214  0.          0.        ]
2025-03-18 14:31:18,977 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,978 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,978 - INFO -   Participant 4 Coefficients: [ 0.62101858 -0.15314399  0.          0.          0.          0.        ]
2025-03-18 14:31:18,978 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,980 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,980 - INFO -   Participant 5 Coefficients: [ 0.61968634 -0.48985603  0.          0.10132519  0.          0.        ]
2025-03-18 14:31:18,980 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,981 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,981 - INFO -   Participant 6 Coefficients: [ 0.65992197 -0.22007956  0.          0.          0.          0.        ]
2025-03-18 14:31:18,981 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,982 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,982 - INFO -   Participant 7 Coefficients: [ 0.29451518 -0.05567262  0.          0.          0.          0.        ]
2025-03-18 14:31:18,982 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,984 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,984 - INFO -   Participant 8 Coefficients: [ 0.75204348 -0.57989216  0.          0.12007304  0.          0.        ]
2025-03-18 14:31:18,984 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,985 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,985 - INFO -   Participant 9 Coefficients: [0. 0. 0. 0. 0. 0.]
2025-03-18 14:31:18,985 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,986 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,987 - INFO -   Participant 10 Coefficients: [0.20003881 0.         0.         0.         0.         0.        ]
2025-03-18 14:31:18,987 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,988 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,988 - INFO -   Participant 11 Coefficients: [ 0.77040908 -0.57348099  0.          0.11600855  0.          0.        ]
2025-03-18 14:31:18,988 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,989 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,989 - INFO -   Participant 12 Coefficients: [0. 0. 0. 0. 0. 0.]
2025-03-18 14:31:18,989 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,991 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,991 - INFO -   Participant 13 Coefficients: [ 0.14325852 -0.17584616  0.          0.          0.          0.        ]
2025-03-18 14:31:18,991 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,992 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,992 - INFO -   Participant 14 Coefficients: [ 0.12569559 -0.05136569  0.          0.          0.          0.        ]
2025-03-18 14:31:18,992 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,993 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:31:18,993 - INFO -   Participant 15 Coefficients: [ 0.70477751 -0.58144064  0.          0.13242106  0.          0.        ]
2025-03-18 14:31:18,993 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:31:18,994 - INFO - Creating dataset subset with 200 trials per participant
2025-03-18 14:31:18,995 - INFO - Subset with 200 trials per participant:
2025-03-18 14:31:18,995 - INFO -   Dataset shape: torch.Size([16, 200, 5])
2025-03-18 14:31:18,995 - INFO - 
==== Running pipeline for dataset: 200 trials per participant ====
2025-03-18 14:31:18,995 - INFO - 
Training RNN...
2025-03-18 14:31:18,996 - INFO - RNN model trainable parameters: 518
2025-03-18 14:31:18,996 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 14:32:56,612 - INFO - Final training loss: 0.3255879
2025-03-18 14:32:56,612 - INFO - 
Fitting SINDy...
2025-03-18 14:33:13,442 - INFO - 
Evaluating SINDy models...
2025-03-18 14:33:13,442 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-18 14:33:13,443 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 14:33:13,443 - INFO - SINDy model parameters for participant 0: 1
2025-03-18 14:33:14,048 - INFO - Participant 0: Log-likelihood: -71.9964, Normalized LL: -0.3600, Raw BIC: 149.2911, Normalized BIC: 0.7465
2025-03-18 14:33:14,048 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-18 14:33:14,049 - INFO - SINDy model parameters for participant 1: 1
2025-03-18 14:33:14,667 - INFO - Participant 1: Log-likelihood: -252.5557, Normalized LL: -1.2628, Raw BIC: 510.4097, Normalized BIC: 2.5520
2025-03-18 14:33:14,667 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-18 14:33:14,667 - INFO - SINDy model parameters for participant 2: 1
2025-03-18 14:33:15,270 - INFO - Participant 2: Log-likelihood: -13.0640, Normalized LL: -0.0653, Raw BIC: 31.4264, Normalized BIC: 0.1571
2025-03-18 14:33:15,270 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-18 14:33:15,271 - INFO - SINDy model parameters for participant 3: 2
2025-03-18 14:33:15,890 - INFO - Participant 3: Log-likelihood: nan, Normalized LL: nan, Raw BIC: nan, Normalized BIC: nan
2025-03-18 14:33:15,890 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-18 14:33:15,890 - INFO - SINDy model parameters for participant 4: 1
2025-03-18 14:33:16,505 - INFO - Participant 4: Log-likelihood: -22.4236, Normalized LL: -0.1121, Raw BIC: 50.1455, Normalized BIC: 0.2507
2025-03-18 14:33:16,505 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-18 14:33:16,505 - INFO - SINDy model parameters for participant 5: 1
2025-03-18 14:33:17,114 - INFO - Participant 5: Log-likelihood: -0.3301, Normalized LL: -0.0017, Raw BIC: 5.9584, Normalized BIC: 0.0298
2025-03-18 14:33:17,114 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-18 14:33:17,114 - INFO - SINDy model parameters for participant 6: 2
2025-03-18 14:33:17,721 - INFO - Participant 6: Log-likelihood: -11.2917, Normalized LL: -0.0565, Raw BIC: 33.1800, Normalized BIC: 0.1659
2025-03-18 14:33:17,721 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-18 14:33:17,722 - INFO - SINDy model parameters for participant 7: 2
2025-03-18 14:33:18,340 - INFO - Participant 7: Log-likelihood: -45.9440, Normalized LL: -0.2297, Raw BIC: 102.4846, Normalized BIC: 0.5124
2025-03-18 14:33:18,340 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-18 14:33:18,340 - INFO - SINDy model parameters for participant 8: 1
2025-03-18 14:33:18,954 - INFO - Participant 8: Log-likelihood: -67.2055, Normalized LL: -0.3360, Raw BIC: 139.7093, Normalized BIC: 0.6985
2025-03-18 14:33:18,954 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-18 14:33:18,954 - INFO - SINDy model parameters for participant 9: 1
2025-03-18 14:33:19,555 - INFO - Participant 9: Log-likelihood: -188.3324, Normalized LL: -0.9417, Raw BIC: 381.9632, Normalized BIC: 1.9098
2025-03-18 14:33:19,555 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-18 14:33:19,555 - INFO - SINDy model parameters for participant 10: 1
2025-03-18 14:33:20,174 - INFO - Participant 10: Log-likelihood: nan, Normalized LL: nan, Raw BIC: nan, Normalized BIC: nan
2025-03-18 14:33:20,174 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-18 14:33:20,174 - INFO - SINDy model parameters for participant 11: 1
2025-03-18 14:33:20,792 - INFO - Participant 11: Log-likelihood: -41.8017, Normalized LL: -0.2090, Raw BIC: 88.9017, Normalized BIC: 0.4445
2025-03-18 14:33:20,792 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-18 14:33:20,792 - INFO - SINDy model parameters for participant 12: 1
2025-03-18 14:33:21,391 - INFO - Participant 12: Log-likelihood: -137.7331, Normalized LL: -0.6887, Raw BIC: 280.7644, Normalized BIC: 1.4038
2025-03-18 14:33:21,391 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-18 14:33:21,391 - INFO - SINDy model parameters for participant 13: 1
2025-03-18 14:33:21,997 - INFO - Participant 13: Log-likelihood: -130.7978, Normalized LL: -0.6540, Raw BIC: 266.8939, Normalized BIC: 1.3345
2025-03-18 14:33:21,997 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-18 14:33:21,997 - INFO - SINDy model parameters for participant 14: 1
2025-03-18 14:33:22,618 - INFO - Participant 14: Log-likelihood: -1182.2277, Normalized LL: -5.9111, Raw BIC: 2369.7536, Normalized BIC: 11.8488
2025-03-18 14:33:22,618 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-18 14:33:22,618 - INFO - SINDy model parameters for participant 15: 2
2025-03-18 14:33:23,230 - INFO - Participant 15: Log-likelihood: -30.0958, Normalized LL: -0.1505, Raw BIC: 70.7882, Normalized BIC: 0.3539
2025-03-18 14:33:23,230 - INFO - 
Average SINDy BIC for 200 trials per participant: nan
2025-03-18 14:33:23,230 - INFO - 
Average Normalized Log Likelihood for 200 trials per participant: nan
2025-03-18 14:33:23,230 - INFO - 
Identified SINDy equations:
2025-03-18 14:33:23,230 - INFO - Module: x_learning_rate_reward
2025-03-18 14:33:23,231 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,231 - INFO -   Participant 0 Coefficients: [0.99166044 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 14:33:23,231 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,233 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,233 - INFO -   Participant 1 Coefficients: [ 0.67956984  0.44669356  0.11003229  1.04703819 -0.13817686 -0.29236363
  0.          0.         -0.95437106  0.59681551]
2025-03-18 14:33:23,233 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,235 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,235 - INFO -   Participant 2 Coefficients: [ 8.40303999e-01  4.12405462e-01  0.00000000e+00  3.98184639e+00
 -2.59210113e-01 -2.36970515e+01  5.68484204e+02  0.00000000e+00
 -9.56879337e-01  7.77413916e+00]
2025-03-18 14:33:23,235 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,236 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,237 - INFO -   Participant 3 Coefficients: [ 0.3665878   0.8177238   0.3402082   0.60291251 -0.21269892 -2.02111588
  4.29074818  0.          0.          0.31154896]
2025-03-18 14:33:23,237 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,238 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,238 - INFO -   Participant 4 Coefficients: [ 0.09813207  1.36470695  0.56716562  0.         -0.58305811 -0.48090795
  0.          0.          0.          0.        ]
2025-03-18 14:33:23,238 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,240 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,240 - INFO -   Participant 5 Coefficients: [ 0.37755938  1.67065104  0.36935444  0.         -1.05781563 -0.41571962
  0.          0.          0.          0.        ]
2025-03-18 14:33:23,240 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,242 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,242 - INFO -   Participant 6 Coefficients: [ 0.14386405  1.85783604  0.48126327  0.         -1.03155703 -0.51091367
  0.          0.          0.          0.        ]
2025-03-18 14:33:23,242 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,243 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,243 - INFO -   Participant 7 Coefficients: [ 0.50261455  1.12135065  0.43367568  0.         -0.63686615 -0.45799388
  0.          0.          0.          0.        ]
2025-03-18 14:33:23,243 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,245 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,245 - INFO -   Participant 8 Coefficients: [ 0.28718402  1.92289129  0.530103    0.         -1.23553399 -0.57332196
  0.          0.          0.          0.        ]
2025-03-18 14:33:23,245 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,247 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,247 - INFO -   Participant 9 Coefficients: [0.74436816 0.17448284 0.         0.         0.         0.
 0.         0.         0.05944721 0.        ]
2025-03-18 14:33:23,247 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,248 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,248 - INFO -   Participant 10 Coefficients: [ 0.1923126   0.76398187  0.45391034  0.20875781  0.         -1.32271545
  0.66240702  0.          0.          0.12800056]
2025-03-18 14:33:23,248 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,250 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,250 - INFO -   Participant 11 Coefficients: [ 0.1993733   1.87759851  0.45458552  0.         -1.11246723 -0.48895023
  0.          0.          0.          0.        ]
2025-03-18 14:33:23,250 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,251 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,252 - INFO -   Participant 12 Coefficients: [ 0.46183999  0.88137479  0.49097162  0.         -0.35731077 -0.51336501
  0.          0.          0.          0.        ]
2025-03-18 14:33:23,252 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,253 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,253 - INFO -   Participant 13 Coefficients: [ 0.34860051  0.62231575  0.59543546  0.          0.         -0.58236087
  0.          0.          0.          0.        ]
2025-03-18 14:33:23,253 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,255 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,255 - INFO -   Participant 14 Coefficients: [ 0.79851801  0.17519457  0.          4.3190157   0.         -3.12466314
 13.25775599  0.         -5.27021354  9.00054179]
2025-03-18 14:33:23,255 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,257 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,257 - INFO -   Participant 15 Coefficients: [ 0.          0.6792683   0.19503969  0.         -0.67389402  0.72899705
  0.          0.          0.          0.        ]
2025-03-18 14:33:23,257 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:33:23,257 - INFO - Module: x_value_reward_not_chosen
2025-03-18 14:33:23,258 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,258 - INFO -   Participant 0 Coefficients: [-2.97543788 -0.34682985  0.          0.          0.          0.        ]
2025-03-18 14:33:23,258 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,259 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,260 - INFO -   Participant 1 Coefficients: [-2.29539161 -0.80980934  0.         -0.14268344  0.          0.        ]
2025-03-18 14:33:23,260 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,261 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,261 - INFO -   Participant 2 Coefficients: [-3.45893935  0.48687383  0.          0.          0.          0.        ]
2025-03-18 14:33:23,261 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,262 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,262 - INFO -   Participant 3 Coefficients: [-2.26737745  0.90471958  0.          0.38362725  0.          0.        ]
2025-03-18 14:33:23,262 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,264 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,264 - INFO -   Participant 4 Coefficients: [-1.39011679  0.61877495  0.          0.          0.          0.        ]
2025-03-18 14:33:23,264 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,265 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,265 - INFO -   Participant 5 Coefficients: [-3.63175946  0.44285907  0.          0.          0.          0.        ]
2025-03-18 14:33:23,265 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,267 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,267 - INFO -   Participant 6 Coefficients: [-3.36963331 -0.2546096   0.         -0.10673126  0.          0.        ]
2025-03-18 14:33:23,267 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,268 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,268 - INFO -   Participant 7 Coefficients: [-1.4811872   0.40812057  0.          0.          0.          0.        ]
2025-03-18 14:33:23,268 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,269 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,270 - INFO -   Participant 8 Coefficients: [-3.39332983 -1.19474645  0.         -0.25055971  0.          0.        ]
2025-03-18 14:33:23,270 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,271 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,271 - INFO -   Participant 9 Coefficients: [2.27819944 0.07090174 0.         0.         0.         0.        ]
2025-03-18 14:33:23,271 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,272 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,272 - INFO -   Participant 10 Coefficients: [-0.92536462  0.36687357  0.          0.48278034  0.          0.        ]
2025-03-18 14:33:23,272 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,274 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,274 - INFO -   Participant 11 Coefficients: [-3.94301877 -0.92940597  0.         -0.18651582  0.          0.        ]
2025-03-18 14:33:23,274 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,275 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,275 - INFO -   Participant 12 Coefficients: [0.09427181 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,275 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,276 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,276 - INFO -   Participant 13 Coefficients: [0.56081013 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,277 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,278 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,278 - INFO -   Participant 14 Coefficients: [-1.44717329 -0.29992604  0.          0.          0.          0.        ]
2025-03-18 14:33:23,278 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,279 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,279 - INFO -   Participant 15 Coefficients: [-3.8873733  -0.6609222   0.         -0.14457793  0.          0.        ]
2025-03-18 14:33:23,279 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-18 14:33:23,279 - INFO - Module: x_value_choice_chosen
2025-03-18 14:33:23,281 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,281 - INFO -   Participant 0 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,281 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,282 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,282 - INFO -   Participant 1 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,282 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,283 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,284 - INFO -   Participant 2 Coefficients: [0.55376197 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,284 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,285 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,285 - INFO -   Participant 3 Coefficients: [0.56210657 0.22018261 0.         0.         0.         0.        ]
2025-03-18 14:33:23,285 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,286 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,286 - INFO -   Participant 4 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,286 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,288 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,288 - INFO -   Participant 5 Coefficients: [0.55376208 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,288 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,289 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,289 - INFO -   Participant 6 Coefficients: [0.58749934 0.1515992  0.         0.         0.         0.        ]
2025-03-18 14:33:23,289 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,290 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,290 - INFO -   Participant 7 Coefficients: [0.56037723 0.22177218 0.         0.         0.         0.        ]
2025-03-18 14:33:23,291 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,292 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,292 - INFO -   Participant 8 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,292 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,293 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,293 - INFO -   Participant 9 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,293 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,295 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,295 - INFO -   Participant 10 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,295 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,296 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,296 - INFO -   Participant 11 Coefficients: [0.55849433 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,296 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,298 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,298 - INFO -   Participant 12 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,298 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,299 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,299 - INFO -   Participant 13 Coefficients: [0.55283701 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,299 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,300 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,300 - INFO -   Participant 14 Coefficients: [0.56311333 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,300 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,302 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,302 - INFO -   Participant 15 Coefficients: [0.55310953 0.24282566 0.         0.         0.         0.        ]
2025-03-18 14:33:23,302 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-18 14:33:23,302 - INFO - Module: x_value_choice_not_chosen
2025-03-18 14:33:23,303 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,303 - INFO -   Participant 0 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,303 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,304 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,305 - INFO -   Participant 1 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,305 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,306 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,306 - INFO -   Participant 2 Coefficients: [0.28236774 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,306 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,307 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,307 - INFO -   Participant 3 Coefficients: [0.27053916 0.24434069 0.         0.         0.         0.        ]
2025-03-18 14:33:23,307 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,309 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,309 - INFO -   Participant 4 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,309 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,310 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,310 - INFO -   Participant 5 Coefficients: [0.28236781 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,310 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,311 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,312 - INFO -   Participant 6 Coefficients: [0.29692178 0.20782833 0.         0.         0.         0.        ]
2025-03-18 14:33:23,312 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,313 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,313 - INFO -   Participant 7 Coefficients: [0.36097302 0.         0.         0.16260052 0.         0.        ]
2025-03-18 14:33:23,313 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,314 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,314 - INFO -   Participant 8 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,314 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,316 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,316 - INFO -   Participant 9 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,316 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,317 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,317 - INFO -   Participant 10 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,317 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,319 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,319 - INFO -   Participant 11 Coefficients: [0.28623112 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,319 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,320 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,320 - INFO -   Participant 12 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,320 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,321 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,322 - INFO -   Participant 13 Coefficients: [0.28161722 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,322 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,323 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,323 - INFO -   Participant 14 Coefficients: [0.29004034 0.         0.         0.         0.         0.        ]
2025-03-18 14:33:23,323 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:23,324 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:33:23,325 - INFO -   Participant 15 Coefficients: [0.28099002 0.21325301 0.         0.         0.         0.        ]
2025-03-18 14:33:23,325 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-18 14:33:53,999 - INFO - ================================================================================
2025-03-18 14:33:53,999 - INFO - EXPERIMENT CONFIG
2025-03-18 14:33:53,999 - INFO - ================================================================================
2025-03-18 14:33:53,999 - INFO - Number of actions: 2
2025-03-18 14:33:54,007 - INFO - Number of participants: 16
2025-03-18 14:33:54,007 - INFO - ================================================================================
2025-03-18 14:33:54,007 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 14:33:54,007 - INFO - ================================================================================
2025-03-18 14:33:54,180 - INFO - ================================================================================
2025-03-18 14:33:54,180 - INFO - COMBINED DATASET INFORMATION
2025-03-18 14:33:54,180 - INFO - ================================================================================
2025-03-18 14:33:54,180 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 14:33:54,180 - INFO - Number of participants in dataset: 16
2025-03-18 14:33:54,180 - INFO - ================================================================================
2025-03-18 14:33:54,180 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 14:33:54,180 - INFO - ================================================================================
2025-03-18 14:33:54,180 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 14:33:54,181 - INFO - Subset with 100 trials per participant:
2025-03-18 14:33:54,181 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 14:33:54,181 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 14:33:54,181 - INFO - 
Training RNN...
2025-03-18 14:33:54,183 - INFO - RNN model trainable parameters: 518
2025-03-18 14:33:55,113 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 14:34:01,936 - INFO - Final training loss: 0.3298943
2025-03-18 14:34:01,937 - INFO - 
Fitting SINDy...
2025-03-18 14:34:28,996 - INFO - 
Evaluating SINDy models...
2025-03-18 14:34:28,997 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-18 14:36:01,906 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 14:37:41,605 - INFO - SINDy model parameters for participant 0: 1
2025-03-18 14:42:36,664 - INFO - Participant 0: Log-likelihood: -48.0797, Normalized LL: -0.4808, Raw BIC: 100.7646, Normalized BIC: 1.0076
2025-03-18 14:42:56,669 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-18 14:42:56,669 - INFO - SINDy model parameters for participant 1: 1
2025-03-18 14:42:57,187 - INFO - Participant 1: Log-likelihood: -44.2005, Normalized LL: -0.4420, Raw BIC: 93.0062, Normalized BIC: 0.9301
2025-03-18 14:42:59,835 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-18 14:42:59,835 - INFO - SINDy model parameters for participant 2: 1
2025-03-18 14:43:00,326 - INFO - Participant 2: Log-likelihood: -2.4984, Normalized LL: -0.0250, Raw BIC: 9.6020, Normalized BIC: 0.0960
2025-03-18 14:43:00,326 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-18 14:43:00,326 - INFO - SINDy model parameters for participant 3: 1
2025-03-18 14:43:00,818 - INFO - Participant 3: Log-likelihood: -18.1625, Normalized LL: -0.1816, Raw BIC: 40.9302, Normalized BIC: 0.4093
2025-03-18 14:43:00,818 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-18 14:43:00,818 - INFO - SINDy model parameters for participant 4: 1
2025-03-18 14:43:01,308 - INFO - Participant 4: Log-likelihood: -12.7181, Normalized LL: -0.1272, Raw BIC: 30.0414, Normalized BIC: 0.3004
2025-03-18 14:43:01,309 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-18 14:43:01,309 - INFO - SINDy model parameters for participant 5: 1
2025-03-18 14:43:01,868 - INFO - Participant 5: Log-likelihood: nan, Normalized LL: nan, Raw BIC: nan, Normalized BIC: nan
2025-03-18 14:43:01,868 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-18 14:43:01,868 - INFO - SINDy model parameters for participant 6: 1
2025-03-18 14:43:02,397 - INFO - Participant 6: Log-likelihood: -4.7407, Normalized LL: -0.0474, Raw BIC: 14.0866, Normalized BIC: 0.1409
2025-03-18 14:43:02,398 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-18 14:43:02,398 - INFO - SINDy model parameters for participant 7: 1
2025-03-18 14:43:02,931 - INFO - Participant 7: Log-likelihood: -26.4611, Normalized LL: -0.2646, Raw BIC: 57.5273, Normalized BIC: 0.5753
2025-03-18 14:43:02,931 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-18 14:43:02,931 - INFO - SINDy model parameters for participant 8: 1
2025-03-18 14:43:03,456 - INFO - Participant 8: Log-likelihood: -40.5384, Normalized LL: -0.4054, Raw BIC: 85.6819, Normalized BIC: 0.8568
2025-03-18 14:43:03,456 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-18 14:43:03,456 - INFO - SINDy model parameters for participant 9: 1
2025-03-18 14:43:03,982 - INFO - Participant 9: Log-likelihood: -61.6752, Normalized LL: -0.6168, Raw BIC: 127.9556, Normalized BIC: 1.2796
2025-03-18 14:43:03,982 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-18 14:43:03,982 - INFO - SINDy model parameters for participant 10: 1
2025-03-18 14:43:04,526 - INFO - Participant 10: Log-likelihood: -63.4187, Normalized LL: -0.6342, Raw BIC: 131.4426, Normalized BIC: 1.3144
2025-03-18 14:43:04,527 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-18 14:43:04,527 - INFO - SINDy model parameters for participant 11: 1
2025-03-18 14:43:05,072 - INFO - Participant 11: Log-likelihood: -18.5435, Normalized LL: -0.1854, Raw BIC: 41.6922, Normalized BIC: 0.4169
2025-03-18 14:43:05,072 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-18 14:43:05,080 - INFO - SINDy model parameters for participant 12: 1
2025-03-18 14:43:05,633 - INFO - Participant 12: Log-likelihood: -67.7624, Normalized LL: -0.6776, Raw BIC: 140.1299, Normalized BIC: 1.4013
2025-03-18 14:43:05,633 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-18 14:43:05,634 - INFO - SINDy model parameters for participant 13: 1
2025-03-18 14:43:06,156 - INFO - Participant 13: Log-likelihood: -67.1595, Normalized LL: -0.6716, Raw BIC: 138.9242, Normalized BIC: 1.3892
2025-03-18 14:43:06,156 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-18 14:43:06,156 - INFO - SINDy model parameters for participant 14: 1
2025-03-18 14:43:06,649 - INFO - Participant 14: Log-likelihood: -50.9728, Normalized LL: -0.5097, Raw BIC: 106.5508, Normalized BIC: 1.0655
2025-03-18 14:43:06,649 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-18 14:43:06,649 - INFO - SINDy model parameters for participant 15: 1
2025-03-18 14:43:07,131 - INFO - Participant 15: Log-likelihood: -18.7163, Normalized LL: -0.1872, Raw BIC: 42.0378, Normalized BIC: 0.4204
2025-03-18 14:43:39,270 - INFO - 
Average SINDy BIC for 100 trials per participant: nan
2025-03-18 14:43:50,435 - INFO - 
Average Normalized Log Likelihood for 100 trials per participant: nan
2025-03-18 14:53:21,261 - INFO - ================================================================================
2025-03-18 14:53:21,261 - INFO - EXPERIMENT CONFIG
2025-03-18 14:53:21,261 - INFO - ================================================================================
2025-03-18 14:53:21,261 - INFO - Number of actions: 2
2025-03-18 14:53:21,270 - INFO - Number of participants: 16
2025-03-18 14:53:21,270 - INFO - ================================================================================
2025-03-18 14:53:21,270 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 14:53:21,270 - INFO - ================================================================================
2025-03-18 14:53:21,452 - INFO - ================================================================================
2025-03-18 14:53:21,452 - INFO - COMBINED DATASET INFORMATION
2025-03-18 14:53:21,452 - INFO - ================================================================================
2025-03-18 14:53:21,452 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 14:53:21,452 - INFO - Number of participants in dataset: 16
2025-03-18 14:53:21,452 - INFO - ================================================================================
2025-03-18 14:53:21,452 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 14:53:21,452 - INFO - ================================================================================
2025-03-18 14:53:21,453 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 14:53:21,453 - INFO - Subset with 100 trials per participant:
2025-03-18 14:53:21,453 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 14:53:21,454 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 14:53:21,454 - INFO - 
Training RNN...
2025-03-18 14:53:21,456 - INFO - RNN model trainable parameters: 518
2025-03-18 14:53:22,423 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 14:53:29,382 - INFO - Final training loss: 0.3298943
2025-03-18 14:53:29,384 - INFO - 
Fitting SINDy...
2025-03-18 14:53:56,686 - INFO - 
Evaluating SINDy models...
2025-03-18 14:53:56,686 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-18 14:53:56,686 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 14:53:56,686 - INFO - SINDy model parameters for participant 0: 1
2025-03-18 14:53:57,264 - INFO - Participant 0: Log-likelihood: -48.0797, Normalized LL: -0.4808, Raw BIC: 100.7646, Normalized BIC: 1.0076
2025-03-18 14:53:57,265 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-18 14:53:57,265 - INFO - SINDy model parameters for participant 1: 1
2025-03-18 14:53:57,796 - INFO - Participant 1: Log-likelihood: -44.2005, Normalized LL: -0.4420, Raw BIC: 93.0062, Normalized BIC: 0.9301
2025-03-18 14:53:57,796 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-18 14:53:57,796 - INFO - SINDy model parameters for participant 2: 1
2025-03-18 14:53:58,355 - INFO - Participant 2: Log-likelihood: -2.4984, Normalized LL: -0.0250, Raw BIC: 9.6020, Normalized BIC: 0.0960
2025-03-18 14:53:58,355 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-18 14:53:58,355 - INFO - SINDy model parameters for participant 3: 1
2025-03-18 14:53:58,925 - INFO - Participant 3: Log-likelihood: -18.1625, Normalized LL: -0.1816, Raw BIC: 40.9302, Normalized BIC: 0.4093
2025-03-18 14:53:58,925 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-18 14:53:58,926 - INFO - SINDy model parameters for participant 4: 1
2025-03-18 14:53:59,496 - INFO - Participant 4: Log-likelihood: -12.7181, Normalized LL: -0.1272, Raw BIC: 30.0414, Normalized BIC: 0.3004
2025-03-18 14:53:59,496 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-18 14:53:59,497 - INFO - SINDy model parameters for participant 5: 1
2025-03-18 14:54:00,067 - INFO - Participant 5: Log-likelihood: -0.3711, Normalized LL: -0.0037, Raw BIC: 5.3474, Normalized BIC: 0.0535
2025-03-18 14:54:00,067 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-18 14:54:00,067 - INFO - SINDy model parameters for participant 6: 1
2025-03-18 14:54:00,638 - INFO - Participant 6: Log-likelihood: -0.3268, Normalized LL: -0.0033, Raw BIC: 5.2587, Normalized BIC: 0.0526
2025-03-18 14:54:00,638 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-18 14:54:00,638 - INFO - SINDy model parameters for participant 7: 1
2025-03-18 14:54:01,208 - INFO - Participant 7: Log-likelihood: -26.4611, Normalized LL: -0.2646, Raw BIC: 57.5273, Normalized BIC: 0.5753
2025-03-18 14:54:01,208 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-18 14:54:01,208 - INFO - SINDy model parameters for participant 8: 1
2025-03-18 14:54:01,779 - INFO - Participant 8: Log-likelihood: -40.5384, Normalized LL: -0.4054, Raw BIC: 85.6819, Normalized BIC: 0.8568
2025-03-18 14:54:01,779 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-18 14:54:01,780 - INFO - SINDy model parameters for participant 9: 1
2025-03-18 14:54:02,349 - INFO - Participant 9: Log-likelihood: -61.6752, Normalized LL: -0.6168, Raw BIC: 127.9556, Normalized BIC: 1.2796
2025-03-18 14:54:02,350 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-18 14:54:02,350 - INFO - SINDy model parameters for participant 10: 1
2025-03-18 14:54:02,906 - INFO - Participant 10: Log-likelihood: -63.4187, Normalized LL: -0.6342, Raw BIC: 131.4426, Normalized BIC: 1.3144
2025-03-18 14:54:02,906 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-18 14:54:02,907 - INFO - SINDy model parameters for participant 11: 1
2025-03-18 14:54:03,473 - INFO - Participant 11: Log-likelihood: -18.5435, Normalized LL: -0.1854, Raw BIC: 41.6922, Normalized BIC: 0.4169
2025-03-18 14:54:03,473 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-18 14:54:03,474 - INFO - SINDy model parameters for participant 12: 1
2025-03-18 14:54:04,042 - INFO - Participant 12: Log-likelihood: -67.7624, Normalized LL: -0.6776, Raw BIC: 140.1299, Normalized BIC: 1.4013
2025-03-18 14:54:04,042 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-18 14:54:04,042 - INFO - SINDy model parameters for participant 13: 1
2025-03-18 14:54:04,610 - INFO - Participant 13: Log-likelihood: -67.1595, Normalized LL: -0.6716, Raw BIC: 138.9242, Normalized BIC: 1.3892
2025-03-18 14:54:04,610 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-18 14:54:04,611 - INFO - SINDy model parameters for participant 14: 1
2025-03-18 14:54:05,179 - INFO - Participant 14: Log-likelihood: -50.9728, Normalized LL: -0.5097, Raw BIC: 106.5508, Normalized BIC: 1.0655
2025-03-18 14:54:05,180 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-18 14:54:05,180 - INFO - SINDy model parameters for participant 15: 1
2025-03-18 14:54:05,760 - INFO - Participant 15: Log-likelihood: -18.7163, Normalized LL: -0.1872, Raw BIC: 42.0378, Normalized BIC: 0.4204
2025-03-18 14:54:30,526 - INFO - 
Average SINDy BIC for 100 trials per participant: 0.7231
2025-03-18 14:54:35,269 - INFO - 
Average Normalized Log Likelihood for 100 trials per participant: -0.3385
2025-03-18 14:54:45,714 - INFO - 
Identified SINDy equations:
2025-03-18 14:54:47,633 - INFO - Module: x_learning_rate_reward
2025-03-18 14:54:50,354 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:54:57,646 - INFO -   Participant 0 Coefficients: [0.46383453 0.15929678 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 14:54:58,150 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:55:02,016 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:55:03,897 - INFO -   Participant 1 Coefficients: [0.50463783 0.20026719 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 14:55:04,634 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:55:08,799 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:55:10,487 - INFO -   Participant 2 Coefficients: [0.60362925 0.13908448 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 14:55:11,852 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:55:14,788 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:55:16,365 - INFO -   Participant 3 Coefficients: [0.56840292 0.13156764 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 14:55:16,957 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:55:56,883 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 14:55:59,746 - INFO -   Participant 4 Coefficients: [0.49349938 0.18622225 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 14:56:02,000 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 14:59:19,992 - INFO - ================================================================================
2025-03-18 14:59:19,992 - INFO - EXPERIMENT CONFIG
2025-03-18 14:59:19,992 - INFO - ================================================================================
2025-03-18 14:59:19,992 - INFO - Number of actions: 2
2025-03-18 14:59:20,000 - INFO - Number of participants: 16
2025-03-18 14:59:20,000 - INFO - ================================================================================
2025-03-18 14:59:20,000 - INFO - PROCESSING PARTICIPANT DATA
2025-03-18 14:59:20,000 - INFO - ================================================================================
2025-03-18 14:59:20,179 - INFO - ================================================================================
2025-03-18 14:59:20,179 - INFO - COMBINED DATASET INFORMATION
2025-03-18 14:59:20,179 - INFO - ================================================================================
2025-03-18 14:59:20,179 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-18 14:59:20,180 - INFO - Number of participants in dataset: 16
2025-03-18 14:59:20,180 - INFO - ================================================================================
2025-03-18 14:59:20,180 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-18 14:59:20,180 - INFO - ================================================================================
2025-03-18 14:59:20,180 - INFO - Creating dataset subset with 100 trials per participant
2025-03-18 14:59:20,180 - INFO - Subset with 100 trials per participant:
2025-03-18 14:59:20,180 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-18 14:59:20,181 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-18 14:59:20,181 - INFO - 
Training RNN...
2025-03-18 14:59:20,183 - INFO - RNN model trainable parameters: 518
2025-03-18 14:59:21,048 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-18 14:59:27,380 - INFO - Final training loss: 0.3298943
2025-03-18 14:59:27,381 - INFO - 
Fitting SINDy...
2025-03-18 14:59:54,487 - INFO - 
Evaluating SINDy models...
2025-03-18 14:59:54,487 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-18 14:59:54,487 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-18 14:59:54,487 - INFO - SINDy model parameters for participant 0: 6
2025-03-18 14:59:55,059 - INFO - Participant 0: Log-likelihood: -48.0797, Normalized LL: -0.4808, Raw BIC: 123.7905, Normalized BIC: 1.2379
2025-03-18 14:59:55,059 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-18 14:59:55,059 - INFO - SINDy model parameters for participant 1: 6
2025-03-18 14:59:55,633 - INFO - Participant 1: Log-likelihood: -44.2005, Normalized LL: -0.4420, Raw BIC: 116.0321, Normalized BIC: 1.1603
2025-03-18 14:59:55,633 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-18 14:59:55,633 - INFO - SINDy model parameters for participant 2: 6
2025-03-18 14:59:56,180 - INFO - Participant 2: Log-likelihood: -2.4984, Normalized LL: -0.0250, Raw BIC: 32.6278, Normalized BIC: 0.3263
2025-03-18 14:59:56,180 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-18 14:59:56,181 - INFO - SINDy model parameters for participant 3: 6
2025-03-18 14:59:56,735 - INFO - Participant 3: Log-likelihood: -18.1625, Normalized LL: -0.1816, Raw BIC: 63.9561, Normalized BIC: 0.6396
2025-03-18 14:59:56,735 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-18 14:59:56,735 - INFO - SINDy model parameters for participant 4: 6
2025-03-18 14:59:57,310 - INFO - Participant 4: Log-likelihood: -12.7181, Normalized LL: -0.1272, Raw BIC: 53.0673, Normalized BIC: 0.5307
2025-03-18 14:59:57,311 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-18 14:59:57,311 - INFO - SINDy model parameters for participant 5: 5
2025-03-18 14:59:57,833 - INFO - Participant 5: Log-likelihood: -0.3711, Normalized LL: -0.0037, Raw BIC: 23.7681, Normalized BIC: 0.2377
2025-03-18 14:59:57,833 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-18 14:59:57,834 - INFO - SINDy model parameters for participant 6: 6
2025-03-18 14:59:58,349 - INFO - Participant 6: Log-likelihood: -0.3268, Normalized LL: -0.0033, Raw BIC: 28.2846, Normalized BIC: 0.2828
2025-03-18 14:59:58,349 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-18 14:59:58,349 - INFO - SINDy model parameters for participant 7: 5
2025-03-18 14:59:58,866 - INFO - Participant 7: Log-likelihood: -26.4611, Normalized LL: -0.2646, Raw BIC: 75.9480, Normalized BIC: 0.7595
2025-03-18 14:59:58,866 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-18 14:59:58,866 - INFO - SINDy model parameters for participant 8: 6
2025-03-18 14:59:59,396 - INFO - Participant 8: Log-likelihood: -40.5384, Normalized LL: -0.4054, Raw BIC: 108.7077, Normalized BIC: 1.0871
2025-03-18 14:59:59,397 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-18 14:59:59,397 - INFO - SINDy model parameters for participant 9: 8
2025-03-18 14:59:59,922 - INFO - Participant 9: Log-likelihood: -61.6752, Normalized LL: -0.6168, Raw BIC: 160.1917, Normalized BIC: 1.6019
2025-03-18 14:59:59,922 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-18 14:59:59,922 - INFO - SINDy model parameters for participant 10: 6
2025-03-18 15:00:00,481 - INFO - Participant 10: Log-likelihood: -63.4187, Normalized LL: -0.6342, Raw BIC: 154.4684, Normalized BIC: 1.5447
2025-03-18 15:00:00,481 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-18 15:00:00,481 - INFO - SINDy model parameters for participant 11: 7
2025-03-18 15:00:01,035 - INFO - Participant 11: Log-likelihood: -18.5435, Normalized LL: -0.1854, Raw BIC: 69.3232, Normalized BIC: 0.6932
2025-03-18 15:00:01,035 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-18 15:00:01,036 - INFO - SINDy model parameters for participant 12: 7
2025-03-18 15:00:01,575 - INFO - Participant 12: Log-likelihood: -67.7624, Normalized LL: -0.6776, Raw BIC: 167.7609, Normalized BIC: 1.6776
2025-03-18 15:00:01,575 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-18 15:00:01,575 - INFO - SINDy model parameters for participant 13: 7
2025-03-18 15:00:02,115 - INFO - Participant 13: Log-likelihood: -67.1595, Normalized LL: -0.6716, Raw BIC: 166.5553, Normalized BIC: 1.6656
2025-03-18 15:00:02,115 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-18 15:00:02,115 - INFO - SINDy model parameters for participant 14: 6
2025-03-18 15:00:02,665 - INFO - Participant 14: Log-likelihood: -50.9728, Normalized LL: -0.5097, Raw BIC: 129.5767, Normalized BIC: 1.2958
2025-03-18 15:00:02,665 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-18 15:00:02,665 - INFO - SINDy model parameters for participant 15: 6
2025-03-18 15:00:03,216 - INFO - Participant 15: Log-likelihood: -18.7163, Normalized LL: -0.1872, Raw BIC: 65.0637, Normalized BIC: 0.6506
2025-03-18 15:00:07,676 - INFO - 
Average SINDy BIC for 100 trials per participant: 0.9620
2025-03-18 15:00:10,061 - INFO - 
Average Normalized Log Likelihood for 100 trials per participant: -0.3385
2025-03-18 15:00:33,987 - INFO - 
Identified SINDy equations:
2025-03-18 15:00:34,846 - INFO - Module: x_learning_rate_reward
2025-03-18 15:00:37,716 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 15:00:39,088 - INFO -   Participant 0 Coefficients: [0.46383453 0.15929678 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 15:00:39,535 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-18 15:00:42,561 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-18 15:00:43,906 - INFO -   Participant 1 Coefficients: [0.50463783 0.20026719 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-18 15:00:44,305 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 09:55:28,466 - INFO - ================================================================================
2025-03-25 09:55:28,466 - INFO - EXPERIMENT CONFIG
2025-03-25 09:55:28,466 - INFO - ================================================================================
2025-03-25 09:55:28,466 - INFO - Number of actions: 2
2025-03-25 09:55:28,492 - INFO - Number of participants: 16
2025-03-25 09:55:28,492 - INFO - ================================================================================
2025-03-25 09:55:28,492 - INFO - PROCESSING PARTICIPANT DATA
2025-03-25 09:55:28,492 - INFO - ================================================================================
2025-03-25 09:55:29,064 - INFO - ================================================================================
2025-03-25 09:55:29,064 - INFO - COMBINED DATASET INFORMATION
2025-03-25 09:55:29,064 - INFO - ================================================================================
2025-03-25 09:55:29,065 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-25 09:55:29,073 - INFO - Number of participants in dataset: 16
2025-03-25 09:55:29,074 - INFO - ================================================================================
2025-03-25 09:55:29,074 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-25 09:55:29,074 - INFO - ================================================================================
2025-03-25 09:55:29,074 - INFO - Creating dataset subset with 100 trials per participant
2025-03-25 09:55:29,083 - INFO - Subset with 100 trials per participant:
2025-03-25 09:55:29,083 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-25 09:55:29,083 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-25 09:55:29,084 - INFO - 
Training RNN...
2025-03-25 09:55:29,093 - INFO - RNN model trainable parameters: 518
2025-03-25 09:55:31,639 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-25 09:57:23,099 - INFO - ================================================================================
2025-03-25 09:57:23,100 - INFO - EXPERIMENT CONFIG
2025-03-25 09:57:23,100 - INFO - ================================================================================
2025-03-25 09:57:23,101 - INFO - Number of actions: 2
2025-03-25 09:57:23,138 - INFO - Number of participants: 16
2025-03-25 09:57:23,139 - INFO - ================================================================================
2025-03-25 09:57:23,139 - INFO - PROCESSING PARTICIPANT DATA
2025-03-25 09:57:23,139 - INFO - ================================================================================
2025-03-25 09:57:23,666 - INFO - ================================================================================
2025-03-25 09:57:23,667 - INFO - COMBINED DATASET INFORMATION
2025-03-25 09:57:23,667 - INFO - ================================================================================
2025-03-25 09:57:23,667 - INFO - Combined full dataset shape: torch.Size([16, 200, 5])
2025-03-25 09:57:23,668 - INFO - Number of participants in dataset: 16
2025-03-25 09:57:23,668 - INFO - ================================================================================
2025-03-25 09:57:23,668 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-25 09:57:23,668 - INFO - ================================================================================
2025-03-25 09:57:23,668 - INFO - Creating dataset subset with 100 trials per participant
2025-03-25 09:57:23,670 - INFO - Subset with 100 trials per participant:
2025-03-25 09:57:23,670 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-25 09:57:23,670 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-25 09:57:23,670 - INFO - 
Training RNN...
2025-03-25 09:57:23,676 - INFO - RNN model trainable parameters: 518
2025-03-25 09:57:26,227 - INFO - Training configuration: epochs=512, steps=16, scheduler=True
2025-03-25 22:03:34,114 - INFO - ================================================================================
2025-03-25 22:03:34,114 - INFO - EXPERIMENT CONFIG
2025-03-25 22:03:34,114 - INFO - ================================================================================
2025-03-25 22:03:34,114 - INFO - Number of actions: 2
2025-03-25 22:03:34,187 - INFO - Number of participants: 256
2025-03-25 22:03:34,188 - INFO - ================================================================================
2025-03-25 22:03:34,188 - INFO - PROCESSING PARTICIPANT DATA
2025-03-25 22:03:34,188 - INFO - ================================================================================
2025-03-25 22:03:35,594 - INFO - ================================================================================
2025-03-25 22:03:35,594 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-25 22:03:35,594 - INFO - ================================================================================
2025-03-25 22:03:35,594 - INFO - Creating dataset subset with 100 trials per participant
2025-03-25 22:03:35,600 - INFO - Subset with 100 trials per participant:
2025-03-25 22:03:35,600 - INFO -   Dataset shape: torch.Size([256, 100, 5])
2025-03-25 22:03:35,600 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-25 22:03:35,600 - INFO - 
Training RNN...
2025-03-25 22:03:35,601 - INFO - RNN model trainable parameters: 2438
2025-03-25 22:03:39,818 - INFO - Final training loss: 0.0000000
2025-03-25 22:03:39,819 - INFO - 
Fitting SINDy...
2025-03-25 22:03:55,756 - INFO - ================================================================================
2025-03-25 22:03:55,756 - INFO - EXPERIMENT CONFIG
2025-03-25 22:03:55,756 - INFO - ================================================================================
2025-03-25 22:03:55,756 - INFO - Number of actions: 2
2025-03-25 22:03:55,838 - INFO - Number of participants: 256
2025-03-25 22:03:55,838 - INFO - ================================================================================
2025-03-25 22:03:55,838 - INFO - PROCESSING PARTICIPANT DATA
2025-03-25 22:03:55,838 - INFO - ================================================================================
2025-03-25 22:03:57,349 - INFO - ================================================================================
2025-03-25 22:03:57,349 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-25 22:03:57,349 - INFO - ================================================================================
2025-03-25 22:03:57,349 - INFO - Creating dataset subset with 100 trials per participant
2025-03-25 22:03:57,356 - INFO - Subset with 100 trials per participant:
2025-03-25 22:03:57,356 - INFO -   Dataset shape: torch.Size([256, 100, 5])
2025-03-25 22:03:57,356 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-25 22:03:57,356 - INFO - 
Training RNN...
2025-03-25 22:03:57,357 - INFO - RNN model trainable parameters: 2438
2025-03-25 22:04:24,582 - INFO - Final training loss: 0.3513188
2025-03-25 22:04:24,583 - INFO - 
Fitting SINDy...
2025-03-25 22:09:06,327 - INFO - 
Evaluating SINDy models...
2025-03-25 22:09:06,327 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255}
2025-03-25 22:09:06,327 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-25 22:09:06,327 - INFO - SINDy model parameters for participant 0: 8
2025-03-25 22:09:06,661 - INFO - Participant 0: Log-likelihood: -2.7023, Normalized LL: -0.0270, Raw BIC: 42.2459, Normalized BIC: 0.4225
2025-03-25 22:09:06,661 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-25 22:09:06,661 - INFO - SINDy model parameters for participant 1: 6
2025-03-25 22:09:06,983 - INFO - Participant 1: Log-likelihood: -69.3096, Normalized LL: -0.6931, Raw BIC: 166.2502, Normalized BIC: 1.6625
2025-03-25 22:09:06,983 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-25 22:09:06,984 - INFO - SINDy model parameters for participant 2: 10
2025-03-25 22:09:07,303 - INFO - Participant 2: Log-likelihood: -71.3372, Normalized LL: -0.7134, Raw BIC: 188.7261, Normalized BIC: 1.8873
2025-03-25 22:09:07,303 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-25 22:09:07,304 - INFO - SINDy model parameters for participant 3: 10
2025-03-25 22:09:07,628 - INFO - Participant 3: Log-likelihood: -24.0575, Normalized LL: -0.2406, Raw BIC: 94.1667, Normalized BIC: 0.9417
2025-03-25 22:09:07,628 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-25 22:09:07,628 - INFO - SINDy model parameters for participant 4: 10
2025-03-25 22:09:07,950 - INFO - Participant 4: Log-likelihood: -36.5396, Normalized LL: -0.3654, Raw BIC: 119.1310, Normalized BIC: 1.1913
2025-03-25 22:09:07,950 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-25 22:09:07,951 - INFO - SINDy model parameters for participant 5: 8
2025-03-25 22:09:08,275 - INFO - Participant 5: Log-likelihood: -32.5722, Normalized LL: -0.3257, Raw BIC: 101.9857, Normalized BIC: 1.0199
2025-03-25 22:09:08,275 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-25 22:09:08,276 - INFO - SINDy model parameters for participant 6: 6
2025-03-25 22:09:08,600 - INFO - Participant 6: Log-likelihood: -5.0116, Normalized LL: -0.0501, Raw BIC: 37.6543, Normalized BIC: 0.3765
2025-03-25 22:09:08,600 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-25 22:09:08,600 - INFO - SINDy model parameters for participant 7: 8
2025-03-25 22:09:08,923 - INFO - Participant 7: Log-likelihood: -76.7238, Normalized LL: -0.7672, Raw BIC: 190.2890, Normalized BIC: 1.9029
2025-03-25 22:09:08,923 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-25 22:09:08,923 - INFO - SINDy model parameters for participant 8: 8
2025-03-25 22:09:09,247 - INFO - Participant 8: Log-likelihood: -55.4123, Normalized LL: -0.5541, Raw BIC: 147.6660, Normalized BIC: 1.4767
2025-03-25 22:09:09,247 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-25 22:09:09,248 - INFO - SINDy model parameters for participant 9: 7
2025-03-25 22:09:09,570 - INFO - Participant 9: Log-likelihood: -67.0966, Normalized LL: -0.6710, Raw BIC: 166.4293, Normalized BIC: 1.6643
2025-03-25 22:09:09,570 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-25 22:09:09,570 - INFO - SINDy model parameters for participant 10: 6
2025-03-25 22:09:09,874 - INFO - Participant 10: Log-likelihood: -43.3555, Normalized LL: -0.4336, Raw BIC: 114.3421, Normalized BIC: 1.1434
2025-03-25 22:09:09,874 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-25 22:09:09,874 - INFO - SINDy model parameters for participant 11: 9
2025-03-25 22:09:10,168 - INFO - Participant 11: Log-likelihood: -26.1583, Normalized LL: -0.2616, Raw BIC: 93.7631, Normalized BIC: 0.9376
2025-03-25 22:09:10,169 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-25 22:09:10,169 - INFO - SINDy model parameters for participant 12: 6
2025-03-25 22:09:10,469 - INFO - Participant 12: Log-likelihood: -45.6529, Normalized LL: -0.4565, Raw BIC: 118.9368, Normalized BIC: 1.1894
2025-03-25 22:09:10,469 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-25 22:09:10,469 - INFO - SINDy model parameters for participant 13: 6
2025-03-25 22:09:10,773 - INFO - Participant 13: Log-likelihood: -23.8112, Normalized LL: -0.2381, Raw BIC: 75.2534, Normalized BIC: 0.7525
2025-03-25 22:09:10,773 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-25 22:09:10,773 - INFO - SINDy model parameters for participant 14: 6
2025-03-25 22:09:11,075 - INFO - Participant 14: Log-likelihood: -49.8558, Normalized LL: -0.4986, Raw BIC: 127.3427, Normalized BIC: 1.2734
2025-03-25 22:09:11,075 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-25 22:09:11,075 - INFO - SINDy model parameters for participant 15: 9
2025-03-25 22:09:11,375 - INFO - Participant 15: Log-likelihood: -3.3725, Normalized LL: -0.0337, Raw BIC: 48.1916, Normalized BIC: 0.4819
2025-03-25 22:09:11,375 - INFO - Evaluating participant 16 using its own SINDy model...
2025-03-25 22:09:11,376 - INFO - SINDy model parameters for participant 16: 8
2025-03-25 22:09:11,689 - INFO - Participant 16: Log-likelihood: -23.9284, Normalized LL: -0.2393, Raw BIC: 84.6982, Normalized BIC: 0.8470
2025-03-25 22:09:11,689 - INFO - Evaluating participant 17 using its own SINDy model...
2025-03-25 22:09:11,690 - INFO - SINDy model parameters for participant 17: 8
2025-03-25 22:09:11,996 - INFO - Participant 17: Log-likelihood: -61.7931, Normalized LL: -0.6179, Raw BIC: 160.4276, Normalized BIC: 1.6043
2025-03-25 22:09:11,996 - INFO - Evaluating participant 18 using its own SINDy model...
2025-03-25 22:09:11,996 - INFO - SINDy model parameters for participant 18: 8
2025-03-25 22:09:12,295 - INFO - Participant 18: Log-likelihood: -3.0851, Normalized LL: -0.0309, Raw BIC: 43.0116, Normalized BIC: 0.4301
2025-03-25 22:09:12,295 - INFO - Evaluating participant 19 using its own SINDy model...
2025-03-25 22:09:12,295 - INFO - SINDy model parameters for participant 19: 8
2025-03-25 22:09:12,601 - INFO - Participant 19: Log-likelihood: -36.7067, Normalized LL: -0.3671, Raw BIC: 110.2547, Normalized BIC: 1.1025
2025-03-25 22:09:12,601 - INFO - Evaluating participant 20 using its own SINDy model...
2025-03-25 22:09:12,601 - INFO - SINDy model parameters for participant 20: 6
2025-03-25 22:09:12,904 - INFO - Participant 20: Log-likelihood: -14.0352, Normalized LL: -0.1404, Raw BIC: 55.7014, Normalized BIC: 0.5570
2025-03-25 22:09:12,904 - INFO - Evaluating participant 21 using its own SINDy model...
2025-03-25 22:09:12,905 - INFO - SINDy model parameters for participant 21: 6
2025-03-25 22:09:13,205 - INFO - Participant 21: Log-likelihood: -7.7240, Normalized LL: -0.0772, Raw BIC: 43.0790, Normalized BIC: 0.4308
2025-03-25 22:09:13,205 - INFO - Evaluating participant 22 using its own SINDy model...
2025-03-25 22:09:13,206 - INFO - SINDy model parameters for participant 22: 10
2025-03-25 22:09:13,543 - INFO - Participant 22: Log-likelihood: -23.2492, Normalized LL: -0.2325, Raw BIC: 92.5500, Normalized BIC: 0.9255
2025-03-25 22:09:13,543 - INFO - Evaluating participant 23 using its own SINDy model...
2025-03-25 22:09:13,544 - INFO - SINDy model parameters for participant 23: 11
2025-03-25 22:09:13,877 - INFO - Participant 23: Log-likelihood: -46.9517, Normalized LL: -0.4695, Raw BIC: 144.5602, Normalized BIC: 1.4456
2025-03-25 22:09:13,877 - INFO - Evaluating participant 24 using its own SINDy model...
2025-03-25 22:09:13,877 - INFO - SINDy model parameters for participant 24: 10
2025-03-25 22:09:14,203 - INFO - Participant 24: Log-likelihood: -74.1063, Normalized LL: -0.7411, Raw BIC: 194.2642, Normalized BIC: 1.9426
2025-03-25 22:09:14,203 - INFO - Evaluating participant 25 using its own SINDy model...
2025-03-25 22:09:14,203 - INFO - SINDy model parameters for participant 25: 6
2025-03-25 22:09:14,517 - INFO - Participant 25: Log-likelihood: -70.0283, Normalized LL: -0.7003, Raw BIC: 167.6876, Normalized BIC: 1.6769
2025-03-25 22:09:14,517 - INFO - Evaluating participant 26 using its own SINDy model...
2025-03-25 22:09:14,517 - INFO - SINDy model parameters for participant 26: 6
2025-03-25 22:09:14,851 - INFO - Participant 26: Log-likelihood: -3.4987, Normalized LL: -0.0350, Raw BIC: 34.6284, Normalized BIC: 0.3463
2025-03-25 22:09:14,851 - INFO - Evaluating participant 27 using its own SINDy model...
2025-03-25 22:09:14,851 - INFO - SINDy model parameters for participant 27: 10
2025-03-25 22:09:15,192 - INFO - Participant 27: Log-likelihood: -52.9228, Normalized LL: -0.5292, Raw BIC: 151.8973, Normalized BIC: 1.5190
2025-03-25 22:09:15,192 - INFO - Evaluating participant 28 using its own SINDy model...
2025-03-25 22:09:15,192 - INFO - SINDy model parameters for participant 28: 6
2025-03-25 22:09:15,508 - INFO - Participant 28: Log-likelihood: -21.1909, Normalized LL: -0.2119, Raw BIC: 70.0129, Normalized BIC: 0.7001
2025-03-25 22:09:15,508 - INFO - Evaluating participant 29 using its own SINDy model...
2025-03-25 22:09:15,508 - INFO - SINDy model parameters for participant 29: 8
2025-03-25 22:09:15,815 - INFO - Participant 29: Log-likelihood: -26.0268, Normalized LL: -0.2603, Raw BIC: 88.8950, Normalized BIC: 0.8890
2025-03-25 22:09:15,815 - INFO - Evaluating participant 30 using its own SINDy model...
2025-03-25 22:09:15,816 - INFO - SINDy model parameters for participant 30: 12
2025-03-25 22:09:16,122 - INFO - Participant 30: Log-likelihood: -39.5411, Normalized LL: -0.3954, Raw BIC: 134.3441, Normalized BIC: 1.3434
2025-03-25 22:09:16,122 - INFO - Evaluating participant 31 using its own SINDy model...
2025-03-25 22:09:16,122 - INFO - SINDy model parameters for participant 31: 8
2025-03-25 22:09:16,434 - INFO - Participant 31: Log-likelihood: -23.8055, Normalized LL: -0.2381, Raw BIC: 84.4523, Normalized BIC: 0.8445
2025-03-25 22:09:16,434 - INFO - Evaluating participant 32 using its own SINDy model...
2025-03-25 22:09:16,434 - INFO - SINDy model parameters for participant 32: 8
2025-03-25 22:09:16,744 - INFO - Participant 32: Log-likelihood: -20.4146, Normalized LL: -0.2041, Raw BIC: 77.6706, Normalized BIC: 0.7767
2025-03-25 22:09:16,744 - INFO - Evaluating participant 33 using its own SINDy model...
2025-03-25 22:09:16,744 - INFO - SINDy model parameters for participant 33: 6
2025-03-25 22:09:17,055 - INFO - Participant 33: Log-likelihood: -35.0871, Normalized LL: -0.3509, Raw BIC: 97.8052, Normalized BIC: 0.9781
2025-03-25 22:09:17,055 - INFO - Evaluating participant 34 using its own SINDy model...
2025-03-25 22:09:17,056 - INFO - SINDy model parameters for participant 34: 6
2025-03-25 22:09:17,360 - INFO - Participant 34: Log-likelihood: -40.6291, Normalized LL: -0.4063, Raw BIC: 108.8891, Normalized BIC: 1.0889
2025-03-25 22:09:17,360 - INFO - Evaluating participant 35 using its own SINDy model...
2025-03-25 22:09:17,361 - INFO - SINDy model parameters for participant 35: 8
2025-03-25 22:09:17,664 - INFO - Participant 35: Log-likelihood: -65.0428, Normalized LL: -0.6504, Raw BIC: 166.9269, Normalized BIC: 1.6693
2025-03-25 22:09:17,664 - INFO - Evaluating participant 36 using its own SINDy model...
2025-03-25 22:09:17,664 - INFO - SINDy model parameters for participant 36: 9
2025-03-25 22:09:17,977 - INFO - Participant 36: Log-likelihood: -51.6936, Normalized LL: -0.5169, Raw BIC: 144.8338, Normalized BIC: 1.4483
2025-03-25 22:09:17,977 - INFO - Evaluating participant 37 using its own SINDy model...
2025-03-25 22:09:17,977 - INFO - SINDy model parameters for participant 37: 8
2025-03-25 22:09:18,278 - INFO - Participant 37: Log-likelihood: -3.9803, Normalized LL: -0.0398, Raw BIC: 44.8020, Normalized BIC: 0.4480
2025-03-25 22:09:18,278 - INFO - Evaluating participant 38 using its own SINDy model...
2025-03-25 22:09:18,279 - INFO - SINDy model parameters for participant 38: 10
2025-03-25 22:09:18,581 - INFO - Participant 38: Log-likelihood: -3.9985, Normalized LL: -0.0400, Raw BIC: 54.0487, Normalized BIC: 0.5405
2025-03-25 22:09:18,581 - INFO - Evaluating participant 39 using its own SINDy model...
2025-03-25 22:09:18,581 - INFO - SINDy model parameters for participant 39: 6
2025-03-25 22:09:18,889 - INFO - Participant 39: Log-likelihood: -24.6879, Normalized LL: -0.2469, Raw BIC: 77.0067, Normalized BIC: 0.7701
2025-03-25 22:09:18,890 - INFO - Evaluating participant 40 using its own SINDy model...
2025-03-25 22:09:18,890 - INFO - SINDy model parameters for participant 40: 6
2025-03-25 22:09:19,193 - INFO - Participant 40: Log-likelihood: -71.1022, Normalized LL: -0.7110, Raw BIC: 169.8354, Normalized BIC: 1.6984
2025-03-25 22:09:19,193 - INFO - Evaluating participant 41 using its own SINDy model...
2025-03-25 22:09:19,193 - INFO - SINDy model parameters for participant 41: 11
2025-03-25 22:09:19,518 - INFO - Participant 41: Log-likelihood: -76.0689, Normalized LL: -0.7607, Raw BIC: 202.7947, Normalized BIC: 2.0279
2025-03-25 22:09:19,518 - INFO - Evaluating participant 42 using its own SINDy model...
2025-03-25 22:09:19,519 - INFO - SINDy model parameters for participant 42: 8
2025-03-25 22:09:19,842 - INFO - Participant 42: Log-likelihood: -24.3884, Normalized LL: -0.2439, Raw BIC: 85.6183, Normalized BIC: 0.8562
2025-03-25 22:09:19,842 - INFO - Evaluating participant 43 using its own SINDy model...
2025-03-25 22:09:19,842 - INFO - SINDy model parameters for participant 43: 8
2025-03-25 22:09:20,162 - INFO - Participant 43: Log-likelihood: -70.5212, Normalized LL: -0.7052, Raw BIC: 177.8838, Normalized BIC: 1.7788
2025-03-25 22:09:20,162 - INFO - Evaluating participant 44 using its own SINDy model...
2025-03-25 22:09:20,162 - INFO - SINDy model parameters for participant 44: 6
2025-03-25 22:09:20,491 - INFO - Participant 44: Log-likelihood: -10.0381, Normalized LL: -0.1004, Raw BIC: 47.7073, Normalized BIC: 0.4771
2025-03-25 22:09:20,491 - INFO - Evaluating participant 45 using its own SINDy model...
2025-03-25 22:09:20,492 - INFO - SINDy model parameters for participant 45: 8
2025-03-25 22:09:20,816 - INFO - Participant 45: Log-likelihood: -5.7004, Normalized LL: -0.0570, Raw BIC: 48.2422, Normalized BIC: 0.4824
2025-03-25 22:09:20,816 - INFO - Evaluating participant 46 using its own SINDy model...
2025-03-25 22:09:20,816 - INFO - SINDy model parameters for participant 46: 8
2025-03-25 22:09:21,139 - INFO - Participant 46: Log-likelihood: -51.4692, Normalized LL: -0.5147, Raw BIC: 139.7798, Normalized BIC: 1.3978
2025-03-25 22:09:21,139 - INFO - Evaluating participant 47 using its own SINDy model...
2025-03-25 22:09:21,139 - INFO - SINDy model parameters for participant 47: 9
2025-03-25 22:09:21,465 - INFO - Participant 47: Log-likelihood: -66.7521, Normalized LL: -0.6675, Raw BIC: 174.9507, Normalized BIC: 1.7495
2025-03-25 22:09:21,465 - INFO - Evaluating participant 48 using its own SINDy model...
2025-03-25 22:09:21,465 - INFO - SINDy model parameters for participant 48: 8
2025-03-25 22:09:21,790 - INFO - Participant 48: Log-likelihood: -29.1848, Normalized LL: -0.2918, Raw BIC: 95.2110, Normalized BIC: 0.9521
2025-03-25 22:09:21,790 - INFO - Evaluating participant 49 using its own SINDy model...
2025-03-25 22:09:21,790 - INFO - SINDy model parameters for participant 49: 10
2025-03-25 22:09:22,112 - INFO - Participant 49: Log-likelihood: -19.1396, Normalized LL: -0.1914, Raw BIC: 84.3308, Normalized BIC: 0.8433
2025-03-25 22:09:22,112 - INFO - Evaluating participant 50 using its own SINDy model...
2025-03-25 22:09:22,112 - INFO - SINDy model parameters for participant 50: 10
2025-03-25 22:09:22,438 - INFO - Participant 50: Log-likelihood: -3.0874, Normalized LL: -0.0309, Raw BIC: 52.2264, Normalized BIC: 0.5223
2025-03-25 22:09:22,438 - INFO - Evaluating participant 51 using its own SINDy model...
2025-03-25 22:09:22,438 - INFO - SINDy model parameters for participant 51: 10
2025-03-25 22:09:22,738 - INFO - Participant 51: Log-likelihood: -15.0224, Normalized LL: -0.1502, Raw BIC: 76.0966, Normalized BIC: 0.7610
2025-03-25 22:09:22,738 - INFO - Evaluating participant 52 using its own SINDy model...
2025-03-25 22:09:22,738 - INFO - SINDy model parameters for participant 52: 10
2025-03-25 22:09:23,037 - INFO - Participant 52: Log-likelihood: -45.7007, Normalized LL: -0.4570, Raw BIC: 137.4531, Normalized BIC: 1.3745
2025-03-25 22:09:23,037 - INFO - Evaluating participant 53 using its own SINDy model...
2025-03-25 22:09:23,037 - INFO - SINDy model parameters for participant 53: 8
2025-03-25 22:09:23,336 - INFO - Participant 53: Log-likelihood: -2.5941, Normalized LL: -0.0259, Raw BIC: 42.0295, Normalized BIC: 0.4203
2025-03-25 22:09:23,336 - INFO - Evaluating participant 54 using its own SINDy model...
2025-03-25 22:09:23,337 - INFO - SINDy model parameters for participant 54: 9
2025-03-25 22:09:23,637 - INFO - Participant 54: Log-likelihood: -26.8300, Normalized LL: -0.2683, Raw BIC: 95.1066, Normalized BIC: 0.9511
2025-03-25 22:09:23,637 - INFO - Evaluating participant 55 using its own SINDy model...
2025-03-25 22:09:23,637 - INFO - SINDy model parameters for participant 55: 6
2025-03-25 22:09:23,939 - INFO - Participant 55: Log-likelihood: -16.5220, Normalized LL: -0.1652, Raw BIC: 60.6751, Normalized BIC: 0.6068
2025-03-25 22:09:23,939 - INFO - Evaluating participant 56 using its own SINDy model...
2025-03-25 22:09:23,939 - INFO - SINDy model parameters for participant 56: 12
2025-03-25 22:09:24,240 - INFO - Participant 56: Log-likelihood: -30.3032, Normalized LL: -0.3030, Raw BIC: 115.8685, Normalized BIC: 1.1587
2025-03-25 22:09:24,240 - INFO - Evaluating participant 57 using its own SINDy model...
2025-03-25 22:09:24,240 - INFO - SINDy model parameters for participant 57: 10
2025-03-25 22:09:24,542 - INFO - Participant 57: Log-likelihood: -13.3757, Normalized LL: -0.1338, Raw BIC: 72.8032, Normalized BIC: 0.7280
2025-03-25 22:09:24,542 - INFO - Evaluating participant 58 using its own SINDy model...
2025-03-25 22:09:24,542 - INFO - SINDy model parameters for participant 58: 8
2025-03-25 22:09:24,853 - INFO - Participant 58: Log-likelihood: -57.1738, Normalized LL: -0.5717, Raw BIC: 151.1889, Normalized BIC: 1.5119
2025-03-25 22:09:24,854 - INFO - Evaluating participant 59 using its own SINDy model...
2025-03-25 22:09:24,854 - INFO - SINDy model parameters for participant 59: 6
2025-03-25 22:09:25,161 - INFO - Participant 59: Log-likelihood: -2.2382, Normalized LL: -0.0224, Raw BIC: 32.1074, Normalized BIC: 0.3211
2025-03-25 22:09:25,161 - INFO - Evaluating participant 60 using its own SINDy model...
2025-03-25 22:09:25,161 - INFO - SINDy model parameters for participant 60: 8
2025-03-25 22:09:25,465 - INFO - Participant 60: Log-likelihood: -7.4811, Normalized LL: -0.0748, Raw BIC: 51.8035, Normalized BIC: 0.5180
2025-03-25 22:09:25,466 - INFO - Evaluating participant 61 using its own SINDy model...
2025-03-25 22:09:25,466 - INFO - SINDy model parameters for participant 61: 6
2025-03-25 22:09:25,766 - INFO - Participant 61: Log-likelihood: -3.7900, Normalized LL: -0.0379, Raw BIC: 35.2111, Normalized BIC: 0.3521
2025-03-25 22:09:25,766 - INFO - Evaluating participant 62 using its own SINDy model...
2025-03-25 22:09:25,766 - INFO - SINDy model parameters for participant 62: 8
2025-03-25 22:09:26,067 - INFO - Participant 62: Log-likelihood: -32.3737, Normalized LL: -0.3237, Raw BIC: 101.5887, Normalized BIC: 1.0159
2025-03-25 22:09:26,067 - INFO - Evaluating participant 63 using its own SINDy model...
2025-03-25 22:09:26,067 - INFO - SINDy model parameters for participant 63: 10
2025-03-25 22:09:26,371 - INFO - Participant 63: Log-likelihood: -47.8234, Normalized LL: -0.4782, Raw BIC: 141.6985, Normalized BIC: 1.4170
2025-03-25 22:09:26,371 - INFO - Evaluating participant 64 using its own SINDy model...
2025-03-25 22:09:26,371 - INFO - SINDy model parameters for participant 64: 6
2025-03-25 22:09:26,673 - INFO - Participant 64: Log-likelihood: -2.9303, Normalized LL: -0.0293, Raw BIC: 33.4915, Normalized BIC: 0.3349
2025-03-25 22:09:26,673 - INFO - Evaluating participant 65 using its own SINDy model...
2025-03-25 22:09:26,673 - INFO - SINDy model parameters for participant 65: 7
2025-03-25 22:09:26,983 - INFO - Participant 65: Log-likelihood: -35.6472, Normalized LL: -0.3565, Raw BIC: 103.5306, Normalized BIC: 1.0353
2025-03-25 22:09:26,983 - INFO - Evaluating participant 66 using its own SINDy model...
2025-03-25 22:09:26,983 - INFO - SINDy model parameters for participant 66: 8
2025-03-25 22:09:27,290 - INFO - Participant 66: Log-likelihood: -74.2440, Normalized LL: -0.7424, Raw BIC: 185.3294, Normalized BIC: 1.8533
2025-03-25 22:09:27,290 - INFO - Evaluating participant 67 using its own SINDy model...
2025-03-25 22:09:27,291 - INFO - SINDy model parameters for participant 67: 6
2025-03-25 22:09:27,598 - INFO - Participant 67: Log-likelihood: -53.0727, Normalized LL: -0.5307, Raw BIC: 133.7765, Normalized BIC: 1.3378
2025-03-25 22:09:27,598 - INFO - Evaluating participant 68 using its own SINDy model...
2025-03-25 22:09:27,598 - INFO - SINDy model parameters for participant 68: 10
2025-03-25 22:09:27,927 - INFO - Participant 68: Log-likelihood: -60.1723, Normalized LL: -0.6017, Raw BIC: 166.3962, Normalized BIC: 1.6640
2025-03-25 22:09:27,927 - INFO - Evaluating participant 69 using its own SINDy model...
2025-03-25 22:09:27,928 - INFO - SINDy model parameters for participant 69: 8
2025-03-25 22:09:28,256 - INFO - Participant 69: Log-likelihood: -52.9645, Normalized LL: -0.5296, Raw BIC: 142.7704, Normalized BIC: 1.4277
2025-03-25 22:09:28,256 - INFO - Evaluating participant 70 using its own SINDy model...
2025-03-25 22:09:28,256 - INFO - SINDy model parameters for participant 70: 8
2025-03-25 22:09:28,585 - INFO - Participant 70: Log-likelihood: -10.6194, Normalized LL: -0.1062, Raw BIC: 58.0801, Normalized BIC: 0.5808
2025-03-25 22:09:28,585 - INFO - Evaluating participant 71 using its own SINDy model...
2025-03-25 22:09:28,585 - INFO - SINDy model parameters for participant 71: 8
2025-03-25 22:09:28,912 - INFO - Participant 71: Log-likelihood: -33.3919, Normalized LL: -0.3339, Raw BIC: 103.6252, Normalized BIC: 1.0363
2025-03-25 22:09:28,912 - INFO - Evaluating participant 72 using its own SINDy model...
2025-03-25 22:09:28,912 - INFO - SINDy model parameters for participant 72: 8
2025-03-25 22:09:29,237 - INFO - Participant 72: Log-likelihood: -41.6142, Normalized LL: -0.4161, Raw BIC: 120.0698, Normalized BIC: 1.2007
2025-03-25 22:09:29,238 - INFO - Evaluating participant 73 using its own SINDy model...
2025-03-25 22:09:29,238 - INFO - SINDy model parameters for participant 73: 7
2025-03-25 22:09:29,564 - INFO - Participant 73: Log-likelihood: -73.8501, Normalized LL: -0.7385, Raw BIC: 179.9363, Normalized BIC: 1.7994
2025-03-25 22:09:29,564 - INFO - Evaluating participant 74 using its own SINDy model...
2025-03-25 22:09:29,564 - INFO - SINDy model parameters for participant 74: 6
2025-03-25 22:09:29,887 - INFO - Participant 74: Log-likelihood: -16.5582, Normalized LL: -0.1656, Raw BIC: 60.7473, Normalized BIC: 0.6075
2025-03-25 22:09:29,887 - INFO - Evaluating participant 75 using its own SINDy model...
2025-03-25 22:09:29,887 - INFO - SINDy model parameters for participant 75: 12
2025-03-25 22:09:30,209 - INFO - Participant 75: Log-likelihood: -38.1228, Normalized LL: -0.3812, Raw BIC: 131.5077, Normalized BIC: 1.3151
2025-03-25 22:09:30,209 - INFO - Evaluating participant 76 using its own SINDy model...
2025-03-25 22:09:30,209 - INFO - SINDy model parameters for participant 76: 6
2025-03-25 22:09:30,544 - INFO - Participant 76: Log-likelihood: -10.4793, Normalized LL: -0.1048, Raw BIC: 48.5895, Normalized BIC: 0.4859
2025-03-25 22:09:30,544 - INFO - Evaluating participant 77 using its own SINDy model...
2025-03-25 22:09:30,544 - INFO - SINDy model parameters for participant 77: 6
2025-03-25 22:09:30,868 - INFO - Participant 77: Log-likelihood: -73.5122, Normalized LL: -0.7351, Raw BIC: 174.6553, Normalized BIC: 1.7466
2025-03-25 22:09:30,868 - INFO - Evaluating participant 78 using its own SINDy model...
2025-03-25 22:09:30,868 - INFO - SINDy model parameters for participant 78: 6
2025-03-25 22:09:31,189 - INFO - Participant 78: Log-likelihood: -45.7143, Normalized LL: -0.4571, Raw BIC: 119.0596, Normalized BIC: 1.1906
2025-03-25 22:09:31,189 - INFO - Evaluating participant 79 using its own SINDy model...
2025-03-25 22:09:31,189 - INFO - SINDy model parameters for participant 79: 6
2025-03-25 22:09:31,512 - INFO - Participant 79: Log-likelihood: -58.7038, Normalized LL: -0.5870, Raw BIC: 145.0386, Normalized BIC: 1.4504
2025-03-25 22:09:31,512 - INFO - Evaluating participant 80 using its own SINDy model...
2025-03-25 22:09:31,513 - INFO - SINDy model parameters for participant 80: 8
2025-03-25 22:09:31,836 - INFO - Participant 80: Log-likelihood: -61.1810, Normalized LL: -0.6118, Raw BIC: 159.2034, Normalized BIC: 1.5920
2025-03-25 22:09:31,837 - INFO - Evaluating participant 81 using its own SINDy model...
2025-03-25 22:09:31,837 - INFO - SINDy model parameters for participant 81: 10
2025-03-25 22:09:32,161 - INFO - Participant 81: Log-likelihood: -24.7856, Normalized LL: -0.2479, Raw BIC: 95.6228, Normalized BIC: 0.9562
2025-03-25 22:09:32,161 - INFO - Evaluating participant 82 using its own SINDy model...
2025-03-25 22:09:32,162 - INFO - SINDy model parameters for participant 82: 6
2025-03-25 22:09:32,489 - INFO - Participant 82: Log-likelihood: -2.7160, Normalized LL: -0.0272, Raw BIC: 33.0629, Normalized BIC: 0.3306
2025-03-25 22:09:32,490 - INFO - Evaluating participant 83 using its own SINDy model...
2025-03-25 22:09:32,490 - INFO - SINDy model parameters for participant 83: 6
2025-03-25 22:09:32,815 - INFO - Participant 83: Log-likelihood: -21.7855, Normalized LL: -0.2179, Raw BIC: 71.2021, Normalized BIC: 0.7120
2025-03-25 22:09:32,815 - INFO - Evaluating participant 84 using its own SINDy model...
2025-03-25 22:09:32,816 - INFO - SINDy model parameters for participant 84: 10
2025-03-25 22:09:33,140 - INFO - Participant 84: Log-likelihood: -83.3483, Normalized LL: -0.8335, Raw BIC: 212.7482, Normalized BIC: 2.1275
2025-03-25 22:09:33,141 - INFO - Evaluating participant 85 using its own SINDy model...
2025-03-25 22:09:33,141 - INFO - SINDy model parameters for participant 85: 6
2025-03-25 22:09:33,466 - INFO - Participant 85: Log-likelihood: -2.4205, Normalized LL: -0.0242, Raw BIC: 32.4719, Normalized BIC: 0.3247
2025-03-25 22:09:33,466 - INFO - Evaluating participant 86 using its own SINDy model...
2025-03-25 22:09:33,466 - INFO - SINDy model parameters for participant 86: 10
2025-03-25 22:09:33,789 - INFO - Participant 86: Log-likelihood: -3.2184, Normalized LL: -0.0322, Raw BIC: 52.4885, Normalized BIC: 0.5249
2025-03-25 22:09:33,789 - INFO - Evaluating participant 87 using its own SINDy model...
2025-03-25 22:09:33,789 - INFO - SINDy model parameters for participant 87: 6
2025-03-25 22:09:34,117 - INFO - Participant 87: Log-likelihood: -27.3247, Normalized LL: -0.2732, Raw BIC: 82.2805, Normalized BIC: 0.8228
2025-03-25 22:09:34,117 - INFO - Evaluating participant 88 using its own SINDy model...
2025-03-25 22:09:34,118 - INFO - SINDy model parameters for participant 88: 10
2025-03-25 22:09:34,440 - INFO - Participant 88: Log-likelihood: -67.3648, Normalized LL: -0.6736, Raw BIC: 180.7814, Normalized BIC: 1.8078
2025-03-25 22:09:34,440 - INFO - Evaluating participant 89 using its own SINDy model...
2025-03-25 22:09:34,440 - INFO - SINDy model parameters for participant 89: 6
2025-03-25 22:09:34,767 - INFO - Participant 89: Log-likelihood: -15.2488, Normalized LL: -0.1525, Raw BIC: 58.1287, Normalized BIC: 0.5813
2025-03-25 22:09:34,768 - INFO - Evaluating participant 90 using its own SINDy model...
2025-03-25 22:09:34,768 - INFO - SINDy model parameters for participant 90: 8
2025-03-25 22:09:35,101 - INFO - Participant 90: Log-likelihood: -65.5691, Normalized LL: -0.6557, Raw BIC: 167.9796, Normalized BIC: 1.6798
2025-03-25 22:09:35,101 - INFO - Evaluating participant 91 using its own SINDy model...
2025-03-25 22:09:35,101 - INFO - SINDy model parameters for participant 91: 10
2025-03-25 22:09:35,428 - INFO - Participant 91: Log-likelihood: -16.4183, Normalized LL: -0.1642, Raw BIC: 78.8883, Normalized BIC: 0.7889
2025-03-25 22:09:35,428 - INFO - Evaluating participant 92 using its own SINDy model...
2025-03-25 22:09:35,428 - INFO - SINDy model parameters for participant 92: 8
2025-03-25 22:09:35,753 - INFO - Participant 92: Log-likelihood: -3.6353, Normalized LL: -0.0364, Raw BIC: 44.1119, Normalized BIC: 0.4411
2025-03-25 22:09:35,753 - INFO - Evaluating participant 93 using its own SINDy model...
2025-03-25 22:09:35,753 - INFO - SINDy model parameters for participant 93: 8
2025-03-25 22:09:36,078 - INFO - Participant 93: Log-likelihood: -40.6429, Normalized LL: -0.4064, Raw BIC: 118.1271, Normalized BIC: 1.1813
2025-03-25 22:09:36,078 - INFO - Evaluating participant 94 using its own SINDy model...
2025-03-25 22:09:36,079 - INFO - SINDy model parameters for participant 94: 10
2025-03-25 22:09:36,399 - INFO - Participant 94: Log-likelihood: -68.1512, Normalized LL: -0.6815, Raw BIC: 182.3540, Normalized BIC: 1.8235
2025-03-25 22:09:36,399 - INFO - Evaluating participant 95 using its own SINDy model...
2025-03-25 22:09:36,399 - INFO - SINDy model parameters for participant 95: 8
2025-03-25 22:09:36,721 - INFO - Participant 95: Log-likelihood: -63.8949, Normalized LL: -0.6389, Raw BIC: 164.6312, Normalized BIC: 1.6463
2025-03-25 22:09:36,721 - INFO - Evaluating participant 96 using its own SINDy model...
2025-03-25 22:09:36,722 - INFO - SINDy model parameters for participant 96: 12
2025-03-25 22:09:37,044 - INFO - Participant 96: Log-likelihood: -6.9074, Normalized LL: -0.0691, Raw BIC: 69.0768, Normalized BIC: 0.6908
2025-03-25 22:09:37,044 - INFO - Evaluating participant 97 using its own SINDy model...
2025-03-25 22:09:37,044 - INFO - SINDy model parameters for participant 97: 7
2025-03-25 22:09:37,367 - INFO - Participant 97: Log-likelihood: -66.4722, Normalized LL: -0.6647, Raw BIC: 165.1806, Normalized BIC: 1.6518
2025-03-25 22:09:37,367 - INFO - Evaluating participant 98 using its own SINDy model...
2025-03-25 22:09:37,367 - INFO - SINDy model parameters for participant 98: 8
2025-03-25 22:09:37,688 - INFO - Participant 98: Log-likelihood: -2.0482, Normalized LL: -0.0205, Raw BIC: 40.9378, Normalized BIC: 0.4094
2025-03-25 22:09:37,688 - INFO - Evaluating participant 99 using its own SINDy model...
2025-03-25 22:09:37,688 - INFO - SINDy model parameters for participant 99: 6
2025-03-25 22:09:38,010 - INFO - Participant 99: Log-likelihood: -26.9833, Normalized LL: -0.2698, Raw BIC: 81.5975, Normalized BIC: 0.8160
2025-03-25 22:09:38,010 - INFO - Evaluating participant 100 using its own SINDy model...
2025-03-25 22:09:38,010 - INFO - SINDy model parameters for participant 100: 6
2025-03-25 22:09:38,325 - INFO - Participant 100: Log-likelihood: -2.9154, Normalized LL: -0.0292, Raw BIC: 33.4619, Normalized BIC: 0.3346
2025-03-25 22:09:38,325 - INFO - Evaluating participant 101 using its own SINDy model...
2025-03-25 22:09:38,325 - INFO - SINDy model parameters for participant 101: 9
2025-03-25 22:09:38,672 - INFO - Participant 101: Log-likelihood: -44.2788, Normalized LL: -0.4428, Raw BIC: 130.0042, Normalized BIC: 1.3000
2025-03-25 22:09:38,672 - INFO - Evaluating participant 102 using its own SINDy model...
2025-03-25 22:09:38,672 - INFO - SINDy model parameters for participant 102: 10
2025-03-25 22:09:38,983 - INFO - Participant 102: Log-likelihood: -61.8392, Normalized LL: -0.6184, Raw BIC: 169.7300, Normalized BIC: 1.6973
2025-03-25 22:09:38,984 - INFO - Evaluating participant 103 using its own SINDy model...
2025-03-25 22:09:38,984 - INFO - SINDy model parameters for participant 103: 7
2025-03-25 22:09:39,300 - INFO - Participant 103: Log-likelihood: -14.3768, Normalized LL: -0.1438, Raw BIC: 60.9898, Normalized BIC: 0.6099
2025-03-25 22:09:39,300 - INFO - Evaluating participant 104 using its own SINDy model...
2025-03-25 22:09:39,301 - INFO - SINDy model parameters for participant 104: 8
2025-03-25 22:09:39,605 - INFO - Participant 104: Log-likelihood: -69.8332, Normalized LL: -0.6983, Raw BIC: 176.5077, Normalized BIC: 1.7651
2025-03-25 22:09:39,605 - INFO - Evaluating participant 105 using its own SINDy model...
2025-03-25 22:09:39,605 - INFO - SINDy model parameters for participant 105: 11
2025-03-25 22:09:39,932 - INFO - Participant 105: Log-likelihood: -29.2993, Normalized LL: -0.2930, Raw BIC: 109.2555, Normalized BIC: 1.0926
2025-03-25 22:09:39,932 - INFO - Evaluating participant 106 using its own SINDy model...
2025-03-25 22:09:39,933 - INFO - SINDy model parameters for participant 106: 9
2025-03-25 22:09:40,255 - INFO - Participant 106: Log-likelihood: -62.8275, Normalized LL: -0.6283, Raw BIC: 167.1015, Normalized BIC: 1.6710
2025-03-25 22:09:40,255 - INFO - Evaluating participant 107 using its own SINDy model...
2025-03-25 22:09:40,256 - INFO - SINDy model parameters for participant 107: 8
2025-03-25 22:09:40,564 - INFO - Participant 107: Log-likelihood: -15.1736, Normalized LL: -0.1517, Raw BIC: 67.1885, Normalized BIC: 0.6719
2025-03-25 22:09:40,564 - INFO - Evaluating participant 108 using its own SINDy model...
2025-03-25 22:09:40,564 - INFO - SINDy model parameters for participant 108: 6
2025-03-25 22:09:40,864 - INFO - Participant 108: Log-likelihood: -41.3715, Normalized LL: -0.4137, Raw BIC: 110.3740, Normalized BIC: 1.1037
2025-03-25 22:09:40,864 - INFO - Evaluating participant 109 using its own SINDy model...
2025-03-25 22:09:40,864 - INFO - SINDy model parameters for participant 109: 9
2025-03-25 22:09:41,174 - INFO - Participant 109: Log-likelihood: -65.7887, Normalized LL: -0.6579, Raw BIC: 173.0239, Normalized BIC: 1.7302
2025-03-25 22:09:41,174 - INFO - Evaluating participant 110 using its own SINDy model...
2025-03-25 22:09:41,174 - INFO - SINDy model parameters for participant 110: 8
2025-03-25 22:09:41,516 - INFO - Participant 110: Log-likelihood: -13.0340, Normalized LL: -0.1303, Raw BIC: 62.9093, Normalized BIC: 0.6291
2025-03-25 22:09:41,516 - INFO - Evaluating participant 111 using its own SINDy model...
2025-03-25 22:09:41,517 - INFO - SINDy model parameters for participant 111: 10
2025-03-25 22:09:41,832 - INFO - Participant 111: Log-likelihood: -24.2614, Normalized LL: -0.2426, Raw BIC: 94.5746, Normalized BIC: 0.9457
2025-03-25 22:09:41,832 - INFO - Evaluating participant 112 using its own SINDy model...
2025-03-25 22:09:41,832 - INFO - SINDy model parameters for participant 112: 6
2025-03-25 22:09:42,155 - INFO - Participant 112: Log-likelihood: -41.6663, Normalized LL: -0.4167, Raw BIC: 110.9635, Normalized BIC: 1.1096
2025-03-25 22:09:42,155 - INFO - Evaluating participant 113 using its own SINDy model...
2025-03-25 22:09:42,156 - INFO - SINDy model parameters for participant 113: 6
2025-03-25 22:09:42,486 - INFO - Participant 113: Log-likelihood: -39.5622, Normalized LL: -0.3956, Raw BIC: 106.7554, Normalized BIC: 1.0676
2025-03-25 22:09:42,487 - INFO - Evaluating participant 114 using its own SINDy model...
2025-03-25 22:09:42,487 - INFO - SINDy model parameters for participant 114: 8
2025-03-25 22:09:42,818 - INFO - Participant 114: Log-likelihood: -35.8064, Normalized LL: -0.3581, Raw BIC: 108.4541, Normalized BIC: 1.0845
2025-03-25 22:09:42,818 - INFO - Evaluating participant 115 using its own SINDy model...
2025-03-25 22:09:42,818 - INFO - SINDy model parameters for participant 115: 6
2025-03-25 22:09:43,145 - INFO - Participant 115: Log-likelihood: -29.0514, Normalized LL: -0.2905, Raw BIC: 85.7338, Normalized BIC: 0.8573
2025-03-25 22:09:43,145 - INFO - Evaluating participant 116 using its own SINDy model...
2025-03-25 22:09:43,145 - INFO - SINDy model parameters for participant 116: 10
2025-03-25 22:09:43,467 - INFO - Participant 116: Log-likelihood: -24.0531, Normalized LL: -0.2405, Raw BIC: 94.1579, Normalized BIC: 0.9416
2025-03-25 22:09:43,467 - INFO - Evaluating participant 117 using its own SINDy model...
2025-03-25 22:09:43,467 - INFO - SINDy model parameters for participant 117: 9
2025-03-25 22:09:43,789 - INFO - Participant 117: Log-likelihood: -37.1409, Normalized LL: -0.3714, Raw BIC: 115.7284, Normalized BIC: 1.1573
2025-03-25 22:09:43,789 - INFO - Evaluating participant 118 using its own SINDy model...
2025-03-25 22:09:43,789 - INFO - SINDy model parameters for participant 118: 8
2025-03-25 22:09:44,107 - INFO - Participant 118: Log-likelihood: -62.8775, Normalized LL: -0.6288, Raw BIC: 162.5963, Normalized BIC: 1.6260
2025-03-25 22:09:44,107 - INFO - Evaluating participant 119 using its own SINDy model...
2025-03-25 22:09:44,107 - INFO - SINDy model parameters for participant 119: 6
2025-03-25 22:09:44,423 - INFO - Participant 119: Log-likelihood: -37.3123, Normalized LL: -0.3731, Raw BIC: 102.2556, Normalized BIC: 1.0226
2025-03-25 22:09:44,423 - INFO - Evaluating participant 120 using its own SINDy model...
2025-03-25 22:09:44,424 - INFO - SINDy model parameters for participant 120: 6
2025-03-25 22:09:44,749 - INFO - Participant 120: Log-likelihood: -16.6216, Normalized LL: -0.1662, Raw BIC: 60.8742, Normalized BIC: 0.6087
2025-03-25 22:09:44,749 - INFO - Evaluating participant 121 using its own SINDy model...
2025-03-25 22:09:44,749 - INFO - SINDy model parameters for participant 121: 8
2025-03-25 22:09:45,070 - INFO - Participant 121: Log-likelihood: -17.5734, Normalized LL: -0.1757, Raw BIC: 71.9881, Normalized BIC: 0.7199
2025-03-25 22:09:45,070 - INFO - Evaluating participant 122 using its own SINDy model...
2025-03-25 22:09:45,070 - INFO - SINDy model parameters for participant 122: 6
2025-03-25 22:09:45,394 - INFO - Participant 122: Log-likelihood: -32.3291, Normalized LL: -0.3233, Raw BIC: 92.2893, Normalized BIC: 0.9229
2025-03-25 22:09:45,394 - INFO - Evaluating participant 123 using its own SINDy model...
2025-03-25 22:09:45,394 - INFO - SINDy model parameters for participant 123: 6
2025-03-25 22:09:45,756 - INFO - Participant 123: Log-likelihood: -72.7277, Normalized LL: -0.7273, Raw BIC: 173.0864, Normalized BIC: 1.7309
2025-03-25 22:09:45,757 - INFO - Evaluating participant 124 using its own SINDy model...
2025-03-25 22:09:45,757 - INFO - SINDy model parameters for participant 124: 12
2025-03-25 22:09:46,083 - INFO - Participant 124: Log-likelihood: -3.4488, Normalized LL: -0.0345, Raw BIC: 62.1597, Normalized BIC: 0.6216
2025-03-25 22:09:46,083 - INFO - Evaluating participant 125 using its own SINDy model...
2025-03-25 22:09:46,084 - INFO - SINDy model parameters for participant 125: 6
2025-03-25 22:09:46,402 - INFO - Participant 125: Log-likelihood: -15.9785, Normalized LL: -0.1598, Raw BIC: 59.5881, Normalized BIC: 0.5959
2025-03-25 22:09:46,402 - INFO - Evaluating participant 126 using its own SINDy model...
2025-03-25 22:09:46,403 - INFO - SINDy model parameters for participant 126: 9
2025-03-25 22:09:46,719 - INFO - Participant 126: Log-likelihood: -23.1582, Normalized LL: -0.2316, Raw BIC: 87.7629, Normalized BIC: 0.8776
2025-03-25 22:09:46,720 - INFO - Evaluating participant 127 using its own SINDy model...
2025-03-25 22:09:46,720 - INFO - SINDy model parameters for participant 127: 13
2025-03-25 22:09:47,039 - INFO - Participant 127: Log-likelihood: -36.5282, Normalized LL: -0.3653, Raw BIC: 132.9236, Normalized BIC: 1.3292
2025-03-25 22:09:47,040 - INFO - Evaluating participant 128 using its own SINDy model...
2025-03-25 22:09:47,040 - INFO - SINDy model parameters for participant 128: 8
2025-03-25 22:09:47,357 - INFO - Participant 128: Log-likelihood: -3.4695, Normalized LL: -0.0347, Raw BIC: 43.7804, Normalized BIC: 0.4378
2025-03-25 22:09:47,358 - INFO - Evaluating participant 129 using its own SINDy model...
2025-03-25 22:09:47,358 - INFO - SINDy model parameters for participant 129: 9
2025-03-25 22:09:47,679 - INFO - Participant 129: Log-likelihood: -29.0921, Normalized LL: -0.2909, Raw BIC: 99.6307, Normalized BIC: 0.9963
2025-03-25 22:09:47,679 - INFO - Evaluating participant 130 using its own SINDy model...
2025-03-25 22:09:47,679 - INFO - SINDy model parameters for participant 130: 6
2025-03-25 22:09:48,031 - INFO - Participant 130: Log-likelihood: -38.3745, Normalized LL: -0.3837, Raw BIC: 104.3799, Normalized BIC: 1.0438
2025-03-25 22:09:48,031 - INFO - Evaluating participant 131 using its own SINDy model...
2025-03-25 22:09:48,031 - INFO - SINDy model parameters for participant 131: 6
2025-03-25 22:09:48,348 - INFO - Participant 131: Log-likelihood: -32.4685, Normalized LL: -0.3247, Raw BIC: 92.5680, Normalized BIC: 0.9257
2025-03-25 22:09:48,348 - INFO - Evaluating participant 132 using its own SINDy model...
2025-03-25 22:09:48,348 - INFO - SINDy model parameters for participant 132: 6
2025-03-25 22:09:48,661 - INFO - Participant 132: Log-likelihood: -41.0226, Normalized LL: -0.4102, Raw BIC: 109.6762, Normalized BIC: 1.0968
2025-03-25 22:09:48,661 - INFO - Evaluating participant 133 using its own SINDy model...
2025-03-25 22:09:48,662 - INFO - SINDy model parameters for participant 133: 8
2025-03-25 22:09:48,986 - INFO - Participant 133: Log-likelihood: -16.2861, Normalized LL: -0.1629, Raw BIC: 69.4135, Normalized BIC: 0.6941
2025-03-25 22:09:48,986 - INFO - Evaluating participant 134 using its own SINDy model...
2025-03-25 22:09:48,986 - INFO - SINDy model parameters for participant 134: 10
2025-03-25 22:09:49,306 - INFO - Participant 134: Log-likelihood: -18.9902, Normalized LL: -0.1899, Raw BIC: 84.0321, Normalized BIC: 0.8403
2025-03-25 22:09:49,306 - INFO - Evaluating participant 135 using its own SINDy model...
2025-03-25 22:09:49,306 - INFO - SINDy model parameters for participant 135: 8
2025-03-25 22:09:49,626 - INFO - Participant 135: Log-likelihood: -17.9957, Normalized LL: -0.1800, Raw BIC: 72.8328, Normalized BIC: 0.7283
2025-03-25 22:09:49,626 - INFO - Evaluating participant 136 using its own SINDy model...
2025-03-25 22:09:49,626 - INFO - SINDy model parameters for participant 136: 9
2025-03-25 22:09:49,963 - INFO - Participant 136: Log-likelihood: -12.7077, Normalized LL: -0.1271, Raw BIC: 66.8619, Normalized BIC: 0.6686
2025-03-25 22:09:49,963 - INFO - Evaluating participant 137 using its own SINDy model...
2025-03-25 22:09:49,963 - INFO - SINDy model parameters for participant 137: 6
2025-03-25 22:09:50,289 - INFO - Participant 137: Log-likelihood: -29.7605, Normalized LL: -0.2976, Raw BIC: 87.1520, Normalized BIC: 0.8715
2025-03-25 22:09:50,290 - INFO - Evaluating participant 138 using its own SINDy model...
2025-03-25 22:09:50,290 - INFO - SINDy model parameters for participant 138: 6
2025-03-25 22:09:50,608 - INFO - Participant 138: Log-likelihood: -34.0635, Normalized LL: -0.3406, Raw BIC: 95.7580, Normalized BIC: 0.9576
2025-03-25 22:09:50,608 - INFO - Evaluating participant 139 using its own SINDy model...
2025-03-25 22:09:50,609 - INFO - SINDy model parameters for participant 139: 8
2025-03-25 22:09:50,925 - INFO - Participant 139: Log-likelihood: -79.0230, Normalized LL: -0.7902, Raw BIC: 194.8874, Normalized BIC: 1.9489
2025-03-25 22:09:50,925 - INFO - Evaluating participant 140 using its own SINDy model...
2025-03-25 22:09:50,925 - INFO - SINDy model parameters for participant 140: 6
2025-03-25 22:09:51,242 - INFO - Participant 140: Log-likelihood: -8.8758, Normalized LL: -0.0888, Raw BIC: 45.3827, Normalized BIC: 0.4538
2025-03-25 22:09:51,242 - INFO - Evaluating participant 141 using its own SINDy model...
2025-03-25 22:09:51,242 - INFO - SINDy model parameters for participant 141: 13
2025-03-25 22:09:51,560 - INFO - Participant 141: Log-likelihood: -34.9983, Normalized LL: -0.3500, Raw BIC: 129.8638, Normalized BIC: 1.2986
2025-03-25 22:09:51,560 - INFO - Evaluating participant 142 using its own SINDy model...
2025-03-25 22:09:51,560 - INFO - SINDy model parameters for participant 142: 6
2025-03-25 22:09:51,918 - INFO - Participant 142: Log-likelihood: -45.6802, Normalized LL: -0.4568, Raw BIC: 118.9914, Normalized BIC: 1.1899
2025-03-25 22:09:51,918 - INFO - Evaluating participant 143 using its own SINDy model...
2025-03-25 22:09:51,918 - INFO - SINDy model parameters for participant 143: 12
2025-03-25 22:09:52,225 - INFO - Participant 143: Log-likelihood: -69.3739, Normalized LL: -0.6937, Raw BIC: 194.0099, Normalized BIC: 1.9401
2025-03-25 22:09:52,226 - INFO - Evaluating participant 144 using its own SINDy model...
2025-03-25 22:09:52,226 - INFO - SINDy model parameters for participant 144: 6
2025-03-25 22:09:52,545 - INFO - Participant 144: Log-likelihood: -2.6924, Normalized LL: -0.0269, Raw BIC: 33.0159, Normalized BIC: 0.3302
2025-03-25 22:09:52,545 - INFO - Evaluating participant 145 using its own SINDy model...
2025-03-25 22:09:52,545 - INFO - SINDy model parameters for participant 145: 6
2025-03-25 22:09:52,862 - INFO - Participant 145: Log-likelihood: -2.6072, Normalized LL: -0.0261, Raw BIC: 32.8455, Normalized BIC: 0.3285
2025-03-25 22:09:52,862 - INFO - Evaluating participant 146 using its own SINDy model...
2025-03-25 22:09:52,862 - INFO - SINDy model parameters for participant 146: 6
2025-03-25 22:09:53,182 - INFO - Participant 146: Log-likelihood: -60.4925, Normalized LL: -0.6049, Raw BIC: 148.6160, Normalized BIC: 1.4862
2025-03-25 22:09:53,182 - INFO - Evaluating participant 147 using its own SINDy model...
2025-03-25 22:09:53,182 - INFO - SINDy model parameters for participant 147: 12
2025-03-25 22:09:53,500 - INFO - Participant 147: Log-likelihood: -74.6191, Normalized LL: -0.7462, Raw BIC: 204.5002, Normalized BIC: 2.0450
2025-03-25 22:09:53,500 - INFO - Evaluating participant 148 using its own SINDy model...
2025-03-25 22:09:53,500 - INFO - SINDy model parameters for participant 148: 8
2025-03-25 22:09:53,802 - INFO - Participant 148: Log-likelihood: -41.3134, Normalized LL: -0.4131, Raw BIC: 119.4682, Normalized BIC: 1.1947
2025-03-25 22:09:53,802 - INFO - Evaluating participant 149 using its own SINDy model...
2025-03-25 22:09:53,802 - INFO - SINDy model parameters for participant 149: 6
2025-03-25 22:09:54,120 - INFO - Participant 149: Log-likelihood: -3.7282, Normalized LL: -0.0373, Raw BIC: 35.0874, Normalized BIC: 0.3509
2025-03-25 22:09:54,120 - INFO - Evaluating participant 150 using its own SINDy model...
2025-03-25 22:09:54,120 - INFO - SINDy model parameters for participant 150: 10
2025-03-25 22:09:54,462 - INFO - Participant 150: Log-likelihood: -11.2401, Normalized LL: -0.1124, Raw BIC: 68.5320, Normalized BIC: 0.6853
2025-03-25 22:09:54,462 - INFO - Evaluating participant 151 using its own SINDy model...
2025-03-25 22:09:54,462 - INFO - SINDy model parameters for participant 151: 9
2025-03-25 22:09:54,784 - INFO - Participant 151: Log-likelihood: -47.8646, Normalized LL: -0.4786, Raw BIC: 137.1757, Normalized BIC: 1.3718
2025-03-25 22:09:54,784 - INFO - Evaluating participant 152 using its own SINDy model...
2025-03-25 22:09:54,784 - INFO - SINDy model parameters for participant 152: 10
2025-03-25 22:09:55,106 - INFO - Participant 152: Log-likelihood: -12.4364, Normalized LL: -0.1244, Raw BIC: 70.9245, Normalized BIC: 0.7092
2025-03-25 22:09:55,106 - INFO - Evaluating participant 153 using its own SINDy model...
2025-03-25 22:09:55,106 - INFO - SINDy model parameters for participant 153: 8
2025-03-25 22:09:55,415 - INFO - Participant 153: Log-likelihood: -47.8646, Normalized LL: -0.4786, Raw BIC: 132.5705, Normalized BIC: 1.3257
2025-03-25 22:09:55,416 - INFO - Evaluating participant 154 using its own SINDy model...
2025-03-25 22:09:55,416 - INFO - SINDy model parameters for participant 154: 9
2025-03-25 22:09:55,770 - INFO - Participant 154: Log-likelihood: -77.3405, Normalized LL: -0.7734, Raw BIC: 196.1274, Normalized BIC: 1.9613
2025-03-25 22:09:55,770 - INFO - Evaluating participant 155 using its own SINDy model...
2025-03-25 22:09:55,770 - INFO - SINDy model parameters for participant 155: 11
2025-03-25 22:09:56,088 - INFO - Participant 155: Log-likelihood: -11.6394, Normalized LL: -0.1164, Raw BIC: 73.9357, Normalized BIC: 0.7394
2025-03-25 22:09:56,088 - INFO - Evaluating participant 156 using its own SINDy model...
2025-03-25 22:09:56,088 - INFO - SINDy model parameters for participant 156: 8
2025-03-25 22:09:56,409 - INFO - Participant 156: Log-likelihood: -52.7057, Normalized LL: -0.5271, Raw BIC: 142.2527, Normalized BIC: 1.4225
2025-03-25 22:09:56,409 - INFO - Evaluating participant 157 using its own SINDy model...
2025-03-25 22:09:56,410 - INFO - SINDy model parameters for participant 157: 10
2025-03-25 22:09:56,712 - INFO - Participant 157: Log-likelihood: -23.5514, Normalized LL: -0.2355, Raw BIC: 93.1545, Normalized BIC: 0.9315
2025-03-25 22:09:56,712 - INFO - Evaluating participant 158 using its own SINDy model...
2025-03-25 22:09:56,712 - INFO - SINDy model parameters for participant 158: 6
2025-03-25 22:09:57,014 - INFO - Participant 158: Log-likelihood: -3.3967, Normalized LL: -0.0340, Raw BIC: 34.4245, Normalized BIC: 0.3442
2025-03-25 22:09:57,014 - INFO - Evaluating participant 159 using its own SINDy model...
2025-03-25 22:09:57,014 - INFO - SINDy model parameters for participant 159: 8
2025-03-25 22:09:57,323 - INFO - Participant 159: Log-likelihood: -66.0683, Normalized LL: -0.6607, Raw BIC: 168.9779, Normalized BIC: 1.6898
2025-03-25 22:09:57,323 - INFO - Evaluating participant 160 using its own SINDy model...
2025-03-25 22:09:57,323 - INFO - SINDy model parameters for participant 160: 12
2025-03-25 22:09:57,655 - INFO - Participant 160: Log-likelihood: -75.1462, Normalized LL: -0.7515, Raw BIC: 205.5545, Normalized BIC: 2.0555
2025-03-25 22:09:57,655 - INFO - Evaluating participant 161 using its own SINDy model...
2025-03-25 22:09:57,656 - INFO - SINDy model parameters for participant 161: 8
2025-03-25 22:09:57,965 - INFO - Participant 161: Log-likelihood: -38.5463, Normalized LL: -0.3855, Raw BIC: 113.9340, Normalized BIC: 1.1393
2025-03-25 22:09:57,965 - INFO - Evaluating participant 162 using its own SINDy model...
2025-03-25 22:09:57,965 - INFO - SINDy model parameters for participant 162: 10
2025-03-25 22:09:58,272 - INFO - Participant 162: Log-likelihood: -22.0872, Normalized LL: -0.2209, Raw BIC: 90.2261, Normalized BIC: 0.9023
2025-03-25 22:09:58,272 - INFO - Evaluating participant 163 using its own SINDy model...
2025-03-25 22:09:58,272 - INFO - SINDy model parameters for participant 163: 11
2025-03-25 22:09:58,578 - INFO - Participant 163: Log-likelihood: -46.8714, Normalized LL: -0.4687, Raw BIC: 144.3997, Normalized BIC: 1.4440
2025-03-25 22:09:58,578 - INFO - Evaluating participant 164 using its own SINDy model...
2025-03-25 22:09:58,578 - INFO - SINDy model parameters for participant 164: 12
2025-03-25 22:09:58,879 - INFO - Participant 164: Log-likelihood: -41.8963, Normalized LL: -0.4190, Raw BIC: 139.0547, Normalized BIC: 1.3905
2025-03-25 22:09:58,879 - INFO - Evaluating participant 165 using its own SINDy model...
2025-03-25 22:09:58,879 - INFO - SINDy model parameters for participant 165: 9
2025-03-25 22:09:59,203 - INFO - Participant 165: Log-likelihood: -10.1088, Normalized LL: -0.1011, Raw BIC: 61.6641, Normalized BIC: 0.6166
2025-03-25 22:09:59,203 - INFO - Evaluating participant 166 using its own SINDy model...
2025-03-25 22:09:59,204 - INFO - SINDy model parameters for participant 166: 12
2025-03-25 22:09:59,515 - INFO - Participant 166: Log-likelihood: -15.4639, Normalized LL: -0.1546, Raw BIC: 86.1899, Normalized BIC: 0.8619
2025-03-25 22:09:59,515 - INFO - Evaluating participant 167 using its own SINDy model...
2025-03-25 22:09:59,515 - INFO - SINDy model parameters for participant 167: 6
2025-03-25 22:09:59,824 - INFO - Participant 167: Log-likelihood: -56.2373, Normalized LL: -0.5624, Raw BIC: 140.1057, Normalized BIC: 1.4011
2025-03-25 22:09:59,824 - INFO - Evaluating participant 168 using its own SINDy model...
2025-03-25 22:09:59,825 - INFO - SINDy model parameters for participant 168: 6
2025-03-25 22:10:00,128 - INFO - Participant 168: Log-likelihood: -44.5725, Normalized LL: -0.4457, Raw BIC: 116.7761, Normalized BIC: 1.1678
2025-03-25 22:10:00,128 - INFO - Evaluating participant 169 using its own SINDy model...
2025-03-25 22:10:00,128 - INFO - SINDy model parameters for participant 169: 10
2025-03-25 22:10:00,429 - INFO - Participant 169: Log-likelihood: -2.9937, Normalized LL: -0.0299, Raw BIC: 52.0391, Normalized BIC: 0.5204
2025-03-25 22:10:00,430 - INFO - Evaluating participant 170 using its own SINDy model...
2025-03-25 22:10:00,430 - INFO - SINDy model parameters for participant 170: 8
2025-03-25 22:10:00,732 - INFO - Participant 170: Log-likelihood: -60.8096, Normalized LL: -0.6081, Raw BIC: 158.4605, Normalized BIC: 1.5846
2025-03-25 22:10:00,732 - INFO - Evaluating participant 171 using its own SINDy model...
2025-03-25 22:10:00,732 - INFO - SINDy model parameters for participant 171: 10
2025-03-25 22:10:01,035 - INFO - Participant 171: Log-likelihood: -78.6366, Normalized LL: -0.7864, Raw BIC: 203.3249, Normalized BIC: 2.0332
2025-03-25 22:10:01,035 - INFO - Evaluating participant 172 using its own SINDy model...
2025-03-25 22:10:01,035 - INFO - SINDy model parameters for participant 172: 8
2025-03-25 22:10:01,338 - INFO - Participant 172: Log-likelihood: -15.2543, Normalized LL: -0.1525, Raw BIC: 67.3500, Normalized BIC: 0.6735
2025-03-25 22:10:01,338 - INFO - Evaluating participant 173 using its own SINDy model...
2025-03-25 22:10:01,338 - INFO - SINDy model parameters for participant 173: 6
2025-03-25 22:10:01,642 - INFO - Participant 173: Log-likelihood: -56.1371, Normalized LL: -0.5614, Raw BIC: 139.9052, Normalized BIC: 1.3991
2025-03-25 22:10:01,642 - INFO - Evaluating participant 174 using its own SINDy model...
2025-03-25 22:10:01,642 - INFO - SINDy model parameters for participant 174: 6
2025-03-25 22:10:01,943 - INFO - Participant 174: Log-likelihood: -29.5146, Normalized LL: -0.2951, Raw BIC: 86.6602, Normalized BIC: 0.8666
2025-03-25 22:10:01,943 - INFO - Evaluating participant 175 using its own SINDy model...
2025-03-25 22:10:01,944 - INFO - SINDy model parameters for participant 175: 10
2025-03-25 22:10:02,247 - INFO - Participant 175: Log-likelihood: -74.1324, Normalized LL: -0.7413, Raw BIC: 194.3165, Normalized BIC: 1.9432
2025-03-25 22:10:02,247 - INFO - Evaluating participant 176 using its own SINDy model...
2025-03-25 22:10:02,247 - INFO - SINDy model parameters for participant 176: 9
2025-03-25 22:10:02,550 - INFO - Participant 176: Log-likelihood: -3.4855, Normalized LL: -0.0349, Raw BIC: 48.4176, Normalized BIC: 0.4842
2025-03-25 22:10:02,550 - INFO - Evaluating participant 177 using its own SINDy model...
2025-03-25 22:10:02,551 - INFO - SINDy model parameters for participant 177: 11
2025-03-25 22:10:02,870 - INFO - Participant 177: Log-likelihood: -64.1364, Normalized LL: -0.6414, Raw BIC: 178.9297, Normalized BIC: 1.7893
2025-03-25 22:10:02,870 - INFO - Evaluating participant 178 using its own SINDy model...
2025-03-25 22:10:02,871 - INFO - SINDy model parameters for participant 178: 6
2025-03-25 22:10:03,194 - INFO - Participant 178: Log-likelihood: -14.2820, Normalized LL: -0.1428, Raw BIC: 56.1950, Normalized BIC: 0.5620
2025-03-25 22:10:03,195 - INFO - Evaluating participant 179 using its own SINDy model...
2025-03-25 22:10:03,195 - INFO - SINDy model parameters for participant 179: 6
2025-03-25 22:10:03,523 - INFO - Participant 179: Log-likelihood: -14.9284, Normalized LL: -0.1493, Raw BIC: 57.4878, Normalized BIC: 0.5749
2025-03-25 22:10:03,523 - INFO - Evaluating participant 180 using its own SINDy model...
2025-03-25 22:10:03,524 - INFO - SINDy model parameters for participant 180: 8
2025-03-25 22:10:03,845 - INFO - Participant 180: Log-likelihood: -16.0718, Normalized LL: -0.1607, Raw BIC: 68.9850, Normalized BIC: 0.6898
2025-03-25 22:10:03,845 - INFO - Evaluating participant 181 using its own SINDy model...
2025-03-25 22:10:03,845 - INFO - SINDy model parameters for participant 181: 8
2025-03-25 22:10:04,169 - INFO - Participant 181: Log-likelihood: -12.5736, Normalized LL: -0.1257, Raw BIC: 61.9885, Normalized BIC: 0.6199
2025-03-25 22:10:04,169 - INFO - Evaluating participant 182 using its own SINDy model...
2025-03-25 22:10:04,169 - INFO - SINDy model parameters for participant 182: 6
2025-03-25 22:10:04,499 - INFO - Participant 182: Log-likelihood: -3.2101, Normalized LL: -0.0321, Raw BIC: 34.0511, Normalized BIC: 0.3405
2025-03-25 22:10:04,499 - INFO - Evaluating participant 183 using its own SINDy model...
2025-03-25 22:10:04,499 - INFO - SINDy model parameters for participant 183: 10
2025-03-25 22:10:04,821 - INFO - Participant 183: Log-likelihood: -64.1685, Normalized LL: -0.6417, Raw BIC: 174.3888, Normalized BIC: 1.7439
2025-03-25 22:10:04,821 - INFO - Evaluating participant 184 using its own SINDy model...
2025-03-25 22:10:04,821 - INFO - SINDy model parameters for participant 184: 7
2025-03-25 22:10:05,142 - INFO - Participant 184: Log-likelihood: -74.8695, Normalized LL: -0.7487, Raw BIC: 181.9751, Normalized BIC: 1.8198
2025-03-25 22:10:05,142 - INFO - Evaluating participant 185 using its own SINDy model...
2025-03-25 22:10:05,142 - INFO - SINDy model parameters for participant 185: 8
2025-03-25 22:10:05,465 - INFO - Participant 185: Log-likelihood: -22.0923, Normalized LL: -0.2209, Raw BIC: 81.0259, Normalized BIC: 0.8103
2025-03-25 22:10:05,465 - INFO - Evaluating participant 186 using its own SINDy model...
2025-03-25 22:10:05,465 - INFO - SINDy model parameters for participant 186: 10
2025-03-25 22:10:05,784 - INFO - Participant 186: Log-likelihood: -65.1381, Normalized LL: -0.6514, Raw BIC: 176.3279, Normalized BIC: 1.7633
2025-03-25 22:10:05,784 - INFO - Evaluating participant 187 using its own SINDy model...
2025-03-25 22:10:05,784 - INFO - SINDy model parameters for participant 187: 10
2025-03-25 22:10:06,105 - INFO - Participant 187: Log-likelihood: -60.8831, Normalized LL: -0.6088, Raw BIC: 167.8179, Normalized BIC: 1.6782
2025-03-25 22:10:06,105 - INFO - Evaluating participant 188 using its own SINDy model...
2025-03-25 22:10:06,105 - INFO - SINDy model parameters for participant 188: 9
2025-03-25 22:10:06,424 - INFO - Participant 188: Log-likelihood: -22.6856, Normalized LL: -0.2269, Raw BIC: 86.8177, Normalized BIC: 0.8682
2025-03-25 22:10:06,424 - INFO - Evaluating participant 189 using its own SINDy model...
2025-03-25 22:10:06,424 - INFO - SINDy model parameters for participant 189: 8
2025-03-25 22:10:06,744 - INFO - Participant 189: Log-likelihood: -65.0559, Normalized LL: -0.6506, Raw BIC: 166.9531, Normalized BIC: 1.6695
2025-03-25 22:10:06,744 - INFO - Evaluating participant 190 using its own SINDy model...
2025-03-25 22:10:06,744 - INFO - SINDy model parameters for participant 190: 9
2025-03-25 22:10:07,064 - INFO - Participant 190: Log-likelihood: -71.6729, Normalized LL: -0.7167, Raw BIC: 184.7924, Normalized BIC: 1.8479
2025-03-25 22:10:07,064 - INFO - Evaluating participant 191 using its own SINDy model...
2025-03-25 22:10:07,065 - INFO - SINDy model parameters for participant 191: 6
2025-03-25 22:10:07,385 - INFO - Participant 191: Log-likelihood: -13.5235, Normalized LL: -0.1352, Raw BIC: 54.6780, Normalized BIC: 0.5468
2025-03-25 22:10:07,385 - INFO - Evaluating participant 192 using its own SINDy model...
2025-03-25 22:10:07,385 - INFO - SINDy model parameters for participant 192: 6
2025-03-25 22:10:07,706 - INFO - Participant 192: Log-likelihood: -54.7008, Normalized LL: -0.5470, Raw BIC: 137.0325, Normalized BIC: 1.3703
2025-03-25 22:10:07,706 - INFO - Evaluating participant 193 using its own SINDy model...
2025-03-25 22:10:07,706 - INFO - SINDy model parameters for participant 193: 6
2025-03-25 22:10:08,015 - INFO - Participant 193: Log-likelihood: -10.7029, Normalized LL: -0.1070, Raw BIC: 49.0368, Normalized BIC: 0.4904
2025-03-25 22:10:08,015 - INFO - Evaluating participant 194 using its own SINDy model...
2025-03-25 22:10:08,016 - INFO - SINDy model parameters for participant 194: 6
2025-03-25 22:10:08,334 - INFO - Participant 194: Log-likelihood: -38.8520, Normalized LL: -0.3885, Raw BIC: 105.3349, Normalized BIC: 1.0533
2025-03-25 22:10:08,334 - INFO - Evaluating participant 195 using its own SINDy model...
2025-03-25 22:10:08,334 - INFO - SINDy model parameters for participant 195: 11
2025-03-25 22:10:08,657 - INFO - Participant 195: Log-likelihood: -75.1973, Normalized LL: -0.7520, Raw BIC: 201.0515, Normalized BIC: 2.0105
2025-03-25 22:10:08,657 - INFO - Evaluating participant 196 using its own SINDy model...
2025-03-25 22:10:08,657 - INFO - SINDy model parameters for participant 196: 6
2025-03-25 22:10:08,977 - INFO - Participant 196: Log-likelihood: -68.6634, Normalized LL: -0.6866, Raw BIC: 164.9578, Normalized BIC: 1.6496
2025-03-25 22:10:08,977 - INFO - Evaluating participant 197 using its own SINDy model...
2025-03-25 22:10:08,978 - INFO - SINDy model parameters for participant 197: 8
2025-03-25 22:10:09,298 - INFO - Participant 197: Log-likelihood: -3.3801, Normalized LL: -0.0338, Raw BIC: 43.6016, Normalized BIC: 0.4360
2025-03-25 22:10:09,298 - INFO - Evaluating participant 198 using its own SINDy model...
2025-03-25 22:10:09,299 - INFO - SINDy model parameters for participant 198: 13
2025-03-25 22:10:09,617 - INFO - Participant 198: Log-likelihood: -29.5273, Normalized LL: -0.2953, Raw BIC: 118.9218, Normalized BIC: 1.1892
2025-03-25 22:10:09,617 - INFO - Evaluating participant 199 using its own SINDy model...
2025-03-25 22:10:09,617 - INFO - SINDy model parameters for participant 199: 6
2025-03-25 22:10:09,937 - INFO - Participant 199: Log-likelihood: -71.6658, Normalized LL: -0.7167, Raw BIC: 170.9625, Normalized BIC: 1.7096
2025-03-25 22:10:09,937 - INFO - Evaluating participant 200 using its own SINDy model...
2025-03-25 22:10:09,937 - INFO - SINDy model parameters for participant 200: 6
2025-03-25 22:10:10,260 - INFO - Participant 200: Log-likelihood: -22.6884, Normalized LL: -0.2269, Raw BIC: 73.0078, Normalized BIC: 0.7301
2025-03-25 22:10:10,260 - INFO - Evaluating participant 201 using its own SINDy model...
2025-03-25 22:10:10,260 - INFO - SINDy model parameters for participant 201: 6
2025-03-25 22:10:10,583 - INFO - Participant 201: Log-likelihood: -51.0369, Normalized LL: -0.5104, Raw BIC: 129.7047, Normalized BIC: 1.2970
2025-03-25 22:10:10,583 - INFO - Evaluating participant 202 using its own SINDy model...
2025-03-25 22:10:10,583 - INFO - SINDy model parameters for participant 202: 10
2025-03-25 22:10:10,901 - INFO - Participant 202: Log-likelihood: -68.6270, Normalized LL: -0.6863, Raw BIC: 183.3057, Normalized BIC: 1.8331
2025-03-25 22:10:10,901 - INFO - Evaluating participant 203 using its own SINDy model...
2025-03-25 22:10:10,901 - INFO - SINDy model parameters for participant 203: 8
2025-03-25 22:10:11,261 - INFO - Participant 203: Log-likelihood: -44.4372, Normalized LL: -0.4444, Raw BIC: 125.7157, Normalized BIC: 1.2572
2025-03-25 22:10:11,261 - INFO - Evaluating participant 204 using its own SINDy model...
2025-03-25 22:10:11,261 - INFO - SINDy model parameters for participant 204: 6
2025-03-25 22:10:11,634 - INFO - Participant 204: Log-likelihood: -28.7796, Normalized LL: -0.2878, Raw BIC: 85.1902, Normalized BIC: 0.8519
2025-03-25 22:10:11,634 - INFO - Evaluating participant 205 using its own SINDy model...
2025-03-25 22:10:11,635 - INFO - SINDy model parameters for participant 205: 8
2025-03-25 22:10:11,960 - INFO - Participant 205: Log-likelihood: -50.7570, Normalized LL: -0.5076, Raw BIC: 138.3554, Normalized BIC: 1.3836
2025-03-25 22:10:11,960 - INFO - Evaluating participant 206 using its own SINDy model...
2025-03-25 22:10:11,961 - INFO - SINDy model parameters for participant 206: 10
2025-03-25 22:10:12,292 - INFO - Participant 206: Log-likelihood: -13.2138, Normalized LL: -0.1321, Raw BIC: 72.4792, Normalized BIC: 0.7248
2025-03-25 22:10:12,292 - INFO - Evaluating participant 207 using its own SINDy model...
2025-03-25 22:10:12,292 - INFO - SINDy model parameters for participant 207: 8
2025-03-25 22:10:12,623 - INFO - Participant 207: Log-likelihood: -3.9241, Normalized LL: -0.0392, Raw BIC: 44.6896, Normalized BIC: 0.4469
2025-03-25 22:10:12,624 - INFO - Evaluating participant 208 using its own SINDy model...
2025-03-25 22:10:12,624 - INFO - SINDy model parameters for participant 208: 12
2025-03-25 22:10:12,973 - INFO - Participant 208: Log-likelihood: -34.7714, Normalized LL: -0.3477, Raw BIC: 124.8048, Normalized BIC: 1.2480
2025-03-25 22:10:12,974 - INFO - Evaluating participant 209 using its own SINDy model...
2025-03-25 22:10:12,974 - INFO - SINDy model parameters for participant 209: 8
2025-03-25 22:10:13,309 - INFO - Participant 209: Log-likelihood: -65.3275, Normalized LL: -0.6533, Raw BIC: 167.4963, Normalized BIC: 1.6750
2025-03-25 22:10:13,309 - INFO - Evaluating participant 210 using its own SINDy model...
2025-03-25 22:10:13,309 - INFO - SINDy model parameters for participant 210: 6
2025-03-25 22:10:13,640 - INFO - Participant 210: Log-likelihood: -49.0485, Normalized LL: -0.4905, Raw BIC: 125.7280, Normalized BIC: 1.2573
2025-03-25 22:10:13,640 - INFO - Evaluating participant 211 using its own SINDy model...
2025-03-25 22:10:13,640 - INFO - SINDy model parameters for participant 211: 10
2025-03-25 22:10:13,961 - INFO - Participant 211: Log-likelihood: -53.2327, Normalized LL: -0.5323, Raw BIC: 152.5172, Normalized BIC: 1.5252
2025-03-25 22:10:13,961 - INFO - Evaluating participant 212 using its own SINDy model...
2025-03-25 22:10:13,961 - INFO - SINDy model parameters for participant 212: 6
2025-03-25 22:10:14,280 - INFO - Participant 212: Log-likelihood: -3.1189, Normalized LL: -0.0312, Raw BIC: 33.8688, Normalized BIC: 0.3387
2025-03-25 22:10:14,281 - INFO - Evaluating participant 213 using its own SINDy model...
2025-03-25 22:10:14,281 - INFO - SINDy model parameters for participant 213: 8
2025-03-25 22:10:14,605 - INFO - Participant 213: Log-likelihood: -57.2274, Normalized LL: -0.5723, Raw BIC: 151.2962, Normalized BIC: 1.5130
2025-03-25 22:10:14,605 - INFO - Evaluating participant 214 using its own SINDy model...
2025-03-25 22:10:14,606 - INFO - SINDy model parameters for participant 214: 6
2025-03-25 22:10:14,933 - INFO - Participant 214: Log-likelihood: -2.8540, Normalized LL: -0.0285, Raw BIC: 33.3390, Normalized BIC: 0.3334
2025-03-25 22:10:14,933 - INFO - Evaluating participant 215 using its own SINDy model...
2025-03-25 22:10:14,934 - INFO - SINDy model parameters for participant 215: 8
2025-03-25 22:10:15,260 - INFO - Participant 215: Log-likelihood: -22.2627, Normalized LL: -0.2226, Raw BIC: 81.3668, Normalized BIC: 0.8137
2025-03-25 22:10:15,260 - INFO - Evaluating participant 216 using its own SINDy model...
2025-03-25 22:10:15,260 - INFO - SINDy model parameters for participant 216: 9
2025-03-25 22:10:15,579 - INFO - Participant 216: Log-likelihood: -4.0334, Normalized LL: -0.0403, Raw BIC: 49.5133, Normalized BIC: 0.4951
2025-03-25 22:10:15,579 - INFO - Evaluating participant 217 using its own SINDy model...
2025-03-25 22:10:15,579 - INFO - SINDy model parameters for participant 217: 6
2025-03-25 22:10:15,899 - INFO - Participant 217: Log-likelihood: -2.4303, Normalized LL: -0.0243, Raw BIC: 32.4917, Normalized BIC: 0.3249
2025-03-25 22:10:15,899 - INFO - Evaluating participant 218 using its own SINDy model...
2025-03-25 22:10:15,900 - INFO - SINDy model parameters for participant 218: 6
2025-03-25 22:10:16,218 - INFO - Participant 218: Log-likelihood: -26.2247, Normalized LL: -0.2622, Raw BIC: 80.0804, Normalized BIC: 0.8008
2025-03-25 22:10:16,218 - INFO - Evaluating participant 219 using its own SINDy model...
2025-03-25 22:10:16,218 - INFO - SINDy model parameters for participant 219: 8
2025-03-25 22:10:16,535 - INFO - Participant 219: Log-likelihood: -4.3604, Normalized LL: -0.0436, Raw BIC: 45.5622, Normalized BIC: 0.4556
2025-03-25 22:10:16,535 - INFO - Evaluating participant 220 using its own SINDy model...
2025-03-25 22:10:16,535 - INFO - SINDy model parameters for participant 220: 12
2025-03-25 22:10:16,853 - INFO - Participant 220: Log-likelihood: -29.4439, Normalized LL: -0.2944, Raw BIC: 114.1499, Normalized BIC: 1.1415
2025-03-25 22:10:16,854 - INFO - Evaluating participant 221 using its own SINDy model...
2025-03-25 22:10:16,854 - INFO - SINDy model parameters for participant 221: 10
2025-03-25 22:10:17,173 - INFO - Participant 221: Log-likelihood: -57.4892, Normalized LL: -0.5749, Raw BIC: 161.0300, Normalized BIC: 1.6103
2025-03-25 22:10:17,173 - INFO - Evaluating participant 222 using its own SINDy model...
2025-03-25 22:10:17,173 - INFO - SINDy model parameters for participant 222: 6
2025-03-25 22:10:17,492 - INFO - Participant 222: Log-likelihood: -35.3529, Normalized LL: -0.3535, Raw BIC: 98.3368, Normalized BIC: 0.9834
2025-03-25 22:10:17,492 - INFO - Evaluating participant 223 using its own SINDy model...
2025-03-25 22:10:17,493 - INFO - SINDy model parameters for participant 223: 6
2025-03-25 22:10:17,811 - INFO - Participant 223: Log-likelihood: -31.4629, Normalized LL: -0.3146, Raw BIC: 90.5568, Normalized BIC: 0.9056
2025-03-25 22:10:17,811 - INFO - Evaluating participant 224 using its own SINDy model...
2025-03-25 22:10:17,811 - INFO - SINDy model parameters for participant 224: 6
2025-03-25 22:10:18,130 - INFO - Participant 224: Log-likelihood: -30.0866, Normalized LL: -0.3009, Raw BIC: 87.8042, Normalized BIC: 0.8780
2025-03-25 22:10:18,130 - INFO - Evaluating participant 225 using its own SINDy model...
2025-03-25 22:10:18,130 - INFO - SINDy model parameters for participant 225: 6
2025-03-25 22:10:18,446 - INFO - Participant 225: Log-likelihood: -19.2126, Normalized LL: -0.1921, Raw BIC: 66.0562, Normalized BIC: 0.6606
2025-03-25 22:10:18,446 - INFO - Evaluating participant 226 using its own SINDy model...
2025-03-25 22:10:18,446 - INFO - SINDy model parameters for participant 226: 6
2025-03-25 22:10:18,769 - INFO - Participant 226: Log-likelihood: -63.4235, Normalized LL: -0.6342, Raw BIC: 154.4780, Normalized BIC: 1.5448
2025-03-25 22:10:18,769 - INFO - Evaluating participant 227 using its own SINDy model...
2025-03-25 22:10:18,769 - INFO - SINDy model parameters for participant 227: 8
2025-03-25 22:10:19,093 - INFO - Participant 227: Log-likelihood: -74.5330, Normalized LL: -0.7453, Raw BIC: 185.9075, Normalized BIC: 1.8591
2025-03-25 22:10:19,093 - INFO - Evaluating participant 228 using its own SINDy model...
2025-03-25 22:10:19,093 - INFO - SINDy model parameters for participant 228: 6
2025-03-25 22:10:19,413 - INFO - Participant 228: Log-likelihood: -14.7458, Normalized LL: -0.1475, Raw BIC: 57.1227, Normalized BIC: 0.5712
2025-03-25 22:10:19,413 - INFO - Evaluating participant 229 using its own SINDy model...
2025-03-25 22:10:19,413 - INFO - SINDy model parameters for participant 229: 10
2025-03-25 22:10:19,734 - INFO - Participant 229: Log-likelihood: -40.0087, Normalized LL: -0.4001, Raw BIC: 126.0690, Normalized BIC: 1.2607
2025-03-25 22:10:19,734 - INFO - Evaluating participant 230 using its own SINDy model...
2025-03-25 22:10:19,734 - INFO - SINDy model parameters for participant 230: 9
2025-03-25 22:10:20,053 - INFO - Participant 230: Log-likelihood: -31.7890, Normalized LL: -0.3179, Raw BIC: 105.0246, Normalized BIC: 1.0502
2025-03-25 22:10:20,053 - INFO - Evaluating participant 231 using its own SINDy model...
2025-03-25 22:10:20,053 - INFO - SINDy model parameters for participant 231: 11
2025-03-25 22:10:20,372 - INFO - Participant 231: Log-likelihood: -25.3123, Normalized LL: -0.2531, Raw BIC: 101.2815, Normalized BIC: 1.0128
2025-03-25 22:10:20,372 - INFO - Evaluating participant 232 using its own SINDy model...
2025-03-25 22:10:20,372 - INFO - SINDy model parameters for participant 232: 6
2025-03-25 22:10:20,688 - INFO - Participant 232: Log-likelihood: -6.3851, Normalized LL: -0.0639, Raw BIC: 40.4013, Normalized BIC: 0.4040
2025-03-25 22:10:20,688 - INFO - Evaluating participant 233 using its own SINDy model...
2025-03-25 22:10:20,688 - INFO - SINDy model parameters for participant 233: 9
2025-03-25 22:10:21,013 - INFO - Participant 233: Log-likelihood: -30.8485, Normalized LL: -0.3085, Raw BIC: 103.1435, Normalized BIC: 1.0314
2025-03-25 22:10:21,013 - INFO - Evaluating participant 234 using its own SINDy model...
2025-03-25 22:10:21,013 - INFO - SINDy model parameters for participant 234: 8
2025-03-25 22:10:21,332 - INFO - Participant 234: Log-likelihood: -21.7863, Normalized LL: -0.2179, Raw BIC: 80.4139, Normalized BIC: 0.8041
2025-03-25 22:10:21,332 - INFO - Evaluating participant 235 using its own SINDy model...
2025-03-25 22:10:21,332 - INFO - SINDy model parameters for participant 235: 6
2025-03-25 22:10:21,647 - INFO - Participant 235: Log-likelihood: -29.0741, Normalized LL: -0.2907, Raw BIC: 85.7792, Normalized BIC: 0.8578
2025-03-25 22:10:21,647 - INFO - Evaluating participant 236 using its own SINDy model...
2025-03-25 22:10:21,648 - INFO - SINDy model parameters for participant 236: 6
2025-03-25 22:10:21,965 - INFO - Participant 236: Log-likelihood: -63.9343, Normalized LL: -0.6393, Raw BIC: 155.4995, Normalized BIC: 1.5550
2025-03-25 22:10:21,966 - INFO - Evaluating participant 237 using its own SINDy model...
2025-03-25 22:10:21,966 - INFO - SINDy model parameters for participant 237: 6
2025-03-25 22:10:22,282 - INFO - Participant 237: Log-likelihood: -4.0676, Normalized LL: -0.0407, Raw BIC: 35.7663, Normalized BIC: 0.3577
2025-03-25 22:10:22,282 - INFO - Evaluating participant 238 using its own SINDy model...
2025-03-25 22:10:22,283 - INFO - SINDy model parameters for participant 238: 8
2025-03-25 22:10:22,607 - INFO - Participant 238: Log-likelihood: -33.3849, Normalized LL: -0.3338, Raw BIC: 103.6113, Normalized BIC: 1.0361
2025-03-25 22:10:22,607 - INFO - Evaluating participant 239 using its own SINDy model...
2025-03-25 22:10:22,607 - INFO - SINDy model parameters for participant 239: 6
2025-03-25 22:10:22,933 - INFO - Participant 239: Log-likelihood: -35.4278, Normalized LL: -0.3543, Raw BIC: 98.4867, Normalized BIC: 0.9849
2025-03-25 22:10:22,933 - INFO - Evaluating participant 240 using its own SINDy model...
2025-03-25 22:10:22,934 - INFO - SINDy model parameters for participant 240: 6
2025-03-25 22:10:23,257 - INFO - Participant 240: Log-likelihood: -25.5438, Normalized LL: -0.2554, Raw BIC: 78.7186, Normalized BIC: 0.7872
2025-03-25 22:10:23,257 - INFO - Evaluating participant 241 using its own SINDy model...
2025-03-25 22:10:23,258 - INFO - SINDy model parameters for participant 241: 8
2025-03-25 22:10:23,585 - INFO - Participant 241: Log-likelihood: -2.9144, Normalized LL: -0.0291, Raw BIC: 42.6702, Normalized BIC: 0.4267
2025-03-25 22:10:23,585 - INFO - Evaluating participant 242 using its own SINDy model...
2025-03-25 22:10:23,585 - INFO - SINDy model parameters for participant 242: 6
2025-03-25 22:10:23,913 - INFO - Participant 242: Log-likelihood: -2.1352, Normalized LL: -0.0214, Raw BIC: 31.9014, Normalized BIC: 0.3190
2025-03-25 22:10:23,913 - INFO - Evaluating participant 243 using its own SINDy model...
2025-03-25 22:10:23,913 - INFO - SINDy model parameters for participant 243: 6
2025-03-25 22:10:24,239 - INFO - Participant 243: Log-likelihood: -53.0193, Normalized LL: -0.5302, Raw BIC: 133.6696, Normalized BIC: 1.3367
2025-03-25 22:10:24,239 - INFO - Evaluating participant 244 using its own SINDy model...
2025-03-25 22:10:24,239 - INFO - SINDy model parameters for participant 244: 6
2025-03-25 22:10:24,564 - INFO - Participant 244: Log-likelihood: -42.2650, Normalized LL: -0.4226, Raw BIC: 112.1610, Normalized BIC: 1.1216
2025-03-25 22:10:24,565 - INFO - Evaluating participant 245 using its own SINDy model...
2025-03-25 22:10:24,565 - INFO - SINDy model parameters for participant 245: 6
2025-03-25 22:10:24,892 - INFO - Participant 245: Log-likelihood: -54.3756, Normalized LL: -0.5438, Raw BIC: 136.3822, Normalized BIC: 1.3638
2025-03-25 22:10:24,892 - INFO - Evaluating participant 246 using its own SINDy model...
2025-03-25 22:10:24,892 - INFO - SINDy model parameters for participant 246: 9
2025-03-25 22:10:25,222 - INFO - Participant 246: Log-likelihood: -59.3051, Normalized LL: -0.5931, Raw BIC: 160.0568, Normalized BIC: 1.6006
2025-03-25 22:10:25,222 - INFO - Evaluating participant 247 using its own SINDy model...
2025-03-25 22:10:25,223 - INFO - SINDy model parameters for participant 247: 8
2025-03-25 22:10:25,543 - INFO - Participant 247: Log-likelihood: -45.9221, Normalized LL: -0.4592, Raw BIC: 128.6855, Normalized BIC: 1.2869
2025-03-25 22:10:25,543 - INFO - Evaluating participant 248 using its own SINDy model...
2025-03-25 22:10:25,544 - INFO - SINDy model parameters for participant 248: 10
2025-03-25 22:10:25,877 - INFO - Participant 248: Log-likelihood: -15.7782, Normalized LL: -0.1578, Raw BIC: 77.6081, Normalized BIC: 0.7761
2025-03-25 22:10:25,877 - INFO - Evaluating participant 249 using its own SINDy model...
2025-03-25 22:10:25,877 - INFO - SINDy model parameters for participant 249: 6
2025-03-25 22:10:26,197 - INFO - Participant 249: Log-likelihood: -21.5659, Normalized LL: -0.2157, Raw BIC: 70.7629, Normalized BIC: 0.7076
2025-03-25 22:10:26,197 - INFO - Evaluating participant 250 using its own SINDy model...
2025-03-25 22:10:26,198 - INFO - SINDy model parameters for participant 250: 7
2025-03-25 22:10:26,521 - INFO - Participant 250: Log-likelihood: -66.9570, Normalized LL: -0.6696, Raw BIC: 166.1501, Normalized BIC: 1.6615
2025-03-25 22:10:26,521 - INFO - Evaluating participant 251 using its own SINDy model...
2025-03-25 22:10:26,521 - INFO - SINDy model parameters for participant 251: 9
2025-03-25 22:10:26,833 - INFO - Participant 251: Log-likelihood: -27.1946, Normalized LL: -0.2719, Raw BIC: 95.8358, Normalized BIC: 0.9584
2025-03-25 22:10:26,833 - INFO - Evaluating participant 252 using its own SINDy model...
2025-03-25 22:10:26,833 - INFO - SINDy model parameters for participant 252: 6
2025-03-25 22:10:27,136 - INFO - Participant 252: Log-likelihood: -34.8172, Normalized LL: -0.3482, Raw BIC: 97.2654, Normalized BIC: 0.9727
2025-03-25 22:10:27,136 - INFO - Evaluating participant 253 using its own SINDy model...
2025-03-25 22:10:27,136 - INFO - SINDy model parameters for participant 253: 9
2025-03-25 22:10:27,441 - INFO - Participant 253: Log-likelihood: -4.0036, Normalized LL: -0.0400, Raw BIC: 49.4537, Normalized BIC: 0.4945
2025-03-25 22:10:27,441 - INFO - Evaluating participant 254 using its own SINDy model...
2025-03-25 22:10:27,442 - INFO - SINDy model parameters for participant 254: 9
2025-03-25 22:10:27,743 - INFO - Participant 254: Log-likelihood: -25.5496, Normalized LL: -0.2555, Raw BIC: 92.5457, Normalized BIC: 0.9255
2025-03-25 22:10:27,743 - INFO - Evaluating participant 255 using its own SINDy model...
2025-03-25 22:10:27,743 - INFO - SINDy model parameters for participant 255: 7
2025-03-25 22:10:28,044 - INFO - Participant 255: Log-likelihood: -48.7688, Normalized LL: -0.4877, Raw BIC: 129.7738, Normalized BIC: 1.2977
2025-03-25 22:10:28,044 - INFO - 
Average SINDy BIC for 100 trials per participant: 1.0662
2025-03-25 22:10:28,044 - INFO - 
Average Normalized Log Likelihood for 100 trials per participant: -0.3491
2025-03-25 22:10:28,044 - INFO - 
Identified SINDy equations:
2025-03-25 22:10:28,044 - INFO - Module: x_learning_rate_reward
2025-03-25 22:10:28,055 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,055 - INFO -   Participant 0 Coefficients: [ 0.70705873  0.17727088  0.21361421 -1.04587424  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,055 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,056 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,056 - INFO -   Participant 1 Coefficients: [0.77257638 0.12640956 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,056 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,058 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,058 - INFO -   Participant 2 Coefficients: [ 0.71638458  0.17166482  0.15348346 -0.40241587  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,058 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,059 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,059 - INFO -   Participant 3 Coefficients: [ 0.76979343  0.14048042  0.13904156 -0.20463195  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,059 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,061 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,061 - INFO -   Participant 4 Coefficients: [ 0.616257    0.23079799  0.17237941 -1.44043467  0.          0.
 -0.09608167  0.          0.         -0.64128206]
2025-03-25 22:10:28,061 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,063 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,063 - INFO -   Participant 5 Coefficients: [0.70887238 0.15974512 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,063 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,064 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,064 - INFO -   Participant 6 Coefficients: [0.72059742 0.15624222 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,064 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,066 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,066 - INFO -   Participant 7 Coefficients: [0.71791527 0.15956182 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,066 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,068 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,068 - INFO -   Participant 8 Coefficients: [ 0.79438947  0.12451483  0.145999   -0.21686949  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,068 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,069 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,070 - INFO -   Participant 9 Coefficients: [0.81569725 0.1025305  0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,070 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,071 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,071 - INFO -   Participant 10 Coefficients: [0.64836318 0.17384664 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,071 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,073 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,073 - INFO -   Participant 11 Coefficients: [ 0.7013998   0.18126943  0.16855807 -0.3797528   0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,073 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,075 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,075 - INFO -   Participant 12 Coefficients: [0.52900762 0.19007392 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,075 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,076 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,076 - INFO -   Participant 13 Coefficients: [0.6946068  0.16101847 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,076 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,078 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,078 - INFO -   Participant 14 Coefficients: [0.70873841 0.15544735 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,078 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,080 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,080 - INFO -   Participant 15 Coefficients: [ 0.62140772  0.22562076  0.19733893 -2.43344947  0.          0.
  0.          0.          0.         -2.52174708]
2025-03-25 22:10:28,080 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,081 - INFO -   Participant 16 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,082 - INFO -   Participant 16 Coefficients: [0.72397699 0.14867261 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,082 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,083 - INFO -   Participant 17 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,084 - INFO -   Participant 17 Coefficients: [0.78441277 0.1237038  0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,084 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,085 - INFO -   Participant 18 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,086 - INFO -   Participant 18 Coefficients: [ 0.70938954  0.17518025  0.17360504 -0.71733635  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,086 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,088 - INFO -   Participant 19 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,088 - INFO -   Participant 19 Coefficients: [0.81156352 0.11157409 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,088 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,090 - INFO -   Participant 20 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,090 - INFO -   Participant 20 Coefficients: [0.64885627 0.17080813 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,090 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,091 - INFO -   Participant 21 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,092 - INFO -   Participant 21 Coefficients: [0.64360699 0.17923191 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,092 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,093 - INFO -   Participant 22 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,093 - INFO -   Participant 22 Coefficients: [ 0.77621027  0.13893932  0.15635689 -0.30994111  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,093 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,095 - INFO -   Participant 23 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,095 - INFO -   Participant 23 Coefficients: [ 0.61355283  0.23063586  0.19679598 -2.8978685   0.          0.
  0.          0.          0.         -3.16179648]
2025-03-25 22:10:28,095 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,097 - INFO -   Participant 24 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,097 - INFO -   Participant 24 Coefficients: [ 0.7344954   0.16185239  0.17802458 -0.572019    0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,097 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,098 - INFO -   Participant 25 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,098 - INFO -   Participant 25 Coefficients: [0.6531581  0.16853571 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,098 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,100 - INFO -   Participant 26 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,100 - INFO -   Participant 26 Coefficients: [0.65884754 0.17414659 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,100 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,101 - INFO -   Participant 27 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,102 - INFO -   Participant 27 Coefficients: [ 0.668506    0.19819941  0.15872878 -0.40165003  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,102 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,104 - INFO -   Participant 28 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,104 - INFO -   Participant 28 Coefficients: [0.72384184 0.14340815 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,104 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,105 - INFO -   Participant 29 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,105 - INFO -   Participant 29 Coefficients: [0.71262939 0.15218892 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,105 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,107 - INFO -   Participant 30 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,107 - INFO -   Participant 30 Coefficients: [ 0.72637975  0.15912358  0.         -0.29129786  0.         -0.18586561
  1.19822818  0.          0.         11.50917519]
2025-03-25 22:10:28,107 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,109 - INFO -   Participant 31 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,109 - INFO -   Participant 31 Coefficients: [ 0.68826829  0.18623991  0.18616185 -0.63477556  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,109 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,110 - INFO -   Participant 32 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,110 - INFO -   Participant 32 Coefficients: [0.71749569 0.15127484 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,110 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,112 - INFO -   Participant 33 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,112 - INFO -   Participant 33 Coefficients: [0.76690206 0.12916776 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,112 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,113 - INFO -   Participant 34 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,114 - INFO -   Participant 34 Coefficients: [0.60811494 0.1862934  0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,114 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,115 - INFO -   Participant 35 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,115 - INFO -   Participant 35 Coefficients: [ 0.71822466  0.16893979  0.14166422 -0.34577562  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,115 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,117 - INFO -   Participant 36 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,117 - INFO -   Participant 36 Coefficients: [ 0.76607784  0.14466511  0.1611443  -0.37696963  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,117 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,119 - INFO -   Participant 37 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,119 - INFO -   Participant 37 Coefficients: [ 0.69679251  0.17991278  0.1755266  -0.35980363  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,119 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,121 - INFO -   Participant 38 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,121 - INFO -   Participant 38 Coefficients: [ 0.76441128  0.14742706  0.16720845 -4.46076007  0.          0.
 -0.21988562  0.          0.          5.57580632]
2025-03-25 22:10:28,121 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,123 - INFO -   Participant 39 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,123 - INFO -   Participant 39 Coefficients: [0.63677203 0.18172988 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,123 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,124 - INFO -   Participant 40 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,124 - INFO -   Participant 40 Coefficients: [0.7334844  0.13970623 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,124 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,126 - INFO -   Participant 41 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,126 - INFO -   Participant 41 Coefficients: [ 0.75585711  0.13032137  0.          0.21329936  0.         -0.15634923
  1.15946803  0.          0.          0.        ]
2025-03-25 22:10:28,126 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,127 - INFO -   Participant 42 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,128 - INFO -   Participant 42 Coefficients: [ 0.74417719  0.15491717  0.1828566  -0.45129517  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,128 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,129 - INFO -   Participant 43 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,129 - INFO -   Participant 43 Coefficients: [ 0.75923203  0.14619314  0.15081932 -0.24179464  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,129 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,131 - INFO -   Participant 44 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,131 - INFO -   Participant 44 Coefficients: [0.75647154 0.12763341 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,131 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,132 - INFO -   Participant 45 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,133 - INFO -   Participant 45 Coefficients: [0.82425594 0.10011438 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,133 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,134 - INFO -   Participant 46 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,134 - INFO -   Participant 46 Coefficients: [ 0.72521347  0.16559767  0.15580452 -0.38098653  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,134 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,136 - INFO -   Participant 47 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,136 - INFO -   Participant 47 Coefficients: [0.74015744 0.14053943 0.         0.12201316 0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,136 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,138 - INFO -   Participant 48 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,138 - INFO -   Participant 48 Coefficients: [ 0.72970012  0.16278447  0.18477559 -0.42168469  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,138 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,139 - INFO -   Participant 49 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,140 - INFO -   Participant 49 Coefficients: [ 0.70212371  0.18024041  0.17353266 -0.60634323  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,140 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,141 - INFO -   Participant 50 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,141 - INFO -   Participant 50 Coefficients: [ 0.69254082  0.16513774  0.         -0.22606081  0.         -0.24416154
  2.27047866  0.          0.         27.76258583]
2025-03-25 22:10:28,141 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,143 - INFO -   Participant 51 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,143 - INFO -   Participant 51 Coefficients: [ 0.76816115  0.14209273  0.15393699 -0.21764108  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,143 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,144 - INFO -   Participant 52 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,145 - INFO -   Participant 52 Coefficients: [ 0.73514412  0.1625302   0.16059856 -0.29763188  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,145 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,146 - INFO -   Participant 53 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,146 - INFO -   Participant 53 Coefficients: [ 0.71222751  0.17380271  0.18824854 -0.70080059  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,146 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,148 - INFO -   Participant 54 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,148 - INFO -   Participant 54 Coefficients: [ 0.63229463  0.2208288   0.17523325 -1.07873855  0.          0.
 -0.07937907  0.          0.          0.        ]
2025-03-25 22:10:28,148 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,149 - INFO -   Participant 55 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,149 - INFO -   Participant 55 Coefficients: [0.66047971 0.17285758 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,149 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,151 - INFO -   Participant 56 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,151 - INFO -   Participant 56 Coefficients: [ 0.72827805  0.1545563   0.         -0.32417231  0.         -0.2015407
  1.63913374  0.          0.         19.0330856 ]
2025-03-25 22:10:28,151 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,153 - INFO -   Participant 57 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,153 - INFO -   Participant 57 Coefficients: [ 0.81772031  0.11311926  0.12931339 -0.14457681  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,153 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,154 - INFO -   Participant 58 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,154 - INFO -   Participant 58 Coefficients: [0.79938646 0.11228762 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,154 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,156 - INFO -   Participant 59 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,156 - INFO -   Participant 59 Coefficients: [0.45582859 0.17212331 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,156 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,158 - INFO -   Participant 60 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,158 - INFO -   Participant 60 Coefficients: [0.82773959 0.09678319 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,158 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,159 - INFO -   Participant 61 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,159 - INFO -   Participant 61 Coefficients: [0.68315584 0.1600072  0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,159 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,161 - INFO -   Participant 62 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,161 - INFO -   Participant 62 Coefficients: [0.82711127 0.09766242 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,161 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,163 - INFO -   Participant 63 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,163 - INFO -   Participant 63 Coefficients: [ 0.69526023  0.17042784  0.         -0.1851111   0.         -0.245034
  1.69954833  0.          0.         13.00564984]
2025-03-25 22:10:28,163 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,164 - INFO -   Participant 64 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,165 - INFO -   Participant 64 Coefficients: [0.69383219 0.15556378 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,165 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,166 - INFO -   Participant 65 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,166 - INFO -   Participant 65 Coefficients: [0.81100005 0.10758651 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,166 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,168 - INFO -   Participant 66 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,168 - INFO -   Participant 66 Coefficients: [ 0.80542988  0.11854147  0.15176078 -0.13777954  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,168 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,170 - INFO -   Participant 67 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,170 - INFO -   Participant 67 Coefficients: [0.63712712 0.17455342 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,170 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,171 - INFO -   Participant 68 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,171 - INFO -   Participant 68 Coefficients: [ 0.70153914  0.18176548  0.16165029 -0.63469706  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,172 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,173 - INFO -   Participant 69 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,173 - INFO -   Participant 69 Coefficients: [0.82727501 0.10250777 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,173 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,175 - INFO -   Participant 70 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,175 - INFO -   Participant 70 Coefficients: [ 0.74123979  0.15559961  0.15733799 -0.28485663  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,175 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,176 - INFO -   Participant 71 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,177 - INFO -   Participant 71 Coefficients: [ 0.70757524  0.17551817  0.19692695 -0.84249691  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,177 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,178 - INFO -   Participant 72 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,178 - INFO -   Participant 72 Coefficients: [0.76437393 0.13449878 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,178 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,180 - INFO -   Participant 73 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,180 - INFO -   Participant 73 Coefficients: [0.77168349 0.12211781 0.         0.08617179 0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,180 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,182 - INFO -   Participant 74 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,182 - INFO -   Participant 74 Coefficients: [0.67043382 0.17138813 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,182 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,183 - INFO -   Participant 75 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,183 - INFO -   Participant 75 Coefficients: [ 5.66886881e-01  2.47288657e-01  2.08571826e-01 -9.94777508e+01
  0.00000000e+00  8.02231467e-01 -6.55473682e+02  0.00000000e+00
 -7.21185377e+01  1.58653683e+04]
2025-03-25 22:10:28,184 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,185 - INFO -   Participant 76 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,185 - INFO -   Participant 76 Coefficients: [0.65769068 0.16756802 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,185 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,187 - INFO -   Participant 77 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,187 - INFO -   Participant 77 Coefficients: [0.66789044 0.16477464 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,187 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,188 - INFO -   Participant 78 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,189 - INFO -   Participant 78 Coefficients: [0.67020701 0.16571875 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,189 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,190 - INFO -   Participant 79 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,190 - INFO -   Participant 79 Coefficients: [0.66942606 0.17958413 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,190 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,192 - INFO -   Participant 80 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,192 - INFO -   Participant 80 Coefficients: [ 0.74678826  0.15499787  0.17761487 -0.77903075  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,192 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,194 - INFO -   Participant 81 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,194 - INFO -   Participant 81 Coefficients: [ 0.77586294  0.13916836  0.12677244 -0.16342     0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,194 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,195 - INFO -   Participant 82 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,195 - INFO -   Participant 82 Coefficients: [0.66235008 0.16391191 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,195 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,197 - INFO -   Participant 83 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,197 - INFO -   Participant 83 Coefficients: [0.66318706 0.17777272 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,197 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,199 - INFO -   Participant 84 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,199 - INFO -   Participant 84 Coefficients: [ 0.72695766  0.15615816  0.         -0.27386069  0.         -0.27917286
  1.48873931  0.          0.          6.0104678 ]
2025-03-25 22:10:28,199 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,200 - INFO -   Participant 85 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,200 - INFO -   Participant 85 Coefficients: [0.58574008 0.1769483  0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,200 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,202 - INFO -   Participant 86 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,202 - INFO -   Participant 86 Coefficients: [ 0.75561099  0.14867108  0.12951131 -0.14897708  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,202 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,204 - INFO -   Participant 87 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,204 - INFO -   Participant 87 Coefficients: [0.58416555 0.19841091 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,204 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,205 - INFO -   Participant 88 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,205 - INFO -   Participant 88 Coefficients: [ 0.71144435  0.16421555  0.         -0.17773613  0.         -0.27122459
  1.51346987  0.          0.          6.23494775]
2025-03-25 22:10:28,205 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,207 - INFO -   Participant 89 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,207 - INFO -   Participant 89 Coefficients: [0.61304648 0.17923249 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,207 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,209 - INFO -   Participant 90 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,209 - INFO -   Participant 90 Coefficients: [ 0.74888477  0.15191072  0.13968839 -0.1748818   0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,209 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,210 - INFO -   Participant 91 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,210 - INFO -   Participant 91 Coefficients: [ 0.79552041  0.12657973  0.13598481 -0.20749167  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,211 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,212 - INFO -   Participant 92 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,212 - INFO -   Participant 92 Coefficients: [ 0.72414566  0.16789675  0.16581443 -0.5405034   0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,212 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,214 - INFO -   Participant 93 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,214 - INFO -   Participant 93 Coefficients: [ 0.77120832  0.1404315   0.14117521 -0.1570658   0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,214 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,215 - INFO -   Participant 94 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,215 - INFO -   Participant 94 Coefficients: [ 0.73335142  0.16200463  0.14982643 -0.39360579  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,216 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,217 - INFO -   Participant 95 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,217 - INFO -   Participant 95 Coefficients: [ 0.78269653  0.13131445  0.1622484  -0.22248097  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,217 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,219 - INFO -   Participant 96 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,219 - INFO -   Participant 96 Coefficients: [ 0.72864063  0.15452377  0.         -0.25543652  0.         -0.22640024
  1.2265923   0.          0.          6.78431552]
2025-03-25 22:10:28,219 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,220 - INFO -   Participant 97 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,221 - INFO -   Participant 97 Coefficients: [0.77518951 0.12498004 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,221 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,222 - INFO -   Participant 98 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,222 - INFO -   Participant 98 Coefficients: [ 0.75467122  0.14750735  0.16492686 -0.19225072  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,222 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,224 - INFO -   Participant 99 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,224 - INFO -   Participant 99 Coefficients: [0.62722177 0.18355394 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,224 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,226 - INFO -   Participant 100 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,226 - INFO -   Participant 100 Coefficients: [0.73415386 0.13978526 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,226 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,227 - INFO -   Participant 101 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,227 - INFO -   Participant 101 Coefficients: [ 0.79257407  0.1140627   0.          0.19627869  0.         -0.16594318
  1.35384759  0.          0.          0.        ]
2025-03-25 22:10:28,227 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,229 - INFO -   Participant 102 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,229 - INFO -   Participant 102 Coefficients: [ 0.66836803  0.18085186  0.         -0.07414919  0.         -0.10170343
  0.15256062  0.          0.         20.34392399]
2025-03-25 22:10:28,229 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,231 - INFO -   Participant 103 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,231 - INFO -   Participant 103 Coefficients: [0.78195701 0.12894146 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,231 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,233 - INFO -   Participant 104 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,233 - INFO -   Participant 104 Coefficients: [ 0.77389592  0.13955826  0.13722926 -0.23127116  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,233 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,234 - INFO -   Participant 105 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,234 - INFO -   Participant 105 Coefficients: [  0.68973158   0.19188772   0.18215657  -5.24344254   0.
   0.60716824 -20.79163276   0.           0.          -0.47091707]
2025-03-25 22:10:28,234 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,236 - INFO -   Participant 106 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,236 - INFO -   Participant 106 Coefficients: [ 0.67114091  0.19992223  0.17865255 -0.87161278  0.          0.
 -0.06838297  0.          0.          0.        ]
2025-03-25 22:10:28,236 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,238 - INFO -   Participant 107 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,238 - INFO -   Participant 107 Coefficients: [0.68325864 0.16609573 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,238 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,239 - INFO -   Participant 108 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,240 - INFO -   Participant 108 Coefficients: [0.64013221 0.18183416 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,240 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,241 - INFO -   Participant 109 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,241 - INFO -   Participant 109 Coefficients: [0.79183396 0.11748112 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,241 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,243 - INFO -   Participant 110 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,243 - INFO -   Participant 110 Coefficients: [ 0.68138171  0.19369415  0.18775502 -0.47581352  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,243 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,245 - INFO -   Participant 111 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,245 - INFO -   Participant 111 Coefficients: [ 0.7922532   0.12837846  0.14038036 -0.17608309  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,245 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,246 - INFO -   Participant 112 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,246 - INFO -   Participant 112 Coefficients: [0.60838258 0.19380226 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,246 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,248 - INFO -   Participant 113 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,248 - INFO -   Participant 113 Coefficients: [0.54046124 0.19519642 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,248 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,250 - INFO -   Participant 114 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,250 - INFO -   Participant 114 Coefficients: [ 0.74721687  0.15253332  0.19062809 -0.4089171   0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,250 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,251 - INFO -   Participant 115 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,252 - INFO -   Participant 115 Coefficients: [0.67087096 0.17088443 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,252 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,253 - INFO -   Participant 116 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,253 - INFO -   Participant 116 Coefficients: [ 0.70234665  0.1839427   0.17898187 -0.85920482  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,253 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,255 - INFO -   Participant 117 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,255 - INFO -   Participant 117 Coefficients: [ 0.6763449   0.19448652  0.17140701 -0.49882214  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,255 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,257 - INFO -   Participant 118 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,257 - INFO -   Participant 118 Coefficients: [ 0.69080163  0.18595894  0.18174421 -0.54212691  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,257 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,258 - INFO -   Participant 119 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,258 - INFO -   Participant 119 Coefficients: [0.70821349 0.15886848 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,259 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,260 - INFO -   Participant 120 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,260 - INFO -   Participant 120 Coefficients: [0.64294652 0.1766928  0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,260 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,262 - INFO -   Participant 121 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,262 - INFO -   Participant 121 Coefficients: [0.71918557 0.15216959 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,262 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,264 - INFO -   Participant 122 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,264 - INFO -   Participant 122 Coefficients: [0.78478723 0.11499971 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,264 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,265 - INFO -   Participant 123 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,265 - INFO -   Participant 123 Coefficients: [0.66833044 0.17639657 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,265 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,267 - INFO -   Participant 124 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,267 - INFO -   Participant 124 Coefficients: [  0.70133518   0.18394228   0.23100046  -7.200383     0.
   0.77558067 -38.42746494   0.          -5.44596538 118.4719811 ]
2025-03-25 22:10:28,267 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,269 - INFO -   Participant 125 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,269 - INFO -   Participant 125 Coefficients: [0.56433539 0.18280548 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,269 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,270 - INFO -   Participant 126 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,271 - INFO -   Participant 126 Coefficients: [ 0.63067448  0.22217299  0.20610274 -1.3671633   0.          0.
  0.          0.          0.         -0.5975561 ]
2025-03-25 22:10:28,271 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,272 - INFO -   Participant 127 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,272 - INFO -   Participant 127 Coefficients: [  0.66525246   0.2047179    0.1868631   -6.73235684   0.
   0.68712744 -28.79587948   0.           0.          -2.76441656]
2025-03-25 22:10:28,272 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,274 - INFO -   Participant 128 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,274 - INFO -   Participant 128 Coefficients: [0.77362559 0.12463548 0.         0.07172968 0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,274 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,276 - INFO -   Participant 129 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,276 - INFO -   Participant 129 Coefficients: [0.76774507 0.12477308 0.         0.07533818 0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,276 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,277 - INFO -   Participant 130 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,277 - INFO -   Participant 130 Coefficients: [0.59287538 0.18185886 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,277 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,279 - INFO -   Participant 131 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,279 - INFO -   Participant 131 Coefficients: [0.70839194 0.15491291 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,279 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,281 - INFO -   Participant 132 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,281 - INFO -   Participant 132 Coefficients: [0.64574202 0.17793243 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,281 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,282 - INFO -   Participant 133 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,282 - INFO -   Participant 133 Coefficients: [ 0.77431178  0.13921925  0.16929648 -0.35048375  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,282 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,284 - INFO -   Participant 134 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,284 - INFO -   Participant 134 Coefficients: [ 0.69751629  0.18290514  0.16470666 -0.50698312  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,284 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,286 - INFO -   Participant 135 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,286 - INFO -   Participant 135 Coefficients: [ 0.74832247  0.15232417  0.17327446 -0.32209792  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,286 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,288 - INFO -   Participant 136 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,288 - INFO -   Participant 136 Coefficients: [ 0.63251549  0.22068654  0.18220747 -1.15979972  0.          0.
 -0.0684541   0.          0.          0.        ]
2025-03-25 22:10:28,288 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,290 - INFO -   Participant 137 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,290 - INFO -   Participant 137 Coefficients: [0.66307985 0.15847279 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,290 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,291 - INFO -   Participant 138 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,291 - INFO -   Participant 138 Coefficients: [0.68109517 0.16412214 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,291 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,293 - INFO -   Participant 139 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,293 - INFO -   Participant 139 Coefficients: [ 0.72934042  0.1643704   0.20144037 -0.74450309  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,293 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,294 - INFO -   Participant 140 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,294 - INFO -   Participant 140 Coefficients: [0.64223667 0.18685538 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,295 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,296 - INFO -   Participant 141 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,296 - INFO -   Participant 141 Coefficients: [  0.66932366   0.20127187   0.19717389  -5.24920358   0.
   0.51534751 -16.55073404   0.           0.          -3.29153   ]
2025-03-25 22:10:28,296 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,298 - INFO -   Participant 142 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,298 - INFO -   Participant 142 Coefficients: [0.65421987 0.17467829 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,298 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,299 - INFO -   Participant 143 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,299 - INFO -   Participant 143 Coefficients: [ 6.68538584e-01  2.01540771e-01  2.07420888e-01 -4.75197929e+01
  0.00000000e+00  1.02770189e+00 -3.25389385e+02  0.00000000e+00
 -1.48271330e+01  1.42506736e+03]
2025-03-25 22:10:28,300 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,301 - INFO -   Participant 144 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,301 - INFO -   Participant 144 Coefficients: [0.56709743 0.19297466 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,301 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,303 - INFO -   Participant 145 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,303 - INFO -   Participant 145 Coefficients: [0.67238521 0.15686754 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,303 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,305 - INFO -   Participant 146 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,305 - INFO -   Participant 146 Coefficients: [0.59830376 0.18479355 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,305 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,306 - INFO -   Participant 147 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,306 - INFO -   Participant 147 Coefficients: [  0.6214468    0.22466196   0.22114258  -2.74541792   0.
   0.43483633 -10.94566829   0.          -3.57068554  37.83153117]
2025-03-25 22:10:28,306 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,308 - INFO -   Participant 148 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,308 - INFO -   Participant 148 Coefficients: [ 0.78375118  0.13261051  0.15109138 -0.22014941  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,308 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,310 - INFO -   Participant 149 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,310 - INFO -   Participant 149 Coefficients: [0.65583541 0.17464425 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,310 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,311 - INFO -   Participant 150 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,312 - INFO -   Participant 150 Coefficients: [ 0.73686803  0.15895615  0.14353605 -0.23626565  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,312 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,313 - INFO -   Participant 151 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,313 - INFO -   Participant 151 Coefficients: [ 0.63546473  0.21468486  0.15777255 -0.36532904  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,313 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,315 - INFO -   Participant 152 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,315 - INFO -   Participant 152 Coefficients: [ 0.69673356  0.1698832   0.         -0.28254527  0.         -0.16880413
  1.24882288  0.          0.         27.1845926 ]
2025-03-25 22:10:28,315 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,317 - INFO -   Participant 153 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,317 - INFO -   Participant 153 Coefficients: [0.73324405 0.15084825 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,317 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,318 - INFO -   Participant 154 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,318 - INFO -   Participant 154 Coefficients: [ 0.61303694  0.23194562  0.17802481 -1.20949027  0.          0.
  0.          0.          0.         -0.67633481]
2025-03-25 22:10:28,318 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,320 - INFO -   Participant 155 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,320 - INFO -   Participant 155 Coefficients: [ 0.76505254  0.14489049  0.14640302 -0.21637601  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,320 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,322 - INFO -   Participant 156 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,322 - INFO -   Participant 156 Coefficients: [0.69663722 0.16426457 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,322 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,323 - INFO -   Participant 157 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,324 - INFO -   Participant 157 Coefficients: [ 0.70419169  0.1793171   0.18040625 -0.54764969  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,324 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,325 - INFO -   Participant 158 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,325 - INFO -   Participant 158 Coefficients: [0.71011719 0.15503766 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,325 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,327 - INFO -   Participant 159 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,327 - INFO -   Participant 159 Coefficients: [ 0.78082012  0.13511566  0.16476694 -0.3002974   0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,327 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,329 - INFO -   Participant 160 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,329 - INFO -   Participant 160 Coefficients: [  0.61312293   0.22683857   0.22416467  -6.69694448   0.
   0.69195275 -39.73509274   0.          -7.56075787 148.43444665]
2025-03-25 22:10:28,329 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,330 - INFO -   Participant 161 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,330 - INFO -   Participant 161 Coefficients: [0.75471837 0.13868646 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,330 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,332 - INFO -   Participant 162 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,332 - INFO -   Participant 162 Coefficients: [ 0.77693214  0.13719653  0.15209182 -0.24319493  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,332 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,334 - INFO -   Participant 163 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,334 - INFO -   Participant 163 Coefficients: [ 0.76617638  0.14496398  0.13571953 -0.22131051  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,334 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,335 - INFO -   Participant 164 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,335 - INFO -   Participant 164 Coefficients: [ 0.71094995  0.1614477   0.         -0.37777924  0.         -0.108141
  0.46840525  0.          0.         25.96324943]
2025-03-25 22:10:28,335 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,337 - INFO -   Participant 165 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,337 - INFO -   Participant 165 Coefficients: [ 0.74020238  0.15901249  0.17444824 -0.51863708  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,337 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,339 - INFO -   Participant 166 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,339 - INFO -   Participant 166 Coefficients: [ 7.02129711e-01  1.84081787e-01  2.37769361e-01 -1.27829978e+01
  0.00000000e+00  1.01814777e+00 -1.00974735e+02  0.00000000e+00
 -1.60950725e+01  7.11771720e+02]
2025-03-25 22:10:28,339 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,341 - INFO -   Participant 167 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,341 - INFO -   Participant 167 Coefficients: [0.6657632  0.17621131 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,341 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,342 - INFO -   Participant 168 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,342 - INFO -   Participant 168 Coefficients: [0.72659427 0.14344604 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,342 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,344 - INFO -   Participant 169 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,344 - INFO -   Participant 169 Coefficients: [ 0.71166602  0.17574468  0.17778223 -0.74082039  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,344 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,346 - INFO -   Participant 170 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,346 - INFO -   Participant 170 Coefficients: [0.77467908 0.1255888  0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,346 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,348 - INFO -   Participant 171 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,348 - INFO -   Participant 171 Coefficients: [ 0.71006703  0.15945666  0.         -0.33529392  0.         -0.2181589
  2.06062536  0.          0.         30.06226913]
2025-03-25 22:10:28,348 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,349 - INFO -   Participant 172 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,349 - INFO -   Participant 172 Coefficients: [ 0.80485498  0.12031483  0.15277359 -0.27027675  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,349 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,351 - INFO -   Participant 173 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,351 - INFO -   Participant 173 Coefficients: [0.53555611 0.18139295 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,351 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,353 - INFO -   Participant 174 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,353 - INFO -   Participant 174 Coefficients: [0.70098134 0.14652092 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,353 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,354 - INFO -   Participant 175 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,355 - INFO -   Participant 175 Coefficients: [ 0.688725    0.16867184  0.         -0.27094197  0.         -0.24365364
  2.23325747  0.          0.         25.20219525]
2025-03-25 22:10:28,355 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,356 - INFO -   Participant 176 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,356 - INFO -   Participant 176 Coefficients: [0.77438915 0.12322191 0.         0.09308895 0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,356 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,358 - INFO -   Participant 177 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,358 - INFO -   Participant 177 Coefficients: [ 0.76714563  0.1241206   0.          0.16276915  0.         -0.19463179
  1.0938405   0.          0.          0.        ]
2025-03-25 22:10:28,358 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,359 - INFO -   Participant 178 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,360 - INFO -   Participant 178 Coefficients: [0.51716346 0.18681393 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,360 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,361 - INFO -   Participant 179 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,361 - INFO -   Participant 179 Coefficients: [0.59138531 0.1883682  0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,361 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,363 - INFO -   Participant 180 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,363 - INFO -   Participant 180 Coefficients: [0.80305189 0.11156537 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,363 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,365 - INFO -   Participant 181 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,365 - INFO -   Participant 181 Coefficients: [0.78949715 0.11351811 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,365 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,366 - INFO -   Participant 182 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,366 - INFO -   Participant 182 Coefficients: [0.72624379 0.14588098 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,367 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,368 - INFO -   Participant 183 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,368 - INFO -   Participant 183 Coefficients: [ 0.78938287  0.13037096  0.13257191 -0.18334458  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,368 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,370 - INFO -   Participant 184 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,370 - INFO -   Participant 184 Coefficients: [0.75176555 0.13026979 0.         0.10442878 0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,370 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,372 - INFO -   Participant 185 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,372 - INFO -   Participant 185 Coefficients: [0.76163983 0.13056862 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,372 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,373 - INFO -   Participant 186 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,373 - INFO -   Participant 186 Coefficients: [ 0.75594885  0.14856253  0.16541994 -0.25020423  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,373 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,375 - INFO -   Participant 187 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,375 - INFO -   Participant 187 Coefficients: [ 0.73501317  0.1632371   0.16765365 -0.52653476  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,375 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,377 - INFO -   Participant 188 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,377 - INFO -   Participant 188 Coefficients: [ 0.61424352  0.23153089  0.19475498 -2.70742243  0.          0.
  0.          0.          0.         -3.22367614]
2025-03-25 22:10:28,377 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,378 - INFO -   Participant 189 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,379 - INFO -   Participant 189 Coefficients: [0.74891251 0.13658276 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,379 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,380 - INFO -   Participant 190 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,380 - INFO -   Participant 190 Coefficients: [ 0.71285426  0.17808388  0.17739478 -0.87943198  0.          0.
 -0.06339297  0.          0.          0.        ]
2025-03-25 22:10:28,380 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,382 - INFO -   Participant 191 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,382 - INFO -   Participant 191 Coefficients: [0.62787889 0.15525213 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,382 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,384 - INFO -   Participant 192 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,384 - INFO -   Participant 192 Coefficients: [0.69930895 0.15906397 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,384 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,385 - INFO -   Participant 193 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,385 - INFO -   Participant 193 Coefficients: [0.54585639 0.19535651 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,385 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,387 - INFO -   Participant 194 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,387 - INFO -   Participant 194 Coefficients: [0.72636356 0.14509435 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,387 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,389 - INFO -   Participant 195 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,389 - INFO -   Participant 195 Coefficients: [ 0.65916226  0.18964645  0.         -0.12490789  0.          0.
 -2.07743454  0.          0.         50.66353599]
2025-03-25 22:10:28,389 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,390 - INFO -   Participant 196 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,391 - INFO -   Participant 196 Coefficients: [0.65821878 0.16886242 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,391 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,392 - INFO -   Participant 197 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,392 - INFO -   Participant 197 Coefficients: [ 0.67477669  0.19448762  0.18463988 -0.52617935  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,392 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,394 - INFO -   Participant 198 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,394 - INFO -   Participant 198 Coefficients: [  0.66982035   0.20372133   0.18417082  -5.39552814   0.
   0.6178341  -21.7459512    0.           0.          -2.07848184]
2025-03-25 22:10:28,394 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,396 - INFO -   Participant 199 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,396 - INFO -   Participant 199 Coefficients: [0.62841976 0.19220087 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,396 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,397 - INFO -   Participant 200 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,398 - INFO -   Participant 200 Coefficients: [0.65119873 0.17162644 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,398 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,399 - INFO -   Participant 201 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,399 - INFO -   Participant 201 Coefficients: [0.69719261 0.15677261 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,399 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,401 - INFO -   Participant 202 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,401 - INFO -   Participant 202 Coefficients: [ 0.72673826  0.16580706  0.16043518 -0.27382557  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,401 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,403 - INFO -   Participant 203 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,403 - INFO -   Participant 203 Coefficients: [0.80375186 0.11218245 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,403 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,404 - INFO -   Participant 204 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,404 - INFO -   Participant 204 Coefficients: [0.58884302 0.18395157 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,404 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,406 - INFO -   Participant 205 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,406 - INFO -   Participant 205 Coefficients: [0.75032368 0.14018295 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,406 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,408 - INFO -   Participant 206 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,408 - INFO -   Participant 206 Coefficients: [ 0.70001089  0.16706483  0.         -0.22935915  0.         -0.28356133
  1.88806753  0.          0.         10.98789656]
2025-03-25 22:10:28,408 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,409 - INFO -   Participant 207 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,409 - INFO -   Participant 207 Coefficients: [0.76601985 0.12762575 0.         0.10683187 0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,409 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,411 - INFO -   Participant 208 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,411 - INFO -   Participant 208 Coefficients: [  0.65478746   0.20951327   0.21192353  -6.93088868   0.
   0.75673943 -41.71623217   0.          -5.7303612  145.17600455]
2025-03-25 22:10:28,411 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,413 - INFO -   Participant 209 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,413 - INFO -   Participant 209 Coefficients: [0.76542802 0.13188329 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,413 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,414 - INFO -   Participant 210 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,414 - INFO -   Participant 210 Coefficients: [0.6978726  0.15516826 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,414 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,416 - INFO -   Participant 211 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,416 - INFO -   Participant 211 Coefficients: [ 0.74544652  0.15508825  0.15330304 -0.24670322  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,416 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,418 - INFO -   Participant 212 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,418 - INFO -   Participant 212 Coefficients: [0.631287   0.17906424 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,418 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,419 - INFO -   Participant 213 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,419 - INFO -   Participant 213 Coefficients: [0.80675967 0.10842253 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,419 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,421 - INFO -   Participant 214 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,421 - INFO -   Participant 214 Coefficients: [0.63011328 0.17878563 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,421 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,423 - INFO -   Participant 215 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,423 - INFO -   Participant 215 Coefficients: [ 0.75408962  0.14967368  0.17462934 -0.4046547   0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,423 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,424 - INFO -   Participant 216 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,424 - INFO -   Participant 216 Coefficients: [0.74301513 0.13725401 0.         0.11248415 0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,425 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,426 - INFO -   Participant 217 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,426 - INFO -   Participant 217 Coefficients: [0.60446301 0.18055395 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,426 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,428 - INFO -   Participant 218 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,428 - INFO -   Participant 218 Coefficients: [0.60890982 0.15943607 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,428 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,429 - INFO -   Participant 219 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,430 - INFO -   Participant 219 Coefficients: [0.83842343 0.09760324 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,430 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,431 - INFO -   Participant 220 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,431 - INFO -   Participant 220 Coefficients: [  0.59048289   0.23566624   0.20301249  -5.36494917   0.
   0.61914645 -32.79500449   0.          -6.6679197  118.16632473]
2025-03-25 22:10:28,431 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,433 - INFO -   Participant 221 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,433 - INFO -   Participant 221 Coefficients: [ 0.71721373  0.17233498  0.16480524 -0.45101491  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,433 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,434 - INFO -   Participant 222 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,435 - INFO -   Participant 222 Coefficients: [0.6758683  0.15793341 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,435 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,436 - INFO -   Participant 223 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,436 - INFO -   Participant 223 Coefficients: [0.70124375 0.15458662 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,436 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,438 - INFO -   Participant 224 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,438 - INFO -   Participant 224 Coefficients: [0.74153862 0.14069216 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,438 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,440 - INFO -   Participant 225 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,440 - INFO -   Participant 225 Coefficients: [0.60882581 0.18109532 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,440 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,441 - INFO -   Participant 226 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,441 - INFO -   Participant 226 Coefficients: [0.70825924 0.15737686 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,441 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,443 - INFO -   Participant 227 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,443 - INFO -   Participant 227 Coefficients: [ 0.75542461  0.14798433  0.18197109 -0.30032437  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,443 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,445 - INFO -   Participant 228 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,445 - INFO -   Participant 228 Coefficients: [0.65721323 0.1674625  0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,445 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,446 - INFO -   Participant 229 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,446 - INFO -   Participant 229 Coefficients: [ 0.80862657  0.11879982  0.12945039 -0.15436433  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,446 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,448 - INFO -   Participant 230 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,448 - INFO -   Participant 230 Coefficients: [0.77871915 0.11953261 0.         0.05835771 0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,448 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,450 - INFO -   Participant 231 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,450 - INFO -   Participant 231 Coefficients: [ 0.76880309  0.14363399  0.1388554  -0.2854693   0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,450 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,451 - INFO -   Participant 232 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,451 - INFO -   Participant 232 Coefficients: [0.73751166 0.13320203 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,451 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,453 - INFO -   Participant 233 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,453 - INFO -   Participant 233 Coefficients: [0.79156064 0.11345284 0.         0.06276277 0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,453 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,455 - INFO -   Participant 234 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,455 - INFO -   Participant 234 Coefficients: [ 0.77523387  0.13793758  0.16479352 -0.33004417  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,455 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,456 - INFO -   Participant 235 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,456 - INFO -   Participant 235 Coefficients: [0.71120757 0.15102672 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,456 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,458 - INFO -   Participant 236 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,458 - INFO -   Participant 236 Coefficients: [0.69310303 0.16588722 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,458 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,460 - INFO -   Participant 237 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,460 - INFO -   Participant 237 Coefficients: [0.60179815 0.1981711  0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,460 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,461 - INFO -   Participant 238 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,461 - INFO -   Participant 238 Coefficients: [ 0.71488799  0.17447012  0.1986941  -0.98243655  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,461 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,463 - INFO -   Participant 239 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,463 - INFO -   Participant 239 Coefficients: [0.66785393 0.16797052 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,463 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,465 - INFO -   Participant 240 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,465 - INFO -   Participant 240 Coefficients: [0.64149695 0.16303603 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,465 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,466 - INFO -   Participant 241 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,467 - INFO -   Participant 241 Coefficients: [ 0.65344302  0.20614097  0.19286956 -0.80543056  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,467 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,468 - INFO -   Participant 242 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,468 - INFO -   Participant 242 Coefficients: [0.46350855 0.18421788 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,468 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,470 - INFO -   Participant 243 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,470 - INFO -   Participant 243 Coefficients: [0.60478283 0.19343482 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,470 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,472 - INFO -   Participant 244 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,472 - INFO -   Participant 244 Coefficients: [0.6740411  0.16308922 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,472 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,473 - INFO -   Participant 245 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,473 - INFO -   Participant 245 Coefficients: [0.59083012 0.19801531 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,473 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,475 - INFO -   Participant 246 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,475 - INFO -   Participant 246 Coefficients: [ 0.74279424  0.15755437  0.15512746 -0.23093173  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:10:28,475 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,477 - INFO -   Participant 247 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,477 - INFO -   Participant 247 Coefficients: [0.7867755  0.11667069 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,477 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,478 - INFO -   Participant 248 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,478 - INFO -   Participant 248 Coefficients: [ 0.65567099  0.20491222  0.24171057 -2.90423313  0.          0.
  0.          0.         -4.26952087 43.30649756]
2025-03-25 22:10:28,478 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,480 - INFO -   Participant 249 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,480 - INFO -   Participant 249 Coefficients: [0.65384448 0.16855961 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,480 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,482 - INFO -   Participant 250 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,482 - INFO -   Participant 250 Coefficients: [0.75515374 0.13718864 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,482 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,484 - INFO -   Participant 251 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,484 - INFO -   Participant 251 Coefficients: [ 0.63356504  0.22051404  0.18350783 -1.61142628  0.          0.
 -0.39640575  0.          0.          0.        ]
2025-03-25 22:10:28,484 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,486 - INFO -   Participant 252 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,486 - INFO -   Participant 252 Coefficients: [0.64683858 0.17664876 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,486 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,488 - INFO -   Participant 253 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,488 - INFO -   Participant 253 Coefficients: [ 0.75487572  0.13566783  0.          0.18457894  0.         -0.16821028
  0.91408408  0.          0.          0.        ]
2025-03-25 22:10:28,488 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,490 - INFO -   Participant 254 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,490 - INFO -   Participant 254 Coefficients: [0.7908272  0.11194338 0.         0.09344565 0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,490 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,491 - INFO -   Participant 255 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,491 - INFO -   Participant 255 Coefficients: [0.77317707 0.12200049 0.         0.06957421 0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:10:28,491 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:10:28,492 - INFO - Module: x_value_reward_not_chosen
2025-03-25 22:10:28,493 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,493 - INFO -   Participant 0 Coefficients: [-0.36105921  0.99530184  0.          0.          0.          0.        ]
2025-03-25 22:10:28,493 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,494 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,494 - INFO -   Participant 1 Coefficients: [-0.30640276  0.98850175  0.          0.          0.          0.        ]
2025-03-25 22:10:28,494 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,496 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,496 - INFO -   Participant 2 Coefficients: [-0.19873621  0.98284254  0.          0.          0.          0.        ]
2025-03-25 22:10:28,496 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,497 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,497 - INFO -   Participant 3 Coefficients: [-0.23586635  0.97747637  0.          0.          0.          0.        ]
2025-03-25 22:10:28,497 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,498 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,498 - INFO -   Participant 4 Coefficients: [-0.29071584  0.99147783  0.          0.          0.          0.        ]
2025-03-25 22:10:28,498 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,500 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,500 - INFO -   Participant 5 Coefficients: [-0.24092667  0.9743933   0.          0.          0.          0.        ]
2025-03-25 22:10:28,500 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,501 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,501 - INFO -   Participant 6 Coefficients: [-0.23708542  0.97882054  0.          0.          0.          0.        ]
2025-03-25 22:10:28,501 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,503 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,503 - INFO -   Participant 7 Coefficients: [-0.20452481  0.98357034  0.          0.          0.          0.        ]
2025-03-25 22:10:28,503 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,504 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,504 - INFO -   Participant 8 Coefficients: [-0.28668418  0.97982866  0.          0.          0.          0.        ]
2025-03-25 22:10:28,504 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,506 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,506 - INFO -   Participant 9 Coefficients: [-0.26872281  0.98093651  0.          0.          0.          0.        ]
2025-03-25 22:10:28,506 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,507 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,507 - INFO -   Participant 10 Coefficients: [-0.32093297  0.98683381  0.          0.          0.          0.        ]
2025-03-25 22:10:28,507 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,508 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,508 - INFO -   Participant 11 Coefficients: [-0.23884306  0.98814601  0.          0.          0.          0.        ]
2025-03-25 22:10:28,509 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,510 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,510 - INFO -   Participant 12 Coefficients: [-0.39200568  0.98345822  0.          0.          0.          0.        ]
2025-03-25 22:10:28,510 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,511 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,511 - INFO -   Participant 13 Coefficients: [-0.29475205  0.97758395  0.          0.          0.          0.        ]
2025-03-25 22:10:28,511 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,513 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,513 - INFO -   Participant 14 Coefficients: [-0.31785839  0.98459613  0.          0.          0.          0.        ]
2025-03-25 22:10:28,513 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,514 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,514 - INFO -   Participant 15 Coefficients: [-0.32355222  0.98459437  0.          0.          0.          0.        ]
2025-03-25 22:10:28,514 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,515 - INFO -   Participant 16 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,515 - INFO -   Participant 16 Coefficients: [-0.2808709   0.98462054  0.          0.          0.          0.        ]
2025-03-25 22:10:28,515 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,517 - INFO -   Participant 17 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,517 - INFO -   Participant 17 Coefficients: [-0.17611345  0.98348881  0.          0.          0.          0.        ]
2025-03-25 22:10:28,517 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,518 - INFO -   Participant 18 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,518 - INFO -   Participant 18 Coefficients: [-0.29908128  0.9888126   0.          0.          0.          0.        ]
2025-03-25 22:10:28,518 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,520 - INFO -   Participant 19 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,520 - INFO -   Participant 19 Coefficients: [-0.13777054  0.97250218  0.          0.          0.          0.        ]
2025-03-25 22:10:28,520 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,521 - INFO -   Participant 20 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,521 - INFO -   Participant 20 Coefficients: [-0.38200703  0.98324475  0.          0.          0.          0.        ]
2025-03-25 22:10:28,521 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,522 - INFO -   Participant 21 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,523 - INFO -   Participant 21 Coefficients: [-0.28880132  0.99081245  0.          0.          0.          0.        ]
2025-03-25 22:10:28,523 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,524 - INFO -   Participant 22 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,524 - INFO -   Participant 22 Coefficients: [-0.28071795  0.98223885  0.          0.          0.          0.        ]
2025-03-25 22:10:28,524 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,525 - INFO -   Participant 23 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,525 - INFO -   Participant 23 Coefficients: [-0.3640929   0.98985101  0.          0.          0.          0.        ]
2025-03-25 22:10:28,525 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,527 - INFO -   Participant 24 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,527 - INFO -   Participant 24 Coefficients: [-0.22807482  0.97621196  0.          0.          0.          0.        ]
2025-03-25 22:10:28,527 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,528 - INFO -   Participant 25 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,528 - INFO -   Participant 25 Coefficients: [-0.34117445  0.98116749  0.          0.          0.          0.        ]
2025-03-25 22:10:28,528 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,530 - INFO -   Participant 26 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,530 - INFO -   Participant 26 Coefficients: [-0.32181144  0.98213257  0.          0.          0.          0.        ]
2025-03-25 22:10:28,530 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,531 - INFO -   Participant 27 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,531 - INFO -   Participant 27 Coefficients: [-0.28705203  0.98694265  0.          0.          0.          0.        ]
2025-03-25 22:10:28,531 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,533 - INFO -   Participant 28 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,533 - INFO -   Participant 28 Coefficients: [-0.33748475  0.98169723  0.          0.          0.          0.        ]
2025-03-25 22:10:28,533 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,534 - INFO -   Participant 29 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,534 - INFO -   Participant 29 Coefficients: [-0.31311873  0.98725442  0.          0.          0.          0.        ]
2025-03-25 22:10:28,534 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,535 - INFO -   Participant 30 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,535 - INFO -   Participant 30 Coefficients: [-0.24955994  0.98170922  0.          0.          0.          0.        ]
2025-03-25 22:10:28,535 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,537 - INFO -   Participant 31 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,537 - INFO -   Participant 31 Coefficients: [-0.25898986  0.98305052  0.          0.          0.          0.        ]
2025-03-25 22:10:28,537 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,538 - INFO -   Participant 32 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,538 - INFO -   Participant 32 Coefficients: [-0.29613254  0.97996006  0.          0.          0.          0.        ]
2025-03-25 22:10:28,538 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,539 - INFO -   Participant 33 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,540 - INFO -   Participant 33 Coefficients: [-0.31235343  0.98805764  0.          0.          0.          0.        ]
2025-03-25 22:10:28,540 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,541 - INFO -   Participant 34 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,541 - INFO -   Participant 34 Coefficients: [-0.33468549  0.98181032  0.          0.          0.          0.        ]
2025-03-25 22:10:28,541 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,542 - INFO -   Participant 35 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,542 - INFO -   Participant 35 Coefficients: [-0.25100182  0.97963487  0.          0.          0.          0.        ]
2025-03-25 22:10:28,542 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,544 - INFO -   Participant 36 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,544 - INFO -   Participant 36 Coefficients: [-0.24994622  0.97956872  0.          0.          0.          0.        ]
2025-03-25 22:10:28,544 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,545 - INFO -   Participant 37 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,545 - INFO -   Participant 37 Coefficients: [-0.25889714  0.98311057  0.          0.          0.          0.        ]
2025-03-25 22:10:28,545 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,547 - INFO -   Participant 38 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,547 - INFO -   Participant 38 Coefficients: [-0.28873376  0.97236081  0.          0.          0.          0.        ]
2025-03-25 22:10:28,547 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,548 - INFO -   Participant 39 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,548 - INFO -   Participant 39 Coefficients: [-0.31640335  0.98383616  0.          0.          0.          0.        ]
2025-03-25 22:10:28,548 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,550 - INFO -   Participant 40 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,550 - INFO -   Participant 40 Coefficients: [-0.32352643  0.97692991  0.          0.          0.          0.        ]
2025-03-25 22:10:28,550 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,551 - INFO -   Participant 41 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,551 - INFO -   Participant 41 Coefficients: [-0.29638854  0.97972397  0.          0.          0.          0.        ]
2025-03-25 22:10:28,551 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,552 - INFO -   Participant 42 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,553 - INFO -   Participant 42 Coefficients: [-0.31529874  0.98013272  0.          0.          0.          0.        ]
2025-03-25 22:10:28,553 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,554 - INFO -   Participant 43 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,554 - INFO -   Participant 43 Coefficients: [-0.29727007  0.98521801  0.          0.          0.          0.        ]
2025-03-25 22:10:28,554 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,555 - INFO -   Participant 44 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,555 - INFO -   Participant 44 Coefficients: [-0.36651631  0.98283225  0.          0.          0.          0.        ]
2025-03-25 22:10:28,555 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,557 - INFO -   Participant 45 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,557 - INFO -   Participant 45 Coefficients: [-0.22037134  0.97880624  0.          0.          0.          0.        ]
2025-03-25 22:10:28,557 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,558 - INFO -   Participant 46 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,558 - INFO -   Participant 46 Coefficients: [-0.24048167  0.98425828  0.          0.          0.          0.        ]
2025-03-25 22:10:28,558 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,560 - INFO -   Participant 47 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,560 - INFO -   Participant 47 Coefficients: [-0.19490843  0.98380886  0.          0.          0.          0.        ]
2025-03-25 22:10:28,560 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,561 - INFO -   Participant 48 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,561 - INFO -   Participant 48 Coefficients: [-0.34805127  0.98203027  0.          0.          0.          0.        ]
2025-03-25 22:10:28,561 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,562 - INFO -   Participant 49 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,562 - INFO -   Participant 49 Coefficients: [-0.33266863  0.99642592  0.          0.          0.          0.        ]
2025-03-25 22:10:28,563 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,564 - INFO -   Participant 50 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,564 - INFO -   Participant 50 Coefficients: [-0.34037416  0.98459786  0.          0.          0.          0.        ]
2025-03-25 22:10:28,564 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,565 - INFO -   Participant 51 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,565 - INFO -   Participant 51 Coefficients: [-0.21105882  0.9861153   0.          0.          0.          0.        ]
2025-03-25 22:10:28,565 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,567 - INFO -   Participant 52 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,567 - INFO -   Participant 52 Coefficients: [-0.21684518  0.98816541  0.          0.          0.          0.        ]
2025-03-25 22:10:28,567 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,568 - INFO -   Participant 53 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,568 - INFO -   Participant 53 Coefficients: [-0.33995044  0.98223399  0.          0.          0.          0.        ]
2025-03-25 22:10:28,568 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,570 - INFO -   Participant 54 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,570 - INFO -   Participant 54 Coefficients: [-0.31204344  0.9835482   0.          0.          0.          0.        ]
2025-03-25 22:10:28,570 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,571 - INFO -   Participant 55 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,571 - INFO -   Participant 55 Coefficients: [-0.29543458  0.98084412  0.          0.          0.          0.        ]
2025-03-25 22:10:28,571 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,572 - INFO -   Participant 56 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,573 - INFO -   Participant 56 Coefficients: [-0.3178697   0.98150869  0.          0.          0.          0.        ]
2025-03-25 22:10:28,573 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,574 - INFO -   Participant 57 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,574 - INFO -   Participant 57 Coefficients: [-0.25458287  0.97922327  0.          0.          0.          0.        ]
2025-03-25 22:10:28,574 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,575 - INFO -   Participant 58 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,575 - INFO -   Participant 58 Coefficients: [-0.2193924   0.97364594  0.          0.          0.          0.        ]
2025-03-25 22:10:28,575 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,577 - INFO -   Participant 59 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,577 - INFO -   Participant 59 Coefficients: [-0.46549094  0.98453868  0.          0.          0.          0.        ]
2025-03-25 22:10:28,577 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,578 - INFO -   Participant 60 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,578 - INFO -   Participant 60 Coefficients: [-0.2667343   0.98206473  0.          0.          0.          0.        ]
2025-03-25 22:10:28,578 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,580 - INFO -   Participant 61 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,580 - INFO -   Participant 61 Coefficients: [-0.34536136  0.97755381  0.          0.          0.          0.        ]
2025-03-25 22:10:28,580 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,581 - INFO -   Participant 62 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,581 - INFO -   Participant 62 Coefficients: [-0.23299269  0.97419059  0.          0.          0.          0.        ]
2025-03-25 22:10:28,581 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,582 - INFO -   Participant 63 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,583 - INFO -   Participant 63 Coefficients: [-0.27905695  0.9985317   0.          0.          0.          0.        ]
2025-03-25 22:10:28,583 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,584 - INFO -   Participant 64 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,584 - INFO -   Participant 64 Coefficients: [-0.37376937  0.98189267  0.          0.          0.          0.        ]
2025-03-25 22:10:28,584 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,585 - INFO -   Participant 65 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,585 - INFO -   Participant 65 Coefficients: [-0.2040811   0.96924541  0.          0.          0.          0.        ]
2025-03-25 22:10:28,585 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,587 - INFO -   Participant 66 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,587 - INFO -   Participant 66 Coefficients: [-0.28223439  0.98478191  0.          0.          0.          0.        ]
2025-03-25 22:10:28,587 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,588 - INFO -   Participant 67 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,588 - INFO -   Participant 67 Coefficients: [-0.34093863  0.98225061  0.          0.          0.          0.        ]
2025-03-25 22:10:28,588 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,589 - INFO -   Participant 68 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,589 - INFO -   Participant 68 Coefficients: [-0.26794779  0.98755931  0.          0.          0.          0.        ]
2025-03-25 22:10:28,589 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,591 - INFO -   Participant 69 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,591 - INFO -   Participant 69 Coefficients: [-0.12195373  0.97274571  0.          0.          0.          0.        ]
2025-03-25 22:10:28,591 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,592 - INFO -   Participant 70 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,592 - INFO -   Participant 70 Coefficients: [-0.29419462  0.98924111  0.          0.          0.          0.        ]
2025-03-25 22:10:28,592 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,594 - INFO -   Participant 71 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,594 - INFO -   Participant 71 Coefficients: [-0.33935681  0.98093087  0.          0.          0.          0.        ]
2025-03-25 22:10:28,594 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,595 - INFO -   Participant 72 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,595 - INFO -   Participant 72 Coefficients: [-0.24164344  0.98588432  0.          0.          0.          0.        ]
2025-03-25 22:10:28,595 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,596 - INFO -   Participant 73 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,596 - INFO -   Participant 73 Coefficients: [-0.24455957  0.97764216  0.          0.          0.          0.        ]
2025-03-25 22:10:28,597 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,598 - INFO -   Participant 74 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,598 - INFO -   Participant 74 Coefficients: [-0.29264771  0.98072797  0.          0.          0.          0.        ]
2025-03-25 22:10:28,598 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,599 - INFO -   Participant 75 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,599 - INFO -   Participant 75 Coefficients: [-0.32105263  0.99172521  0.          0.          0.          0.        ]
2025-03-25 22:10:28,599 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,601 - INFO -   Participant 76 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,601 - INFO -   Participant 76 Coefficients: [-0.39289139  0.98623908  0.          0.          0.          0.        ]
2025-03-25 22:10:28,601 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,602 - INFO -   Participant 77 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,602 - INFO -   Participant 77 Coefficients: [-0.34223462  0.98628105  0.          0.          0.          0.        ]
2025-03-25 22:10:28,602 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,603 - INFO -   Participant 78 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,603 - INFO -   Participant 78 Coefficients: [-0.34166525  0.98032612  0.          0.          0.          0.        ]
2025-03-25 22:10:28,603 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,605 - INFO -   Participant 79 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,605 - INFO -   Participant 79 Coefficients: [-0.23519538  0.98873855  0.          0.          0.          0.        ]
2025-03-25 22:10:28,605 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,606 - INFO -   Participant 80 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,606 - INFO -   Participant 80 Coefficients: [-0.29501233  0.99089341  0.          0.          0.          0.        ]
2025-03-25 22:10:28,606 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,608 - INFO -   Participant 81 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,608 - INFO -   Participant 81 Coefficients: [-0.20243187  0.98674767  0.          0.          0.          0.        ]
2025-03-25 22:10:28,608 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,609 - INFO -   Participant 82 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,609 - INFO -   Participant 82 Coefficients: [-0.36425198  0.97703865  0.          0.          0.          0.        ]
2025-03-25 22:10:28,609 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,610 - INFO -   Participant 83 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,610 - INFO -   Participant 83 Coefficients: [-0.26616218  0.9809424   0.          0.          0.          0.        ]
2025-03-25 22:10:28,610 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,612 - INFO -   Participant 84 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,612 - INFO -   Participant 84 Coefficients: [-0.2333794   0.98096821  0.          0.          0.          0.        ]
2025-03-25 22:10:28,612 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,613 - INFO -   Participant 85 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,613 - INFO -   Participant 85 Coefficients: [-0.43752594  0.98262181  0.          0.          0.          0.        ]
2025-03-25 22:10:28,613 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,615 - INFO -   Participant 86 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,615 - INFO -   Participant 86 Coefficients: [-0.22586136  0.98857507  0.          0.          0.          0.        ]
2025-03-25 22:10:28,615 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,616 - INFO -   Participant 87 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,616 - INFO -   Participant 87 Coefficients: [-0.25703663  0.97314424  0.          0.          0.          0.        ]
2025-03-25 22:10:28,616 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,617 - INFO -   Participant 88 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,617 - INFO -   Participant 88 Coefficients: [-0.24270586  0.9783176   0.          0.          0.          0.        ]
2025-03-25 22:10:28,617 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,619 - INFO -   Participant 89 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,619 - INFO -   Participant 89 Coefficients: [-0.35567329  0.97921698  0.          0.          0.          0.        ]
2025-03-25 22:10:28,619 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,620 - INFO -   Participant 90 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,620 - INFO -   Participant 90 Coefficients: [-0.19879181  0.98555503  0.          0.          0.          0.        ]
2025-03-25 22:10:28,620 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,622 - INFO -   Participant 91 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,622 - INFO -   Participant 91 Coefficients: [-0.31029536  0.98552434  0.          0.          0.          0.        ]
2025-03-25 22:10:28,622 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,623 - INFO -   Participant 92 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,623 - INFO -   Participant 92 Coefficients: [-0.24268578  0.98034791  0.          0.          0.          0.        ]
2025-03-25 22:10:28,623 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,625 - INFO -   Participant 93 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,625 - INFO -   Participant 93 Coefficients: [-0.28946658  0.9956987   0.          0.          0.          0.        ]
2025-03-25 22:10:28,625 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,626 - INFO -   Participant 94 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,626 - INFO -   Participant 94 Coefficients: [-0.32320447  0.99281372  0.          0.          0.          0.        ]
2025-03-25 22:10:28,626 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,627 - INFO -   Participant 95 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,628 - INFO -   Participant 95 Coefficients: [-0.28071096  0.98461938  0.          0.          0.          0.        ]
2025-03-25 22:10:28,628 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,629 - INFO -   Participant 96 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,629 - INFO -   Participant 96 Coefficients: [-0.27843161  0.99061189  0.          0.          0.          0.        ]
2025-03-25 22:10:28,629 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,630 - INFO -   Participant 97 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,630 - INFO -   Participant 97 Coefficients: [-0.19759205  0.9797945   0.          0.          0.          0.        ]
2025-03-25 22:10:28,630 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,632 - INFO -   Participant 98 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,632 - INFO -   Participant 98 Coefficients: [-0.31459649  0.97836648  0.          0.          0.          0.        ]
2025-03-25 22:10:28,632 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,633 - INFO -   Participant 99 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,633 - INFO -   Participant 99 Coefficients: [-0.30370845  0.98809616  0.          0.          0.          0.        ]
2025-03-25 22:10:28,633 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,635 - INFO -   Participant 100 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,635 - INFO -   Participant 100 Coefficients: [-0.32674286  0.98564764  0.          0.          0.          0.        ]
2025-03-25 22:10:28,635 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,636 - INFO -   Participant 101 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,636 - INFO -   Participant 101 Coefficients: [-0.29716512  0.98696681  0.          0.          0.          0.        ]
2025-03-25 22:10:28,636 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,637 - INFO -   Participant 102 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,638 - INFO -   Participant 102 Coefficients: [-0.29870717  0.98714996  0.          0.          0.          0.        ]
2025-03-25 22:10:28,638 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,639 - INFO -   Participant 103 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,639 - INFO -   Participant 103 Coefficients: [-0.10084062  0.97642096  0.          0.          0.          0.        ]
2025-03-25 22:10:28,639 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,640 - INFO -   Participant 104 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,640 - INFO -   Participant 104 Coefficients: [-0.22530237  0.98106197  0.          0.          0.          0.        ]
2025-03-25 22:10:28,640 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,642 - INFO -   Participant 105 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,642 - INFO -   Participant 105 Coefficients: [-0.27624118  0.98023749  0.          0.          0.          0.        ]
2025-03-25 22:10:28,642 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,643 - INFO -   Participant 106 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,643 - INFO -   Participant 106 Coefficients: [-0.22128785  0.98087646  0.          0.          0.          0.        ]
2025-03-25 22:10:28,643 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,644 - INFO -   Participant 107 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,645 - INFO -   Participant 107 Coefficients: [-0.3015867   0.99575094  0.          0.          0.          0.        ]
2025-03-25 22:10:28,645 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,646 - INFO -   Participant 108 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,646 - INFO -   Participant 108 Coefficients: [-0.31244104  0.99116322  0.          0.          0.          0.        ]
2025-03-25 22:10:28,646 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,647 - INFO -   Participant 109 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,647 - INFO -   Participant 109 Coefficients: [-0.18175241  0.98217827  0.          0.          0.          0.        ]
2025-03-25 22:10:28,647 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,649 - INFO -   Participant 110 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,649 - INFO -   Participant 110 Coefficients: [-0.37468873  0.98843583  0.          0.          0.          0.        ]
2025-03-25 22:10:28,649 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,650 - INFO -   Participant 111 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,650 - INFO -   Participant 111 Coefficients: [-0.23975473  0.9849221   0.          0.          0.          0.        ]
2025-03-25 22:10:28,650 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,652 - INFO -   Participant 112 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,652 - INFO -   Participant 112 Coefficients: [-0.26878931  0.97702147  0.          0.          0.          0.        ]
2025-03-25 22:10:28,652 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,653 - INFO -   Participant 113 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,653 - INFO -   Participant 113 Coefficients: [-0.33450749  0.98502611  0.          0.          0.          0.        ]
2025-03-25 22:10:28,653 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,654 - INFO -   Participant 114 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,654 - INFO -   Participant 114 Coefficients: [-0.32955015  0.9819598   0.          0.          0.          0.        ]
2025-03-25 22:10:28,655 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,656 - INFO -   Participant 115 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,656 - INFO -   Participant 115 Coefficients: [-0.27619476  0.97879282  0.          0.          0.          0.        ]
2025-03-25 22:10:28,656 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,657 - INFO -   Participant 116 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,657 - INFO -   Participant 116 Coefficients: [-0.30617717  0.98669494  0.          0.          0.          0.        ]
2025-03-25 22:10:28,657 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,659 - INFO -   Participant 117 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,659 - INFO -   Participant 117 Coefficients: [-0.24588416  0.99760197  0.          0.          0.          0.        ]
2025-03-25 22:10:28,659 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,660 - INFO -   Participant 118 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,660 - INFO -   Participant 118 Coefficients: [-0.28799617  0.98482437  0.          0.          0.          0.        ]
2025-03-25 22:10:28,660 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,661 - INFO -   Participant 119 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,661 - INFO -   Participant 119 Coefficients: [-0.26316068  0.98658048  0.          0.          0.          0.        ]
2025-03-25 22:10:28,661 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,663 - INFO -   Participant 120 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,663 - INFO -   Participant 120 Coefficients: [-0.3458292   0.98079694  0.          0.          0.          0.        ]
2025-03-25 22:10:28,663 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,664 - INFO -   Participant 121 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,664 - INFO -   Participant 121 Coefficients: [-0.27209272  0.97017668  0.          0.          0.          0.        ]
2025-03-25 22:10:28,664 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,666 - INFO -   Participant 122 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,666 - INFO -   Participant 122 Coefficients: [-0.33914713  0.98059858  0.          0.          0.          0.        ]
2025-03-25 22:10:28,666 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,667 - INFO -   Participant 123 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,667 - INFO -   Participant 123 Coefficients: [-0.22910665  0.98122754  0.          0.          0.          0.        ]
2025-03-25 22:10:28,667 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,668 - INFO -   Participant 124 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,668 - INFO -   Participant 124 Coefficients: [-0.32328384  0.97784684  0.          0.          0.          0.        ]
2025-03-25 22:10:28,669 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,670 - INFO -   Participant 125 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,670 - INFO -   Participant 125 Coefficients: [-0.39320291  0.98693746  0.          0.          0.          0.        ]
2025-03-25 22:10:28,670 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,671 - INFO -   Participant 126 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,671 - INFO -   Participant 126 Coefficients: [-0.33122741  0.98344678  0.          0.          0.          0.        ]
2025-03-25 22:10:28,671 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,673 - INFO -   Participant 127 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,673 - INFO -   Participant 127 Coefficients: [-0.28393424  0.9919174   0.          0.          0.          0.        ]
2025-03-25 22:10:28,673 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,674 - INFO -   Participant 128 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,674 - INFO -   Participant 128 Coefficients: [-0.25516465  0.98248832  0.          0.          0.          0.        ]
2025-03-25 22:10:28,674 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,675 - INFO -   Participant 129 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,676 - INFO -   Participant 129 Coefficients: [-0.23369897  0.97291097  0.          0.          0.          0.        ]
2025-03-25 22:10:28,676 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,677 - INFO -   Participant 130 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,677 - INFO -   Participant 130 Coefficients: [-0.40062828  0.98261797  0.          0.          0.          0.        ]
2025-03-25 22:10:28,677 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,678 - INFO -   Participant 131 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,678 - INFO -   Participant 131 Coefficients: [-0.31575334  0.98159558  0.          0.          0.          0.        ]
2025-03-25 22:10:28,678 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,680 - INFO -   Participant 132 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,680 - INFO -   Participant 132 Coefficients: [-0.28840588  0.98251601  0.          0.          0.          0.        ]
2025-03-25 22:10:28,680 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,681 - INFO -   Participant 133 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,681 - INFO -   Participant 133 Coefficients: [-0.27254798  0.98404535  0.          0.          0.          0.        ]
2025-03-25 22:10:28,681 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,682 - INFO -   Participant 134 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,683 - INFO -   Participant 134 Coefficients: [-0.19639145  0.9849242   0.          0.          0.          0.        ]
2025-03-25 22:10:28,683 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,684 - INFO -   Participant 135 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,684 - INFO -   Participant 135 Coefficients: [-0.29168655  0.98869328  0.          0.          0.          0.        ]
2025-03-25 22:10:28,684 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,685 - INFO -   Participant 136 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,686 - INFO -   Participant 136 Coefficients: [-0.28009099  0.98691103  0.          0.          0.          0.        ]
2025-03-25 22:10:28,686 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,687 - INFO -   Participant 137 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,687 - INFO -   Participant 137 Coefficients: [-0.41820143  0.98469948  0.          0.          0.          0.        ]
2025-03-25 22:10:28,687 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,688 - INFO -   Participant 138 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,688 - INFO -   Participant 138 Coefficients: [-0.31311326  0.97748409  0.          0.          0.          0.        ]
2025-03-25 22:10:28,688 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,690 - INFO -   Participant 139 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,690 - INFO -   Participant 139 Coefficients: [-0.3525947   0.97918628  0.          0.          0.          0.        ]
2025-03-25 22:10:28,690 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,691 - INFO -   Participant 140 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,691 - INFO -   Participant 140 Coefficients: [-0.24652221  0.98143459  0.          0.          0.          0.        ]
2025-03-25 22:10:28,691 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,692 - INFO -   Participant 141 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,693 - INFO -   Participant 141 Coefficients: [-0.34517198  0.98973863  0.          0.          0.          0.        ]
2025-03-25 22:10:28,693 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,694 - INFO -   Participant 142 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,694 - INFO -   Participant 142 Coefficients: [-0.33228799  0.98171872  0.          0.          0.          0.        ]
2025-03-25 22:10:28,694 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,695 - INFO -   Participant 143 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,695 - INFO -   Participant 143 Coefficients: [-0.2387641   0.99117317  0.          0.          0.          0.        ]
2025-03-25 22:10:28,695 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,697 - INFO -   Participant 144 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,697 - INFO -   Participant 144 Coefficients: [-0.35138769  0.99121414  0.          0.          0.          0.        ]
2025-03-25 22:10:28,697 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,698 - INFO -   Participant 145 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,698 - INFO -   Participant 145 Coefficients: [-0.41265764  0.9805663   0.          0.          0.          0.        ]
2025-03-25 22:10:28,698 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,699 - INFO -   Participant 146 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,700 - INFO -   Participant 146 Coefficients: [-0.35966439  0.97633442  0.          0.          0.          0.        ]
2025-03-25 22:10:28,700 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,701 - INFO -   Participant 147 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,701 - INFO -   Participant 147 Coefficients: [-0.30423035  0.98476848  0.          0.          0.          0.        ]
2025-03-25 22:10:28,701 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,702 - INFO -   Participant 148 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,702 - INFO -   Participant 148 Coefficients: [-0.25575717  0.98518751  0.          0.          0.          0.        ]
2025-03-25 22:10:28,702 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,704 - INFO -   Participant 149 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,704 - INFO -   Participant 149 Coefficients: [-0.30132629  0.98780037  0.          0.          0.          0.        ]
2025-03-25 22:10:28,704 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,705 - INFO -   Participant 150 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,705 - INFO -   Participant 150 Coefficients: [-0.22236745  0.98435248  0.          0.          0.          0.        ]
2025-03-25 22:10:28,705 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,707 - INFO -   Participant 151 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,707 - INFO -   Participant 151 Coefficients: [-0.20500408  0.99897485  0.          0.          0.          0.        ]
2025-03-25 22:10:28,707 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,708 - INFO -   Participant 152 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,708 - INFO -   Participant 152 Coefficients: [-0.26921266  0.98244518  0.          0.          0.          0.        ]
2025-03-25 22:10:28,708 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,709 - INFO -   Participant 153 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,709 - INFO -   Participant 153 Coefficients: [-0.2429269   0.98122003  0.          0.          0.          0.        ]
2025-03-25 22:10:28,710 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,711 - INFO -   Participant 154 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,711 - INFO -   Participant 154 Coefficients: [-0.32081734  0.99473483  0.          0.          0.          0.        ]
2025-03-25 22:10:28,711 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,712 - INFO -   Participant 155 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,712 - INFO -   Participant 155 Coefficients: [-0.23777625  0.98559934  0.          0.          0.          0.        ]
2025-03-25 22:10:28,712 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,714 - INFO -   Participant 156 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,714 - INFO -   Participant 156 Coefficients: [-0.2601558   0.97829683  0.          0.          0.          0.        ]
2025-03-25 22:10:28,714 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,715 - INFO -   Participant 157 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,715 - INFO -   Participant 157 Coefficients: [-0.28856687  0.98800907  0.          0.          0.          0.        ]
2025-03-25 22:10:28,715 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,717 - INFO -   Participant 158 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,717 - INFO -   Participant 158 Coefficients: [-0.32620311  0.98833072  0.          0.          0.          0.        ]
2025-03-25 22:10:28,717 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,718 - INFO -   Participant 159 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,718 - INFO -   Participant 159 Coefficients: [-0.24685633  0.98177593  0.          0.          0.          0.        ]
2025-03-25 22:10:28,718 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,719 - INFO -   Participant 160 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,720 - INFO -   Participant 160 Coefficients: [-0.34901146  0.98005341  0.          0.          0.          0.        ]
2025-03-25 22:10:28,720 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,721 - INFO -   Participant 161 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,721 - INFO -   Participant 161 Coefficients: [-0.25473223  0.97455882  0.          0.          0.          0.        ]
2025-03-25 22:10:28,721 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,722 - INFO -   Participant 162 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,722 - INFO -   Participant 162 Coefficients: [-0.25118176  0.97973206  0.          0.          0.          0.        ]
2025-03-25 22:10:28,722 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,724 - INFO -   Participant 163 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,724 - INFO -   Participant 163 Coefficients: [-0.20440096  0.98638214  0.          0.          0.          0.        ]
2025-03-25 22:10:28,724 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,725 - INFO -   Participant 164 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,725 - INFO -   Participant 164 Coefficients: [-0.29464088  0.99668104  0.          0.          0.          0.        ]
2025-03-25 22:10:28,725 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,727 - INFO -   Participant 165 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,727 - INFO -   Participant 165 Coefficients: [-0.28268156  0.98226525  0.          0.          0.          0.        ]
2025-03-25 22:10:28,727 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,728 - INFO -   Participant 166 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,728 - INFO -   Participant 166 Coefficients: [-0.22867582  0.97398765  0.          0.          0.          0.        ]
2025-03-25 22:10:28,728 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,730 - INFO -   Participant 167 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,730 - INFO -   Participant 167 Coefficients: [-0.27541947  0.98702524  0.          0.          0.          0.        ]
2025-03-25 22:10:28,730 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,731 - INFO -   Participant 168 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,731 - INFO -   Participant 168 Coefficients: [-0.33205081  0.97724456  0.          0.          0.          0.        ]
2025-03-25 22:10:28,731 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,733 - INFO -   Participant 169 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,733 - INFO -   Participant 169 Coefficients: [-0.31975495  0.98166755  0.          0.          0.          0.        ]
2025-03-25 22:10:28,733 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,734 - INFO -   Participant 170 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,734 - INFO -   Participant 170 Coefficients: [-0.20818561  0.97808281  0.          0.          0.          0.        ]
2025-03-25 22:10:28,734 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,735 - INFO -   Participant 171 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,736 - INFO -   Participant 171 Coefficients: [-0.32641443  0.98238309  0.          0.          0.          0.        ]
2025-03-25 22:10:28,736 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,737 - INFO -   Participant 172 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,737 - INFO -   Participant 172 Coefficients: [-0.23476148  0.97416168  0.          0.          0.          0.        ]
2025-03-25 22:10:28,737 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,738 - INFO -   Participant 173 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,738 - INFO -   Participant 173 Coefficients: [-0.4449752  0.9754886  0.         0.         0.         0.       ]
2025-03-25 22:10:28,738 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,740 - INFO -   Participant 174 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,740 - INFO -   Participant 174 Coefficients: [-0.39873192  0.98321118  0.          0.          0.          0.        ]
2025-03-25 22:10:28,740 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,741 - INFO -   Participant 175 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,741 - INFO -   Participant 175 Coefficients: [-0.28507675  0.97783044  0.          0.          0.          0.        ]
2025-03-25 22:10:28,741 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,743 - INFO -   Participant 176 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,743 - INFO -   Participant 176 Coefficients: [-0.2314787   0.97942986  0.          0.          0.          0.        ]
2025-03-25 22:10:28,743 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,744 - INFO -   Participant 177 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,744 - INFO -   Participant 177 Coefficients: [-0.28198562  0.97650048  0.          0.          0.          0.        ]
2025-03-25 22:10:28,744 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,745 - INFO -   Participant 178 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,746 - INFO -   Participant 178 Coefficients: [-0.41914389  0.98045832  0.          0.          0.          0.        ]
2025-03-25 22:10:28,746 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,747 - INFO -   Participant 179 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,747 - INFO -   Participant 179 Coefficients: [-0.37080622  0.98400214  0.          0.          0.          0.        ]
2025-03-25 22:10:28,747 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,748 - INFO -   Participant 180 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,748 - INFO -   Participant 180 Coefficients: [-0.22447612  0.98013233  0.          0.          0.          0.        ]
2025-03-25 22:10:28,749 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,750 - INFO -   Participant 181 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,750 - INFO -   Participant 181 Coefficients: [-0.27400979  0.97657966  0.          0.          0.          0.        ]
2025-03-25 22:10:28,750 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,751 - INFO -   Participant 182 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,751 - INFO -   Participant 182 Coefficients: [-0.30061591  0.98016777  0.          0.          0.          0.        ]
2025-03-25 22:10:28,751 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,753 - INFO -   Participant 183 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,753 - INFO -   Participant 183 Coefficients: [-0.2726377   0.98412352  0.          0.          0.          0.        ]
2025-03-25 22:10:28,753 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,754 - INFO -   Participant 184 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,754 - INFO -   Participant 184 Coefficients: [-0.25542702  0.98235464  0.          0.          0.          0.        ]
2025-03-25 22:10:28,754 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,755 - INFO -   Participant 185 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,756 - INFO -   Participant 185 Coefficients: [-0.1956111   0.98944814  0.          0.          0.          0.        ]
2025-03-25 22:10:28,756 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,757 - INFO -   Participant 186 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,757 - INFO -   Participant 186 Coefficients: [-0.25675238  0.98932015  0.          0.          0.          0.        ]
2025-03-25 22:10:28,757 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,758 - INFO -   Participant 187 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,758 - INFO -   Participant 187 Coefficients: [-0.2331841  0.9863961  0.         0.         0.         0.       ]
2025-03-25 22:10:28,758 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,760 - INFO -   Participant 188 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,760 - INFO -   Participant 188 Coefficients: [-0.32340713  0.98989942  0.          0.          0.          0.        ]
2025-03-25 22:10:28,760 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,761 - INFO -   Participant 189 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,761 - INFO -   Participant 189 Coefficients: [-0.32284483  0.98269925  0.          0.          0.          0.        ]
2025-03-25 22:10:28,761 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,763 - INFO -   Participant 190 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,763 - INFO -   Participant 190 Coefficients: [-0.28776361  0.99129857  0.          0.          0.          0.        ]
2025-03-25 22:10:28,763 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,764 - INFO -   Participant 191 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,764 - INFO -   Participant 191 Coefficients: [-0.48783138  0.97783786  0.          0.          0.          0.        ]
2025-03-25 22:10:28,764 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,766 - INFO -   Participant 192 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,766 - INFO -   Participant 192 Coefficients: [-0.30831485  0.98187639  0.          0.          0.          0.        ]
2025-03-25 22:10:28,766 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,767 - INFO -   Participant 193 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,767 - INFO -   Participant 193 Coefficients: [-0.31292657  0.98691774  0.          0.          0.          0.        ]
2025-03-25 22:10:28,767 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,769 - INFO -   Participant 194 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,769 - INFO -   Participant 194 Coefficients: [-0.30550278  0.99112715  0.          0.          0.          0.        ]
2025-03-25 22:10:28,769 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,770 - INFO -   Participant 195 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,770 - INFO -   Participant 195 Coefficients: [-0.24424159  0.99445461  0.          0.          0.          0.        ]
2025-03-25 22:10:28,770 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,772 - INFO -   Participant 196 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,772 - INFO -   Participant 196 Coefficients: [-0.35025449  0.98355956  0.          0.          0.          0.        ]
2025-03-25 22:10:28,772 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,773 - INFO -   Participant 197 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,773 - INFO -   Participant 197 Coefficients: [-0.25714702  0.9913644   0.          0.          0.          0.        ]
2025-03-25 22:10:28,773 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,775 - INFO -   Participant 198 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,775 - INFO -   Participant 198 Coefficients: [-0.27918223  0.97971552  0.          0.          0.          0.        ]
2025-03-25 22:10:28,775 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,776 - INFO -   Participant 199 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,776 - INFO -   Participant 199 Coefficients: [-0.24825776  0.98635175  0.          0.          0.          0.        ]
2025-03-25 22:10:28,776 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,777 - INFO -   Participant 200 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,778 - INFO -   Participant 200 Coefficients: [-0.32796496  0.97907174  0.          0.          0.          0.        ]
2025-03-25 22:10:28,778 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,779 - INFO -   Participant 201 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,779 - INFO -   Participant 201 Coefficients: [-0.30937183  0.99026178  0.          0.          0.          0.        ]
2025-03-25 22:10:28,779 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,780 - INFO -   Participant 202 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,780 - INFO -   Participant 202 Coefficients: [-0.21713318  0.98927464  0.          0.          0.          0.        ]
2025-03-25 22:10:28,780 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,782 - INFO -   Participant 203 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,782 - INFO -   Participant 203 Coefficients: [-0.25209409  0.9832157   0.          0.          0.          0.        ]
2025-03-25 22:10:28,782 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,783 - INFO -   Participant 204 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,783 - INFO -   Participant 204 Coefficients: [-0.37241312  0.97853241  0.          0.          0.          0.        ]
2025-03-25 22:10:28,783 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,785 - INFO -   Participant 205 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,785 - INFO -   Participant 205 Coefficients: [-0.25082138  0.98342957  0.          0.          0.          0.        ]
2025-03-25 22:10:28,785 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,786 - INFO -   Participant 206 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,786 - INFO -   Participant 206 Coefficients: [-0.28302428  0.98067593  0.          0.          0.          0.        ]
2025-03-25 22:10:28,786 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,788 - INFO -   Participant 207 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,788 - INFO -   Participant 207 Coefficients: [-0.24836623  0.98191575  0.          0.          0.          0.        ]
2025-03-25 22:10:28,788 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,789 - INFO -   Participant 208 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,789 - INFO -   Participant 208 Coefficients: [-0.22850306  0.97872656  0.          0.          0.          0.        ]
2025-03-25 22:10:28,789 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,790 - INFO -   Participant 209 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,791 - INFO -   Participant 209 Coefficients: [-0.26526668  0.97793997  0.          0.          0.          0.        ]
2025-03-25 22:10:28,791 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,792 - INFO -   Participant 210 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,792 - INFO -   Participant 210 Coefficients: [-0.31647583  0.97818534  0.          0.          0.          0.        ]
2025-03-25 22:10:28,792 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,793 - INFO -   Participant 211 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,793 - INFO -   Participant 211 Coefficients: [-0.1892671   0.98423735  0.          0.          0.          0.        ]
2025-03-25 22:10:28,794 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,795 - INFO -   Participant 212 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,795 - INFO -   Participant 212 Coefficients: [-0.31456246  0.97643996  0.          0.          0.          0.        ]
2025-03-25 22:10:28,795 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,796 - INFO -   Participant 213 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,796 - INFO -   Participant 213 Coefficients: [-0.25104708  0.98583944  0.          0.          0.          0.        ]
2025-03-25 22:10:28,796 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,798 - INFO -   Participant 214 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,798 - INFO -   Participant 214 Coefficients: [-0.33522152  0.98513063  0.          0.          0.          0.        ]
2025-03-25 22:10:28,798 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,799 - INFO -   Participant 215 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,799 - INFO -   Participant 215 Coefficients: [-0.32447034  0.98588352  0.          0.          0.          0.        ]
2025-03-25 22:10:28,799 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,800 - INFO -   Participant 216 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,801 - INFO -   Participant 216 Coefficients: [-0.211513    0.98181103  0.          0.          0.          0.        ]
2025-03-25 22:10:28,801 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,802 - INFO -   Participant 217 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,802 - INFO -   Participant 217 Coefficients: [-0.40055002  0.98855258  0.          0.          0.          0.        ]
2025-03-25 22:10:28,802 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,803 - INFO -   Participant 218 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,803 - INFO -   Participant 218 Coefficients: [-0.49042606  0.98060378  0.          0.          0.          0.        ]
2025-03-25 22:10:28,803 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,805 - INFO -   Participant 219 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,805 - INFO -   Participant 219 Coefficients: [-0.13712421  0.9728046   0.          0.          0.          0.        ]
2025-03-25 22:10:28,805 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,806 - INFO -   Participant 220 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,806 - INFO -   Participant 220 Coefficients: [-0.36407907  0.98950474  0.          0.          0.          0.        ]
2025-03-25 22:10:28,806 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,808 - INFO -   Participant 221 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,808 - INFO -   Participant 221 Coefficients: [-0.24431156  0.98555623  0.          0.          0.          0.        ]
2025-03-25 22:10:28,808 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,809 - INFO -   Participant 222 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,809 - INFO -   Participant 222 Coefficients: [-0.38292047  0.98948355  0.          0.          0.          0.        ]
2025-03-25 22:10:28,809 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,811 - INFO -   Participant 223 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,811 - INFO -   Participant 223 Coefficients: [-0.32637893  0.97817357  0.          0.          0.          0.        ]
2025-03-25 22:10:28,811 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,812 - INFO -   Participant 224 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,812 - INFO -   Participant 224 Coefficients: [-0.28560962  0.98763669  0.          0.          0.          0.        ]
2025-03-25 22:10:28,812 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,813 - INFO -   Participant 225 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,814 - INFO -   Participant 225 Coefficients: [-0.35050672  0.9872651   0.          0.          0.          0.        ]
2025-03-25 22:10:28,814 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,815 - INFO -   Participant 226 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,815 - INFO -   Participant 226 Coefficients: [-0.30356499  0.98463807  0.          0.          0.          0.        ]
2025-03-25 22:10:28,815 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,816 - INFO -   Participant 227 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,817 - INFO -   Participant 227 Coefficients: [-0.33329312  0.99463419  0.          0.          0.          0.        ]
2025-03-25 22:10:28,817 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,818 - INFO -   Participant 228 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,818 - INFO -   Participant 228 Coefficients: [-0.37825461  0.98249159  0.          0.          0.          0.        ]
2025-03-25 22:10:28,818 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,819 - INFO -   Participant 229 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,819 - INFO -   Participant 229 Coefficients: [-0.29446573  0.98216596  0.          0.          0.          0.        ]
2025-03-25 22:10:28,819 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,821 - INFO -   Participant 230 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,821 - INFO -   Participant 230 Coefficients: [-0.26361123  0.97348479  0.          0.          0.          0.        ]
2025-03-25 22:10:28,821 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,822 - INFO -   Participant 231 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,822 - INFO -   Participant 231 Coefficients: [-0.27377148  0.98474065  0.          0.          0.          0.        ]
2025-03-25 22:10:28,822 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,824 - INFO -   Participant 232 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,824 - INFO -   Participant 232 Coefficients: [-0.38451993  0.98207849  0.          0.          0.          0.        ]
2025-03-25 22:10:28,824 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,825 - INFO -   Participant 233 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,825 - INFO -   Participant 233 Coefficients: [-0.25825406  0.97667071  0.          0.          0.          0.        ]
2025-03-25 22:10:28,825 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,826 - INFO -   Participant 234 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,827 - INFO -   Participant 234 Coefficients: [-0.29241346  0.98213705  0.          0.          0.          0.        ]
2025-03-25 22:10:28,827 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,828 - INFO -   Participant 235 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,828 - INFO -   Participant 235 Coefficients: [-0.30683031  0.97905979  0.          0.          0.          0.        ]
2025-03-25 22:10:28,828 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,829 - INFO -   Participant 236 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,829 - INFO -   Participant 236 Coefficients: [-0.26155099  0.98129537  0.          0.          0.          0.        ]
2025-03-25 22:10:28,829 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,831 - INFO -   Participant 237 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,831 - INFO -   Participant 237 Coefficients: [-0.27844057  0.98933479  0.          0.          0.          0.        ]
2025-03-25 22:10:28,831 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,832 - INFO -   Participant 238 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,832 - INFO -   Participant 238 Coefficients: [-0.32211791  0.98788403  0.          0.          0.          0.        ]
2025-03-25 22:10:28,832 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,834 - INFO -   Participant 239 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,834 - INFO -   Participant 239 Coefficients: [-0.32425624  0.98452418  0.          0.          0.          0.        ]
2025-03-25 22:10:28,834 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,835 - INFO -   Participant 240 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,835 - INFO -   Participant 240 Coefficients: [-0.4162549   0.98158309  0.          0.          0.          0.        ]
2025-03-25 22:10:28,835 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,837 - INFO -   Participant 241 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,837 - INFO -   Participant 241 Coefficients: [-0.3589779   0.97965676  0.          0.          0.          0.        ]
2025-03-25 22:10:28,837 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,838 - INFO -   Participant 242 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,838 - INFO -   Participant 242 Coefficients: [-0.48380312  0.98435471  0.          0.          0.          0.        ]
2025-03-25 22:10:28,838 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,839 - INFO -   Participant 243 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,840 - INFO -   Participant 243 Coefficients: [-0.28671977  0.98400944  0.          0.          0.          0.        ]
2025-03-25 22:10:28,840 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,841 - INFO -   Participant 244 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,841 - INFO -   Participant 244 Coefficients: [-0.3399488   0.98254102  0.          0.          0.          0.        ]
2025-03-25 22:10:28,841 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,842 - INFO -   Participant 245 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,842 - INFO -   Participant 245 Coefficients: [-0.27598162  0.98860756  0.          0.          0.          0.        ]
2025-03-25 22:10:28,842 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,844 - INFO -   Participant 246 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,844 - INFO -   Participant 246 Coefficients: [-0.20726823  0.99236974  0.          0.          0.          0.        ]
2025-03-25 22:10:28,844 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,845 - INFO -   Participant 247 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,845 - INFO -   Participant 247 Coefficients: [-0.27387061  0.98259258  0.          0.          0.          0.        ]
2025-03-25 22:10:28,845 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,847 - INFO -   Participant 248 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,847 - INFO -   Participant 248 Coefficients: [-0.2959876   0.98380977  0.          0.          0.          0.        ]
2025-03-25 22:10:28,847 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,848 - INFO -   Participant 249 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,848 - INFO -   Participant 249 Coefficients: [-0.39018487  0.97792857  0.          0.          0.          0.        ]
2025-03-25 22:10:28,848 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,849 - INFO -   Participant 250 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,849 - INFO -   Participant 250 Coefficients: [-0.28187198  0.98149323  0.          0.          0.          0.        ]
2025-03-25 22:10:28,849 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,851 - INFO -   Participant 251 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,851 - INFO -   Participant 251 Coefficients: [-0.30796023  0.98725701  0.          0.          0.          0.        ]
2025-03-25 22:10:28,851 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,852 - INFO -   Participant 252 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,852 - INFO -   Participant 252 Coefficients: [-0.32844493  0.97802217  0.          0.          0.          0.        ]
2025-03-25 22:10:28,852 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,854 - INFO -   Participant 253 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,854 - INFO -   Participant 253 Coefficients: [-0.2593061   0.99053962  0.          0.          0.          0.        ]
2025-03-25 22:10:28,854 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,855 - INFO -   Participant 254 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,855 - INFO -   Participant 254 Coefficients: [-0.27946299  0.9856977   0.          0.          0.          0.        ]
2025-03-25 22:10:28,855 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,857 - INFO -   Participant 255 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,857 - INFO -   Participant 255 Coefficients: [-0.24091059  0.97890376  0.          0.          0.          0.        ]
2025-03-25 22:10:28,857 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:10:28,857 - INFO - Module: x_value_choice_chosen
2025-03-25 22:10:28,858 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,858 - INFO -   Participant 0 Coefficients: [0.36734498 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,858 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,859 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,860 - INFO -   Participant 1 Coefficients: [0.5473964 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:28,860 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,861 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,861 - INFO -   Participant 2 Coefficients: [0.59136847 0.21909505 0.         0.         0.         0.        ]
2025-03-25 22:10:28,861 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,862 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,862 - INFO -   Participant 3 Coefficients: [0.55327222 0.25262238 0.         0.         0.         0.        ]
2025-03-25 22:10:28,862 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,864 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,864 - INFO -   Participant 4 Coefficients: [0.462102 0.       0.       0.       0.       0.      ]
2025-03-25 22:10:28,864 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,865 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,865 - INFO -   Participant 5 Coefficients: [0.57938594 0.24003848 0.         0.         0.         0.        ]
2025-03-25 22:10:28,865 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,867 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,867 - INFO -   Participant 6 Coefficients: [0.52593682 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,867 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,868 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,868 - INFO -   Participant 7 Coefficients: [0.58840097 0.23904962 0.         0.         0.         0.        ]
2025-03-25 22:10:28,868 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,870 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,870 - INFO -   Participant 8 Coefficients: [0.49765265 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,870 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,871 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,871 - INFO -   Participant 9 Coefficients: [0.57550048 0.24666432 0.         0.         0.         0.        ]
2025-03-25 22:10:28,871 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,873 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,873 - INFO -   Participant 10 Coefficients: [0.49464388 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,873 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,874 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,874 - INFO -   Participant 11 Coefficients: [0.56295586 0.23354674 0.         0.         0.         0.        ]
2025-03-25 22:10:28,874 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,876 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,876 - INFO -   Participant 12 Coefficients: [0.34720942 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,876 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,877 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,877 - INFO -   Participant 13 Coefficients: [0.44957206 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,877 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,878 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,879 - INFO -   Participant 14 Coefficients: [0.55062941 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,879 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,880 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,880 - INFO -   Participant 15 Coefficients: [0.44800189 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,880 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,881 - INFO -   Participant 16 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,881 - INFO -   Participant 16 Coefficients: [0.55922405 0.23603243 0.         0.         0.         0.        ]
2025-03-25 22:10:28,881 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,883 - INFO -   Participant 17 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,883 - INFO -   Participant 17 Coefficients: [0.70626411 0.14392425 0.         0.         0.         0.        ]
2025-03-25 22:10:28,883 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,884 - INFO -   Participant 18 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,885 - INFO -   Participant 18 Coefficients: [0.45438507 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,885 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,886 - INFO -   Participant 19 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,886 - INFO -   Participant 19 Coefficients: [0.67979388 0.1497765  0.         0.         0.         0.        ]
2025-03-25 22:10:28,886 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,888 - INFO -   Participant 20 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,888 - INFO -   Participant 20 Coefficients: [0.39207146 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,888 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,889 - INFO -   Participant 21 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,889 - INFO -   Participant 21 Coefficients: [0.44313174 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,889 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,890 - INFO -   Participant 22 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,890 - INFO -   Participant 22 Coefficients: [0.58083654 0.2345432  0.         0.         0.         0.        ]
2025-03-25 22:10:28,890 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,892 - INFO -   Participant 23 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,892 - INFO -   Participant 23 Coefficients: [0.53269876 0.24002001 0.         0.         0.         0.        ]
2025-03-25 22:10:28,892 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,893 - INFO -   Participant 24 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,893 - INFO -   Participant 24 Coefficients: [0.4897041  0.25534759 0.         0.         0.         0.        ]
2025-03-25 22:10:28,893 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,894 - INFO -   Participant 25 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,895 - INFO -   Participant 25 Coefficients: [0.44121993 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,895 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,896 - INFO -   Participant 26 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,896 - INFO -   Participant 26 Coefficients: [0.42198634 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,896 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,897 - INFO -   Participant 27 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,897 - INFO -   Participant 27 Coefficients: [0.62015177 0.22047506 0.         0.         0.         0.        ]
2025-03-25 22:10:28,897 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,899 - INFO -   Participant 28 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,899 - INFO -   Participant 28 Coefficients: [0.49875808 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,899 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,900 - INFO -   Participant 29 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,900 - INFO -   Participant 29 Coefficients: [0.55723519 0.22691557 0.         0.         0.         0.        ]
2025-03-25 22:10:28,900 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,902 - INFO -   Participant 30 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,902 - INFO -   Participant 30 Coefficients: [0.59477657 0.23233428 0.         0.         0.         0.        ]
2025-03-25 22:10:28,902 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,903 - INFO -   Participant 31 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,903 - INFO -   Participant 31 Coefficients: [0.44280604 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,903 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,904 - INFO -   Participant 32 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,905 - INFO -   Participant 32 Coefficients: [0.57755209 0.23290228 0.         0.         0.         0.        ]
2025-03-25 22:10:28,905 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,906 - INFO -   Participant 33 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,906 - INFO -   Participant 33 Coefficients: [0.51383287 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,906 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,907 - INFO -   Participant 34 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,907 - INFO -   Participant 34 Coefficients: [0.54070948 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,907 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,909 - INFO -   Participant 35 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,909 - INFO -   Participant 35 Coefficients: [0.50502521 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,909 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,910 - INFO -   Participant 36 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,910 - INFO -   Participant 36 Coefficients: [0.5726645  0.22529227 0.         0.         0.         0.        ]
2025-03-25 22:10:28,910 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,912 - INFO -   Participant 37 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,912 - INFO -   Participant 37 Coefficients: [0.4371593 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:28,912 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,913 - INFO -   Participant 38 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,913 - INFO -   Participant 38 Coefficients: [0.50423225 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,913 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,914 - INFO -   Participant 39 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,914 - INFO -   Participant 39 Coefficients: [0.39983326 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,914 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,916 - INFO -   Participant 40 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,916 - INFO -   Participant 40 Coefficients: [0.42587775 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,916 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,917 - INFO -   Participant 41 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,917 - INFO -   Participant 41 Coefficients: [0.59118694 0.22430783 0.         0.         0.         0.        ]
2025-03-25 22:10:28,917 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,919 - INFO -   Participant 42 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,919 - INFO -   Participant 42 Coefficients: [0.46286532 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,919 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,920 - INFO -   Participant 43 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,920 - INFO -   Participant 43 Coefficients: [0.53661096 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,920 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,922 - INFO -   Participant 44 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,922 - INFO -   Participant 44 Coefficients: [0.53535073 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,922 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,923 - INFO -   Participant 45 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,923 - INFO -   Participant 45 Coefficients: [0.62184284 0.21687612 0.         0.         0.         0.        ]
2025-03-25 22:10:28,923 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,925 - INFO -   Participant 46 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,925 - INFO -   Participant 46 Coefficients: [0.4818162 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:28,925 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,926 - INFO -   Participant 47 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,926 - INFO -   Participant 47 Coefficients: [0.59859106 0.21076227 0.         0.         0.         0.        ]
2025-03-25 22:10:28,926 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,927 - INFO -   Participant 48 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,927 - INFO -   Participant 48 Coefficients: [0.49061111 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,927 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,929 - INFO -   Participant 49 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,929 - INFO -   Participant 49 Coefficients: [0.55576943 0.23174307 0.         0.         0.         0.        ]
2025-03-25 22:10:28,929 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,930 - INFO -   Participant 50 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,930 - INFO -   Participant 50 Coefficients: [0.51397527 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,930 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,932 - INFO -   Participant 51 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,932 - INFO -   Participant 51 Coefficients: [0.53864452 0.24582982 0.         0.         0.         0.        ]
2025-03-25 22:10:28,932 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,933 - INFO -   Participant 52 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,933 - INFO -   Participant 52 Coefficients: [0.52034669 0.24835952 0.         0.         0.         0.        ]
2025-03-25 22:10:28,933 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,934 - INFO -   Participant 53 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,934 - INFO -   Participant 53 Coefficients: [0.51599666 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,935 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,936 - INFO -   Participant 54 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,936 - INFO -   Participant 54 Coefficients: [0.51560509 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,936 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,937 - INFO -   Participant 55 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,937 - INFO -   Participant 55 Coefficients: [0.41607851 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,937 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,939 - INFO -   Participant 56 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,939 - INFO -   Participant 56 Coefficients: [0.57849621 0.24138751 0.         0.         0.         0.        ]
2025-03-25 22:10:28,939 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,940 - INFO -   Participant 57 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,940 - INFO -   Participant 57 Coefficients: [0.64896772 0.18969412 0.         0.         0.         0.        ]
2025-03-25 22:10:28,940 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,941 - INFO -   Participant 58 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,942 - INFO -   Participant 58 Coefficients: [0.56824148 0.23211007 0.         0.         0.         0.        ]
2025-03-25 22:10:28,942 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,943 - INFO -   Participant 59 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,943 - INFO -   Participant 59 Coefficients: [0.32800925 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,943 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,944 - INFO -   Participant 60 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,944 - INFO -   Participant 60 Coefficients: [0.5905428  0.23290537 0.         0.         0.         0.        ]
2025-03-25 22:10:28,944 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,946 - INFO -   Participant 61 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,946 - INFO -   Participant 61 Coefficients: [0.4476667 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:28,946 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,947 - INFO -   Participant 62 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,947 - INFO -   Participant 62 Coefficients: [0.61473308 0.21433505 0.         0.         0.         0.        ]
2025-03-25 22:10:28,947 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,948 - INFO -   Participant 63 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,948 - INFO -   Participant 63 Coefficients: [0.52555624 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,949 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,950 - INFO -   Participant 64 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,950 - INFO -   Participant 64 Coefficients: [0.46410063 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,950 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,951 - INFO -   Participant 65 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,951 - INFO -   Participant 65 Coefficients: [0.58925226 0.22684854 0.         0.         0.         0.        ]
2025-03-25 22:10:28,951 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,953 - INFO -   Participant 66 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,953 - INFO -   Participant 66 Coefficients: [0.52666046 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,953 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,954 - INFO -   Participant 67 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,954 - INFO -   Participant 67 Coefficients: [0.36181146 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,954 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,955 - INFO -   Participant 68 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,955 - INFO -   Participant 68 Coefficients: [0.62171962 0.21602416 0.         0.         0.         0.        ]
2025-03-25 22:10:28,956 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,957 - INFO -   Participant 69 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,957 - INFO -   Participant 69 Coefficients: [0.61609853 0.20578513 0.         0.         0.         0.        ]
2025-03-25 22:10:28,957 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,958 - INFO -   Participant 70 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,958 - INFO -   Participant 70 Coefficients: [0.47610229 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,958 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,960 - INFO -   Participant 71 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,960 - INFO -   Participant 71 Coefficients: [0.42744169 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,960 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,961 - INFO -   Participant 72 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,961 - INFO -   Participant 72 Coefficients: [0.5843077  0.22656409 0.         0.         0.         0.        ]
2025-03-25 22:10:28,961 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,963 - INFO -   Participant 73 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,963 - INFO -   Participant 73 Coefficients: [0.50918682 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,963 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,964 - INFO -   Participant 74 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,964 - INFO -   Participant 74 Coefficients: [0.38096151 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,964 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,965 - INFO -   Participant 75 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,966 - INFO -   Participant 75 Coefficients: [0.41335303 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,966 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,967 - INFO -   Participant 76 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,967 - INFO -   Participant 76 Coefficients: [0.44184408 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,967 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,968 - INFO -   Participant 77 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,968 - INFO -   Participant 77 Coefficients: [0.3986167 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:28,968 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,970 - INFO -   Participant 78 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,970 - INFO -   Participant 78 Coefficients: [0.44769126 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,970 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,971 - INFO -   Participant 79 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,971 - INFO -   Participant 79 Coefficients: [0.47876957 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,971 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,973 - INFO -   Participant 80 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,973 - INFO -   Participant 80 Coefficients: [0.48284605 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,973 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,974 - INFO -   Participant 81 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,974 - INFO -   Participant 81 Coefficients: [0.64903171 0.19569183 0.         0.         0.         0.        ]
2025-03-25 22:10:28,974 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,975 - INFO -   Participant 82 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,976 - INFO -   Participant 82 Coefficients: [0.4296895 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:28,976 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,977 - INFO -   Participant 83 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,977 - INFO -   Participant 83 Coefficients: [0.47647813 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,977 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,978 - INFO -   Participant 84 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,978 - INFO -   Participant 84 Coefficients: [0.52802058 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,978 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,980 - INFO -   Participant 85 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,980 - INFO -   Participant 85 Coefficients: [0.38619554 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,980 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,981 - INFO -   Participant 86 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,981 - INFO -   Participant 86 Coefficients: [0.60540293 0.23514969 0.         0.         0.         0.        ]
2025-03-25 22:10:28,981 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,982 - INFO -   Participant 87 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,982 - INFO -   Participant 87 Coefficients: [0.37544209 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,982 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,984 - INFO -   Participant 88 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,984 - INFO -   Participant 88 Coefficients: [0.43307683 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,984 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,985 - INFO -   Participant 89 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,985 - INFO -   Participant 89 Coefficients: [0.45137143 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,985 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,987 - INFO -   Participant 90 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,987 - INFO -   Participant 90 Coefficients: [0.55080795 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,987 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,988 - INFO -   Participant 91 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,988 - INFO -   Participant 91 Coefficients: [0.62043474 0.22893016 0.         0.         0.         0.        ]
2025-03-25 22:10:28,988 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,990 - INFO -   Participant 92 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,990 - INFO -   Participant 92 Coefficients: [0.46603021 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,990 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,991 - INFO -   Participant 93 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,991 - INFO -   Participant 93 Coefficients: [0.58821562 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,991 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,993 - INFO -   Participant 94 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,993 - INFO -   Participant 94 Coefficients: [0.679072   0.15927681 0.         0.         0.         0.        ]
2025-03-25 22:10:28,993 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,994 - INFO -   Participant 95 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,994 - INFO -   Participant 95 Coefficients: [0.46288943 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:28,994 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,995 - INFO -   Participant 96 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,996 - INFO -   Participant 96 Coefficients: [0.59570465 0.13274064 0.         0.         0.         0.        ]
2025-03-25 22:10:28,996 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,997 - INFO -   Participant 97 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,997 - INFO -   Participant 97 Coefficients: [0.58477868 0.22440188 0.         0.         0.         0.        ]
2025-03-25 22:10:28,997 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:28,998 - INFO -   Participant 98 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:28,998 - INFO -   Participant 98 Coefficients: [0.5434303 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:28,998 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,000 - INFO -   Participant 99 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,000 - INFO -   Participant 99 Coefficients: [0.524515 0.       0.       0.       0.       0.      ]
2025-03-25 22:10:29,000 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,001 - INFO -   Participant 100 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,001 - INFO -   Participant 100 Coefficients: [0.42185569 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,001 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,002 - INFO -   Participant 101 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,003 - INFO -   Participant 101 Coefficients: [0.57355428 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,003 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,004 - INFO -   Participant 102 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,004 - INFO -   Participant 102 Coefficients: [0.43547314 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,004 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,005 - INFO -   Participant 103 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,006 - INFO -   Participant 103 Coefficients: [0.8439679 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,006 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,007 - INFO -   Participant 104 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,007 - INFO -   Participant 104 Coefficients: [0.57495864 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,007 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,008 - INFO -   Participant 105 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,008 - INFO -   Participant 105 Coefficients: [0.51498469 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,008 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,010 - INFO -   Participant 106 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,010 - INFO -   Participant 106 Coefficients: [0.42318898 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,010 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,011 - INFO -   Participant 107 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,011 - INFO -   Participant 107 Coefficients: [0.55599778 0.22981659 0.         0.         0.         0.        ]
2025-03-25 22:10:29,011 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,013 - INFO -   Participant 108 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,013 - INFO -   Participant 108 Coefficients: [0.45556253 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,013 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,014 - INFO -   Participant 109 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,014 - INFO -   Participant 109 Coefficients: [0.58399982 0.23857806 0.         0.         0.         0.        ]
2025-03-25 22:10:29,014 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,015 - INFO -   Participant 110 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,015 - INFO -   Participant 110 Coefficients: [0.50512067 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,015 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,017 - INFO -   Participant 111 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,017 - INFO -   Participant 111 Coefficients: [0.57087498 0.23679414 0.         0.         0.         0.        ]
2025-03-25 22:10:29,017 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,018 - INFO -   Participant 112 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,018 - INFO -   Participant 112 Coefficients: [0.37909108 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,018 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,020 - INFO -   Participant 113 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,020 - INFO -   Participant 113 Coefficients: [0.37459531 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,020 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,021 - INFO -   Participant 114 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,021 - INFO -   Participant 114 Coefficients: [0.44754278 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,021 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,022 - INFO -   Participant 115 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,022 - INFO -   Participant 115 Coefficients: [0.33913091 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,022 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,024 - INFO -   Participant 116 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,024 - INFO -   Participant 116 Coefficients: [0.57805269 0.22127075 0.         0.         0.         0.        ]
2025-03-25 22:10:29,024 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,025 - INFO -   Participant 117 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,025 - INFO -   Participant 117 Coefficients: [0.57717651 0.21831501 0.         0.         0.         0.        ]
2025-03-25 22:10:29,025 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,027 - INFO -   Participant 118 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,027 - INFO -   Participant 118 Coefficients: [0.46608081 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,027 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,028 - INFO -   Participant 119 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,028 - INFO -   Participant 119 Coefficients: [0.57277195 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,028 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,029 - INFO -   Participant 120 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,029 - INFO -   Participant 120 Coefficients: [0.38538268 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,029 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,031 - INFO -   Participant 121 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,031 - INFO -   Participant 121 Coefficients: [0.55429771 0.24713482 0.         0.         0.         0.        ]
2025-03-25 22:10:29,031 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,032 - INFO -   Participant 122 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,032 - INFO -   Participant 122 Coefficients: [0.43355355 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,032 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,034 - INFO -   Participant 123 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,034 - INFO -   Participant 123 Coefficients: [0.31640163 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,034 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,035 - INFO -   Participant 124 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,035 - INFO -   Participant 124 Coefficients: [0.47571769 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,035 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,036 - INFO -   Participant 125 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,037 - INFO -   Participant 125 Coefficients: [0.30548787 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,037 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,038 - INFO -   Participant 126 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,038 - INFO -   Participant 126 Coefficients: [0.42800444 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,038 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,039 - INFO -   Participant 127 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,039 - INFO -   Participant 127 Coefficients: [0.59612926 0.20618857 0.         0.         0.         0.        ]
2025-03-25 22:10:29,039 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,041 - INFO -   Participant 128 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,041 - INFO -   Participant 128 Coefficients: [0.63429718 0.21383606 0.         0.         0.         0.        ]
2025-03-25 22:10:29,041 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,042 - INFO -   Participant 129 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,042 - INFO -   Participant 129 Coefficients: [0.55146673 0.24604633 0.         0.         0.         0.        ]
2025-03-25 22:10:29,042 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,043 - INFO -   Participant 130 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,044 - INFO -   Participant 130 Coefficients: [0.3199169 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,044 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,045 - INFO -   Participant 131 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,045 - INFO -   Participant 131 Coefficients: [0.49520698 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,045 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,046 - INFO -   Participant 132 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,047 - INFO -   Participant 132 Coefficients: [0.43057096 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,047 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,048 - INFO -   Participant 133 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,048 - INFO -   Participant 133 Coefficients: [0.44746378 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,048 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,049 - INFO -   Participant 134 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,050 - INFO -   Participant 134 Coefficients: [0.52524211 0.25223125 0.         0.         0.         0.        ]
2025-03-25 22:10:29,050 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,051 - INFO -   Participant 135 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,051 - INFO -   Participant 135 Coefficients: [0.44063139 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,051 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,052 - INFO -   Participant 136 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,053 - INFO -   Participant 136 Coefficients: [0.538066 0.       0.       0.       0.       0.      ]
2025-03-25 22:10:29,053 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,054 - INFO -   Participant 137 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,054 - INFO -   Participant 137 Coefficients: [0.43467489 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,054 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,055 - INFO -   Participant 138 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,055 - INFO -   Participant 138 Coefficients: [0.49329269 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,055 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,057 - INFO -   Participant 139 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,057 - INFO -   Participant 139 Coefficients: [0.4234249 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,057 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,058 - INFO -   Participant 140 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,058 - INFO -   Participant 140 Coefficients: [0.36642322 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,058 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,059 - INFO -   Participant 141 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,059 - INFO -   Participant 141 Coefficients: [0.56876867 0.24171182 0.         0.         0.         0.        ]
2025-03-25 22:10:29,059 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,061 - INFO -   Participant 142 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,061 - INFO -   Participant 142 Coefficients: [0.42912027 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,061 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,062 - INFO -   Participant 143 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,062 - INFO -   Participant 143 Coefficients: [0.42884636 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,062 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,064 - INFO -   Participant 144 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,064 - INFO -   Participant 144 Coefficients: [0.37467 0.      0.      0.      0.      0.     ]
2025-03-25 22:10:29,064 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,065 - INFO -   Participant 145 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,065 - INFO -   Participant 145 Coefficients: [0.41944453 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,065 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,066 - INFO -   Participant 146 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,067 - INFO -   Participant 146 Coefficients: [0.34589344 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,067 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,068 - INFO -   Participant 147 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,068 - INFO -   Participant 147 Coefficients: [0.51524688 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,068 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,069 - INFO -   Participant 148 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,069 - INFO -   Participant 148 Coefficients: [0.47959387 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,070 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,071 - INFO -   Participant 149 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,071 - INFO -   Participant 149 Coefficients: [0.46495354 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,071 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,072 - INFO -   Participant 150 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,072 - INFO -   Participant 150 Coefficients: [0.5460604  0.25277546 0.         0.         0.         0.        ]
2025-03-25 22:10:29,072 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,074 - INFO -   Participant 151 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,074 - INFO -   Participant 151 Coefficients: [0.5074012  0.25651064 0.         0.         0.         0.        ]
2025-03-25 22:10:29,074 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,075 - INFO -   Participant 152 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,075 - INFO -   Participant 152 Coefficients: [0.41527408 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,075 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,076 - INFO -   Participant 153 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,077 - INFO -   Participant 153 Coefficients: [0.59977345 0.23165417 0.         0.         0.         0.        ]
2025-03-25 22:10:29,077 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,078 - INFO -   Participant 154 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,078 - INFO -   Participant 154 Coefficients: [0.49510377 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,078 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,079 - INFO -   Participant 155 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,079 - INFO -   Participant 155 Coefficients: [0.62758806 0.20241448 0.         0.         0.         0.        ]
2025-03-25 22:10:29,079 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,081 - INFO -   Participant 156 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,081 - INFO -   Participant 156 Coefficients: [0.56760279 0.24173359 0.         0.         0.         0.        ]
2025-03-25 22:10:29,081 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,082 - INFO -   Participant 157 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,082 - INFO -   Participant 157 Coefficients: [0.58851041 0.21624152 0.         0.         0.         0.        ]
2025-03-25 22:10:29,082 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,084 - INFO -   Participant 158 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,084 - INFO -   Participant 158 Coefficients: [0.45126751 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,084 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,085 - INFO -   Participant 159 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,085 - INFO -   Participant 159 Coefficients: [0.57133401 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,085 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,087 - INFO -   Participant 160 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,087 - INFO -   Participant 160 Coefficients: [0.37010893 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,087 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,088 - INFO -   Participant 161 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,088 - INFO -   Participant 161 Coefficients: [0.55243422 0.23805494 0.         0.         0.         0.        ]
2025-03-25 22:10:29,088 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,090 - INFO -   Participant 162 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,090 - INFO -   Participant 162 Coefficients: [0.56204148 0.2489148  0.         0.         0.         0.        ]
2025-03-25 22:10:29,090 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,091 - INFO -   Participant 163 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,091 - INFO -   Participant 163 Coefficients: [0.63833955 0.19637967 0.         0.         0.         0.        ]
2025-03-25 22:10:29,091 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,092 - INFO -   Participant 164 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,093 - INFO -   Participant 164 Coefficients: [0.6675432 0.        0.        0.1621286 0.        0.       ]
2025-03-25 22:10:29,093 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,094 - INFO -   Participant 165 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,094 - INFO -   Participant 165 Coefficients: [0.52984942 0.24682811 0.         0.         0.         0.        ]
2025-03-25 22:10:29,094 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,095 - INFO -   Participant 166 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,095 - INFO -   Participant 166 Coefficients: [0.46117706 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,095 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,096 - INFO -   Participant 167 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,097 - INFO -   Participant 167 Coefficients: [0.4562692 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,097 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,098 - INFO -   Participant 168 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,098 - INFO -   Participant 168 Coefficients: [0.44839263 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,098 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,099 - INFO -   Participant 169 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,100 - INFO -   Participant 169 Coefficients: [0.56820941 0.2422383  0.         0.         0.         0.        ]
2025-03-25 22:10:29,100 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,101 - INFO -   Participant 170 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,101 - INFO -   Participant 170 Coefficients: [0.59884049 0.23603296 0.         0.         0.         0.        ]
2025-03-25 22:10:29,101 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,102 - INFO -   Participant 171 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,103 - INFO -   Participant 171 Coefficients: [0.48398295 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,103 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,104 - INFO -   Participant 172 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,104 - INFO -   Participant 172 Coefficients: [0.49055997 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,104 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,106 - INFO -   Participant 173 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,106 - INFO -   Participant 173 Coefficients: [0.32841876 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,106 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,107 - INFO -   Participant 174 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,107 - INFO -   Participant 174 Coefficients: [0.43547559 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,107 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,108 - INFO -   Participant 175 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,108 - INFO -   Participant 175 Coefficients: [0.39868289 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,108 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,110 - INFO -   Participant 176 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,110 - INFO -   Participant 176 Coefficients: [0.65494854 0.13471233 0.         0.         0.         0.        ]
2025-03-25 22:10:29,110 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,111 - INFO -   Participant 177 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,111 - INFO -   Participant 177 Coefficients: [0.52399162 0.25101229 0.         0.         0.         0.        ]
2025-03-25 22:10:29,111 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,112 - INFO -   Participant 178 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,112 - INFO -   Participant 178 Coefficients: [0.30832538 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,112 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,114 - INFO -   Participant 179 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,114 - INFO -   Participant 179 Coefficients: [0.33714223 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,114 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,115 - INFO -   Participant 180 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,115 - INFO -   Participant 180 Coefficients: [0.66398632 0.19467841 0.         0.         0.         0.        ]
2025-03-25 22:10:29,115 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,117 - INFO -   Participant 181 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,117 - INFO -   Participant 181 Coefficients: [0.58681007 0.24166356 0.         0.         0.         0.        ]
2025-03-25 22:10:29,117 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,118 - INFO -   Participant 182 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,118 - INFO -   Participant 182 Coefficients: [0.3966527 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,118 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,119 - INFO -   Participant 183 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,120 - INFO -   Participant 183 Coefficients: [0.60879729 0.22819366 0.         0.         0.         0.        ]
2025-03-25 22:10:29,120 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,121 - INFO -   Participant 184 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,121 - INFO -   Participant 184 Coefficients: [0.55069955 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,121 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,122 - INFO -   Participant 185 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,122 - INFO -   Participant 185 Coefficients: [0.55643151 0.23395966 0.         0.         0.         0.        ]
2025-03-25 22:10:29,123 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,124 - INFO -   Participant 186 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,124 - INFO -   Participant 186 Coefficients: [0.51925398 0.24916316 0.         0.         0.         0.        ]
2025-03-25 22:10:29,124 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,125 - INFO -   Participant 187 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,125 - INFO -   Participant 187 Coefficients: [0.5794958  0.21471627 0.         0.         0.         0.        ]
2025-03-25 22:10:29,125 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,127 - INFO -   Participant 188 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,127 - INFO -   Participant 188 Coefficients: [0.46282247 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,127 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,128 - INFO -   Participant 189 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,128 - INFO -   Participant 189 Coefficients: [0.55076422 0.24701318 0.         0.         0.         0.        ]
2025-03-25 22:10:29,128 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,129 - INFO -   Participant 190 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,130 - INFO -   Participant 190 Coefficients: [0.47473013 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,130 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,131 - INFO -   Participant 191 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,131 - INFO -   Participant 191 Coefficients: [0.45414737 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,131 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,132 - INFO -   Participant 192 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,132 - INFO -   Participant 192 Coefficients: [0.43587339 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,132 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,134 - INFO -   Participant 193 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,134 - INFO -   Participant 193 Coefficients: [0.43841711 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,134 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,135 - INFO -   Participant 194 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,135 - INFO -   Participant 194 Coefficients: [0.368442 0.       0.       0.       0.       0.      ]
2025-03-25 22:10:29,135 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,137 - INFO -   Participant 195 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,137 - INFO -   Participant 195 Coefficients: [0.52012628 0.25030612 0.         0.         0.         0.        ]
2025-03-25 22:10:29,137 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,138 - INFO -   Participant 196 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,138 - INFO -   Participant 196 Coefficients: [0.4511742 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,138 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,140 - INFO -   Participant 197 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,140 - INFO -   Participant 197 Coefficients: [0.46845407 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,140 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,141 - INFO -   Participant 198 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,141 - INFO -   Participant 198 Coefficients: [0.56049147 0.24972584 0.         0.         0.         0.        ]
2025-03-25 22:10:29,141 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,142 - INFO -   Participant 199 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,143 - INFO -   Participant 199 Coefficients: [0.51888406 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,143 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,144 - INFO -   Participant 200 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,144 - INFO -   Participant 200 Coefficients: [0.46614152 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,144 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,145 - INFO -   Participant 201 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,145 - INFO -   Participant 201 Coefficients: [0.54803651 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,145 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,147 - INFO -   Participant 202 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,147 - INFO -   Participant 202 Coefficients: [0.54377034 0.24353807 0.         0.         0.         0.        ]
2025-03-25 22:10:29,147 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,148 - INFO -   Participant 203 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,148 - INFO -   Participant 203 Coefficients: [0.71023002 0.13968192 0.         0.         0.         0.        ]
2025-03-25 22:10:29,148 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,150 - INFO -   Participant 204 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,150 - INFO -   Participant 204 Coefficients: [0.3858968 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,150 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,151 - INFO -   Participant 205 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,151 - INFO -   Participant 205 Coefficients: [0.53707625 0.24575888 0.         0.         0.         0.        ]
2025-03-25 22:10:29,151 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,152 - INFO -   Participant 206 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,152 - INFO -   Participant 206 Coefficients: [0.45055839 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,153 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,154 - INFO -   Participant 207 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,154 - INFO -   Participant 207 Coefficients: [0.62372387 0.21586998 0.         0.         0.         0.        ]
2025-03-25 22:10:29,154 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,155 - INFO -   Participant 208 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,155 - INFO -   Participant 208 Coefficients: [0.46796778 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,155 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,157 - INFO -   Participant 209 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,157 - INFO -   Participant 209 Coefficients: [0.57287007 0.22209196 0.         0.         0.         0.        ]
2025-03-25 22:10:29,157 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,158 - INFO -   Participant 210 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,158 - INFO -   Participant 210 Coefficients: [0.39957595 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,158 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,160 - INFO -   Participant 211 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,160 - INFO -   Participant 211 Coefficients: [0.51313441 0.25527154 0.         0.         0.         0.        ]
2025-03-25 22:10:29,160 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,161 - INFO -   Participant 212 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,161 - INFO -   Participant 212 Coefficients: [0.38484874 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,161 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,163 - INFO -   Participant 213 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,163 - INFO -   Participant 213 Coefficients: [0.62251654 0.20528069 0.         0.         0.         0.        ]
2025-03-25 22:10:29,163 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,164 - INFO -   Participant 214 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,164 - INFO -   Participant 214 Coefficients: [0.34470469 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,164 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,165 - INFO -   Participant 215 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,165 - INFO -   Participant 215 Coefficients: [0.55323169 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,165 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,167 - INFO -   Participant 216 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,167 - INFO -   Participant 216 Coefficients: [0.5483854  0.24983582 0.         0.         0.         0.        ]
2025-03-25 22:10:29,167 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,168 - INFO -   Participant 217 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,168 - INFO -   Participant 217 Coefficients: [0.31356242 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,168 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,170 - INFO -   Participant 218 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,170 - INFO -   Participant 218 Coefficients: [0.43669087 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,170 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,171 - INFO -   Participant 219 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,171 - INFO -   Participant 219 Coefficients: [0.75685362 0.1052296  0.         0.         0.         0.        ]
2025-03-25 22:10:29,171 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,172 - INFO -   Participant 220 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,173 - INFO -   Participant 220 Coefficients: [0.37954897 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,173 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,174 - INFO -   Participant 221 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,174 - INFO -   Participant 221 Coefficients: [0.54253593 0.24880803 0.         0.         0.         0.        ]
2025-03-25 22:10:29,174 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,175 - INFO -   Participant 222 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,175 - INFO -   Participant 222 Coefficients: [0.51030127 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,175 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,177 - INFO -   Participant 223 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,177 - INFO -   Participant 223 Coefficients: [0.50724885 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,177 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,178 - INFO -   Participant 224 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,178 - INFO -   Participant 224 Coefficients: [0.44329205 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,178 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,179 - INFO -   Participant 225 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,180 - INFO -   Participant 225 Coefficients: [0.42648888 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,180 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,181 - INFO -   Participant 226 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,181 - INFO -   Participant 226 Coefficients: [0.45548978 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,181 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,182 - INFO -   Participant 227 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,182 - INFO -   Participant 227 Coefficients: [0.38321301 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,182 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,184 - INFO -   Participant 228 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,184 - INFO -   Participant 228 Coefficients: [0.35958454 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,184 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,185 - INFO -   Participant 229 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,185 - INFO -   Participant 229 Coefficients: [0.6703712  0.17824841 0.         0.         0.         0.        ]
2025-03-25 22:10:29,185 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,186 - INFO -   Participant 230 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,187 - INFO -   Participant 230 Coefficients: [0.59530223 0.23961376 0.         0.         0.         0.        ]
2025-03-25 22:10:29,187 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,188 - INFO -   Participant 231 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,188 - INFO -   Participant 231 Coefficients: [0.63133437 0.21640743 0.         0.         0.         0.        ]
2025-03-25 22:10:29,188 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,189 - INFO -   Participant 232 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,189 - INFO -   Participant 232 Coefficients: [0.54688642 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,189 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,191 - INFO -   Participant 233 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,191 - INFO -   Participant 233 Coefficients: [0.53881432 0.24743339 0.         0.         0.         0.        ]
2025-03-25 22:10:29,191 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,192 - INFO -   Participant 234 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,192 - INFO -   Participant 234 Coefficients: [0.50656974 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,192 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,194 - INFO -   Participant 235 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,194 - INFO -   Participant 235 Coefficients: [0.48624826 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,194 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,195 - INFO -   Participant 236 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,195 - INFO -   Participant 236 Coefficients: [0.39002469 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,195 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,196 - INFO -   Participant 237 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,196 - INFO -   Participant 237 Coefficients: [0.47646832 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,196 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,198 - INFO -   Participant 238 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,198 - INFO -   Participant 238 Coefficients: [0.44246972 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,198 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,199 - INFO -   Participant 239 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,199 - INFO -   Participant 239 Coefficients: [0.48228264 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,199 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,201 - INFO -   Participant 240 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,201 - INFO -   Participant 240 Coefficients: [0.3471109 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,201 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,202 - INFO -   Participant 241 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,202 - INFO -   Participant 241 Coefficients: [0.43891516 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,202 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,203 - INFO -   Participant 242 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,203 - INFO -   Participant 242 Coefficients: [0.28534997 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,204 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,205 - INFO -   Participant 243 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,205 - INFO -   Participant 243 Coefficients: [0.41377181 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,205 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,206 - INFO -   Participant 244 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,206 - INFO -   Participant 244 Coefficients: [0.52729912 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,206 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,208 - INFO -   Participant 245 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,208 - INFO -   Participant 245 Coefficients: [0.40069488 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,208 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,209 - INFO -   Participant 246 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,209 - INFO -   Participant 246 Coefficients: [0.56626288 0.22850923 0.         0.         0.         0.        ]
2025-03-25 22:10:29,209 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,210 - INFO -   Participant 247 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,210 - INFO -   Participant 247 Coefficients: [0.60217218 0.21790391 0.         0.         0.         0.        ]
2025-03-25 22:10:29,211 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,212 - INFO -   Participant 248 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,212 - INFO -   Participant 248 Coefficients: [0.40438217 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,212 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,213 - INFO -   Participant 249 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,213 - INFO -   Participant 249 Coefficients: [0.40636614 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,213 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,215 - INFO -   Participant 250 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,215 - INFO -   Participant 250 Coefficients: [0.603592   0.22201797 0.         0.         0.         0.        ]
2025-03-25 22:10:29,215 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,216 - INFO -   Participant 251 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,216 - INFO -   Participant 251 Coefficients: [0.55146977 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,216 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,217 - INFO -   Participant 252 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,217 - INFO -   Participant 252 Coefficients: [0.38122836 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,218 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,219 - INFO -   Participant 253 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,219 - INFO -   Participant 253 Coefficients: [0.53964704 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,219 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,220 - INFO -   Participant 254 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,220 - INFO -   Participant 254 Coefficients: [0.56869481 0.24811199 0.         0.         0.         0.        ]
2025-03-25 22:10:29,220 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,222 - INFO -   Participant 255 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,222 - INFO -   Participant 255 Coefficients: [0.52182084 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,222 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:10:29,222 - INFO - Module: x_value_choice_not_chosen
2025-03-25 22:10:29,223 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,223 - INFO -   Participant 0 Coefficients: [0.56800324 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,223 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,224 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,225 - INFO -   Participant 1 Coefficients: [0.35642036 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,225 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,226 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,226 - INFO -   Participant 2 Coefficients: [0.31504878 0.40413553 0.         0.         0.         0.        ]
2025-03-25 22:10:29,226 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,227 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,227 - INFO -   Participant 3 Coefficients: [0.35717827 0.23446965 0.         0.         0.         0.        ]
2025-03-25 22:10:29,227 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,229 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,229 - INFO -   Participant 4 Coefficients: [0.44652295 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,229 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,230 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,230 - INFO -   Participant 5 Coefficients: [0.34529811 0.24086032 0.         0.         0.         0.        ]
2025-03-25 22:10:29,230 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,231 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,232 - INFO -   Participant 6 Coefficients: [0.40813134 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,232 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,233 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,233 - INFO -   Participant 7 Coefficients: [0.33992779 0.24079637 0.         0.         0.         0.        ]
2025-03-25 22:10:29,233 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,234 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,234 - INFO -   Participant 8 Coefficients: [0.39623415 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,234 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,236 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,236 - INFO -   Participant 9 Coefficients: [0.3652083 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,236 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,237 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,237 - INFO -   Participant 10 Coefficients: [0.53463236 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,237 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,238 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,239 - INFO -   Participant 11 Coefficients: [0.41523736 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,239 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,240 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,240 - INFO -   Participant 12 Coefficients: [0.57040673 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,240 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,241 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,241 - INFO -   Participant 13 Coefficients: [0.47792169 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,241 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,243 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,243 - INFO -   Participant 14 Coefficients: [0.42195836 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,243 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,244 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,244 - INFO -   Participant 15 Coefficients: [0.51266325 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,244 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,246 - INFO -   Participant 16 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,246 - INFO -   Participant 16 Coefficients: [0.46021626 0.2325219  0.         0.         0.         0.        ]
2025-03-25 22:10:29,246 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,247 - INFO -   Participant 17 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,247 - INFO -   Participant 17 Coefficients: [0.30195759 0.23377194 0.         0.         0.         0.        ]
2025-03-25 22:10:29,247 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,248 - INFO -   Participant 18 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,248 - INFO -   Participant 18 Coefficients: [0.40967226 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,249 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,250 - INFO -   Participant 19 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,250 - INFO -   Participant 19 Coefficients: [0.22818578 0.25153339 0.         0.         0.         0.        ]
2025-03-25 22:10:29,250 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,251 - INFO -   Participant 20 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,251 - INFO -   Participant 20 Coefficients: [0.50721663 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,251 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,253 - INFO -   Participant 21 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,253 - INFO -   Participant 21 Coefficients: [0.41372702 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,253 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,254 - INFO -   Participant 22 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,254 - INFO -   Participant 22 Coefficients: [0.34100148 0.22452183 0.         0.         0.         0.        ]
2025-03-25 22:10:29,254 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,256 - INFO -   Participant 23 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,256 - INFO -   Participant 23 Coefficients: [0.47019582 0.24057436 0.         0.         0.         0.        ]
2025-03-25 22:10:29,256 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,257 - INFO -   Participant 24 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,257 - INFO -   Participant 24 Coefficients: [0.4124524  0.23751907 0.         0.         0.         0.        ]
2025-03-25 22:10:29,257 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,259 - INFO -   Participant 25 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,259 - INFO -   Participant 25 Coefficients: [0.52142209 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,259 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,260 - INFO -   Participant 26 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,260 - INFO -   Participant 26 Coefficients: [0.53768808 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,260 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,261 - INFO -   Participant 27 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,262 - INFO -   Participant 27 Coefficients: [0.37365882 0.22763617 0.         0.         0.         0.        ]
2025-03-25 22:10:29,262 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,263 - INFO -   Participant 28 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,263 - INFO -   Participant 28 Coefficients: [0.40895429 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,263 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,265 - INFO -   Participant 29 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,265 - INFO -   Participant 29 Coefficients: [0.43892863 0.23036772 0.         0.         0.         0.        ]
2025-03-25 22:10:29,265 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,266 - INFO -   Participant 30 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,266 - INFO -   Participant 30 Coefficients: [0.31226525 0.23065742 0.         0.         0.         0.        ]
2025-03-25 22:10:29,266 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,267 - INFO -   Participant 31 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,267 - INFO -   Participant 31 Coefficients: [0.50582039 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,267 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,269 - INFO -   Participant 32 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,269 - INFO -   Participant 32 Coefficients: [0.35660772 0.23300769 0.         0.         0.         0.        ]
2025-03-25 22:10:29,269 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,271 - INFO -   Participant 33 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,271 - INFO -   Participant 33 Coefficients: [0.41019094 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,271 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,272 - INFO -   Participant 34 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,273 - INFO -   Participant 34 Coefficients: [0.47524496 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,273 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,274 - INFO -   Participant 35 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,274 - INFO -   Participant 35 Coefficients: [0.43066639 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,274 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,275 - INFO -   Participant 36 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,275 - INFO -   Participant 36 Coefficients: [0.46762116 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,275 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,277 - INFO -   Participant 37 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,277 - INFO -   Participant 37 Coefficients: [0.48776227 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,277 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,278 - INFO -   Participant 38 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,278 - INFO -   Participant 38 Coefficients: [0.44469957 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,278 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,279 - INFO -   Participant 39 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,280 - INFO -   Participant 39 Coefficients: [0.55856609 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,280 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,281 - INFO -   Participant 40 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,281 - INFO -   Participant 40 Coefficients: [0.50756729 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,281 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,282 - INFO -   Participant 41 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,282 - INFO -   Participant 41 Coefficients: [0.40258861 0.22975301 0.         0.         0.         0.        ]
2025-03-25 22:10:29,282 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,284 - INFO -   Participant 42 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,284 - INFO -   Participant 42 Coefficients: [0.45422217 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,284 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,285 - INFO -   Participant 43 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,285 - INFO -   Participant 43 Coefficients: [0.40093166 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,285 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,287 - INFO -   Participant 44 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,287 - INFO -   Participant 44 Coefficients: [0.38897114 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,287 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,288 - INFO -   Participant 45 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,288 - INFO -   Participant 45 Coefficients: [0.29147571 0.24147531 0.         0.         0.         0.        ]
2025-03-25 22:10:29,288 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,290 - INFO -   Participant 46 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,290 - INFO -   Participant 46 Coefficients: [0.40007448 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,290 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,291 - INFO -   Participant 47 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,291 - INFO -   Participant 47 Coefficients: [0.35222363 0.23259374 0.         0.         0.         0.        ]
2025-03-25 22:10:29,291 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,293 - INFO -   Participant 48 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,293 - INFO -   Participant 48 Coefficients: [0.48304462 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,293 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,294 - INFO -   Participant 49 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,294 - INFO -   Participant 49 Coefficients: [0.40814747 0.22735041 0.         0.         0.         0.        ]
2025-03-25 22:10:29,294 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,295 - INFO -   Participant 50 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,296 - INFO -   Participant 50 Coefficients: [0.52051735 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,296 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,297 - INFO -   Participant 51 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,297 - INFO -   Participant 51 Coefficients: [0.37877312 0.23180272 0.         0.         0.         0.        ]
2025-03-25 22:10:29,297 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,298 - INFO -   Participant 52 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,298 - INFO -   Participant 52 Coefficients: [0.41177723 0.22597024 0.         0.         0.         0.        ]
2025-03-25 22:10:29,298 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,300 - INFO -   Participant 53 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,300 - INFO -   Participant 53 Coefficients: [0.44622992 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,300 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,301 - INFO -   Participant 54 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,301 - INFO -   Participant 54 Coefficients: [0.44045833 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,301 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,303 - INFO -   Participant 55 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,303 - INFO -   Participant 55 Coefficients: [0.56406826 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,303 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,304 - INFO -   Participant 56 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,304 - INFO -   Participant 56 Coefficients: [0.33455941 0.22020197 0.         0.         0.         0.        ]
2025-03-25 22:10:29,304 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,306 - INFO -   Participant 57 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,306 - INFO -   Participant 57 Coefficients: [0.26933613 0.33291747 0.         0.         0.         0.        ]
2025-03-25 22:10:29,306 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,307 - INFO -   Participant 58 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,307 - INFO -   Participant 58 Coefficients: [0.39421415 0.23143286 0.         0.         0.         0.        ]
2025-03-25 22:10:29,307 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,308 - INFO -   Participant 59 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,308 - INFO -   Participant 59 Coefficients: [0.71521145 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,308 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,310 - INFO -   Participant 60 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,310 - INFO -   Participant 60 Coefficients: [0.36070888 0.22870952 0.         0.         0.         0.        ]
2025-03-25 22:10:29,310 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,311 - INFO -   Participant 61 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,311 - INFO -   Participant 61 Coefficients: [0.4786655 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,311 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,313 - INFO -   Participant 62 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,313 - INFO -   Participant 62 Coefficients: [0.31223204 0.23976183 0.         0.         0.         0.        ]
2025-03-25 22:10:29,313 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,314 - INFO -   Participant 63 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,314 - INFO -   Participant 63 Coefficients: [0.46515693 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,314 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,315 - INFO -   Participant 64 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,315 - INFO -   Participant 64 Coefficients: [0.50539356 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,315 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,317 - INFO -   Participant 65 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,317 - INFO -   Participant 65 Coefficients: [0.38578926 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,317 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,318 - INFO -   Participant 66 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,318 - INFO -   Participant 66 Coefficients: [0.4275816 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,318 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,320 - INFO -   Participant 67 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,320 - INFO -   Participant 67 Coefficients: [0.61441958 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,320 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,321 - INFO -   Participant 68 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,321 - INFO -   Participant 68 Coefficients: [0.27398626 0.30647767 0.         0.         0.         0.        ]
2025-03-25 22:10:29,321 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,322 - INFO -   Participant 69 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,323 - INFO -   Participant 69 Coefficients: [0.26182643 0.30364454 0.         0.         0.         0.        ]
2025-03-25 22:10:29,323 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,324 - INFO -   Participant 70 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,324 - INFO -   Participant 70 Coefficients: [0.4486962 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,324 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,325 - INFO -   Participant 71 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,325 - INFO -   Participant 71 Coefficients: [0.47175804 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,325 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,327 - INFO -   Participant 72 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,327 - INFO -   Participant 72 Coefficients: [0.26955892 0.40215338 0.         0.         0.         0.        ]
2025-03-25 22:10:29,327 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,328 - INFO -   Participant 73 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,328 - INFO -   Participant 73 Coefficients: [0.40071079 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,328 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,329 - INFO -   Participant 74 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,330 - INFO -   Participant 74 Coefficients: [0.50622261 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,330 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,331 - INFO -   Participant 75 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,331 - INFO -   Participant 75 Coefficients: [0.56310385 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,331 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,332 - INFO -   Participant 76 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,332 - INFO -   Participant 76 Coefficients: [0.41639534 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,332 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,334 - INFO -   Participant 77 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,334 - INFO -   Participant 77 Coefficients: [0.48760498 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,334 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,335 - INFO -   Participant 78 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,335 - INFO -   Participant 78 Coefficients: [0.49914995 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,335 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,337 - INFO -   Participant 79 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,337 - INFO -   Participant 79 Coefficients: [0.42202765 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,337 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,338 - INFO -   Participant 80 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,338 - INFO -   Participant 80 Coefficients: [0.37789148 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,338 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,339 - INFO -   Participant 81 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,340 - INFO -   Participant 81 Coefficients: [0.32117813 0.22754835 0.         0.         0.         0.        ]
2025-03-25 22:10:29,340 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,341 - INFO -   Participant 82 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,341 - INFO -   Participant 82 Coefficients: [0.54362482 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,341 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,342 - INFO -   Participant 83 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,343 - INFO -   Participant 83 Coefficients: [0.44996908 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,343 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,344 - INFO -   Participant 84 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,344 - INFO -   Participant 84 Coefficients: [0.54732841 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,344 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,345 - INFO -   Participant 85 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,345 - INFO -   Participant 85 Coefficients: [0.56765652 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,345 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,347 - INFO -   Participant 86 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,347 - INFO -   Participant 86 Coefficients: [0.3257121  0.22780145 0.         0.         0.         0.        ]
2025-03-25 22:10:29,347 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,348 - INFO -   Participant 87 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,348 - INFO -   Participant 87 Coefficients: [0.5218854 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,348 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,350 - INFO -   Participant 88 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,350 - INFO -   Participant 88 Coefficients: [0.4545981 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,350 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,351 - INFO -   Participant 89 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,351 - INFO -   Participant 89 Coefficients: [0.47641703 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,351 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,352 - INFO -   Participant 90 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,352 - INFO -   Participant 90 Coefficients: [0.42426832 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,352 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,354 - INFO -   Participant 91 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,354 - INFO -   Participant 91 Coefficients: [0.32591774 0.21740828 0.         0.         0.         0.        ]
2025-03-25 22:10:29,354 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,355 - INFO -   Participant 92 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,355 - INFO -   Participant 92 Coefficients: [0.43762043 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,355 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,357 - INFO -   Participant 93 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,357 - INFO -   Participant 93 Coefficients: [0.46105492 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,357 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,358 - INFO -   Participant 94 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,358 - INFO -   Participant 94 Coefficients: [0.36954969 0.22329048 0.         0.         0.         0.        ]
2025-03-25 22:10:29,358 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,359 - INFO -   Participant 95 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,360 - INFO -   Participant 95 Coefficients: [0.39936528 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,360 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,361 - INFO -   Participant 96 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,361 - INFO -   Participant 96 Coefficients: [0.49073344 0.15779862 0.         0.         0.         0.        ]
2025-03-25 22:10:29,361 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,362 - INFO -   Participant 97 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,362 - INFO -   Participant 97 Coefficients: [0.43460222 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,362 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,364 - INFO -   Participant 98 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,364 - INFO -   Participant 98 Coefficients: [0.36487533 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,364 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,365 - INFO -   Participant 99 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,365 - INFO -   Participant 99 Coefficients: [0.51937088 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,365 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,367 - INFO -   Participant 100 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,367 - INFO -   Participant 100 Coefficients: [0.49312839 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,367 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,368 - INFO -   Participant 101 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,368 - INFO -   Participant 101 Coefficients: [0.35472253 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,368 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,370 - INFO -   Participant 102 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,370 - INFO -   Participant 102 Coefficients: [0.46471372 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,370 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,371 - INFO -   Participant 103 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,371 - INFO -   Participant 103 Coefficients: [0.24322508 0.25071678 0.         0.         0.         0.        ]
2025-03-25 22:10:29,371 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,373 - INFO -   Participant 104 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,373 - INFO -   Participant 104 Coefficients: [0.34099073 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,373 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,374 - INFO -   Participant 105 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,374 - INFO -   Participant 105 Coefficients: [0.42889337 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,374 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,375 - INFO -   Participant 106 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,376 - INFO -   Participant 106 Coefficients: [0.48227394 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,376 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,377 - INFO -   Participant 107 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,377 - INFO -   Participant 107 Coefficients: [0.39887206 0.23122757 0.         0.         0.         0.        ]
2025-03-25 22:10:29,377 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,378 - INFO -   Participant 108 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,378 - INFO -   Participant 108 Coefficients: [0.54791021 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,378 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,380 - INFO -   Participant 109 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,380 - INFO -   Participant 109 Coefficients: [ 0.13668061  1.76467506  0.         -3.50194865  0.          0.        ]
2025-03-25 22:10:29,380 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,381 - INFO -   Participant 110 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,381 - INFO -   Participant 110 Coefficients: [0.50615224 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,381 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,383 - INFO -   Participant 111 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,383 - INFO -   Participant 111 Coefficients: [0.3919449  0.22534209 0.         0.         0.         0.        ]
2025-03-25 22:10:29,383 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,384 - INFO -   Participant 112 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,384 - INFO -   Participant 112 Coefficients: [0.45103812 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,384 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,385 - INFO -   Participant 113 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,385 - INFO -   Participant 113 Coefficients: [0.62125015 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,385 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,387 - INFO -   Participant 114 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,387 - INFO -   Participant 114 Coefficients: [0.51727849 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,387 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,388 - INFO -   Participant 115 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,388 - INFO -   Participant 115 Coefficients: [0.59373027 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,388 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,390 - INFO -   Participant 116 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,390 - INFO -   Participant 116 Coefficients: [0.42528901 0.22943051 0.         0.         0.         0.        ]
2025-03-25 22:10:29,390 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,391 - INFO -   Participant 117 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,391 - INFO -   Participant 117 Coefficients: [0.53947143 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,391 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,392 - INFO -   Participant 118 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,392 - INFO -   Participant 118 Coefficients: [0.45530671 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,392 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,394 - INFO -   Participant 119 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,394 - INFO -   Participant 119 Coefficients: [0.50658289 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,394 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,395 - INFO -   Participant 120 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,395 - INFO -   Participant 120 Coefficients: [0.53096086 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,395 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,397 - INFO -   Participant 121 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,397 - INFO -   Participant 121 Coefficients: [0.39047187 0.24203733 0.         0.         0.         0.        ]
2025-03-25 22:10:29,397 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,398 - INFO -   Participant 122 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,398 - INFO -   Participant 122 Coefficients: [0.45559236 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,398 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,399 - INFO -   Participant 123 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,400 - INFO -   Participant 123 Coefficients: [0.5213052 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,400 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,401 - INFO -   Participant 124 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,401 - INFO -   Participant 124 Coefficients: [0.44328612 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,401 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,402 - INFO -   Participant 125 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,402 - INFO -   Participant 125 Coefficients: [0.6327861 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,402 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,404 - INFO -   Participant 126 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,404 - INFO -   Participant 126 Coefficients: [0.52105886 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,404 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,405 - INFO -   Participant 127 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,405 - INFO -   Participant 127 Coefficients: [0.30361336 0.45241761 0.         0.         0.         0.        ]
2025-03-25 22:10:29,405 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,406 - INFO -   Participant 128 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,406 - INFO -   Participant 128 Coefficients: [0.34890713 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,407 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,408 - INFO -   Participant 129 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,408 - INFO -   Participant 129 Coefficients: [0.3681568  0.23945678 0.         0.         0.         0.        ]
2025-03-25 22:10:29,408 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,409 - INFO -   Participant 130 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,409 - INFO -   Participant 130 Coefficients: [0.64981735 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,409 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,411 - INFO -   Participant 131 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,411 - INFO -   Participant 131 Coefficients: [0.45104739 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,411 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,412 - INFO -   Participant 132 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,412 - INFO -   Participant 132 Coefficients: [0.53005594 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,412 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,413 - INFO -   Participant 133 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,414 - INFO -   Participant 133 Coefficients: [0.42588028 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,414 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,415 - INFO -   Participant 134 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,415 - INFO -   Participant 134 Coefficients: [0.36954887 0.23558368 0.         0.         0.         0.        ]
2025-03-25 22:10:29,415 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,416 - INFO -   Participant 135 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,416 - INFO -   Participant 135 Coefficients: [0.4383218 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,416 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,418 - INFO -   Participant 136 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,418 - INFO -   Participant 136 Coefficients: [0.47190801 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,418 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,419 - INFO -   Participant 137 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,419 - INFO -   Participant 137 Coefficients: [0.55423111 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,419 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,420 - INFO -   Participant 138 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,421 - INFO -   Participant 138 Coefficients: [0.44914085 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,421 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,422 - INFO -   Participant 139 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,422 - INFO -   Participant 139 Coefficients: [0.50741756 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,422 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,423 - INFO -   Participant 140 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,423 - INFO -   Participant 140 Coefficients: [0.48362204 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,424 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,425 - INFO -   Participant 141 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,425 - INFO -   Participant 141 Coefficients: [0.41054499 0.22994928 0.         0.         0.         0.        ]
2025-03-25 22:10:29,425 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,426 - INFO -   Participant 142 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,426 - INFO -   Participant 142 Coefficients: [0.47426379 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,426 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,428 - INFO -   Participant 143 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,428 - INFO -   Participant 143 Coefficients: [0.42754966 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,428 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,429 - INFO -   Participant 144 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,429 - INFO -   Participant 144 Coefficients: [0.63255918 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,429 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,430 - INFO -   Participant 145 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,431 - INFO -   Participant 145 Coefficients: [0.58619761 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,431 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,432 - INFO -   Participant 146 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,432 - INFO -   Participant 146 Coefficients: [0.54892683 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,432 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,433 - INFO -   Participant 147 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,433 - INFO -   Participant 147 Coefficients: [0.45888747 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,433 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,435 - INFO -   Participant 148 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,435 - INFO -   Participant 148 Coefficients: [0.4079048 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,435 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,436 - INFO -   Participant 149 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,436 - INFO -   Participant 149 Coefficients: [0.49506798 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,436 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,438 - INFO -   Participant 150 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,438 - INFO -   Participant 150 Coefficients: [0.37610183 0.23312071 0.         0.         0.         0.        ]
2025-03-25 22:10:29,438 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,439 - INFO -   Participant 151 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,439 - INFO -   Participant 151 Coefficients: [0.4181272 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,439 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,440 - INFO -   Participant 152 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,441 - INFO -   Participant 152 Coefficients: [0.45728838 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,441 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,442 - INFO -   Participant 153 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,442 - INFO -   Participant 153 Coefficients: [0.32518756 0.23226674 0.         0.         0.         0.        ]
2025-03-25 22:10:29,442 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,443 - INFO -   Participant 154 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,443 - INFO -   Participant 154 Coefficients: [0.55567308 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,443 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,445 - INFO -   Participant 155 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,445 - INFO -   Participant 155 Coefficients: [ 0.49711711 -0.60036381  0.          0.95296764  0.          0.        ]
2025-03-25 22:10:29,445 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,446 - INFO -   Participant 156 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,446 - INFO -   Participant 156 Coefficients: [0.36652699 0.23458724 0.         0.         0.         0.        ]
2025-03-25 22:10:29,446 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,447 - INFO -   Participant 157 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,448 - INFO -   Participant 157 Coefficients: [0.35215811 0.28374641 0.         0.         0.         0.        ]
2025-03-25 22:10:29,448 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,449 - INFO -   Participant 158 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,449 - INFO -   Participant 158 Coefficients: [0.45430997 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,449 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,450 - INFO -   Participant 159 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,450 - INFO -   Participant 159 Coefficients: [0.53260931 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,450 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,452 - INFO -   Participant 160 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,452 - INFO -   Participant 160 Coefficients: [0.53398734 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,452 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,453 - INFO -   Participant 161 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,453 - INFO -   Participant 161 Coefficients: [0.39300161 0.23485566 0.         0.         0.         0.        ]
2025-03-25 22:10:29,453 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,455 - INFO -   Participant 162 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,455 - INFO -   Participant 162 Coefficients: [0.32102969 0.22764955 0.         0.         0.         0.        ]
2025-03-25 22:10:29,455 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,456 - INFO -   Participant 163 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,456 - INFO -   Participant 163 Coefficients: [ 0.48900071 -0.62713319  0.          0.98781007  0.          0.        ]
2025-03-25 22:10:29,456 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,457 - INFO -   Participant 164 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,458 - INFO -   Participant 164 Coefficients: [0.44123338 0.22023939 0.         0.         0.         0.        ]
2025-03-25 22:10:29,458 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,459 - INFO -   Participant 165 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,459 - INFO -   Participant 165 Coefficients: [0.50039178 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,459 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,460 - INFO -   Participant 166 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,460 - INFO -   Participant 166 Coefficients: [0.41002113 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,460 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,462 - INFO -   Participant 167 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,462 - INFO -   Participant 167 Coefficients: [0.54577214 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,462 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,463 - INFO -   Participant 168 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,463 - INFO -   Participant 168 Coefficients: [0.4802871 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,463 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,464 - INFO -   Participant 169 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,465 - INFO -   Participant 169 Coefficients: [0.36789482 0.22191017 0.         0.         0.         0.        ]
2025-03-25 22:10:29,465 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,466 - INFO -   Participant 170 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,466 - INFO -   Participant 170 Coefficients: [0.31968177 0.23306134 0.         0.         0.         0.        ]
2025-03-25 22:10:29,466 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,467 - INFO -   Participant 171 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,467 - INFO -   Participant 171 Coefficients: [0.49299286 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,467 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,469 - INFO -   Participant 172 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,469 - INFO -   Participant 172 Coefficients: [0.42544707 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,469 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,470 - INFO -   Participant 173 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,470 - INFO -   Participant 173 Coefficients: [0.6641621 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,470 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,472 - INFO -   Participant 174 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,472 - INFO -   Participant 174 Coefficients: [0.49488613 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,472 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,473 - INFO -   Participant 175 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,473 - INFO -   Participant 175 Coefficients: [0.56711549 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,473 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,474 - INFO -   Participant 176 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,475 - INFO -   Participant 176 Coefficients: [0.365635   0.19333414 0.         0.         0.         0.        ]
2025-03-25 22:10:29,475 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,476 - INFO -   Participant 177 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,476 - INFO -   Participant 177 Coefficients: [0.39226284 0.23253077 0.         0.         0.         0.        ]
2025-03-25 22:10:29,476 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,477 - INFO -   Participant 178 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,477 - INFO -   Participant 178 Coefficients: [0.65750617 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,477 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,479 - INFO -   Participant 179 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,479 - INFO -   Participant 179 Coefficients: [0.56539941 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,479 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,480 - INFO -   Participant 180 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,480 - INFO -   Participant 180 Coefficients: [0.39834242 0.         0.         0.14536893 0.         0.        ]
2025-03-25 22:10:29,480 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,482 - INFO -   Participant 181 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,482 - INFO -   Participant 181 Coefficients: [0.33609921 0.23035752 0.         0.         0.         0.        ]
2025-03-25 22:10:29,482 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,483 - INFO -   Participant 182 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,483 - INFO -   Participant 182 Coefficients: [0.49432358 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,483 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,485 - INFO -   Participant 183 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,485 - INFO -   Participant 183 Coefficients: [0.34381228 0.22840887 0.         0.         0.         0.        ]
2025-03-25 22:10:29,485 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,486 - INFO -   Participant 184 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,486 - INFO -   Participant 184 Coefficients: [0.34584706 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,487 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,488 - INFO -   Participant 185 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,488 - INFO -   Participant 185 Coefficients: [0.40935323 0.23153585 0.         0.         0.         0.        ]
2025-03-25 22:10:29,488 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,489 - INFO -   Participant 186 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,489 - INFO -   Participant 186 Coefficients: [0.44536701 0.22782822 0.         0.         0.         0.        ]
2025-03-25 22:10:29,489 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,491 - INFO -   Participant 187 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,491 - INFO -   Participant 187 Coefficients: [0.32667828 0.36521197 0.         0.         0.         0.        ]
2025-03-25 22:10:29,491 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,492 - INFO -   Participant 188 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,492 - INFO -   Participant 188 Coefficients: [0.52975386 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,492 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,494 - INFO -   Participant 189 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,494 - INFO -   Participant 189 Coefficients: [0.34109524 0.22622872 0.         0.         0.         0.        ]
2025-03-25 22:10:29,494 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,495 - INFO -   Participant 190 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,495 - INFO -   Participant 190 Coefficients: [0.38754472 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,495 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,496 - INFO -   Participant 191 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,496 - INFO -   Participant 191 Coefficients: [0.57292676 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,496 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,498 - INFO -   Participant 192 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,498 - INFO -   Participant 192 Coefficients: [0.52128512 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,498 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,499 - INFO -   Participant 193 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,499 - INFO -   Participant 193 Coefficients: [0.57079792 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,499 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,501 - INFO -   Participant 194 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,501 - INFO -   Participant 194 Coefficients: [0.45723954 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,501 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,502 - INFO -   Participant 195 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,503 - INFO -   Participant 195 Coefficients: [0.41770105 0.2307051  0.         0.         0.         0.        ]
2025-03-25 22:10:29,503 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,504 - INFO -   Participant 196 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,504 - INFO -   Participant 196 Coefficients: [0.51875561 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,504 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,505 - INFO -   Participant 197 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,506 - INFO -   Participant 197 Coefficients: [0.53878376 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,506 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,507 - INFO -   Participant 198 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,507 - INFO -   Participant 198 Coefficients: [0.34609234 0.2290943  0.         0.         0.         0.        ]
2025-03-25 22:10:29,507 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,508 - INFO -   Participant 199 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,508 - INFO -   Participant 199 Coefficients: [0.49413595 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,508 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,510 - INFO -   Participant 200 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,510 - INFO -   Participant 200 Coefficients: [0.49738112 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,510 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,511 - INFO -   Participant 201 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,511 - INFO -   Participant 201 Coefficients: [0.54609985 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,511 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,512 - INFO -   Participant 202 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,513 - INFO -   Participant 202 Coefficients: [0.40117351 0.2302851  0.         0.         0.         0.        ]
2025-03-25 22:10:29,513 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,514 - INFO -   Participant 203 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,514 - INFO -   Participant 203 Coefficients: [0.24689401 0.22980264 0.         0.         0.         0.        ]
2025-03-25 22:10:29,514 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,516 - INFO -   Participant 204 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,516 - INFO -   Participant 204 Coefficients: [0.54481292 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,516 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,517 - INFO -   Participant 205 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,517 - INFO -   Participant 205 Coefficients: [0.40346868 0.23506492 0.         0.         0.         0.        ]
2025-03-25 22:10:29,517 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,518 - INFO -   Participant 206 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,519 - INFO -   Participant 206 Coefficients: [0.41860446 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,519 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,520 - INFO -   Participant 207 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,520 - INFO -   Participant 207 Coefficients: [0.3651773 0.        0.        0.        0.        0.       ]
2025-03-25 22:10:29,520 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,521 - INFO -   Participant 208 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,521 - INFO -   Participant 208 Coefficients: [0.42916006 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,521 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,523 - INFO -   Participant 209 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,523 - INFO -   Participant 209 Coefficients: [0.3785917  0.23884555 0.         0.         0.         0.        ]
2025-03-25 22:10:29,523 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,524 - INFO -   Participant 210 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,524 - INFO -   Participant 210 Coefficients: [0.56529146 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,524 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,526 - INFO -   Participant 211 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,526 - INFO -   Participant 211 Coefficients: [0.34593584 0.23740369 0.         0.         0.         0.        ]
2025-03-25 22:10:29,526 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,527 - INFO -   Participant 212 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,527 - INFO -   Participant 212 Coefficients: [0.52080989 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,527 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,528 - INFO -   Participant 213 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,529 - INFO -   Participant 213 Coefficients: [0.28580722 0.26421656 0.         0.         0.         0.        ]
2025-03-25 22:10:29,529 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,530 - INFO -   Participant 214 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,530 - INFO -   Participant 214 Coefficients: [0.52962625 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,530 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,531 - INFO -   Participant 215 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,532 - INFO -   Participant 215 Coefficients: [0.45411052 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,532 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,533 - INFO -   Participant 216 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,533 - INFO -   Participant 216 Coefficients: [0.3238352  0.23033295 0.         0.         0.         0.        ]
2025-03-25 22:10:29,533 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,534 - INFO -   Participant 217 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,534 - INFO -   Participant 217 Coefficients: [0.589755 0.       0.       0.       0.       0.      ]
2025-03-25 22:10:29,534 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,536 - INFO -   Participant 218 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,536 - INFO -   Participant 218 Coefficients: [0.57149637 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,536 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,537 - INFO -   Participant 219 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,537 - INFO -   Participant 219 Coefficients: [0.24985341 0.24059347 0.         0.         0.         0.        ]
2025-03-25 22:10:29,537 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,539 - INFO -   Participant 220 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,539 - INFO -   Participant 220 Coefficients: [0.57721579 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,539 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,540 - INFO -   Participant 221 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,540 - INFO -   Participant 221 Coefficients: [0.38097683 0.22803974 0.         0.         0.         0.        ]
2025-03-25 22:10:29,540 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,541 - INFO -   Participant 222 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,541 - INFO -   Participant 222 Coefficients: [0.51886703 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,541 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,543 - INFO -   Participant 223 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,543 - INFO -   Participant 223 Coefficients: [0.47467314 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,543 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,544 - INFO -   Participant 224 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,544 - INFO -   Participant 224 Coefficients: [0.43350542 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,544 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,546 - INFO -   Participant 225 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,546 - INFO -   Participant 225 Coefficients: [0.55224377 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,546 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,547 - INFO -   Participant 226 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,547 - INFO -   Participant 226 Coefficients: [0.44104773 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,547 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,548 - INFO -   Participant 227 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,549 - INFO -   Participant 227 Coefficients: [0.48284671 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,549 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,550 - INFO -   Participant 228 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,550 - INFO -   Participant 228 Coefficients: [0.48556435 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,550 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,551 - INFO -   Participant 229 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,551 - INFO -   Participant 229 Coefficients: [0.31078592 0.23992335 0.         0.         0.         0.        ]
2025-03-25 22:10:29,551 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,553 - INFO -   Participant 230 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,553 - INFO -   Participant 230 Coefficients: [0.34410394 0.23609135 0.         0.         0.         0.        ]
2025-03-25 22:10:29,553 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,554 - INFO -   Participant 231 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,554 - INFO -   Participant 231 Coefficients: [ 0.155083    1.6796782   0.         -3.21708146  0.          0.        ]
2025-03-25 22:10:29,554 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,556 - INFO -   Participant 232 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,556 - INFO -   Participant 232 Coefficients: [0.52078744 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,556 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,557 - INFO -   Participant 233 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,557 - INFO -   Participant 233 Coefficients: [0.37757754 0.22798776 0.         0.         0.         0.        ]
2025-03-25 22:10:29,557 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,558 - INFO -   Participant 234 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,558 - INFO -   Participant 234 Coefficients: [0.40918258 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,558 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,560 - INFO -   Participant 235 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,560 - INFO -   Participant 235 Coefficients: [0.47633488 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,560 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,561 - INFO -   Participant 236 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,561 - INFO -   Participant 236 Coefficients: [0.49285135 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,561 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,563 - INFO -   Participant 237 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,563 - INFO -   Participant 237 Coefficients: [0.43296707 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,563 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,564 - INFO -   Participant 238 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,564 - INFO -   Participant 238 Coefficients: [0.44780934 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,564 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,565 - INFO -   Participant 239 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,566 - INFO -   Participant 239 Coefficients: [0.42492485 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,566 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,567 - INFO -   Participant 240 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,567 - INFO -   Participant 240 Coefficients: [0.64506388 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,567 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,568 - INFO -   Participant 241 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,568 - INFO -   Participant 241 Coefficients: [0.48056939 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,568 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,570 - INFO -   Participant 242 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,570 - INFO -   Participant 242 Coefficients: [0.64770025 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,570 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,571 - INFO -   Participant 243 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,571 - INFO -   Participant 243 Coefficients: [0.49162528 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,571 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,573 - INFO -   Participant 244 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,573 - INFO -   Participant 244 Coefficients: [0.48430709 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,573 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,574 - INFO -   Participant 245 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,574 - INFO -   Participant 245 Coefficients: [0.54793453 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,574 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,576 - INFO -   Participant 246 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,576 - INFO -   Participant 246 Coefficients: [0.45861357 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,576 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,577 - INFO -   Participant 247 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,577 - INFO -   Participant 247 Coefficients: [0.39552827 0.08892867 0.         0.         0.         0.        ]
2025-03-25 22:10:29,577 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,578 - INFO -   Participant 248 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,578 - INFO -   Participant 248 Coefficients: [0.52898115 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,579 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,580 - INFO -   Participant 249 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,580 - INFO -   Participant 249 Coefficients: [0.50526041 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,580 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,581 - INFO -   Participant 250 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,581 - INFO -   Participant 250 Coefficients: [0.40757422 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,581 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,583 - INFO -   Participant 251 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,583 - INFO -   Participant 251 Coefficients: [0.50461766 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,583 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,584 - INFO -   Participant 252 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,584 - INFO -   Participant 252 Coefficients: [0.47949287 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,584 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,585 - INFO -   Participant 253 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,586 - INFO -   Participant 253 Coefficients: [0.32582027 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,586 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,587 - INFO -   Participant 254 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,587 - INFO -   Participant 254 Coefficients: [0.32150525 0.23153241 0.         0.         0.         0.        ]
2025-03-25 22:10:29,587 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,588 - INFO -   Participant 255 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:10:29,588 - INFO -   Participant 255 Coefficients: [0.36328223 0.         0.         0.         0.         0.        ]
2025-03-25 22:10:29,588 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:10:29,589 - INFO - Visualizing for participant index 49, ID 49.0
2025-03-25 22:10:29,589 - INFO - Data shape for this participant: torch.Size([100, 5])
2025-03-25 22:10:30,903 - INFO - Creating dataset subset with 200 trials per participant
2025-03-25 22:10:30,909 - INFO - Subset with 200 trials per participant:
2025-03-25 22:10:30,909 - INFO -   Dataset shape: torch.Size([256, 200, 5])
2025-03-25 22:10:30,909 - INFO - 
==== Running pipeline for dataset: 200 trials per participant ====
2025-03-25 22:10:30,909 - INFO - 
Training RNN...
2025-03-25 22:10:30,910 - INFO - RNN model trainable parameters: 2438
2025-03-25 22:11:14,444 - INFO - Final training loss: 0.0000000
2025-03-25 22:11:14,445 - INFO - 
Fitting SINDy...
2025-03-25 22:12:16,626 - INFO - ================================================================================
2025-03-25 22:12:16,626 - INFO - EXPERIMENT CONFIG
2025-03-25 22:12:16,626 - INFO - ================================================================================
2025-03-25 22:12:16,626 - INFO - Number of actions: 2
2025-03-25 22:12:16,633 - INFO - Number of participants: 16
2025-03-25 22:12:16,634 - INFO - ================================================================================
2025-03-25 22:12:16,634 - INFO - PROCESSING PARTICIPANT DATA
2025-03-25 22:12:16,634 - INFO - ================================================================================
2025-03-25 22:12:16,726 - INFO - ================================================================================
2025-03-25 22:12:16,726 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-25 22:12:16,726 - INFO - ================================================================================
2025-03-25 22:12:16,726 - INFO - Creating dataset subset with 100 trials per participant
2025-03-25 22:12:16,727 - INFO - Subset with 100 trials per participant:
2025-03-25 22:12:16,727 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-25 22:12:16,727 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-25 22:12:16,727 - INFO - 
Training RNN...
2025-03-25 22:12:16,728 - INFO - RNN model trainable parameters: 518
2025-03-25 22:13:12,670 - INFO - Final training loss: 0.2812638
2025-03-25 22:13:12,671 - INFO - 
Fitting SINDy...
2025-03-25 22:13:30,192 - INFO - 
Evaluating SINDy models...
2025-03-25 22:13:30,192 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-25 22:13:30,192 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-25 22:13:30,193 - INFO - SINDy model parameters for participant 0: 7
2025-03-25 22:13:30,508 - INFO - Participant 0: Log-likelihood: -8.0864, Normalized LL: -0.0809, Raw BIC: 48.4090, Normalized BIC: 0.4841
2025-03-25 22:13:30,508 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-25 22:13:30,508 - INFO - SINDy model parameters for participant 1: 8
2025-03-25 22:13:30,824 - INFO - Participant 1: Log-likelihood: -65.9823, Normalized LL: -0.6598, Raw BIC: 168.8060, Normalized BIC: 1.6881
2025-03-25 22:13:30,824 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-25 22:13:30,824 - INFO - SINDy model parameters for participant 2: 5
2025-03-25 22:13:31,143 - INFO - Participant 2: Log-likelihood: -20.5633, Normalized LL: -0.2056, Raw BIC: 64.1525, Normalized BIC: 0.6415
2025-03-25 22:13:31,143 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-25 22:13:31,144 - INFO - SINDy model parameters for participant 3: 7
2025-03-25 22:13:31,462 - INFO - Participant 3: Log-likelihood: -53.3103, Normalized LL: -0.5331, Raw BIC: 138.8568, Normalized BIC: 1.3886
2025-03-25 22:13:31,462 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-25 22:13:31,462 - INFO - SINDy model parameters for participant 4: 8
2025-03-25 22:13:31,779 - INFO - Participant 4: Log-likelihood: -62.8748, Normalized LL: -0.6287, Raw BIC: 162.5909, Normalized BIC: 1.6259
2025-03-25 22:13:31,779 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-25 22:13:31,779 - INFO - SINDy model parameters for participant 5: 8
2025-03-25 22:13:32,096 - INFO - Participant 5: Log-likelihood: -0.9979, Normalized LL: -0.0100, Raw BIC: 38.8372, Normalized BIC: 0.3884
2025-03-25 22:13:32,096 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-25 22:13:32,097 - INFO - SINDy model parameters for participant 6: 9
2025-03-25 22:13:32,411 - INFO - Participant 6: Log-likelihood: -5.4172, Normalized LL: -0.0542, Raw BIC: 52.2809, Normalized BIC: 0.5228
2025-03-25 22:13:32,411 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-25 22:13:32,411 - INFO - SINDy model parameters for participant 7: 8
2025-03-25 22:13:32,726 - INFO - Participant 7: Log-likelihood: -67.9476, Normalized LL: -0.6795, Raw BIC: 172.7366, Normalized BIC: 1.7274
2025-03-25 22:13:32,726 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-25 22:13:32,727 - INFO - SINDy model parameters for participant 8: 8
2025-03-25 22:13:33,028 - INFO - Participant 8: Log-likelihood: -77.5281, Normalized LL: -0.7753, Raw BIC: 191.8976, Normalized BIC: 1.9190
2025-03-25 22:13:33,028 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-25 22:13:33,028 - INFO - SINDy model parameters for participant 9: 9
2025-03-25 22:13:33,343 - INFO - Participant 9: Log-likelihood: -19.7015, Normalized LL: -0.1970, Raw BIC: 80.8495, Normalized BIC: 0.8085
2025-03-25 22:13:33,343 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-25 22:13:33,343 - INFO - SINDy model parameters for participant 10: 5
2025-03-25 22:13:33,657 - INFO - Participant 10: Log-likelihood: -36.4505, Normalized LL: -0.3645, Raw BIC: 95.9269, Normalized BIC: 0.9593
2025-03-25 22:13:33,657 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-25 22:13:33,657 - INFO - SINDy model parameters for participant 11: 5
2025-03-25 22:13:33,974 - INFO - Participant 11: Log-likelihood: -1.6153, Normalized LL: -0.0162, Raw BIC: 26.2564, Normalized BIC: 0.2626
2025-03-25 22:13:33,974 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-25 22:13:33,974 - INFO - SINDy model parameters for participant 12: 7
2025-03-25 22:13:34,292 - INFO - Participant 12: Log-likelihood: -40.0855, Normalized LL: -0.4009, Raw BIC: 112.4072, Normalized BIC: 1.1241
2025-03-25 22:13:34,292 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-25 22:13:34,293 - INFO - SINDy model parameters for participant 13: 9
2025-03-25 22:13:34,604 - INFO - Participant 13: Log-likelihood: -25.4682, Normalized LL: -0.2547, Raw BIC: 92.3829, Normalized BIC: 0.9238
2025-03-25 22:13:34,604 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-25 22:13:34,604 - INFO - SINDy model parameters for participant 14: 7
2025-03-25 22:13:34,918 - INFO - Participant 14: Log-likelihood: -8.3106, Normalized LL: -0.0831, Raw BIC: 48.8574, Normalized BIC: 0.4886
2025-03-25 22:13:34,918 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-25 22:13:34,919 - INFO - SINDy model parameters for participant 15: 5
2025-03-25 22:13:35,235 - INFO - Participant 15: Log-likelihood: -38.0023, Normalized LL: -0.3800, Raw BIC: 99.0305, Normalized BIC: 0.9903
2025-03-25 22:13:35,235 - INFO - 
Average SINDy BIC for 100 trials per participant: 0.9964
2025-03-25 22:13:35,235 - INFO - 
Average Normalized Log Likelihood for 100 trials per participant: -0.3327
2025-03-25 22:13:35,235 - INFO - 
Identified SINDy equations:
2025-03-25 22:13:35,235 - INFO - Module: x_learning_rate_reward
2025-03-25 22:13:35,238 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,238 - INFO -   Participant 0 Coefficients: [ 0.71460854 -0.32169657  0.          0.          0.49954425  0.
  0.          0.          0.          0.        ]
2025-03-25 22:13:35,238 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,240 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,240 - INFO -   Participant 1 Coefficients: [0.70010372 0.16612015 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:13:35,240 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,242 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,242 - INFO -   Participant 2 Coefficients: [0.94969849 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:13:35,242 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,244 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,244 - INFO -   Participant 3 Coefficients: [0.92122713 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:13:35,244 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,245 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,246 - INFO -   Participant 4 Coefficients: [0.60088421 0.21788134 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:13:35,246 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,247 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,247 - INFO -   Participant 5 Coefficients: [ 0.7873398   0.13996642  0.3811984  -0.39553662  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:13:35,247 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,249 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,249 - INFO -   Participant 6 Coefficients: [ 0.74158463  0.17465939  0.35614799 -0.32727277  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:13:35,249 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,251 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,251 - INFO -   Participant 7 Coefficients: [0.87073528 0.0882058  0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:13:35,251 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,253 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,253 - INFO -   Participant 8 Coefficients: [ 0.93922539  0.          0.18218729 -0.08552152  0.          0.05029877
  0.          0.          0.          0.        ]
2025-03-25 22:13:35,253 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,255 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,255 - INFO -   Participant 9 Coefficients: [ 0.59441013  0.25053844  0.27268266 -0.56091321  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:13:35,255 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,257 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,257 - INFO -   Participant 10 Coefficients: [0.8577153 0.        0.        0.        0.        0.        0.
 0.        0.        0.       ]
2025-03-25 22:13:35,257 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,259 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,259 - INFO -   Participant 11 Coefficients: [0.86874168 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:13:35,259 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,260 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,261 - INFO -   Participant 12 Coefficients: [0.65943019 0.20091392 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:13:35,261 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,262 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,262 - INFO -   Participant 13 Coefficients: [ 0.9055137   0.         -0.09488702  0.09938658  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:13:35,262 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,264 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,264 - INFO -   Participant 14 Coefficients: [0.78027845 0.11244994 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:13:35,264 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,266 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,266 - INFO -   Participant 15 Coefficients: [0.91206453 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:13:35,266 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:13:35,266 - INFO - Module: x_value_reward_not_chosen
2025-03-25 22:13:35,268 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,268 - INFO -   Participant 0 Coefficients: [-0.91988745  0.80382936  0.          0.          0.          0.        ]
2025-03-25 22:13:35,268 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,269 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,269 - INFO -   Participant 1 Coefficients: [-0.21120965  0.74785074  0.          0.          0.          0.        ]
2025-03-25 22:13:35,269 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,271 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,271 - INFO -   Participant 2 Coefficients: [-0.79793271  0.80270553  0.          0.          0.          0.        ]
2025-03-25 22:13:35,271 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,272 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,272 - INFO -   Participant 3 Coefficients: [-0.25570047  0.79618623  0.          0.          0.          0.        ]
2025-03-25 22:13:35,272 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,274 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,274 - INFO -   Participant 4 Coefficients: [-0.16277382  0.74355515  0.          0.          0.          0.        ]
2025-03-25 22:13:35,274 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,275 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,275 - INFO -   Participant 5 Coefficients: [-0.43743969  0.80777641  0.          0.          0.          0.        ]
2025-03-25 22:13:35,275 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,277 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,277 - INFO -   Participant 6 Coefficients: [-0.31855172  0.7956514   0.          0.          0.          0.        ]
2025-03-25 22:13:35,277 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,278 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,278 - INFO -   Participant 7 Coefficients: [0.14921345 0.74286266 0.         0.         0.         0.        ]
2025-03-25 22:13:35,278 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,280 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,280 - INFO -   Participant 8 Coefficients: [-0.46779494  0.84356215  0.          0.          0.          0.        ]
2025-03-25 22:13:35,280 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,281 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,281 - INFO -   Participant 9 Coefficients: [-0.13341687  0.78597418  0.          0.          0.          0.        ]
2025-03-25 22:13:35,281 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,283 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,283 - INFO -   Participant 10 Coefficients: [-0.79926174  0.6998969   0.          0.          0.          0.        ]
2025-03-25 22:13:35,283 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,284 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,284 - INFO -   Participant 11 Coefficients: [-0.90189811  0.82523472  0.          0.          0.          0.        ]
2025-03-25 22:13:35,284 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,286 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,286 - INFO -   Participant 12 Coefficients: [-0.10634746  0.74672196  0.          0.          0.          0.        ]
2025-03-25 22:13:35,286 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,287 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,287 - INFO -   Participant 13 Coefficients: [-0.53553011  0.75436266  0.          0.          0.          0.        ]
2025-03-25 22:13:35,287 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,289 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,289 - INFO -   Participant 14 Coefficients: [-0.35481308  0.84040382  0.          0.          0.          0.        ]
2025-03-25 22:13:35,289 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,290 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,290 - INFO -   Participant 15 Coefficients: [-0.67582551  0.73407228  0.          0.          0.          0.        ]
2025-03-25 22:13:35,290 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:13:35,290 - INFO - Module: x_value_choice_chosen
2025-03-25 22:13:35,292 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,292 - INFO -   Participant 0 Coefficients: [0.63047844 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,292 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,293 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,293 - INFO -   Participant 1 Coefficients: [ 0.72665649  0.          0.         -0.23765991  0.          0.        ]
2025-03-25 22:13:35,293 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,295 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,295 - INFO -   Participant 2 Coefficients: [0.23813234 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,295 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,296 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,296 - INFO -   Participant 3 Coefficients: [0.32827367 0.21543411 0.         0.         0.         0.        ]
2025-03-25 22:13:35,296 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,298 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,298 - INFO -   Participant 4 Coefficients: [0.68105862 0.19566564 0.         0.         0.         0.        ]
2025-03-25 22:13:35,298 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,299 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,299 - INFO -   Participant 5 Coefficients: [0.87042253 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,299 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,301 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,301 - INFO -   Participant 6 Coefficients: [0.81432918 0.06614663 0.         0.         0.         0.        ]
2025-03-25 22:13:35,301 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,302 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,302 - INFO -   Participant 7 Coefficients: [0.31535749 0.2696587  0.         0.         0.         0.        ]
2025-03-25 22:13:35,302 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,304 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,304 - INFO -   Participant 8 Coefficients: [0.35415733 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,304 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,305 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,306 - INFO -   Participant 9 Coefficients: [0.84799487 0.05427357 0.         0.         0.         0.        ]
2025-03-25 22:13:35,306 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,307 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,307 - INFO -   Participant 10 Coefficients: [0.46551964 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,307 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,309 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,309 - INFO -   Participant 11 Coefficients: [0.30241391 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,309 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,310 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,311 - INFO -   Participant 12 Coefficients: [0.80349806 0.09017542 0.         0.         0.         0.        ]
2025-03-25 22:13:35,311 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,312 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,312 - INFO -   Participant 13 Coefficients: [0.66660054 0.17801794 0.         0.         0.         0.        ]
2025-03-25 22:13:35,312 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,313 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,313 - INFO -   Participant 14 Coefficients: [0.79591316 0.08547125 0.         0.         0.         0.        ]
2025-03-25 22:13:35,313 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,314 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,315 - INFO -   Participant 15 Coefficients: [0.53938329 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,315 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:13:35,315 - INFO - Module: x_value_choice_not_chosen
2025-03-25 22:13:35,316 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,316 - INFO -   Participant 0 Coefficients: [0.3040041 0.        0.        0.        0.        0.       ]
2025-03-25 22:13:35,316 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,318 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,318 - INFO -   Participant 1 Coefficients: [0.32299369 0.         0.         0.76841069 0.         0.        ]
2025-03-25 22:13:35,318 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,319 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,320 - INFO -   Participant 2 Coefficients: [0.77063662 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,320 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,321 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,321 - INFO -   Participant 3 Coefficients: [0.7089574  0.11652909 0.         0.         0.         0.        ]
2025-03-25 22:13:35,321 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,322 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,322 - INFO -   Participant 4 Coefficients: [0.15158211 0.11455554 0.         0.         0.         0.        ]
2025-03-25 22:13:35,322 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,323 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,323 - INFO -   Participant 5 Coefficients: [0.33943068 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,323 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,324 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,324 - INFO -   Participant 6 Coefficients: [0.17472118 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,324 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,326 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,326 - INFO -   Participant 7 Coefficients: [0.42129019 0.15021496 0.         0.         0.         0.        ]
2025-03-25 22:13:35,326 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,327 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,327 - INFO -   Participant 8 Coefficients: [0.70952731 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,327 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,328 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,328 - INFO -   Participant 9 Coefficients: [0.25889689 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,328 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,329 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,329 - INFO -   Participant 10 Coefficients: [0.28874207 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,329 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,330 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,330 - INFO -   Participant 11 Coefficients: [0.74807668 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,330 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,332 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,332 - INFO -   Participant 12 Coefficients: [0.15715275 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,332 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,333 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,333 - INFO -   Participant 13 Coefficients: [0.118052   0.09854378 0.         0.         0.         0.        ]
2025-03-25 22:13:35,333 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,335 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,335 - INFO -   Participant 14 Coefficients: [0.21463302 0.         0.         0.         0.         0.        ]
2025-03-25 22:13:35,335 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,336 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:13:35,336 - INFO -   Participant 15 Coefficients: [0.3354995 0.        0.        0.        0.        0.       ]
2025-03-25 22:13:35,336 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:13:35,336 - INFO - Visualizing for participant index 0, ID 0.0
2025-03-25 22:13:35,336 - INFO - Data shape for this participant: torch.Size([100, 5])
2025-03-25 22:13:36,602 - INFO - Creating dataset subset with 200 trials per participant
2025-03-25 22:13:36,602 - INFO - Subset with 200 trials per participant:
2025-03-25 22:13:36,602 - INFO -   Dataset shape: torch.Size([16, 200, 5])
2025-03-25 22:13:36,602 - INFO - 
==== Running pipeline for dataset: 200 trials per participant ====
2025-03-25 22:13:36,603 - INFO - 
Training RNN...
2025-03-25 22:13:36,603 - INFO - RNN model trainable parameters: 518
2025-03-25 22:15:26,116 - INFO - Final training loss: 0.2968013
2025-03-25 22:15:26,117 - INFO - 
Fitting SINDy...
2025-03-25 22:15:43,735 - INFO - 
Evaluating SINDy models...
2025-03-25 22:15:43,735 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-25 22:15:43,735 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-25 22:15:43,735 - INFO - SINDy model parameters for participant 0: 8
2025-03-25 22:15:44,383 - INFO - Participant 0: Log-likelihood: -2133.3540, Normalized LL: -10.6668, Raw BIC: 4309.0946, Normalized BIC: 21.5455
2025-03-25 22:15:44,383 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-25 22:15:44,383 - INFO - SINDy model parameters for participant 1: 9
2025-03-25 22:15:44,992 - INFO - Participant 1: Log-likelihood: -124.9639, Normalized LL: -0.6248, Raw BIC: 297.6127, Normalized BIC: 1.4881
2025-03-25 22:15:44,992 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-25 22:15:44,992 - INFO - SINDy model parameters for participant 2: 10
2025-03-25 22:15:45,604 - INFO - Participant 2: Log-likelihood: -521.3666, Normalized LL: -2.6068, Raw BIC: 1095.7164, Normalized BIC: 5.4786
2025-03-25 22:15:45,604 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-25 22:15:45,605 - INFO - SINDy model parameters for participant 3: 10
2025-03-25 22:15:46,210 - INFO - Participant 3: Log-likelihood: -101.8360, Normalized LL: -0.5092, Raw BIC: 256.6552, Normalized BIC: 1.2833
2025-03-25 22:15:46,210 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-25 22:15:46,210 - INFO - SINDy model parameters for participant 4: 5
2025-03-25 22:15:46,822 - INFO - Participant 4: Log-likelihood: -134.5339, Normalized LL: -0.6727, Raw BIC: 295.5594, Normalized BIC: 1.4778
2025-03-25 22:15:46,822 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-25 22:15:46,822 - INFO - SINDy model parameters for participant 5: 9
2025-03-25 22:15:47,429 - INFO - Participant 5: Log-likelihood: -6.6850, Normalized LL: -0.0334, Raw BIC: 61.0549, Normalized BIC: 0.3053
2025-03-25 22:15:47,429 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-25 22:15:47,429 - INFO - SINDy model parameters for participant 6: 9
2025-03-25 22:15:48,052 - INFO - Participant 6: Log-likelihood: -15.7675, Normalized LL: -0.0788, Raw BIC: 79.2199, Normalized BIC: 0.3961
2025-03-25 22:15:48,052 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-25 22:15:48,052 - INFO - SINDy model parameters for participant 7: 4
2025-03-25 22:15:48,699 - INFO - Participant 7: Log-likelihood: -137.8316, Normalized LL: -0.6892, Raw BIC: 296.8565, Normalized BIC: 1.4843
2025-03-25 22:15:48,699 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-25 22:15:48,699 - INFO - SINDy model parameters for participant 8: 7
2025-03-25 22:15:49,303 - INFO - Participant 8: Log-likelihood: -142.3959, Normalized LL: -0.7120, Raw BIC: 321.8799, Normalized BIC: 1.6094
2025-03-25 22:15:49,303 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-25 22:15:49,303 - INFO - SINDy model parameters for participant 9: 16
2025-03-25 22:15:49,909 - INFO - Participant 9: Log-likelihood: -971.7563, Normalized LL: -4.8588, Raw BIC: 2028.2857, Normalized BIC: 10.1414
2025-03-25 22:15:49,909 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-25 22:15:49,909 - INFO - SINDy model parameters for participant 10: 14
2025-03-25 22:15:50,512 - INFO - Participant 10: Log-likelihood: -181.0345, Normalized LL: -0.9052, Raw BIC: 436.2455, Normalized BIC: 2.1812
2025-03-25 22:15:50,512 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-25 22:15:50,512 - INFO - SINDy model parameters for participant 11: 7
2025-03-25 22:15:51,132 - INFO - Participant 11: Log-likelihood: -6.4846, Normalized LL: -0.0324, Raw BIC: 50.0573, Normalized BIC: 0.2503
2025-03-25 22:15:51,132 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-25 22:15:51,133 - INFO - SINDy model parameters for participant 12: 15
2025-03-25 22:15:51,762 - INFO - Participant 12: Log-likelihood: -387.0044, Normalized LL: -1.9350, Raw BIC: 853.4836, Normalized BIC: 4.2674
2025-03-25 22:15:51,762 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-25 22:15:51,763 - INFO - SINDy model parameters for participant 13: 6
2025-03-25 22:15:52,362 - INFO - Participant 13: Log-likelihood: -37.1914, Normalized LL: -0.1860, Raw BIC: 106.1728, Normalized BIC: 0.5309
2025-03-25 22:15:52,362 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-25 22:15:52,363 - INFO - SINDy model parameters for participant 14: 7
2025-03-25 22:15:52,969 - INFO - Participant 14: Log-likelihood: -18.5396, Normalized LL: -0.0927, Raw BIC: 74.1674, Normalized BIC: 0.3708
2025-03-25 22:15:52,969 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-25 22:15:52,969 - INFO - SINDy model parameters for participant 15: 12
2025-03-25 22:15:53,586 - INFO - Participant 15: Log-likelihood: -669.2743, Normalized LL: -3.3464, Raw BIC: 1402.1285, Normalized BIC: 7.0106
2025-03-25 22:15:53,586 - INFO - 
Average SINDy BIC for 200 trials per participant: 3.7388
2025-03-25 22:15:53,586 - INFO - 
Average Normalized Log Likelihood for 200 trials per participant: -1.7469
2025-03-25 22:15:53,586 - INFO - 
Identified SINDy equations:
2025-03-25 22:15:53,586 - INFO - Module: x_learning_rate_reward
2025-03-25 22:15:53,588 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,588 - INFO -   Participant 0 Coefficients: [ 0.98728454  0.         -2.95109927  0.          0.          0.
  0.          0.          4.26708605 -1.54094013]
2025-03-25 22:15:53,588 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,590 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,590 - INFO -   Participant 1 Coefficients: [ 0.95489526  0.          0.40527536 -0.27299817  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:15:53,590 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,591 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,592 - INFO -   Participant 2 Coefficients: [ 0.97841403  0.          0.64891387 -0.11649516  0.          0.48537524
 -0.38051523  0.         -0.34784972  0.        ]
2025-03-25 22:15:53,592 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,593 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,593 - INFO -   Participant 3 Coefficients: [ 0.8284537   0.13552344  0.37677802 -0.41378915  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:15:53,593 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,595 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,595 - INFO -   Participant 4 Coefficients: [0.96725667 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:15:53,595 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,597 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,597 - INFO -   Participant 5 Coefficients: [ 0.9654351  -0.77745185  0.          0.          0.56511045  0.
  0.          0.          0.          0.        ]
2025-03-25 22:15:53,597 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,599 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,599 - INFO -   Participant 6 Coefficients: [ 0.98011886 -0.33806227  0.          0.          0.23480646  0.
  0.          0.          0.          0.        ]
2025-03-25 22:15:53,599 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,600 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,601 - INFO -   Participant 7 Coefficients: [0.91876071 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:15:53,601 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,602 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,602 - INFO -   Participant 8 Coefficients: [ 0.97954578  0.          0.51175164 -0.32164116  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:15:53,602 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,604 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,604 - INFO -   Participant 9 Coefficients: [ 1.17552470e+00 -6.79627628e-01  1.59490662e+11  5.03847694e+00
  4.82079662e-01  3.91849453e+00 -4.65482938e+00 -1.59490662e+11
  2.86905517e+01 -2.03584535e+01]
2025-03-25 22:15:53,604 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,606 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,606 - INFO -   Participant 10 Coefficients: [ 0.90999152 -0.23451424  0.21160542  0.06052308  0.27729983  0.71429043
 -0.58803048  0.         -0.2724264   0.        ]
2025-03-25 22:15:53,606 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,608 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,608 - INFO -   Participant 11 Coefficients: [ 0.95180534 -1.46624834  0.          0.          1.15024854  0.
  0.          0.          0.          0.        ]
2025-03-25 22:15:53,608 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,610 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,610 - INFO -   Participant 12 Coefficients: [ 4.49747150e-01  5.39782229e-01 -3.87352213e+02 -1.13350715e+02
  0.00000000e+00 -5.21772678e+01  1.42654915e+02 -3.87352213e+02
  4.46494917e+03 -6.10672710e+03]
2025-03-25 22:15:53,610 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,612 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,612 - INFO -   Participant 13 Coefficients: [ 0.97681774 -0.07889523  0.          0.          0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:15:53,612 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,613 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,614 - INFO -   Participant 14 Coefficients: [ 0.9763489  -0.39831796  0.          0.          0.27716717  0.
  0.          0.          0.          0.        ]
2025-03-25 22:15:53,614 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,615 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,616 - INFO -   Participant 15 Coefficients: [ 0.90584633  0.          0.13437774  0.12734164  0.          0.76689438
 -0.67933557  0.          0.         -0.33832651]
2025-03-25 22:15:53,616 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:15:53,616 - INFO - Module: x_value_reward_not_chosen
2025-03-25 22:15:53,617 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,617 - INFO -   Participant 0 Coefficients: [-1.66037886  0.59441881  0.          0.          0.          0.        ]
2025-03-25 22:15:53,617 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,619 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,619 - INFO -   Participant 1 Coefficients: [0.76000796 0.23965648 0.         0.         0.         0.        ]
2025-03-25 22:15:53,619 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,620 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,620 - INFO -   Participant 2 Coefficients: [-2.05274062  0.29383572  0.          0.          0.          0.        ]
2025-03-25 22:15:53,620 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,622 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,622 - INFO -   Participant 3 Coefficients: [0.64417118 0.16619205 0.         0.         0.         0.        ]
2025-03-25 22:15:53,622 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,623 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,623 - INFO -   Participant 4 Coefficients: [-0.30681537  0.4419612   0.          0.          0.          0.        ]
2025-03-25 22:15:53,623 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,625 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,625 - INFO -   Participant 5 Coefficients: [-2.67226912  0.40604493  0.          0.          0.          0.        ]
2025-03-25 22:15:53,625 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,626 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,626 - INFO -   Participant 6 Coefficients: [-2.77936536  0.31600602  0.          0.          0.          0.        ]
2025-03-25 22:15:53,626 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,628 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,628 - INFO -   Participant 7 Coefficients: [0.         0.44315846 0.         0.         0.         0.        ]
2025-03-25 22:15:53,628 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,629 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,630 - INFO -   Participant 8 Coefficients: [-1.57914082  0.38020548  0.          0.          0.          0.        ]
2025-03-25 22:15:53,630 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,631 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,632 - INFO -   Participant 9 Coefficients: [-2.34373356  0.27410338  0.          0.          0.          0.        ]
2025-03-25 22:15:53,632 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,634 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,634 - INFO -   Participant 10 Coefficients: [-0.43921541  0.18250989  0.          0.          0.          0.        ]
2025-03-25 22:15:53,634 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,636 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,636 - INFO -   Participant 11 Coefficients: [-2.93057987  0.40802098  0.          0.          0.          0.        ]
2025-03-25 22:15:53,636 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,637 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,637 - INFO -   Participant 12 Coefficients: [-0.89412612  0.14642827  0.          0.          0.          0.        ]
2025-03-25 22:15:53,637 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,639 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,639 - INFO -   Participant 13 Coefficients: [-2.36295162  0.22038994  0.          0.          0.          0.        ]
2025-03-25 22:15:53,639 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,640 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,640 - INFO -   Participant 14 Coefficients: [-2.65282037  0.30973094  0.          0.          0.          0.        ]
2025-03-25 22:15:53,640 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,641 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,642 - INFO -   Participant 15 Coefficients: [-0.47966218  0.26481315  0.          0.          0.          0.        ]
2025-03-25 22:15:53,642 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:15:53,642 - INFO - Module: x_value_choice_chosen
2025-03-25 22:15:53,643 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,643 - INFO -   Participant 0 Coefficients: [0.7835896 0.        0.        0.        0.        0.       ]
2025-03-25 22:15:53,643 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,644 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,644 - INFO -   Participant 1 Coefficients: [0.78015715 0.14470196 0.         0.         0.         0.        ]
2025-03-25 22:15:53,644 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,645 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,645 - INFO -   Participant 2 Coefficients: [0.77791518 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,645 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,647 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,647 - INFO -   Participant 3 Coefficients: [0.85628803 0.07277528 0.         0.         0.         0.        ]
2025-03-25 22:15:53,647 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,648 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,648 - INFO -   Participant 4 Coefficients: [0.7050159 0.        0.        0.        0.        0.       ]
2025-03-25 22:15:53,648 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,649 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,650 - INFO -   Participant 5 Coefficients: [0.67522046 0.20322054 0.         0.         0.         0.        ]
2025-03-25 22:15:53,650 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,651 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,651 - INFO -   Participant 6 Coefficients: [0.76642606 0.16262698 0.         0.         0.         0.        ]
2025-03-25 22:15:53,651 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,652 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,652 - INFO -   Participant 7 Coefficients: [0.75149179 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,652 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,653 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,653 - INFO -   Participant 8 Coefficients: [0.69393992 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,653 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,654 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,655 - INFO -   Participant 9 Coefficients: [0.7877429  0.16005311 0.         0.         0.         0.        ]
2025-03-25 22:15:53,655 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,656 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,656 - INFO -   Participant 10 Coefficients: [0.81541129 0.1072866  0.         0.         0.         0.        ]
2025-03-25 22:15:53,656 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,657 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,657 - INFO -   Participant 11 Coefficients: [0.72048312 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,657 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,659 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,659 - INFO -   Participant 12 Coefficients: [0.77828112 0.13511614 0.         0.         0.         0.        ]
2025-03-25 22:15:53,659 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,660 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,660 - INFO -   Participant 13 Coefficients: [0.74902844 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,660 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,662 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,662 - INFO -   Participant 14 Coefficients: [0.73455787 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,662 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,666 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,666 - INFO -   Participant 15 Coefficients: [0.8293785  0.08764082 0.         0.         0.         0.        ]
2025-03-25 22:15:53,666 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:15:53,667 - INFO - Module: x_value_choice_not_chosen
2025-03-25 22:15:53,669 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,670 - INFO -   Participant 0 Coefficients: [0.20966685 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,670 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,672 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,672 - INFO -   Participant 1 Coefficients: [0.20023064 0.10693363 0.         0.         0.         0.        ]
2025-03-25 22:15:53,672 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,675 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,675 - INFO -   Participant 2 Coefficients: [0.20623653 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,675 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,677 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,678 - INFO -   Participant 3 Coefficients: [0.13071673 0.1514725  0.         0.         0.         0.        ]
2025-03-25 22:15:53,678 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,681 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,681 - INFO -   Participant 4 Coefficients: [0.26426363 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,681 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,684 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,684 - INFO -   Participant 5 Coefficients: [0.31269198 0.11219125 0.         0.         0.         0.        ]
2025-03-25 22:15:53,684 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,686 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,687 - INFO -   Participant 6 Coefficients: [0.19808181 0.2745499  0.         0.         0.         0.        ]
2025-03-25 22:15:53,687 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,689 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,689 - INFO -   Participant 7 Coefficients: [0.20776103 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,689 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,692 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,692 - INFO -   Participant 8 Coefficients: [0.29537067 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,692 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,694 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,694 - INFO -   Participant 9 Coefficients: [0.19999715 0.09428505 0.         0.         0.         0.        ]
2025-03-25 22:15:53,694 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,697 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,697 - INFO -   Participant 10 Coefficients: [0.18148272 0.12163753 0.         0.         0.         0.        ]
2025-03-25 22:15:53,697 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,699 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,699 - INFO -   Participant 11 Coefficients: [0.25395697 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,700 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,701 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,702 - INFO -   Participant 12 Coefficients: [0.16335789 0.18616742 0.         0.         0.         0.        ]
2025-03-25 22:15:53,702 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,703 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,703 - INFO -   Participant 13 Coefficients: [0.22721784 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,703 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,705 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,705 - INFO -   Participant 14 Coefficients: [0.23160978 0.         0.         0.         0.         0.        ]
2025-03-25 22:15:53,705 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,706 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:15:53,706 - INFO -   Participant 15 Coefficients: [0.15032163 0.14498325 0.         0.         0.         0.        ]
2025-03-25 22:15:53,706 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:15:53,707 - INFO - Visualizing for participant index 0, ID 0.0
2025-03-25 22:15:53,707 - INFO - Data shape for this participant: torch.Size([200, 5])
2025-03-25 22:20:58,464 - INFO - ================================================================================
2025-03-25 22:20:58,464 - INFO - EXPERIMENT CONFIG
2025-03-25 22:20:58,464 - INFO - ================================================================================
2025-03-25 22:20:58,464 - INFO - Number of actions: 2
2025-03-25 22:20:58,474 - INFO - Number of participants: 16
2025-03-25 22:20:58,475 - INFO - ================================================================================
2025-03-25 22:20:58,475 - INFO - PROCESSING PARTICIPANT DATA
2025-03-25 22:20:58,475 - INFO - ================================================================================
2025-03-25 22:20:58,681 - INFO - ================================================================================
2025-03-25 22:20:58,682 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-25 22:20:58,682 - INFO - ================================================================================
2025-03-25 22:20:58,682 - INFO - Creating dataset subset with 100 trials per participant
2025-03-25 22:20:58,682 - INFO - Subset with 100 trials per participant:
2025-03-25 22:20:58,682 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-25 22:20:58,683 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-25 22:20:58,683 - INFO - 
Training RNN...
2025-03-25 22:20:58,685 - INFO - RNN model trainable parameters: 518
2025-03-25 22:22:04,868 - INFO - Final training loss: 0.2812638
2025-03-25 22:22:04,870 - INFO - 
Fitting SINDy...
2025-03-25 22:22:36,291 - INFO - 
Evaluating SINDy models...
2025-03-25 22:22:36,291 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-25 22:22:36,291 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-25 22:22:36,292 - INFO - SINDy model parameters for participant 0: 7
2025-03-25 22:22:36,924 - INFO - Participant 0: Log-likelihood: -8.0864, Normalized LL: -0.0809, Raw BIC: 48.4090, Normalized BIC: 0.4841
2025-03-25 22:22:36,924 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-25 22:22:36,924 - INFO - SINDy model parameters for participant 1: 8
2025-03-25 22:22:37,554 - INFO - Participant 1: Log-likelihood: -65.9823, Normalized LL: -0.6598, Raw BIC: 168.8060, Normalized BIC: 1.6881
2025-03-25 22:22:37,555 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-25 22:22:37,555 - INFO - SINDy model parameters for participant 2: 5
2025-03-25 22:22:38,194 - INFO - Participant 2: Log-likelihood: -20.5633, Normalized LL: -0.2056, Raw BIC: 64.1525, Normalized BIC: 0.6415
2025-03-25 22:22:38,194 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-25 22:22:38,194 - INFO - SINDy model parameters for participant 3: 7
2025-03-25 22:22:38,799 - INFO - Participant 3: Log-likelihood: -53.3103, Normalized LL: -0.5331, Raw BIC: 138.8568, Normalized BIC: 1.3886
2025-03-25 22:22:38,799 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-25 22:22:38,799 - INFO - SINDy model parameters for participant 4: 8
2025-03-25 22:22:39,399 - INFO - Participant 4: Log-likelihood: -62.8748, Normalized LL: -0.6287, Raw BIC: 162.5909, Normalized BIC: 1.6259
2025-03-25 22:22:39,399 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-25 22:22:39,399 - INFO - SINDy model parameters for participant 5: 8
2025-03-25 22:22:40,029 - INFO - Participant 5: Log-likelihood: -0.9979, Normalized LL: -0.0100, Raw BIC: 38.8372, Normalized BIC: 0.3884
2025-03-25 22:22:40,029 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-25 22:22:40,029 - INFO - SINDy model parameters for participant 6: 9
2025-03-25 22:22:40,624 - INFO - Participant 6: Log-likelihood: -5.4172, Normalized LL: -0.0542, Raw BIC: 52.2809, Normalized BIC: 0.5228
2025-03-25 22:22:40,625 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-25 22:22:40,625 - INFO - SINDy model parameters for participant 7: 8
2025-03-25 22:22:41,225 - INFO - Participant 7: Log-likelihood: -67.9476, Normalized LL: -0.6795, Raw BIC: 172.7366, Normalized BIC: 1.7274
2025-03-25 22:22:41,225 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-25 22:22:41,225 - INFO - SINDy model parameters for participant 8: 8
2025-03-25 22:22:41,831 - INFO - Participant 8: Log-likelihood: -77.5281, Normalized LL: -0.7753, Raw BIC: 191.8976, Normalized BIC: 1.9190
2025-03-25 22:22:41,831 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-25 22:22:41,831 - INFO - SINDy model parameters for participant 9: 9
2025-03-25 22:22:42,431 - INFO - Participant 9: Log-likelihood: -19.7015, Normalized LL: -0.1970, Raw BIC: 80.8495, Normalized BIC: 0.8085
2025-03-25 22:22:42,432 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-25 22:22:42,432 - INFO - SINDy model parameters for participant 10: 5
2025-03-25 22:22:43,033 - INFO - Participant 10: Log-likelihood: -36.4505, Normalized LL: -0.3645, Raw BIC: 95.9269, Normalized BIC: 0.9593
2025-03-25 22:22:43,033 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-25 22:22:43,033 - INFO - SINDy model parameters for participant 11: 5
2025-03-25 22:22:43,657 - INFO - Participant 11: Log-likelihood: -1.6153, Normalized LL: -0.0162, Raw BIC: 26.2564, Normalized BIC: 0.2626
2025-03-25 22:22:43,657 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-25 22:22:43,657 - INFO - SINDy model parameters for participant 12: 7
2025-03-25 22:22:44,297 - INFO - Participant 12: Log-likelihood: -40.0855, Normalized LL: -0.4009, Raw BIC: 112.4072, Normalized BIC: 1.1241
2025-03-25 22:22:44,298 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-25 22:22:44,298 - INFO - SINDy model parameters for participant 13: 9
2025-03-25 22:22:44,934 - INFO - Participant 13: Log-likelihood: -25.4682, Normalized LL: -0.2547, Raw BIC: 92.3829, Normalized BIC: 0.9238
2025-03-25 22:22:44,935 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-25 22:22:44,935 - INFO - SINDy model parameters for participant 14: 7
2025-03-25 22:22:45,578 - INFO - Participant 14: Log-likelihood: -8.3106, Normalized LL: -0.0831, Raw BIC: 48.8574, Normalized BIC: 0.4886
2025-03-25 22:22:45,578 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-25 22:22:45,579 - INFO - SINDy model parameters for participant 15: 5
2025-03-25 22:22:46,217 - INFO - Participant 15: Log-likelihood: -38.0023, Normalized LL: -0.3800, Raw BIC: 99.0305, Normalized BIC: 0.9903
2025-03-25 22:22:46,217 - INFO - 
Average SINDy BIC for 100 trials per participant: 0.9964
2025-03-25 22:22:46,217 - INFO - 
Average Normalized Log Likelihood for 100 trials per participant: -0.3327
2025-03-25 22:22:46,217 - INFO - 
Identified SINDy equations:
2025-03-25 22:22:46,217 - INFO - Module: x_learning_rate_reward
2025-03-25 22:22:46,223 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,224 - INFO -   Participant 0 Coefficients: [ 0.71460854 -0.32169657  0.          0.          0.49954425  0.
  0.          0.          0.          0.        ]
2025-03-25 22:22:46,224 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,229 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,230 - INFO -   Participant 1 Coefficients: [0.70010372 0.16612015 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:22:46,230 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,236 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,236 - INFO -   Participant 2 Coefficients: [0.94969849 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:22:46,236 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,241 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,242 - INFO -   Participant 3 Coefficients: [0.92122713 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:22:46,242 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,247 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,247 - INFO -   Participant 4 Coefficients: [0.60088421 0.21788134 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:22:46,247 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,253 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,253 - INFO -   Participant 5 Coefficients: [ 0.7873398   0.13996642  0.3811984  -0.39553662  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:22:46,253 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,259 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,260 - INFO -   Participant 6 Coefficients: [ 0.74158463  0.17465939  0.35614799 -0.32727277  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:22:46,260 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,265 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,265 - INFO -   Participant 7 Coefficients: [0.87073528 0.0882058  0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:22:46,266 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,271 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,272 - INFO -   Participant 8 Coefficients: [ 0.93922539  0.          0.18218729 -0.08552152  0.          0.05029877
  0.          0.          0.          0.        ]
2025-03-25 22:22:46,272 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,277 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,277 - INFO -   Participant 9 Coefficients: [ 0.59441013  0.25053844  0.27268266 -0.56091321  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:22:46,278 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,283 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,284 - INFO -   Participant 10 Coefficients: [0.8577153 0.        0.        0.        0.        0.        0.
 0.        0.        0.       ]
2025-03-25 22:22:46,284 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,289 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,290 - INFO -   Participant 11 Coefficients: [0.86874168 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:22:46,290 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,295 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,296 - INFO -   Participant 12 Coefficients: [0.65943019 0.20091392 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:22:46,296 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,301 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,302 - INFO -   Participant 13 Coefficients: [ 0.9055137   0.         -0.09488702  0.09938658  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:22:46,302 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,307 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,308 - INFO -   Participant 14 Coefficients: [0.78027845 0.11244994 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:22:46,308 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,313 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,314 - INFO -   Participant 15 Coefficients: [0.91206453 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:22:46,314 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:22:46,314 - INFO - Module: x_value_reward_not_chosen
2025-03-25 22:22:46,318 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,318 - INFO -   Participant 0 Coefficients: [-0.91988745  0.80382936  0.          0.          0.          0.        ]
2025-03-25 22:22:46,319 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,323 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,323 - INFO -   Participant 1 Coefficients: [-0.21120965  0.74785074  0.          0.          0.          0.        ]
2025-03-25 22:22:46,323 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,328 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,328 - INFO -   Participant 2 Coefficients: [-0.79793271  0.80270553  0.          0.          0.          0.        ]
2025-03-25 22:22:46,328 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,332 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,333 - INFO -   Participant 3 Coefficients: [-0.25570047  0.79618623  0.          0.          0.          0.        ]
2025-03-25 22:22:46,333 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,337 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,337 - INFO -   Participant 4 Coefficients: [-0.16277382  0.74355515  0.          0.          0.          0.        ]
2025-03-25 22:22:46,337 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,342 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,342 - INFO -   Participant 5 Coefficients: [-0.43743969  0.80777641  0.          0.          0.          0.        ]
2025-03-25 22:22:46,342 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,346 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,347 - INFO -   Participant 6 Coefficients: [-0.31855172  0.7956514   0.          0.          0.          0.        ]
2025-03-25 22:22:46,347 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,351 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,351 - INFO -   Participant 7 Coefficients: [0.14921345 0.74286266 0.         0.         0.         0.        ]
2025-03-25 22:22:46,351 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,356 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,356 - INFO -   Participant 8 Coefficients: [-0.46779494  0.84356215  0.          0.          0.          0.        ]
2025-03-25 22:22:46,356 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,360 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,361 - INFO -   Participant 9 Coefficients: [-0.13341687  0.78597418  0.          0.          0.          0.        ]
2025-03-25 22:22:46,361 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,365 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,366 - INFO -   Participant 10 Coefficients: [-0.79926174  0.6998969   0.          0.          0.          0.        ]
2025-03-25 22:22:46,366 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,370 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,370 - INFO -   Participant 11 Coefficients: [-0.90189811  0.82523472  0.          0.          0.          0.        ]
2025-03-25 22:22:46,370 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,375 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,375 - INFO -   Participant 12 Coefficients: [-0.10634746  0.74672196  0.          0.          0.          0.        ]
2025-03-25 22:22:46,375 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,379 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,380 - INFO -   Participant 13 Coefficients: [-0.53553011  0.75436266  0.          0.          0.          0.        ]
2025-03-25 22:22:46,380 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,384 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,384 - INFO -   Participant 14 Coefficients: [-0.35481308  0.84040382  0.          0.          0.          0.        ]
2025-03-25 22:22:46,384 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,389 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,389 - INFO -   Participant 15 Coefficients: [-0.67582551  0.73407228  0.          0.          0.          0.        ]
2025-03-25 22:22:46,389 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:22:46,389 - INFO - Module: x_value_choice_chosen
2025-03-25 22:22:46,394 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,394 - INFO -   Participant 0 Coefficients: [0.63047844 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,394 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,399 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,399 - INFO -   Participant 1 Coefficients: [ 0.72665649  0.          0.         -0.23765991  0.          0.        ]
2025-03-25 22:22:46,399 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,404 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,404 - INFO -   Participant 2 Coefficients: [0.23813234 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,404 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,408 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,408 - INFO -   Participant 3 Coefficients: [0.32827367 0.21543411 0.         0.         0.         0.        ]
2025-03-25 22:22:46,409 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,413 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,413 - INFO -   Participant 4 Coefficients: [0.68105862 0.19566564 0.         0.         0.         0.        ]
2025-03-25 22:22:46,413 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,418 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,418 - INFO -   Participant 5 Coefficients: [0.87042253 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,418 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,423 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,423 - INFO -   Participant 6 Coefficients: [0.81432918 0.06614663 0.         0.         0.         0.        ]
2025-03-25 22:22:46,423 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,427 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,428 - INFO -   Participant 7 Coefficients: [0.31535749 0.2696587  0.         0.         0.         0.        ]
2025-03-25 22:22:46,428 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,432 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,432 - INFO -   Participant 8 Coefficients: [0.35415733 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,432 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,437 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,437 - INFO -   Participant 9 Coefficients: [0.84799487 0.05427357 0.         0.         0.         0.        ]
2025-03-25 22:22:46,437 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,441 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,442 - INFO -   Participant 10 Coefficients: [0.46551964 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,442 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,446 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,447 - INFO -   Participant 11 Coefficients: [0.30241391 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,447 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,451 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,451 - INFO -   Participant 12 Coefficients: [0.80349806 0.09017542 0.         0.         0.         0.        ]
2025-03-25 22:22:46,451 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,456 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,456 - INFO -   Participant 13 Coefficients: [0.66660054 0.17801794 0.         0.         0.         0.        ]
2025-03-25 22:22:46,456 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,460 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,461 - INFO -   Participant 14 Coefficients: [0.79591316 0.08547125 0.         0.         0.         0.        ]
2025-03-25 22:22:46,461 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,465 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,466 - INFO -   Participant 15 Coefficients: [0.53938329 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,466 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:22:46,466 - INFO - Module: x_value_choice_not_chosen
2025-03-25 22:22:46,470 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,470 - INFO -   Participant 0 Coefficients: [0.3040041 0.        0.        0.        0.        0.       ]
2025-03-25 22:22:46,470 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,475 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,475 - INFO -   Participant 1 Coefficients: [0.32299369 0.         0.         0.76841069 0.         0.        ]
2025-03-25 22:22:46,475 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,480 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,480 - INFO -   Participant 2 Coefficients: [0.77063662 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,481 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,485 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,485 - INFO -   Participant 3 Coefficients: [0.7089574  0.11652909 0.         0.         0.         0.        ]
2025-03-25 22:22:46,485 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,489 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,490 - INFO -   Participant 4 Coefficients: [0.15158211 0.11455554 0.         0.         0.         0.        ]
2025-03-25 22:22:46,490 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,494 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,494 - INFO -   Participant 5 Coefficients: [0.33943068 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,495 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,499 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,499 - INFO -   Participant 6 Coefficients: [0.17472118 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,499 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,504 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,504 - INFO -   Participant 7 Coefficients: [0.42129019 0.15021496 0.         0.         0.         0.        ]
2025-03-25 22:22:46,504 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,508 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,509 - INFO -   Participant 8 Coefficients: [0.70952731 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,509 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,513 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,514 - INFO -   Participant 9 Coefficients: [0.25889689 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,514 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,518 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,518 - INFO -   Participant 10 Coefficients: [0.28874207 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,518 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,523 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,523 - INFO -   Participant 11 Coefficients: [0.74807668 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,523 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,527 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,528 - INFO -   Participant 12 Coefficients: [0.15715275 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,528 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,532 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,532 - INFO -   Participant 13 Coefficients: [0.118052   0.09854378 0.         0.         0.         0.        ]
2025-03-25 22:22:46,532 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,537 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,537 - INFO -   Participant 14 Coefficients: [0.21463302 0.         0.         0.         0.         0.        ]
2025-03-25 22:22:46,537 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,542 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:22:46,542 - INFO -   Participant 15 Coefficients: [0.3354995 0.        0.        0.        0.        0.       ]
2025-03-25 22:22:46,542 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:22:46,542 - INFO - Visualizing for participant index 0, ID 0.0
2025-03-25 22:22:46,542 - INFO - Data shape for this participant: torch.Size([100, 5])
2025-03-25 22:39:12,096 - INFO - ================================================================================
2025-03-25 22:39:12,097 - INFO - EXPERIMENT CONFIG
2025-03-25 22:39:12,097 - INFO - ================================================================================
2025-03-25 22:39:12,097 - INFO - Number of actions: 2
2025-03-25 22:39:12,106 - INFO - Number of participants: 16
2025-03-25 22:39:12,106 - INFO - ================================================================================
2025-03-25 22:39:12,106 - INFO - PROCESSING PARTICIPANT DATA
2025-03-25 22:39:12,106 - INFO - ================================================================================
2025-03-25 22:39:12,311 - INFO - ================================================================================
2025-03-25 22:39:12,311 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-25 22:39:12,311 - INFO - ================================================================================
2025-03-25 22:39:12,311 - INFO - Creating dataset subset with 100 trials per participant
2025-03-25 22:39:12,312 - INFO - Subset with 100 trials per participant:
2025-03-25 22:39:12,312 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-25 22:39:12,312 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-25 22:39:12,312 - INFO - 
Training RNN...
2025-03-25 22:39:12,315 - INFO - RNN model trainable parameters: 518
2025-03-25 22:40:43,847 - INFO - Final training loss: 0.2627234
2025-03-25 22:40:43,849 - INFO - 
Fitting SINDy...
2025-03-25 22:48:43,978 - INFO - ================================================================================
2025-03-25 22:48:43,978 - INFO - EXPERIMENT CONFIG
2025-03-25 22:48:43,978 - INFO - ================================================================================
2025-03-25 22:48:43,978 - INFO - Number of actions: 2
2025-03-25 22:48:43,986 - INFO - Number of participants: 16
2025-03-25 22:48:43,986 - INFO - ================================================================================
2025-03-25 22:48:43,986 - INFO - PROCESSING PARTICIPANT DATA
2025-03-25 22:48:43,986 - INFO - ================================================================================
2025-03-25 22:48:44,083 - INFO - ================================================================================
2025-03-25 22:48:44,083 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-25 22:48:44,083 - INFO - ================================================================================
2025-03-25 22:48:44,083 - INFO - Creating dataset subset with 100 trials per participant
2025-03-25 22:48:44,084 - INFO - Subset with 100 trials per participant:
2025-03-25 22:48:44,084 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-25 22:48:44,084 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-25 22:48:44,084 - INFO - 
Training RNN...
2025-03-25 22:48:44,085 - INFO - RNN model trainable parameters: 518
2025-03-25 22:49:10,486 - INFO - ================================================================================
2025-03-25 22:49:10,487 - INFO - EXPERIMENT CONFIG
2025-03-25 22:49:10,487 - INFO - ================================================================================
2025-03-25 22:49:10,487 - INFO - Number of actions: 2
2025-03-25 22:49:10,494 - INFO - Number of participants: 16
2025-03-25 22:49:10,494 - INFO - ================================================================================
2025-03-25 22:49:10,494 - INFO - PROCESSING PARTICIPANT DATA
2025-03-25 22:49:10,494 - INFO - ================================================================================
2025-03-25 22:49:10,583 - INFO - ================================================================================
2025-03-25 22:49:10,583 - INFO - RUNNING PIPELINE FOR DIFFERENT TRIAL SUBSET SIZES
2025-03-25 22:49:10,583 - INFO - ================================================================================
2025-03-25 22:49:10,583 - INFO - Creating dataset subset with 100 trials per participant
2025-03-25 22:49:10,584 - INFO - Subset with 100 trials per participant:
2025-03-25 22:49:10,584 - INFO -   Dataset shape: torch.Size([16, 100, 5])
2025-03-25 22:49:10,584 - INFO - 
==== Running pipeline for dataset: 100 trials per participant ====
2025-03-25 22:49:10,584 - INFO - 
Training RNN...
2025-03-25 22:49:10,585 - INFO - RNN model trainable parameters: 518
2025-03-25 22:50:03,030 - INFO - Final training loss: 0.3213861
2025-03-25 22:50:03,030 - INFO - 
Fitting SINDy...
2025-03-25 22:50:20,630 - INFO - 
Evaluating SINDy models...
2025-03-25 22:50:20,631 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-25 22:50:20,631 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-25 22:50:20,631 - INFO - SINDy model parameters for participant 0: 6
2025-03-25 22:50:20,949 - INFO - Participant 0: Log-likelihood: -7.3357, Normalized LL: -0.0734, Raw BIC: 42.3023, Normalized BIC: 0.4230
2025-03-25 22:50:20,949 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-25 22:50:20,949 - INFO - SINDy model parameters for participant 1: 9
2025-03-25 22:50:21,245 - INFO - Participant 1: Log-likelihood: -66.1808, Normalized LL: -0.6618, Raw BIC: 173.8081, Normalized BIC: 1.7381
2025-03-25 22:50:21,245 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-25 22:50:21,245 - INFO - SINDy model parameters for participant 2: 7
2025-03-25 22:50:21,561 - INFO - Participant 2: Log-likelihood: -18.8710, Normalized LL: -0.1887, Raw BIC: 69.9782, Normalized BIC: 0.6998
2025-03-25 22:50:21,561 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-25 22:50:21,561 - INFO - SINDy model parameters for participant 3: 9
2025-03-25 22:50:21,877 - INFO - Participant 3: Log-likelihood: -55.9350, Normalized LL: -0.5593, Raw BIC: 153.3165, Normalized BIC: 1.5332
2025-03-25 22:50:21,877 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-25 22:50:21,877 - INFO - SINDy model parameters for participant 4: 8
2025-03-25 22:50:22,181 - INFO - Participant 4: Log-likelihood: -65.3981, Normalized LL: -0.6540, Raw BIC: 167.6376, Normalized BIC: 1.6764
2025-03-25 22:50:22,181 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-25 22:50:22,181 - INFO - SINDy model parameters for participant 5: 5
2025-03-25 22:50:22,488 - INFO - Participant 5: Log-likelihood: -52.9376, Normalized LL: -0.5294, Raw BIC: 128.9010, Normalized BIC: 1.2890
2025-03-25 22:50:22,488 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-25 22:50:22,488 - INFO - SINDy model parameters for participant 6: 7
2025-03-25 22:50:22,797 - INFO - Participant 6: Log-likelihood: -62.8847, Normalized LL: -0.6288, Raw BIC: 158.0055, Normalized BIC: 1.5801
2025-03-25 22:50:22,797 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-25 22:50:22,798 - INFO - SINDy model parameters for participant 7: 10
2025-03-25 22:50:23,101 - INFO - Participant 7: Log-likelihood: -68.5296, Normalized LL: -0.6853, Raw BIC: 183.1109, Normalized BIC: 1.8311
2025-03-25 22:50:23,101 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-25 22:50:23,102 - INFO - SINDy model parameters for participant 8: 11
2025-03-25 22:50:23,407 - INFO - Participant 8: Log-likelihood: -18.3989, Normalized LL: -0.1840, Raw BIC: 87.4547, Normalized BIC: 0.8745
2025-03-25 22:50:23,407 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-25 22:50:23,407 - INFO - SINDy model parameters for participant 9: 9
2025-03-25 22:50:23,713 - INFO - Participant 9: Log-likelihood: -60.5697, Normalized LL: -0.6057, Raw BIC: 162.5860, Normalized BIC: 1.6259
2025-03-25 22:50:23,713 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-25 22:50:23,713 - INFO - SINDy model parameters for participant 10: 9
2025-03-25 22:50:24,032 - INFO - Participant 10: Log-likelihood: -35.9738, Normalized LL: -0.3597, Raw BIC: 113.3942, Normalized BIC: 1.1339
2025-03-25 22:50:24,032 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-25 22:50:24,032 - INFO - SINDy model parameters for participant 11: 10
2025-03-25 22:50:24,351 - INFO - Participant 11: Log-likelihood: -11.3710, Normalized LL: -0.1137, Raw BIC: 68.7938, Normalized BIC: 0.6879
2025-03-25 22:50:24,351 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-25 22:50:24,351 - INFO - SINDy model parameters for participant 12: 8
2025-03-25 22:50:24,673 - INFO - Participant 12: Log-likelihood: -59.7655, Normalized LL: -0.5977, Raw BIC: 156.3723, Normalized BIC: 1.5637
2025-03-25 22:50:24,673 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-25 22:50:24,673 - INFO - SINDy model parameters for participant 13: 9
2025-03-25 22:50:24,995 - INFO - Participant 13: Log-likelihood: -23.8042, Normalized LL: -0.2380, Raw BIC: 89.0549, Normalized BIC: 0.8905
2025-03-25 22:50:24,995 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-25 22:50:24,995 - INFO - SINDy model parameters for participant 14: 8
2025-03-25 22:50:25,311 - INFO - Participant 14: Log-likelihood: -99.9252, Normalized LL: -0.9993, Raw BIC: 236.6917, Normalized BIC: 2.3669
2025-03-25 22:50:25,312 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-25 22:50:25,312 - INFO - SINDy model parameters for participant 15: 10
2025-03-25 22:50:25,634 - INFO - Participant 15: Log-likelihood: -38.1259, Normalized LL: -0.3813, Raw BIC: 122.3035, Normalized BIC: 1.2230
2025-03-25 22:50:25,634 - INFO - 
Average SINDy BIC for 100 trials per participant: 1.3211
2025-03-25 22:50:25,634 - INFO - 
Average Normalized Log Likelihood for 100 trials per participant: -0.4663
2025-03-25 22:50:25,634 - INFO - 
Identified SINDy equations:
2025-03-25 22:50:25,634 - INFO - Module: x_learning_rate_reward
2025-03-25 22:50:25,637 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,637 - INFO -   Participant 0 Coefficients: [0.8908475 0.        0.        0.        0.        0.        0.
 0.        0.        0.       ]
2025-03-25 22:50:25,637 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,638 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,638 - INFO -   Participant 1 Coefficients: [ 0.70596073  0.17383737  0.15690534 -0.1890006   0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:50:25,638 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,640 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,640 - INFO -   Participant 2 Coefficients: [0.9241522 0.        0.        0.        0.        0.        0.
 0.        0.        0.       ]
2025-03-25 22:50:25,640 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,642 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,642 - INFO -   Participant 3 Coefficients: [ 0.90938651  0.         -0.192197    0.20342447  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:50:25,642 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,644 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,644 - INFO -   Participant 4 Coefficients: [0.37051095 0.31437644 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:50:25,644 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,646 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,646 - INFO -   Participant 5 Coefficients: [0.46420629 0.27500293 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:50:25,647 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,648 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,648 - INFO -   Participant 6 Coefficients: [0.43446385 0.29914602 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:50:25,648 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,650 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,650 - INFO -   Participant 7 Coefficients: [ 0.70026964  0.18014425  0.12364419 -0.15404464  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:50:25,650 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,652 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,652 - INFO -   Participant 8 Coefficients: [ 0.87170177  0.          0.21820346 -0.23357671  0.07452298  0.
  0.          0.          0.          0.        ]
2025-03-25 22:50:25,652 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,654 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,654 - INFO -   Participant 9 Coefficients: [ 0.58064933  0.2352849   0.11208909 -0.16798279  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:50:25,654 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,656 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,656 - INFO -   Participant 10 Coefficients: [ 0.6261514   0.215566    0.13193468 -0.17333802  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:50:25,656 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,658 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,658 - INFO -   Participant 11 Coefficients: [ 0.76196769  0.14612575  0.23765666 -0.27058336  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:50:25,658 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,659 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,660 - INFO -   Participant 12 Coefficients: [0.34410983 0.28922439 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:50:25,660 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,661 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,662 - INFO -   Participant 13 Coefficients: [ 0.71161789  0.17229411  0.18477188 -0.22064009  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:50:25,662 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,664 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,664 - INFO -   Participant 14 Coefficients: [ 0.48186535  0.2395065   0.06707171 -0.12236148  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:50:25,664 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,665 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,666 - INFO -   Participant 15 Coefficients: [ 0.67403053  0.19472962  0.13711978 -0.17227589  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:50:25,666 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:50:25,666 - INFO - Module: x_value_reward_not_chosen
2025-03-25 22:50:25,667 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,667 - INFO -   Participant 0 Coefficients: [-1.36561252  0.6190947   0.          0.          0.          0.        ]
2025-03-25 22:50:25,667 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,668 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,669 - INFO -   Participant 1 Coefficients: [-0.25098848  0.5636936   0.          0.          0.          0.        ]
2025-03-25 22:50:25,669 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,670 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,670 - INFO -   Participant 2 Coefficients: [-1.21323004  0.55315493  0.          0.          0.          0.        ]
2025-03-25 22:50:25,670 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,672 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,672 - INFO -   Participant 3 Coefficients: [-0.65055584  0.50931112  0.          0.          0.          0.        ]
2025-03-25 22:50:25,672 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,673 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,673 - INFO -   Participant 4 Coefficients: [0.82120939 0.50894017 0.         0.         0.         0.        ]
2025-03-25 22:50:25,673 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,675 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,675 - INFO -   Participant 5 Coefficients: [0.35325625 0.61747098 0.         0.         0.         0.        ]
2025-03-25 22:50:25,675 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,676 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,676 - INFO -   Participant 6 Coefficients: [0.51681003 0.57259544 0.         0.         0.         0.        ]
2025-03-25 22:50:25,677 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,678 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,678 - INFO -   Participant 7 Coefficients: [0.0519819  0.62988812 0.         0.         0.         0.        ]
2025-03-25 22:50:25,678 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,680 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,680 - INFO -   Participant 8 Coefficients: [-0.97724033  0.514403    0.          0.          0.          0.        ]
2025-03-25 22:50:25,680 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,681 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,681 - INFO -   Participant 9 Coefficients: [0.60571672 0.5311831  0.         0.         0.         0.        ]
2025-03-25 22:50:25,681 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,683 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,683 - INFO -   Participant 10 Coefficients: [0.10892178 0.55616478 0.         0.         0.         0.        ]
2025-03-25 22:50:25,683 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,684 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,685 - INFO -   Participant 11 Coefficients: [-0.63311994  0.59184732  0.          0.          0.          0.        ]
2025-03-25 22:50:25,685 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,686 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,686 - INFO -   Participant 12 Coefficients: [0.46987038 0.57086567 0.         0.         0.         0.        ]
2025-03-25 22:50:25,686 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,688 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,688 - INFO -   Participant 13 Coefficients: [-0.36406157  0.58007757  0.          0.          0.          0.        ]
2025-03-25 22:50:25,688 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,689 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,689 - INFO -   Participant 14 Coefficients: [0.91681717 0.58190438 0.         0.         0.         0.        ]
2025-03-25 22:50:25,689 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,691 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,691 - INFO -   Participant 15 Coefficients: [0.12728912 0.58974981 0.         0.         0.         0.        ]
2025-03-25 22:50:25,691 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:50:25,691 - INFO - Module: x_value_choice_chosen
2025-03-25 22:50:25,692 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,692 - INFO -   Participant 0 Coefficients: [0.91897017 0.         0.         0.         0.         0.        ]
2025-03-25 22:50:25,692 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,694 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,694 - INFO -   Participant 1 Coefficients: [0.90759892 0.         0.         0.         0.         0.        ]
2025-03-25 22:50:25,694 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,695 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,695 - INFO -   Participant 2 Coefficients: [0.37550149 0.31177266 0.         0.         0.         0.        ]
2025-03-25 22:50:25,695 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,697 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,697 - INFO -   Participant 3 Coefficients: [0.40297352 0.43703673 0.         0.         0.         0.        ]
2025-03-25 22:50:25,697 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,698 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,698 - INFO -   Participant 4 Coefficients: [0.47793263 0.36169839 0.         0.         0.         0.        ]
2025-03-25 22:50:25,698 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,700 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,700 - INFO -   Participant 5 Coefficients: [0.93838856 0.         0.         0.         0.         0.        ]
2025-03-25 22:50:25,700 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,701 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,701 - INFO -   Participant 6 Coefficients: [0.85658336 0.10837346 0.         0.         0.         0.        ]
2025-03-25 22:50:25,701 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,703 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,703 - INFO -   Participant 7 Coefficients: [0.22691667 0.23273214 0.         0.         0.         0.        ]
2025-03-25 22:50:25,703 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,704 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,704 - INFO -   Participant 8 Coefficients: [0.24685196 0.08882842 0.         0.18862192 0.         0.        ]
2025-03-25 22:50:25,704 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,706 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,706 - INFO -   Participant 9 Coefficients: [0.87119058 0.09625238 0.         0.         0.         0.        ]
2025-03-25 22:50:25,706 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,707 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,707 - INFO -   Participant 10 Coefficients: [0.82102659 0.13356215 0.         0.         0.         0.        ]
2025-03-25 22:50:25,707 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,709 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,709 - INFO -   Participant 11 Coefficients: [0.40517085 0.44646478 0.         0.         0.         0.        ]
2025-03-25 22:50:25,709 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,710 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,710 - INFO -   Participant 12 Coefficients: [0.70652753 0.21487931 0.         0.         0.         0.        ]
2025-03-25 22:50:25,710 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,712 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,712 - INFO -   Participant 13 Coefficients: [0.8117117  0.14109418 0.         0.         0.         0.        ]
2025-03-25 22:50:25,712 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,713 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,713 - INFO -   Participant 14 Coefficients: [0.86162947 0.10345278 0.         0.         0.         0.        ]
2025-03-25 22:50:25,713 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,715 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,715 - INFO -   Participant 15 Coefficients: [0.73095076 0.20271541 0.         0.         0.         0.        ]
2025-03-25 22:50:25,715 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:50:25,715 - INFO - Module: x_value_choice_not_chosen
2025-03-25 22:50:25,716 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,716 - INFO -   Participant 0 Coefficients: [0.59846547 0.15139524 0.         0.         0.         0.        ]
2025-03-25 22:50:25,716 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,718 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,718 - INFO -   Participant 1 Coefficients: [0.38237583 0.25113642 0.         0.         0.         0.        ]
2025-03-25 22:50:25,718 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,719 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,719 - INFO -   Participant 2 Coefficients: [0.65390266 0.13548422 0.         0.         0.         0.        ]
2025-03-25 22:50:25,719 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,721 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,721 - INFO -   Participant 3 Coefficients: [0.51430712 0.28181483 0.         0.         0.         0.        ]
2025-03-25 22:50:25,721 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,722 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,722 - INFO -   Participant 4 Coefficients: [0.12690639 0.1634742  0.         0.         0.         0.        ]
2025-03-25 22:50:25,722 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,724 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,724 - INFO -   Participant 5 Coefficients: [0. 0. 0. 0. 0. 0.]
2025-03-25 22:50:25,724 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,725 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,725 - INFO -   Participant 6 Coefficients: [0.05346142 0.         0.         0.         0.         0.        ]
2025-03-25 22:50:25,725 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,727 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,727 - INFO -   Participant 7 Coefficients: [0.33523094 0.17200469 0.         0.         0.         0.        ]
2025-03-25 22:50:25,727 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,728 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,728 - INFO -   Participant 8 Coefficients: [0.83257447 0.08014428 0.         0.         0.         0.        ]
2025-03-25 22:50:25,728 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,730 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,730 - INFO -   Participant 9 Coefficients: [0.09888849 0.         0.         0.         0.         0.        ]
2025-03-25 22:50:25,730 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,731 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,731 - INFO -   Participant 10 Coefficients: [0.0842589 0.        0.        0.        0.        0.       ]
2025-03-25 22:50:25,732 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,733 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,733 - INFO -   Participant 11 Coefficients: [0.50543429 0.30986179 0.         0.         0.         0.        ]
2025-03-25 22:50:25,733 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,734 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,734 - INFO -   Participant 12 Coefficients: [0.08487747 0.12505387 0.         0.         0.         0.        ]
2025-03-25 22:50:25,735 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,736 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,736 - INFO -   Participant 13 Coefficients: [0.11658854 0.         0.         0.         0.         0.        ]
2025-03-25 22:50:25,736 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,737 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,737 - INFO -   Participant 14 Coefficients: [0. 0. 0. 0. 0. 0.]
2025-03-25 22:50:25,737 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,739 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:50:25,739 - INFO -   Participant 15 Coefficients: [0.07665246 0.11987136 0.         0.         0.         0.        ]
2025-03-25 22:50:25,739 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:50:25,739 - INFO - Visualizing for participant index 0, ID 0.0
2025-03-25 22:50:25,739 - INFO - Data shape for this participant: torch.Size([100, 5])
2025-03-25 22:50:27,175 - INFO - Creating dataset subset with 200 trials per participant
2025-03-25 22:50:27,176 - INFO - Subset with 200 trials per participant:
2025-03-25 22:50:27,176 - INFO -   Dataset shape: torch.Size([16, 200, 5])
2025-03-25 22:50:27,176 - INFO - 
==== Running pipeline for dataset: 200 trials per participant ====
2025-03-25 22:50:27,176 - INFO - 
Training RNN...
2025-03-25 22:50:27,177 - INFO - RNN model trainable parameters: 518
2025-03-25 22:52:15,717 - INFO - Final training loss: 0.2694993
2025-03-25 22:52:15,718 - INFO - 
Fitting SINDy...
2025-03-25 22:52:34,161 - INFO - 
Evaluating SINDy models...
2025-03-25 22:52:34,161 - INFO - SINDy models are available for participants: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}
2025-03-25 22:52:34,162 - INFO - Evaluating participant 0 using its own SINDy model...
2025-03-25 22:52:34,162 - INFO - SINDy model parameters for participant 0: 7
2025-03-25 22:52:34,824 - INFO - Participant 0: Log-likelihood: -29.8720, Normalized LL: -0.1494, Raw BIC: 96.8323, Normalized BIC: 0.4842
2025-03-25 22:52:34,824 - INFO - Evaluating participant 1 using its own SINDy model...
2025-03-25 22:52:34,825 - INFO - SINDy model parameters for participant 1: 8
2025-03-25 22:52:35,456 - INFO - Participant 1: Log-likelihood: -121.8884, Normalized LL: -0.6094, Raw BIC: 286.1634, Normalized BIC: 1.4308
2025-03-25 22:52:35,456 - INFO - Evaluating participant 2 using its own SINDy model...
2025-03-25 22:52:35,457 - INFO - SINDy model parameters for participant 2: 8
2025-03-25 22:52:36,122 - INFO - Participant 2: Log-likelihood: -36.3759, Normalized LL: -0.1819, Raw BIC: 115.1384, Normalized BIC: 0.5757
2025-03-25 22:52:36,122 - INFO - Evaluating participant 3 using its own SINDy model...
2025-03-25 22:52:36,123 - INFO - SINDy model parameters for participant 3: 12
2025-03-25 22:52:36,793 - INFO - Participant 3: Log-likelihood: -142.9295, Normalized LL: -0.7146, Raw BIC: 349.4389, Normalized BIC: 1.7472
2025-03-25 22:52:36,793 - INFO - Evaluating participant 4 using its own SINDy model...
2025-03-25 22:52:36,793 - INFO - SINDy model parameters for participant 4: 10
2025-03-25 22:52:37,462 - INFO - Participant 4: Log-likelihood: -720.1199, Normalized LL: -3.6006, Raw BIC: 1493.2230, Normalized BIC: 7.4661
2025-03-25 22:52:37,462 - INFO - Evaluating participant 5 using its own SINDy model...
2025-03-25 22:52:37,462 - INFO - SINDy model parameters for participant 5: 9
2025-03-25 22:52:38,128 - INFO - Participant 5: Log-likelihood: -175.8650, Normalized LL: -0.8793, Raw BIC: 399.4149, Normalized BIC: 1.9971
2025-03-25 22:52:38,128 - INFO - Evaluating participant 6 using its own SINDy model...
2025-03-25 22:52:38,128 - INFO - SINDy model parameters for participant 6: 6
2025-03-25 22:52:38,794 - INFO - Participant 6: Log-likelihood: -57.3560, Normalized LL: -0.2868, Raw BIC: 146.5019, Normalized BIC: 0.7325
2025-03-25 22:52:38,794 - INFO - Evaluating participant 7 using its own SINDy model...
2025-03-25 22:52:38,794 - INFO - SINDy model parameters for participant 7: 9
2025-03-25 22:52:39,454 - INFO - Participant 7: Log-likelihood: -174.7192, Normalized LL: -0.8736, Raw BIC: 397.1234, Normalized BIC: 1.9856
2025-03-25 22:52:39,454 - INFO - Evaluating participant 8 using its own SINDy model...
2025-03-25 22:52:39,455 - INFO - SINDy model parameters for participant 8: 14
2025-03-25 22:52:40,117 - INFO - Participant 8: Log-likelihood: -911.0288, Normalized LL: -4.5551, Raw BIC: 1896.2340, Normalized BIC: 9.4812
2025-03-25 22:52:40,117 - INFO - Evaluating participant 9 using its own SINDy model...
2025-03-25 22:52:40,117 - INFO - SINDy model parameters for participant 9: 8
2025-03-25 22:52:40,792 - INFO - Participant 9: Log-likelihood: -27.1413, Normalized LL: -0.1357, Raw BIC: 96.6691, Normalized BIC: 0.4833
2025-03-25 22:52:40,792 - INFO - Evaluating participant 10 using its own SINDy model...
2025-03-25 22:52:40,792 - INFO - SINDy model parameters for participant 10: 13
2025-03-25 22:52:41,468 - INFO - Participant 10: Log-likelihood: -855.3351, Normalized LL: -4.2767, Raw BIC: 1779.5484, Normalized BIC: 8.8977
2025-03-25 22:52:41,468 - INFO - Evaluating participant 11 using its own SINDy model...
2025-03-25 22:52:41,469 - INFO - SINDy model parameters for participant 11: 7
2025-03-25 22:52:42,143 - INFO - Participant 11: Log-likelihood: -16.5319, Normalized LL: -0.0827, Raw BIC: 70.1519, Normalized BIC: 0.3508
2025-03-25 22:52:42,143 - INFO - Evaluating participant 12 using its own SINDy model...
2025-03-25 22:52:42,143 - INFO - SINDy model parameters for participant 12: 8
2025-03-25 22:52:42,799 - INFO - Participant 12: Log-likelihood: -112.2072, Normalized LL: -0.5610, Raw BIC: 266.8008, Normalized BIC: 1.3340
2025-03-25 22:52:42,799 - INFO - Evaluating participant 13 using its own SINDy model...
2025-03-25 22:52:42,799 - INFO - SINDy model parameters for participant 13: 10
2025-03-25 22:52:43,450 - INFO - Participant 13: Log-likelihood: -67.4524, Normalized LL: -0.3373, Raw BIC: 187.8879, Normalized BIC: 0.9394
2025-03-25 22:52:43,451 - INFO - Evaluating participant 14 using its own SINDy model...
2025-03-25 22:52:43,451 - INFO - SINDy model parameters for participant 14: 10
2025-03-25 22:52:44,106 - INFO - Participant 14: Log-likelihood: -79.2173, Normalized LL: -0.3961, Raw BIC: 211.4177, Normalized BIC: 1.0571
2025-03-25 22:52:44,106 - INFO - Evaluating participant 15 using its own SINDy model...
2025-03-25 22:52:44,107 - INFO - SINDy model parameters for participant 15: 9
2025-03-25 22:52:44,769 - INFO - Participant 15: Log-likelihood: -88.8208, Normalized LL: -0.4441, Raw BIC: 225.3265, Normalized BIC: 1.1266
2025-03-25 22:52:44,769 - INFO - 
Average SINDy BIC for 200 trials per participant: 2.5056
2025-03-25 22:52:44,769 - INFO - 
Average Normalized Log Likelihood for 200 trials per participant: -1.1303
2025-03-25 22:52:44,769 - INFO - 
Identified SINDy equations:
2025-03-25 22:52:44,769 - INFO - Module: x_learning_rate_reward
2025-03-25 22:52:44,771 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,771 - INFO -   Participant 0 Coefficients: [0.90906101 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:52:44,771 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,773 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,773 - INFO -   Participant 1 Coefficients: [0.83802939 0.09019055 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:52:44,773 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,775 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,775 - INFO -   Participant 2 Coefficients: [0.88706442 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:52:44,775 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,776 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,777 - INFO -   Participant 3 Coefficients: [ 0.79405568  0.12150001  0.77972239 -0.38169659  0.          0.
  0.          0.         -1.1777349   0.75671682]
2025-03-25 22:52:44,777 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,779 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,779 - INFO -   Participant 4 Coefficients: [ 8.93567088e-01  0.00000000e+00  1.23668577e+12  5.76721191e-01
  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.23668577e+12
  1.00223999e+01 -5.41943359e+00]
2025-03-25 22:52:44,779 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,781 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,781 - INFO -   Participant 5 Coefficients: [ 0.75472963  0.16308937  0.12596674 -0.15904417  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:52:44,781 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,783 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,783 - INFO -   Participant 6 Coefficients: [0.77503528 0.11074826 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:52:44,783 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,785 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,785 - INFO -   Participant 7 Coefficients: [ 0.72894245  0.14821194  0.17213818 -0.20951268  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:52:44,785 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,787 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,787 - INFO -   Participant 8 Coefficients: [ 7.31172353e-01  1.91460858e-01  2.53999026e+11 -2.42843863e-01
  0.00000000e+00  4.53495362e-01 -4.51115308e-01 -2.53999026e+11
 -6.42701126e+00  3.58822162e+00]
2025-03-25 22:52:44,787 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,789 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,789 - INFO -   Participant 9 Coefficients: [0.88177795 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:52:44,789 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,791 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,791 - INFO -   Participant 10 Coefficients: [  0.78846685   0.14645469   4.12617912   0.           0.
   1.34403551  -1.34521359   4.12617912 -18.21843711   9.94274997]
2025-03-25 22:52:44,791 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,793 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,793 - INFO -   Participant 11 Coefficients: [0.85197606 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:52:44,793 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,795 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,795 - INFO -   Participant 12 Coefficients: [0.82777347 0.10766216 0.         0.         0.         0.
 0.         0.         0.         0.        ]
2025-03-25 22:52:44,795 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,797 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,797 - INFO -   Participant 13 Coefficients: [ 0.72253887  0.16060085  0.14629307 -0.18189036  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:52:44,797 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,799 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,799 - INFO -   Participant 14 Coefficients: [ 0.58576821  0.22530899  0.11245643 -0.17040122  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:52:44,799 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,801 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_learning_rate_reward', 'c_reward', 'c_value_reward'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,801 - INFO -   Participant 15 Coefficients: [ 0.75412826  0.14803638  0.12488623 -0.15281975  0.          0.
  0.          0.          0.          0.        ]
2025-03-25 22:52:44,801 - INFO -   Feature names: ['x_learning_rate_reward', 'c_reward', 'c_value_reward']
2025-03-25 22:52:44,801 - INFO - Module: x_value_reward_not_chosen
2025-03-25 22:52:44,803 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,803 - INFO -   Participant 0 Coefficients: [-1.00805815  0.29219845  0.          0.          0.          0.        ]
2025-03-25 22:52:44,803 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,804 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,804 - INFO -   Participant 1 Coefficients: [0.24190424 0.15248851 0.         0.         0.         0.        ]
2025-03-25 22:52:44,804 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,806 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,806 - INFO -   Participant 2 Coefficients: [-1.43743705  0.19130899  0.          0.12585258  0.          0.        ]
2025-03-25 22:52:44,806 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,808 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,808 - INFO -   Participant 3 Coefficients: [-0.19773374 -0.05017634  0.          0.          0.          0.        ]
2025-03-25 22:52:44,808 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,810 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,810 - INFO -   Participant 4 Coefficients: [0. 0. 0. 0. 0. 0.]
2025-03-25 22:52:44,810 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,812 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,812 - INFO -   Participant 5 Coefficients: [1.16462953 0.26679723 0.         0.         0.         0.        ]
2025-03-25 22:52:44,812 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,813 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,814 - INFO -   Participant 6 Coefficients: [0.         0.08585482 0.         0.         0.         0.        ]
2025-03-25 22:52:44,814 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,815 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,816 - INFO -   Participant 7 Coefficients: [-0.27693081  0.          0.          0.          0.          0.        ]
2025-03-25 22:52:44,816 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,819 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,819 - INFO -   Participant 8 Coefficients: [-1.00310209  0.          0.          0.          0.          0.        ]
2025-03-25 22:52:44,819 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,821 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,821 - INFO -   Participant 9 Coefficients: [-1.59470835  0.2657236   0.          0.13564776  0.          0.        ]
2025-03-25 22:52:44,821 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,822 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,823 - INFO -   Participant 10 Coefficients: [-0.64153765  0.          0.          0.          0.          0.        ]
2025-03-25 22:52:44,823 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,824 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,824 - INFO -   Participant 11 Coefficients: [-1.47709054  0.1954923   0.          0.          0.          0.        ]
2025-03-25 22:52:44,824 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,826 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,826 - INFO -   Participant 12 Coefficients: [0.66597466 0.13678661 0.         0.         0.         0.        ]
2025-03-25 22:52:44,826 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,827 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,827 - INFO -   Participant 13 Coefficients: [0.21342618 0.05369071 0.         0.         0.         0.        ]
2025-03-25 22:52:44,827 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,829 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,829 - INFO -   Participant 14 Coefficients: [0.57082183 0.19477482 0.         0.         0.         0.        ]
2025-03-25 22:52:44,829 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,830 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_reward_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,830 - INFO -   Participant 15 Coefficients: [0.52461934 0.         0.         0.         0.         0.        ]
2025-03-25 22:52:44,831 - INFO -   Feature names: ['x_value_reward_not_chosen', 'dummy']
2025-03-25 22:52:44,831 - INFO - Module: x_value_choice_chosen
2025-03-25 22:52:44,832 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,832 - INFO -   Participant 0 Coefficients: [0.71086174 0.11966427 0.         0.         0.         0.        ]
2025-03-25 22:52:44,832 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,834 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,834 - INFO -   Participant 1 Coefficients: [0.72616416 0.15477047 0.         0.         0.         0.        ]
2025-03-25 22:52:44,834 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,835 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,835 - INFO -   Participant 2 Coefficients: [0.60384814 0.20550705 0.         0.         0.         0.        ]
2025-03-25 22:52:44,835 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,837 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,837 - INFO -   Participant 3 Coefficients: [0.72071363 0.14333415 0.         0.         0.         0.        ]
2025-03-25 22:52:44,837 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,839 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,839 - INFO -   Participant 4 Coefficients: [0.63603652 0.19733965 0.         0.         0.         0.        ]
2025-03-25 22:52:44,839 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,840 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,840 - INFO -   Participant 5 Coefficients: [0.87278095 0.07652974 0.         0.         0.         0.        ]
2025-03-25 22:52:44,840 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,842 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,842 - INFO -   Participant 6 Coefficients: [0.86559047 0.08087747 0.         0.         0.         0.        ]
2025-03-25 22:52:44,842 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,843 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,844 - INFO -   Participant 7 Coefficients: [0.63768136 0.19499558 0.         0.         0.         0.        ]
2025-03-25 22:52:44,844 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,845 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,845 - INFO -   Participant 8 Coefficients: [0.47858477 0.18377528 0.         0.         0.         0.        ]
2025-03-25 22:52:44,845 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,847 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,847 - INFO -   Participant 9 Coefficients: [0.7544162  0.14179935 0.         0.         0.         0.        ]
2025-03-25 22:52:44,847 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,848 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,848 - INFO -   Participant 10 Coefficients: [0.72642129 0.15306582 0.         0.         0.         0.        ]
2025-03-25 22:52:44,848 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,850 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,850 - INFO -   Participant 11 Coefficients: [0.66419366 0.13318801 0.         0.         0.         0.        ]
2025-03-25 22:52:44,850 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,851 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,852 - INFO -   Participant 12 Coefficients: [0.80057647 0.11873053 0.         0.         0.         0.        ]
2025-03-25 22:52:44,852 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,853 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,853 - INFO -   Participant 13 Coefficients: [0.83459444 0.09936619 0.         0.         0.         0.        ]
2025-03-25 22:52:44,853 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,855 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,855 - INFO -   Participant 14 Coefficients: [0.84140392 0.09545884 0.         0.         0.         0.        ]
2025-03-25 22:52:44,855 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,856 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,856 - INFO -   Participant 15 Coefficients: [0.79287962 0.12373092 0.         0.         0.         0.        ]
2025-03-25 22:52:44,856 - INFO -   Feature names: ['x_value_choice_chosen', 'dummy']
2025-03-25 22:52:44,856 - INFO - Module: x_value_choice_not_chosen
2025-03-25 22:52:44,858 - INFO -   Participant 0 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,858 - INFO -   Participant 0 Coefficients: [0.56007676 0.15267498 0.         0.         0.         0.        ]
2025-03-25 22:52:44,858 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,859 - INFO -   Participant 1 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,860 - INFO -   Participant 1 Coefficients: [0.21174896 0.19717205 0.         0.         0.         0.        ]
2025-03-25 22:52:44,860 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,861 - INFO -   Participant 2 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,861 - INFO -   Participant 2 Coefficients: [0.256373   0.20927494 0.         0.         0.         0.        ]
2025-03-25 22:52:44,861 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,863 - INFO -   Participant 3 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,863 - INFO -   Participant 3 Coefficients: [0.30390785 0.22044462 0.         0.         0.         0.        ]
2025-03-25 22:52:44,863 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,864 - INFO -   Participant 4 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,864 - INFO -   Participant 4 Coefficients: [0.16224516 0.16925312 0.         0.         0.         0.        ]
2025-03-25 22:52:44,864 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,866 - INFO -   Participant 5 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,866 - INFO -   Participant 5 Coefficients: [0.13056579 0.         0.         0.         0.         0.        ]
2025-03-25 22:52:44,866 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,867 - INFO -   Participant 6 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,867 - INFO -   Participant 6 Coefficients: [0.13567713 0.         0.         0.         0.         0.        ]
2025-03-25 22:52:44,867 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,869 - INFO -   Participant 7 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,869 - INFO -   Participant 7 Coefficients: [0.20288398 0.190845   0.         0.         0.         0.        ]
2025-03-25 22:52:44,869 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,870 - INFO -   Participant 8 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,871 - INFO -   Participant 8 Coefficients: [0.58460028 0.15282684 0.         0.         0.         0.        ]
2025-03-25 22:52:44,871 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,872 - INFO -   Participant 9 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,872 - INFO -   Participant 9 Coefficients: [0.17152968 0.17787589 0.         0.         0.         0.        ]
2025-03-25 22:52:44,872 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,874 - INFO -   Participant 10 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,874 - INFO -   Participant 10 Coefficients: [0.25137922 0.209999   0.         0.         0.         0.        ]
2025-03-25 22:52:44,874 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,875 - INFO -   Participant 11 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,876 - INFO -   Participant 11 Coefficients: [0.46438153 0.16287677 0.         0.         0.         0.        ]
2025-03-25 22:52:44,876 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,877 - INFO -   Participant 12 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,877 - INFO -   Participant 12 Coefficients: [0.10711621 0.13461164 0.         0.         0.         0.        ]
2025-03-25 22:52:44,877 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,879 - INFO -   Participant 13 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,879 - INFO -   Participant 13 Coefficients: [0.08980679 0.11975565 0.         0.         0.         0.        ]
2025-03-25 22:52:44,879 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,880 - INFO -   Participant 14 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,881 - INFO -   Participant 14 Coefficients: [0.08271824 0.1129837  0.         0.         0.         0.        ]
2025-03-25 22:52:44,881 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,882 - INFO -   Participant 15 Equation: SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,
      feature_library=PolynomialLibrary(),
      feature_names=['x_value_choice_not_chosen', 'dummy'],
      optimizer=SR3(nu=1, threshold=0.05, thresholder='weighted_l1',
                    thresholds=array([[0.  , 0.05, 0.05, 0.1 , 0.1 , 0.1 ]]),
                    verbose=True))
2025-03-25 22:52:44,882 - INFO -   Participant 15 Coefficients: [0.09024621 0.11904152 0.         0.         0.         0.        ]
2025-03-25 22:52:44,882 - INFO -   Feature names: ['x_value_choice_not_chosen', 'dummy']
2025-03-25 22:52:44,883 - INFO - Visualizing for participant index 0, ID 0.0
2025-03-25 22:52:44,883 - INFO - Data shape for this participant: torch.Size([200, 5])
2025-03-25 23:05:50,535 - INFO - ================================================================================
2025-03-25 23:05:50,535 - INFO - EXPERIMENT CONFIG
2025-03-25 23:05:50,536 - INFO - ================================================================================
2025-03-25 23:07:06,725 - INFO - ================================================================================
2025-03-25 23:07:06,725 - INFO - EXPERIMENT CONFIG
2025-03-25 23:07:08,543 - INFO - ================================================================================
2025-03-25 23:07:19,829 - INFO - Found 48 data files: ['data_32p_7.csv', 'data_32p_4.csv', 'data_64p_5.csv', 'data_16p_6.csv', 'data_32p_1.csv', 'data_16p_1.csv', 'data_256p_7.csv', 'data_512p_6.csv', 'data_32p_5.csv', 'data_512p_5.csv', 'data_128p_4.csv', 'data_128p_6.csv', 'data_64p_4.csv', 'data_256p_2.csv', 'data_512p_1.csv', 'data_512p_3.csv', 'data_512p_2.csv', 'data_64p_1.csv', 'data_256p_3.csv', 'data_16p_7.csv', 'data_32p_2.csv', 'data_16p_2.csv', 'data_256p_0.csv', 'data_256p_1.csv', 'data_16p_3.csv', 'data_32p_6.csv', 'data_32p_3.csv', 'data_16p_0.csv', 'data_256p_4.csv', 'data_128p_1.csv', 'data_64p_6.csv', 'data_64p_3.csv', 'data_128p_5.csv', 'data_256p_5.csv', 'data_32p_0.csv', 'data_128p_7.csv', 'data_256p_6.csv', 'data_64p_0.csv', 'data_16p_5.csv', 'data_128p_2.csv', 'data_128p_0.csv', 'data_512p_4.csv', 'data_512p_7.csv', 'data_16p_4.csv', 'data_128p_3.csv', 'data_64p_7.csv', 'data_64p_2.csv', 'data_512p_0.csv']
2025-03-25 23:08:03,368 - INFO - ================================================================================
2025-03-25 23:08:03,368 - INFO - EXPERIMENT CONFIG
2025-03-25 23:08:03,368 - INFO - ================================================================================
2025-03-25 23:08:03,368 - INFO - Found 48 data files: ['data_32p_7.csv', 'data_32p_4.csv', 'data_64p_5.csv', 'data_16p_6.csv', 'data_32p_1.csv', 'data_16p_1.csv', 'data_256p_7.csv', 'data_512p_6.csv', 'data_32p_5.csv', 'data_512p_5.csv', 'data_128p_4.csv', 'data_128p_6.csv', 'data_64p_4.csv', 'data_256p_2.csv', 'data_512p_1.csv', 'data_512p_3.csv', 'data_512p_2.csv', 'data_64p_1.csv', 'data_256p_3.csv', 'data_16p_7.csv', 'data_32p_2.csv', 'data_16p_2.csv', 'data_256p_0.csv', 'data_256p_1.csv', 'data_16p_3.csv', 'data_32p_6.csv', 'data_32p_3.csv', 'data_16p_0.csv', 'data_256p_4.csv', 'data_128p_1.csv', 'data_64p_6.csv', 'data_64p_3.csv', 'data_128p_5.csv', 'data_256p_5.csv', 'data_32p_0.csv', 'data_128p_7.csv', 'data_256p_6.csv', 'data_64p_0.csv', 'data_16p_5.csv', 'data_128p_2.csv', 'data_128p_0.csv', 'data_512p_4.csv', 'data_512p_7.csv', 'data_16p_4.csv', 'data_128p_3.csv', 'data_64p_7.csv', 'data_64p_2.csv', 'data_512p_0.csv']
2025-03-25 23:08:03,368 - INFO - Processing dataset: data_32p_7.csv
2025-03-25 23:08:03,368 - INFO - Loading dataset from data_32p_7.csv
2025-03-25 23:09:07,876 - INFO - ================================================================================
2025-03-25 23:09:07,877 - INFO - EXPERIMENT CONFIG
2025-03-25 23:09:07,877 - INFO - ================================================================================
2025-03-25 23:09:07,877 - INFO - Found 48 data files: ['data_32p_7.csv', 'data_32p_4.csv', 'data_64p_5.csv', 'data_16p_6.csv', 'data_32p_1.csv', 'data_16p_1.csv', 'data_256p_7.csv', 'data_512p_6.csv', 'data_32p_5.csv', 'data_512p_5.csv', 'data_128p_4.csv', 'data_128p_6.csv', 'data_64p_4.csv', 'data_256p_2.csv', 'data_512p_1.csv', 'data_512p_3.csv', 'data_512p_2.csv', 'data_64p_1.csv', 'data_256p_3.csv', 'data_16p_7.csv', 'data_32p_2.csv', 'data_16p_2.csv', 'data_256p_0.csv', 'data_256p_1.csv', 'data_16p_3.csv', 'data_32p_6.csv', 'data_32p_3.csv', 'data_16p_0.csv', 'data_256p_4.csv', 'data_128p_1.csv', 'data_64p_6.csv', 'data_64p_3.csv', 'data_128p_5.csv', 'data_256p_5.csv', 'data_32p_0.csv', 'data_128p_7.csv', 'data_256p_6.csv', 'data_64p_0.csv', 'data_16p_5.csv', 'data_128p_2.csv', 'data_128p_0.csv', 'data_512p_4.csv', 'data_512p_7.csv', 'data_16p_4.csv', 'data_128p_3.csv', 'data_64p_7.csv', 'data_64p_2.csv', 'data_512p_0.csv']
2025-03-25 23:09:07,877 - INFO - Processing dataset: data_32p_7.csv
2025-03-25 23:09:07,877 - INFO - Loading dataset from data_32p_7.csv
2025-03-25 23:10:13,902 - INFO - ================================================================================
2025-03-25 23:10:13,902 - INFO - EXPERIMENT CONFIG
2025-03-25 23:10:13,902 - INFO - ================================================================================
2025-03-25 23:10:13,902 - INFO - Found 48 data files: ['data_32p_7.csv', 'data_32p_4.csv', 'data_64p_5.csv', 'data_16p_6.csv', 'data_32p_1.csv', 'data_16p_1.csv', 'data_256p_7.csv', 'data_512p_6.csv', 'data_32p_5.csv', 'data_512p_5.csv', 'data_128p_4.csv', 'data_128p_6.csv', 'data_64p_4.csv', 'data_256p_2.csv', 'data_512p_1.csv', 'data_512p_3.csv', 'data_512p_2.csv', 'data_64p_1.csv', 'data_256p_3.csv', 'data_16p_7.csv', 'data_32p_2.csv', 'data_16p_2.csv', 'data_256p_0.csv', 'data_256p_1.csv', 'data_16p_3.csv', 'data_32p_6.csv', 'data_32p_3.csv', 'data_16p_0.csv', 'data_256p_4.csv', 'data_128p_1.csv', 'data_64p_6.csv', 'data_64p_3.csv', 'data_128p_5.csv', 'data_256p_5.csv', 'data_32p_0.csv', 'data_128p_7.csv', 'data_256p_6.csv', 'data_64p_0.csv', 'data_16p_5.csv', 'data_128p_2.csv', 'data_128p_0.csv', 'data_512p_4.csv', 'data_512p_7.csv', 'data_16p_4.csv', 'data_128p_3.csv', 'data_64p_7.csv', 'data_64p_2.csv', 'data_512p_0.csv']
2025-03-25 23:10:13,902 - INFO - Processing dataset: data_32p_7.csv
2025-03-25 23:10:13,902 - INFO - Loading dataset from data/parameter_recovery_participants/data_32p_7.csv
2025-03-25 23:10:13,913 - INFO - Number of participants: 32
2025-03-25 23:10:13,918 - INFO - Participant 0 (ID=0.0): _reward=0.35, _penalty=0.60
2025-03-25 23:10:13,923 - INFO - Participant 1 (ID=1.0): _reward=0.61, _penalty=0.97
2025-03-25 23:10:13,929 - INFO - Participant 2 (ID=2.0): _reward=0.11, _penalty=0.54
2025-03-25 23:10:13,933 - INFO - Participant 3 (ID=3.0): _reward=0.16, _penalty=0.33
2025-03-25 23:10:13,938 - INFO - Participant 4 (ID=4.0): _reward=0.89, _penalty=0.91
2025-03-25 23:10:13,943 - INFO - Participant 5 (ID=5.0): _reward=0.18, _penalty=0.35
2025-03-25 23:10:13,948 - INFO - Participant 6 (ID=6.0): _reward=0.90, _penalty=0.76
2025-03-25 23:10:13,953 - INFO - Participant 7 (ID=7.0): _reward=0.99, _penalty=0.72
2025-03-25 23:10:13,958 - INFO - Participant 8 (ID=8.0): _reward=0.69, _penalty=0.55
2025-03-25 23:10:13,963 - INFO - Participant 9 (ID=9.0): _reward=0.75, _penalty=0.54
2025-03-25 23:10:13,968 - INFO - Participant 10 (ID=10.0): _reward=0.96, _penalty=0.29
2025-03-25 23:10:13,973 - INFO - Participant 11 (ID=11.0): _reward=0.20, _penalty=0.44
2025-03-25 23:10:13,978 - INFO - Participant 12 (ID=12.0): _reward=0.98, _penalty=0.09
2025-03-25 23:10:13,983 - INFO - Participant 13 (ID=13.0): _reward=0.72, _penalty=0.65
2025-03-25 23:10:13,988 - INFO - Participant 14 (ID=14.0): _reward=0.62, _penalty=0.57
2025-03-25 23:10:13,993 - INFO - Participant 15 (ID=15.0): _reward=0.37, _penalty=0.51
2025-03-25 23:10:13,998 - INFO - Participant 16 (ID=16.0): _reward=0.02, _penalty=0.24
2025-03-25 23:10:14,003 - INFO - Participant 17 (ID=17.0): _reward=0.78, _penalty=0.69
2025-03-25 23:10:14,009 - INFO - Participant 18 (ID=18.0): _reward=0.85, _penalty=0.10
2025-03-25 23:10:14,014 - INFO - Participant 19 (ID=19.0): _reward=0.51, _penalty=0.04
2025-03-25 23:10:14,019 - INFO - Participant 20 (ID=20.0): _reward=0.06, _penalty=0.90
2025-03-25 23:10:14,025 - INFO - Participant 21 (ID=21.0): _reward=0.71, _penalty=0.34
2025-03-25 23:10:14,030 - INFO - Participant 22 (ID=22.0): _reward=0.75, _penalty=0.02
2025-03-25 23:10:14,035 - INFO - Participant 23 (ID=23.0): _reward=0.86, _penalty=0.99
2025-03-25 23:10:14,040 - INFO - Participant 24 (ID=24.0): _reward=0.10, _penalty=0.10
2025-03-25 23:10:14,045 - INFO - Participant 25 (ID=25.0): _reward=0.26, _penalty=0.98
2025-03-25 23:10:14,050 - INFO - Participant 26 (ID=26.0): _reward=0.08, _penalty=0.97
2025-03-25 23:10:14,055 - INFO - Participant 27 (ID=27.0): _reward=0.52, _penalty=0.46
2025-03-25 23:10:14,060 - INFO - Participant 28 (ID=28.0): _reward=0.13, _penalty=0.90
2025-03-25 23:10:14,065 - INFO - Participant 29 (ID=29.0): _reward=0.11, _penalty=0.64
2025-03-25 23:10:14,070 - INFO - Participant 30 (ID=30.0): _reward=0.08, _penalty=0.39
2025-03-25 23:10:14,075 - INFO - Participant 31 (ID=31.0): _reward=0.23, _penalty=0.30
2025-03-25 23:10:14,075 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,075 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:10:14,076 - INFO - Combined xs shape after concatenation: torch.Size([32, 200, 5])
2025-03-25 23:10:14,076 - INFO - Combined ys shape after concatenation: torch.Size([32, 200, 2])
2025-03-25 23:10:14,076 - INFO - Combined dataset shape: X=torch.Size([32, 200, 5]), Y=torch.Size([32, 200, 2])
2025-03-25 23:10:14,076 - INFO - Total unique participants: 32
2025-03-25 23:10:14,076 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-25 23:10:14,076 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,076 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,076 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,076 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,076 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,076 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,077 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,078 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,078 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,078 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-25 23:10:14,078 - INFO - Train xs shape: torch.Size([32, 140, 5])
2025-03-25 23:10:14,078 - INFO - Train ys shape: torch.Size([32, 140, 2])
2025-03-25 23:10:14,078 - INFO - Validation xs shape: torch.Size([32, 60, 5])
2025-03-25 23:10:14,078 - INFO - Validation ys shape: torch.Size([32, 60, 2])
2025-03-25 23:10:14,078 - INFO - Train dataset: torch.Size([32, 140, 5]), Validation dataset: torch.Size([32, 60, 5])
2025-03-25 23:10:14,078 - INFO - Starting hyperparameter optimization...
2025-03-25 23:11:04,752 - INFO - ================================================================================
2025-03-25 23:11:04,752 - INFO - EXPERIMENT CONFIG
2025-03-25 23:11:04,752 - INFO - ================================================================================
2025-03-25 23:11:04,752 - INFO - Found 48 data files: ['data_32p_7.csv', 'data_32p_4.csv', 'data_64p_5.csv', 'data_16p_6.csv', 'data_32p_1.csv', 'data_16p_1.csv', 'data_256p_7.csv', 'data_512p_6.csv', 'data_32p_5.csv', 'data_512p_5.csv', 'data_128p_4.csv', 'data_128p_6.csv', 'data_64p_4.csv', 'data_256p_2.csv', 'data_512p_1.csv', 'data_512p_3.csv', 'data_512p_2.csv', 'data_64p_1.csv', 'data_256p_3.csv', 'data_16p_7.csv', 'data_32p_2.csv', 'data_16p_2.csv', 'data_256p_0.csv', 'data_256p_1.csv', 'data_16p_3.csv', 'data_32p_6.csv', 'data_32p_3.csv', 'data_16p_0.csv', 'data_256p_4.csv', 'data_128p_1.csv', 'data_64p_6.csv', 'data_64p_3.csv', 'data_128p_5.csv', 'data_256p_5.csv', 'data_32p_0.csv', 'data_128p_7.csv', 'data_256p_6.csv', 'data_64p_0.csv', 'data_16p_5.csv', 'data_128p_2.csv', 'data_128p_0.csv', 'data_512p_4.csv', 'data_512p_7.csv', 'data_16p_4.csv', 'data_128p_3.csv', 'data_64p_7.csv', 'data_64p_2.csv', 'data_512p_0.csv']
2025-03-25 23:11:04,752 - INFO - Processing dataset: data_32p_7.csv
2025-03-25 23:11:04,752 - INFO - Loading dataset from data/parameter_recovery_participants/data_32p_7.csv
2025-03-25 23:11:04,762 - INFO - Number of participants: 32
2025-03-25 23:11:04,768 - INFO - Participant 0 (ID=0.0): _reward=0.35, _penalty=0.60
2025-03-25 23:11:04,773 - INFO - Participant 1 (ID=1.0): _reward=0.61, _penalty=0.97
2025-03-25 23:11:04,778 - INFO - Participant 2 (ID=2.0): _reward=0.11, _penalty=0.54
2025-03-25 23:11:04,784 - INFO - Participant 3 (ID=3.0): _reward=0.16, _penalty=0.33
2025-03-25 23:11:04,789 - INFO - Participant 4 (ID=4.0): _reward=0.89, _penalty=0.91
2025-03-25 23:11:04,794 - INFO - Participant 5 (ID=5.0): _reward=0.18, _penalty=0.35
2025-03-25 23:11:04,799 - INFO - Participant 6 (ID=6.0): _reward=0.90, _penalty=0.76
2025-03-25 23:11:04,805 - INFO - Participant 7 (ID=7.0): _reward=0.99, _penalty=0.72
2025-03-25 23:11:04,810 - INFO - Participant 8 (ID=8.0): _reward=0.69, _penalty=0.55
2025-03-25 23:11:04,815 - INFO - Participant 9 (ID=9.0): _reward=0.75, _penalty=0.54
2025-03-25 23:11:04,821 - INFO - Participant 10 (ID=10.0): _reward=0.96, _penalty=0.29
2025-03-25 23:11:04,826 - INFO - Participant 11 (ID=11.0): _reward=0.20, _penalty=0.44
2025-03-25 23:11:04,831 - INFO - Participant 12 (ID=12.0): _reward=0.98, _penalty=0.09
2025-03-25 23:11:04,836 - INFO - Participant 13 (ID=13.0): _reward=0.72, _penalty=0.65
2025-03-25 23:11:04,842 - INFO - Participant 14 (ID=14.0): _reward=0.62, _penalty=0.57
2025-03-25 23:11:04,847 - INFO - Participant 15 (ID=15.0): _reward=0.37, _penalty=0.51
2025-03-25 23:11:04,852 - INFO - Participant 16 (ID=16.0): _reward=0.02, _penalty=0.24
2025-03-25 23:11:04,858 - INFO - Participant 17 (ID=17.0): _reward=0.78, _penalty=0.69
2025-03-25 23:11:04,862 - INFO - Participant 18 (ID=18.0): _reward=0.85, _penalty=0.10
2025-03-25 23:11:04,867 - INFO - Participant 19 (ID=19.0): _reward=0.51, _penalty=0.04
2025-03-25 23:11:04,873 - INFO - Participant 20 (ID=20.0): _reward=0.06, _penalty=0.90
2025-03-25 23:11:04,878 - INFO - Participant 21 (ID=21.0): _reward=0.71, _penalty=0.34
2025-03-25 23:11:04,883 - INFO - Participant 22 (ID=22.0): _reward=0.75, _penalty=0.02
2025-03-25 23:11:04,889 - INFO - Participant 23 (ID=23.0): _reward=0.86, _penalty=0.99
2025-03-25 23:11:04,894 - INFO - Participant 24 (ID=24.0): _reward=0.10, _penalty=0.10
2025-03-25 23:11:04,899 - INFO - Participant 25 (ID=25.0): _reward=0.26, _penalty=0.98
2025-03-25 23:11:04,905 - INFO - Participant 26 (ID=26.0): _reward=0.08, _penalty=0.97
2025-03-25 23:11:04,910 - INFO - Participant 27 (ID=27.0): _reward=0.52, _penalty=0.46
2025-03-25 23:11:04,915 - INFO - Participant 28 (ID=28.0): _reward=0.13, _penalty=0.90
2025-03-25 23:11:04,920 - INFO - Participant 29 (ID=29.0): _reward=0.11, _penalty=0.64
2025-03-25 23:11:04,925 - INFO - Participant 30 (ID=30.0): _reward=0.08, _penalty=0.39
2025-03-25 23:11:04,931 - INFO - Participant 31 (ID=31.0): _reward=0.23, _penalty=0.30
2025-03-25 23:11:04,931 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:11:04,931 - INFO - Combined xs shape after concatenation: torch.Size([32, 200, 5])
2025-03-25 23:11:04,931 - INFO - Combined ys shape after concatenation: torch.Size([32, 200, 2])
2025-03-25 23:11:04,931 - INFO - Combined dataset shape: X=torch.Size([32, 200, 5]), Y=torch.Size([32, 200, 2])
2025-03-25 23:11:04,931 - INFO - Total unique participants: 32
2025-03-25 23:11:04,932 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-25 23:11:04,932 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,932 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,932 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,932 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,932 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,932 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,932 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,932 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,932 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,932 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,932 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,932 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,932 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,933 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,933 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,933 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,933 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,933 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,933 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,933 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,933 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,933 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,934 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,934 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,934 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,934 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,934 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,934 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,934 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,934 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,934 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,934 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-25 23:11:04,935 - INFO - Train xs shape: torch.Size([32, 140, 5])
2025-03-25 23:11:04,935 - INFO - Train ys shape: torch.Size([32, 140, 2])
2025-03-25 23:11:04,935 - INFO - Validation xs shape: torch.Size([32, 60, 5])
2025-03-25 23:11:04,935 - INFO - Validation ys shape: torch.Size([32, 60, 2])
2025-03-25 23:11:04,935 - INFO - Train dataset: torch.Size([32, 140, 5]), Validation dataset: torch.Size([32, 60, 5])
2025-03-25 23:11:04,935 - INFO - Starting hyperparameter optimization...
2025-03-25 23:12:31,391 - INFO - ================================================================================
2025-03-25 23:12:31,392 - INFO - EXPERIMENT CONFIG
2025-03-25 23:12:31,392 - INFO - ================================================================================
2025-03-25 23:12:31,392 - INFO - Found 48 data files: ['data_32p_7.csv', 'data_32p_4.csv', 'data_64p_5.csv', 'data_16p_6.csv', 'data_32p_1.csv', 'data_16p_1.csv', 'data_256p_7.csv', 'data_512p_6.csv', 'data_32p_5.csv', 'data_512p_5.csv', 'data_128p_4.csv', 'data_128p_6.csv', 'data_64p_4.csv', 'data_256p_2.csv', 'data_512p_1.csv', 'data_512p_3.csv', 'data_512p_2.csv', 'data_64p_1.csv', 'data_256p_3.csv', 'data_16p_7.csv', 'data_32p_2.csv', 'data_16p_2.csv', 'data_256p_0.csv', 'data_256p_1.csv', 'data_16p_3.csv', 'data_32p_6.csv', 'data_32p_3.csv', 'data_16p_0.csv', 'data_256p_4.csv', 'data_128p_1.csv', 'data_64p_6.csv', 'data_64p_3.csv', 'data_128p_5.csv', 'data_256p_5.csv', 'data_32p_0.csv', 'data_128p_7.csv', 'data_256p_6.csv', 'data_64p_0.csv', 'data_16p_5.csv', 'data_128p_2.csv', 'data_128p_0.csv', 'data_512p_4.csv', 'data_512p_7.csv', 'data_16p_4.csv', 'data_128p_3.csv', 'data_64p_7.csv', 'data_64p_2.csv', 'data_512p_0.csv']
2025-03-25 23:12:31,392 - INFO - Processing dataset: data_32p_7.csv
2025-03-25 23:12:31,392 - INFO - Loading dataset from data/parameter_recovery_participants/data_32p_7.csv
2025-03-25 23:12:31,402 - INFO - Number of participants: 32
2025-03-25 23:12:31,408 - INFO - Participant 0 (ID=0.0): _reward=0.35, _penalty=0.60
2025-03-25 23:12:31,414 - INFO - Participant 1 (ID=1.0): _reward=0.61, _penalty=0.97
2025-03-25 23:12:31,419 - INFO - Participant 2 (ID=2.0): _reward=0.11, _penalty=0.54
2025-03-25 23:12:31,425 - INFO - Participant 3 (ID=3.0): _reward=0.16, _penalty=0.33
2025-03-25 23:12:31,430 - INFO - Participant 4 (ID=4.0): _reward=0.89, _penalty=0.91
2025-03-25 23:12:31,435 - INFO - Participant 5 (ID=5.0): _reward=0.18, _penalty=0.35
2025-03-25 23:12:31,441 - INFO - Participant 6 (ID=6.0): _reward=0.90, _penalty=0.76
2025-03-25 23:12:31,446 - INFO - Participant 7 (ID=7.0): _reward=0.99, _penalty=0.72
2025-03-25 23:12:31,452 - INFO - Participant 8 (ID=8.0): _reward=0.69, _penalty=0.55
2025-03-25 23:12:31,457 - INFO - Participant 9 (ID=9.0): _reward=0.75, _penalty=0.54
2025-03-25 23:12:31,463 - INFO - Participant 10 (ID=10.0): _reward=0.96, _penalty=0.29
2025-03-25 23:12:31,468 - INFO - Participant 11 (ID=11.0): _reward=0.20, _penalty=0.44
2025-03-25 23:12:31,474 - INFO - Participant 12 (ID=12.0): _reward=0.98, _penalty=0.09
2025-03-25 23:12:31,479 - INFO - Participant 13 (ID=13.0): _reward=0.72, _penalty=0.65
2025-03-25 23:12:31,484 - INFO - Participant 14 (ID=14.0): _reward=0.62, _penalty=0.57
2025-03-25 23:12:31,490 - INFO - Participant 15 (ID=15.0): _reward=0.37, _penalty=0.51
2025-03-25 23:12:31,495 - INFO - Participant 16 (ID=16.0): _reward=0.02, _penalty=0.24
2025-03-25 23:12:31,500 - INFO - Participant 17 (ID=17.0): _reward=0.78, _penalty=0.69
2025-03-25 23:12:31,506 - INFO - Participant 18 (ID=18.0): _reward=0.85, _penalty=0.10
2025-03-25 23:12:31,511 - INFO - Participant 19 (ID=19.0): _reward=0.51, _penalty=0.04
2025-03-25 23:12:31,517 - INFO - Participant 20 (ID=20.0): _reward=0.06, _penalty=0.90
2025-03-25 23:12:31,523 - INFO - Participant 21 (ID=21.0): _reward=0.71, _penalty=0.34
2025-03-25 23:12:31,528 - INFO - Participant 22 (ID=22.0): _reward=0.75, _penalty=0.02
2025-03-25 23:12:31,533 - INFO - Participant 23 (ID=23.0): _reward=0.86, _penalty=0.99
2025-03-25 23:12:31,539 - INFO - Participant 24 (ID=24.0): _reward=0.10, _penalty=0.10
2025-03-25 23:12:31,544 - INFO - Participant 25 (ID=25.0): _reward=0.26, _penalty=0.98
2025-03-25 23:12:31,549 - INFO - Participant 26 (ID=26.0): _reward=0.08, _penalty=0.97
2025-03-25 23:12:31,555 - INFO - Participant 27 (ID=27.0): _reward=0.52, _penalty=0.46
2025-03-25 23:12:31,560 - INFO - Participant 28 (ID=28.0): _reward=0.13, _penalty=0.90
2025-03-25 23:12:31,565 - INFO - Participant 29 (ID=29.0): _reward=0.11, _penalty=0.64
2025-03-25 23:12:31,571 - INFO - Participant 30 (ID=30.0): _reward=0.08, _penalty=0.39
2025-03-25 23:12:31,576 - INFO - Participant 31 (ID=31.0): _reward=0.23, _penalty=0.30
2025-03-25 23:12:31,576 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,576 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:12:31,577 - INFO - Combined xs shape after concatenation: torch.Size([32, 200, 5])
2025-03-25 23:12:31,577 - INFO - Combined ys shape after concatenation: torch.Size([32, 200, 2])
2025-03-25 23:12:31,577 - INFO - Combined dataset shape: X=torch.Size([32, 200, 5]), Y=torch.Size([32, 200, 2])
2025-03-25 23:12:31,577 - INFO - Total unique participants: 32
2025-03-25 23:12:31,577 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-25 23:12:31,577 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,577 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,578 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,579 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,579 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,579 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,579 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,579 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,579 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,579 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,579 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,579 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,579 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-25 23:12:31,579 - INFO - Train xs shape: torch.Size([32, 140, 5])
2025-03-25 23:12:31,579 - INFO - Train ys shape: torch.Size([32, 140, 2])
2025-03-25 23:12:31,579 - INFO - Validation xs shape: torch.Size([32, 60, 5])
2025-03-25 23:12:31,579 - INFO - Validation ys shape: torch.Size([32, 60, 2])
2025-03-25 23:12:31,579 - INFO - Train dataset: torch.Size([32, 140, 5]), Validation dataset: torch.Size([32, 60, 5])
2025-03-25 23:12:31,579 - INFO - Starting hyperparameter optimization...
2025-03-25 23:12:31,580 - INFO - Trial 0: dropout=0.191, lr=0.000134, hidden_size=9, embedding_size=25, n_steps=21
2025-03-25 23:14:12,494 - INFO - Trial 0: RNN Train Loss: 0.0000000
2025-03-25 23:14:12,495 - INFO - Trial 0: Validation set has 32 participants
2025-03-25 23:14:25,393 - INFO - ================================================================================
2025-03-25 23:14:25,393 - INFO - EXPERIMENT CONFIG
2025-03-25 23:14:25,393 - INFO - ================================================================================
2025-03-25 23:14:25,393 - INFO - Found 48 data files: ['data_32p_7.csv', 'data_32p_4.csv', 'data_64p_5.csv', 'data_16p_6.csv', 'data_32p_1.csv', 'data_16p_1.csv', 'data_256p_7.csv', 'data_512p_6.csv', 'data_32p_5.csv', 'data_512p_5.csv', 'data_128p_4.csv', 'data_128p_6.csv', 'data_64p_4.csv', 'data_256p_2.csv', 'data_512p_1.csv', 'data_512p_3.csv', 'data_512p_2.csv', 'data_64p_1.csv', 'data_256p_3.csv', 'data_16p_7.csv', 'data_32p_2.csv', 'data_16p_2.csv', 'data_256p_0.csv', 'data_256p_1.csv', 'data_16p_3.csv', 'data_32p_6.csv', 'data_32p_3.csv', 'data_16p_0.csv', 'data_256p_4.csv', 'data_128p_1.csv', 'data_64p_6.csv', 'data_64p_3.csv', 'data_128p_5.csv', 'data_256p_5.csv', 'data_32p_0.csv', 'data_128p_7.csv', 'data_256p_6.csv', 'data_64p_0.csv', 'data_16p_5.csv', 'data_128p_2.csv', 'data_128p_0.csv', 'data_512p_4.csv', 'data_512p_7.csv', 'data_16p_4.csv', 'data_128p_3.csv', 'data_64p_7.csv', 'data_64p_2.csv', 'data_512p_0.csv']
2025-03-25 23:14:25,393 - INFO - Processing dataset: data_32p_7.csv
2025-03-25 23:14:25,393 - INFO - Loading dataset from data/parameter_recovery_participants/data_32p_7.csv
2025-03-25 23:14:25,404 - INFO - Number of participants: 32
2025-03-25 23:14:25,411 - INFO - Participant 0 (ID=0.0): _reward=0.35, _penalty=0.60
2025-03-25 23:14:25,416 - INFO - Participant 1 (ID=1.0): _reward=0.61, _penalty=0.97
2025-03-25 23:14:25,422 - INFO - Participant 2 (ID=2.0): _reward=0.11, _penalty=0.54
2025-03-25 23:14:25,428 - INFO - Participant 3 (ID=3.0): _reward=0.16, _penalty=0.33
2025-03-25 23:14:25,433 - INFO - Participant 4 (ID=4.0): _reward=0.89, _penalty=0.91
2025-03-25 23:14:25,439 - INFO - Participant 5 (ID=5.0): _reward=0.18, _penalty=0.35
2025-03-25 23:14:25,444 - INFO - Participant 6 (ID=6.0): _reward=0.90, _penalty=0.76
2025-03-25 23:14:25,450 - INFO - Participant 7 (ID=7.0): _reward=0.99, _penalty=0.72
2025-03-25 23:14:25,456 - INFO - Participant 8 (ID=8.0): _reward=0.69, _penalty=0.55
2025-03-25 23:14:25,461 - INFO - Participant 9 (ID=9.0): _reward=0.75, _penalty=0.54
2025-03-25 23:14:25,467 - INFO - Participant 10 (ID=10.0): _reward=0.96, _penalty=0.29
2025-03-25 23:14:25,472 - INFO - Participant 11 (ID=11.0): _reward=0.20, _penalty=0.44
2025-03-25 23:14:25,478 - INFO - Participant 12 (ID=12.0): _reward=0.98, _penalty=0.09
2025-03-25 23:14:25,484 - INFO - Participant 13 (ID=13.0): _reward=0.72, _penalty=0.65
2025-03-25 23:14:25,489 - INFO - Participant 14 (ID=14.0): _reward=0.62, _penalty=0.57
2025-03-25 23:14:25,495 - INFO - Participant 15 (ID=15.0): _reward=0.37, _penalty=0.51
2025-03-25 23:14:25,500 - INFO - Participant 16 (ID=16.0): _reward=0.02, _penalty=0.24
2025-03-25 23:14:25,506 - INFO - Participant 17 (ID=17.0): _reward=0.78, _penalty=0.69
2025-03-25 23:14:25,512 - INFO - Participant 18 (ID=18.0): _reward=0.85, _penalty=0.10
2025-03-25 23:14:25,517 - INFO - Participant 19 (ID=19.0): _reward=0.51, _penalty=0.04
2025-03-25 23:14:25,523 - INFO - Participant 20 (ID=20.0): _reward=0.06, _penalty=0.90
2025-03-25 23:14:25,529 - INFO - Participant 21 (ID=21.0): _reward=0.71, _penalty=0.34
2025-03-25 23:14:25,534 - INFO - Participant 22 (ID=22.0): _reward=0.75, _penalty=0.02
2025-03-25 23:14:25,540 - INFO - Participant 23 (ID=23.0): _reward=0.86, _penalty=0.99
2025-03-25 23:14:25,546 - INFO - Participant 24 (ID=24.0): _reward=0.10, _penalty=0.10
2025-03-25 23:14:25,551 - INFO - Participant 25 (ID=25.0): _reward=0.26, _penalty=0.98
2025-03-25 23:14:25,557 - INFO - Participant 26 (ID=26.0): _reward=0.08, _penalty=0.97
2025-03-25 23:14:25,563 - INFO - Participant 27 (ID=27.0): _reward=0.52, _penalty=0.46
2025-03-25 23:14:25,568 - INFO - Participant 28 (ID=28.0): _reward=0.13, _penalty=0.90
2025-03-25 23:14:25,574 - INFO - Participant 29 (ID=29.0): _reward=0.11, _penalty=0.64
2025-03-25 23:14:25,580 - INFO - Participant 30 (ID=30.0): _reward=0.08, _penalty=0.39
2025-03-25 23:14:25,585 - INFO - Participant 31 (ID=31.0): _reward=0.23, _penalty=0.30
2025-03-25 23:14:25,586 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:14:25,586 - INFO - Combined xs shape after concatenation: torch.Size([32, 200, 5])
2025-03-25 23:14:25,586 - INFO - Combined ys shape after concatenation: torch.Size([32, 200, 2])
2025-03-25 23:14:25,586 - INFO - Combined dataset shape: X=torch.Size([32, 200, 5]), Y=torch.Size([32, 200, 2])
2025-03-25 23:14:25,587 - INFO - Total unique participants: 32
2025-03-25 23:14:25,587 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-25 23:14:25,587 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,587 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,587 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,587 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,587 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,587 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,587 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,587 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,587 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,587 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,587 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,587 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,587 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,587 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-25 23:14:25,588 - INFO - Train xs shape: torch.Size([32, 140, 5])
2025-03-25 23:14:25,588 - INFO - Train ys shape: torch.Size([32, 140, 2])
2025-03-25 23:14:25,588 - INFO - Validation xs shape: torch.Size([32, 60, 5])
2025-03-25 23:14:25,588 - INFO - Validation ys shape: torch.Size([32, 60, 2])
2025-03-25 23:14:25,588 - INFO - Train dataset: torch.Size([32, 140, 5]), Validation dataset: torch.Size([32, 60, 5])
2025-03-25 23:14:25,589 - INFO - Starting hyperparameter optimization...
2025-03-25 23:14:25,589 - INFO - Trial 0: dropout=0.279, lr=0.000569, hidden_size=25, embedding_size=13, n_steps=21
2025-03-25 23:14:26,056 - ERROR - Trial 0 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,056 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,057 - INFO - Trial 1: dropout=0.295, lr=0.003850, hidden_size=11, embedding_size=15, n_steps=7
2025-03-25 23:14:26,058 - ERROR - Trial 1 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,058 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,059 - INFO - Trial 2: dropout=0.144, lr=0.001826, hidden_size=8, embedding_size=15, n_steps=23
2025-03-25 23:14:26,059 - ERROR - Trial 2 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,059 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,060 - INFO - Trial 3: dropout=0.218, lr=0.000189, hidden_size=18, embedding_size=24, n_steps=24
2025-03-25 23:14:26,061 - ERROR - Trial 3 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,061 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,061 - INFO - Trial 4: dropout=0.264, lr=0.000630, hidden_size=13, embedding_size=29, n_steps=6
2025-03-25 23:14:26,062 - ERROR - Trial 4 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,063 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,063 - INFO - Trial 5: dropout=0.198, lr=0.000146, hidden_size=26, embedding_size=28, n_steps=6
2025-03-25 23:14:26,064 - ERROR - Trial 5 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,064 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,064 - INFO - Trial 6: dropout=0.129, lr=0.005560, hidden_size=21, embedding_size=9, n_steps=17
2025-03-25 23:14:26,065 - ERROR - Trial 6 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,065 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,066 - INFO - Trial 7: dropout=0.234, lr=0.001145, hidden_size=21, embedding_size=26, n_steps=22
2025-03-25 23:14:26,066 - ERROR - Trial 7 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,067 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,067 - INFO - Trial 8: dropout=0.145, lr=0.000803, hidden_size=19, embedding_size=17, n_steps=23
2025-03-25 23:14:26,068 - ERROR - Trial 8 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,068 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,068 - INFO - Trial 9: dropout=0.213, lr=0.000321, hidden_size=22, embedding_size=15, n_steps=22
2025-03-25 23:14:26,069 - ERROR - Trial 9 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,069 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,079 - INFO - Trial 10: dropout=0.281, lr=0.000410, hidden_size=31, embedding_size=8, n_steps=32
2025-03-25 23:14:26,080 - ERROR - Trial 10 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,080 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,090 - INFO - Trial 11: dropout=0.297, lr=0.003705, hidden_size=28, embedding_size=20, n_steps=1
2025-03-25 23:14:26,090 - ERROR - Trial 11 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,091 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,100 - INFO - Trial 12: dropout=0.255, lr=0.002512, hidden_size=13, embedding_size=12, n_steps=12
2025-03-25 23:14:26,101 - ERROR - Trial 12 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,101 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,111 - INFO - Trial 13: dropout=0.182, lr=0.008060, hidden_size=8, embedding_size=21, n_steps=13
2025-03-25 23:14:26,111 - ERROR - Trial 13 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,112 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,121 - INFO - Trial 14: dropout=0.298, lr=0.001594, hidden_size=15, embedding_size=12, n_steps=31
2025-03-25 23:14:26,122 - ERROR - Trial 14 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,122 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,132 - INFO - Trial 15: dropout=0.254, lr=0.002902, hidden_size=25, embedding_size=32, n_steps=17
2025-03-25 23:14:26,133 - ERROR - Trial 15 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,133 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,143 - INFO - Trial 16: dropout=0.269, lr=0.009408, hidden_size=30, embedding_size=18, n_steps=9
2025-03-25 23:14:26,144 - ERROR - Trial 16 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,144 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,154 - INFO - Trial 17: dropout=0.240, lr=0.000406, hidden_size=16, embedding_size=12, n_steps=1
2025-03-25 23:14:26,155 - ERROR - Trial 17 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,155 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,165 - INFO - Trial 18: dropout=0.176, lr=0.001202, hidden_size=26, embedding_size=15, n_steps=28
2025-03-25 23:14:26,166 - ERROR - Trial 18 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,166 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,176 - INFO - Trial 19: dropout=0.289, lr=0.004827, hidden_size=11, embedding_size=10, n_steps=14
2025-03-25 23:14:26,177 - ERROR - Trial 19 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,177 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,187 - INFO - Trial 20: dropout=0.102, lr=0.000618, hidden_size=23, embedding_size=22, n_steps=19
2025-03-25 23:14:26,188 - ERROR - Trial 20 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,188 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,198 - INFO - Trial 21: dropout=0.140, lr=0.002001, hidden_size=9, embedding_size=15, n_steps=26
2025-03-25 23:14:26,199 - ERROR - Trial 21 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,199 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,210 - INFO - Trial 22: dropout=0.172, lr=0.001671, hidden_size=10, embedding_size=17, n_steps=19
2025-03-25 23:14:26,210 - ERROR - Trial 22 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,211 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,221 - INFO - Trial 23: dropout=0.104, lr=0.004037, hidden_size=12, embedding_size=14, n_steps=28
2025-03-25 23:14:26,222 - ERROR - Trial 23 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,222 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,232 - INFO - Trial 24: dropout=0.155, lr=0.000260, hidden_size=16, embedding_size=18, n_steps=8
2025-03-25 23:14:26,233 - ERROR - Trial 24 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,233 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,243 - INFO - Trial 25: dropout=0.275, lr=0.002641, hidden_size=8, embedding_size=13, n_steps=20
2025-03-25 23:14:26,244 - ERROR - Trial 25 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,245 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,255 - INFO - Trial 26: dropout=0.122, lr=0.006847, hidden_size=14, embedding_size=16, n_steps=26
2025-03-25 23:14:26,256 - ERROR - Trial 26 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,256 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,267 - INFO - Trial 27: dropout=0.233, lr=0.000969, hidden_size=24, embedding_size=11, n_steps=15
2025-03-25 23:14:26,268 - ERROR - Trial 27 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,268 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,278 - INFO - Trial 28: dropout=0.192, lr=0.000617, hidden_size=28, embedding_size=19, n_steps=11
2025-03-25 23:14:26,279 - ERROR - Trial 28 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,279 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,290 - INFO - Trial 29: dropout=0.209, lr=0.000227, hidden_size=18, embedding_size=22, n_steps=25
2025-03-25 23:14:26,291 - ERROR - Trial 29 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,291 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,302 - INFO - Trial 30: dropout=0.161, lr=0.000117, hidden_size=10, embedding_size=13, n_steps=4
2025-03-25 23:14:26,302 - ERROR - Trial 30 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,303 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,316 - INFO - Trial 31: dropout=0.222, lr=0.000165, hidden_size=18, embedding_size=25, n_steps=24
2025-03-25 23:14:26,317 - ERROR - Trial 31 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,317 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,329 - INFO - Trial 32: dropout=0.256, lr=0.000494, hidden_size=12, embedding_size=24, n_steps=20
2025-03-25 23:14:26,329 - ERROR - Trial 32 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,330 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,340 - INFO - Trial 33: dropout=0.284, lr=0.000183, hidden_size=17, embedding_size=29, n_steps=16
2025-03-25 23:14:26,341 - ERROR - Trial 33 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,341 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,353 - INFO - Trial 34: dropout=0.243, lr=0.000106, hidden_size=20, embedding_size=27, n_steps=28
2025-03-25 23:14:26,353 - ERROR - Trial 34 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,354 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,365 - INFO - Trial 35: dropout=0.195, lr=0.000883, hidden_size=28, embedding_size=23, n_steps=21
2025-03-25 23:14:26,366 - ERROR - Trial 35 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,366 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,377 - INFO - Trial 36: dropout=0.271, lr=0.001325, hidden_size=14, embedding_size=10, n_steps=18
2025-03-25 23:14:26,378 - ERROR - Trial 36 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,378 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,389 - INFO - Trial 37: dropout=0.222, lr=0.001848, hidden_size=22, embedding_size=8, n_steps=22
2025-03-25 23:14:26,390 - ERROR - Trial 37 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,391 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,402 - INFO - Trial 38: dropout=0.121, lr=0.003330, hidden_size=11, embedding_size=20, n_steps=23
2025-03-25 23:14:26,403 - ERROR - Trial 38 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,403 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,414 - INFO - Trial 39: dropout=0.292, lr=0.005255, hidden_size=20, embedding_size=16, n_steps=3
2025-03-25 23:14:26,415 - ERROR - Trial 39 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,415 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,426 - INFO - Trial 40: dropout=0.259, lr=0.000297, hidden_size=32, embedding_size=31, n_steps=24
2025-03-25 23:14:26,427 - ERROR - Trial 40 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,427 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,439 - INFO - Trial 41: dropout=0.264, lr=0.000714, hidden_size=9, embedding_size=29, n_steps=5
2025-03-25 23:14:26,440 - ERROR - Trial 41 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,440 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,452 - INFO - Trial 42: dropout=0.279, lr=0.000425, hidden_size=14, embedding_size=28, n_steps=7
2025-03-25 23:14:26,453 - ERROR - Trial 42 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,453 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,464 - INFO - Trial 43: dropout=0.246, lr=0.000543, hidden_size=12, embedding_size=25, n_steps=30
2025-03-25 23:14:26,465 - ERROR - Trial 43 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,465 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,477 - INFO - Trial 44: dropout=0.293, lr=0.000346, hidden_size=9, embedding_size=30, n_steps=10
2025-03-25 23:14:26,478 - ERROR - Trial 44 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,478 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,490 - INFO - Trial 45: dropout=0.207, lr=0.001354, hidden_size=13, embedding_size=26, n_steps=7
2025-03-25 23:14:26,491 - ERROR - Trial 45 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,491 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,502 - INFO - Trial 46: dropout=0.227, lr=0.002232, hidden_size=10, embedding_size=14, n_steps=12
2025-03-25 23:14:26,503 - ERROR - Trial 46 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,503 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,515 - INFO - Trial 47: dropout=0.299, lr=0.000775, hidden_size=8, embedding_size=17, n_steps=2
2025-03-25 23:14:26,516 - ERROR - Trial 47 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,516 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,528 - INFO - Trial 48: dropout=0.286, lr=0.001079, hidden_size=15, embedding_size=32, n_steps=21
2025-03-25 23:14:26,528 - ERROR - Trial 48 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,529 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,540 - INFO - Trial 49: dropout=0.265, lr=0.006374, hidden_size=26, embedding_size=20, n_steps=5
2025-03-25 23:14:26,541 - ERROR - Trial 49 failed: Expected positive integer T_0, but got 0
2025-03-25 23:14:26,542 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:14:26,542 - INFO - Best hyperparameters: {'dropout': 0.2790334329967886, 'learning_rate': 0.000569483973662502, 'hidden_size': 25, 'embedding_size': 13, 'n_steps': 21}
2025-03-25 23:14:26,542 - INFO - Best validation loss: inf
2025-03-25 23:15:20,224 - INFO - ================================================================================
2025-03-25 23:15:20,225 - INFO - EXPERIMENT CONFIG
2025-03-25 23:15:20,225 - INFO - ================================================================================
2025-03-25 23:15:20,225 - INFO - Found 48 data files: ['data_32p_7.csv', 'data_32p_4.csv', 'data_64p_5.csv', 'data_16p_6.csv', 'data_32p_1.csv', 'data_16p_1.csv', 'data_256p_7.csv', 'data_512p_6.csv', 'data_32p_5.csv', 'data_512p_5.csv', 'data_128p_4.csv', 'data_128p_6.csv', 'data_64p_4.csv', 'data_256p_2.csv', 'data_512p_1.csv', 'data_512p_3.csv', 'data_512p_2.csv', 'data_64p_1.csv', 'data_256p_3.csv', 'data_16p_7.csv', 'data_32p_2.csv', 'data_16p_2.csv', 'data_256p_0.csv', 'data_256p_1.csv', 'data_16p_3.csv', 'data_32p_6.csv', 'data_32p_3.csv', 'data_16p_0.csv', 'data_256p_4.csv', 'data_128p_1.csv', 'data_64p_6.csv', 'data_64p_3.csv', 'data_128p_5.csv', 'data_256p_5.csv', 'data_32p_0.csv', 'data_128p_7.csv', 'data_256p_6.csv', 'data_64p_0.csv', 'data_16p_5.csv', 'data_128p_2.csv', 'data_128p_0.csv', 'data_512p_4.csv', 'data_512p_7.csv', 'data_16p_4.csv', 'data_128p_3.csv', 'data_64p_7.csv', 'data_64p_2.csv', 'data_512p_0.csv']
2025-03-25 23:15:20,225 - INFO - Processing dataset: data_32p_7.csv
2025-03-25 23:15:20,225 - INFO - Loading dataset from data/parameter_recovery_participants/data_32p_7.csv
2025-03-25 23:15:20,235 - INFO - Number of participants: 32
2025-03-25 23:15:20,241 - INFO - Participant 0 (ID=0.0): _reward=0.35, _penalty=0.60
2025-03-25 23:15:20,247 - INFO - Participant 1 (ID=1.0): _reward=0.61, _penalty=0.97
2025-03-25 23:15:20,252 - INFO - Participant 2 (ID=2.0): _reward=0.11, _penalty=0.54
2025-03-25 23:15:20,258 - INFO - Participant 3 (ID=3.0): _reward=0.16, _penalty=0.33
2025-03-25 23:15:20,263 - INFO - Participant 4 (ID=4.0): _reward=0.89, _penalty=0.91
2025-03-25 23:15:20,268 - INFO - Participant 5 (ID=5.0): _reward=0.18, _penalty=0.35
2025-03-25 23:15:20,274 - INFO - Participant 6 (ID=6.0): _reward=0.90, _penalty=0.76
2025-03-25 23:15:20,279 - INFO - Participant 7 (ID=7.0): _reward=0.99, _penalty=0.72
2025-03-25 23:15:20,285 - INFO - Participant 8 (ID=8.0): _reward=0.69, _penalty=0.55
2025-03-25 23:15:20,290 - INFO - Participant 9 (ID=9.0): _reward=0.75, _penalty=0.54
2025-03-25 23:15:20,296 - INFO - Participant 10 (ID=10.0): _reward=0.96, _penalty=0.29
2025-03-25 23:15:20,301 - INFO - Participant 11 (ID=11.0): _reward=0.20, _penalty=0.44
2025-03-25 23:15:20,307 - INFO - Participant 12 (ID=12.0): _reward=0.98, _penalty=0.09
2025-03-25 23:15:20,312 - INFO - Participant 13 (ID=13.0): _reward=0.72, _penalty=0.65
2025-03-25 23:15:20,317 - INFO - Participant 14 (ID=14.0): _reward=0.62, _penalty=0.57
2025-03-25 23:15:20,323 - INFO - Participant 15 (ID=15.0): _reward=0.37, _penalty=0.51
2025-03-25 23:15:20,328 - INFO - Participant 16 (ID=16.0): _reward=0.02, _penalty=0.24
2025-03-25 23:15:20,334 - INFO - Participant 17 (ID=17.0): _reward=0.78, _penalty=0.69
2025-03-25 23:15:20,339 - INFO - Participant 18 (ID=18.0): _reward=0.85, _penalty=0.10
2025-03-25 23:15:20,344 - INFO - Participant 19 (ID=19.0): _reward=0.51, _penalty=0.04
2025-03-25 23:15:20,350 - INFO - Participant 20 (ID=20.0): _reward=0.06, _penalty=0.90
2025-03-25 23:15:20,355 - INFO - Participant 21 (ID=21.0): _reward=0.71, _penalty=0.34
2025-03-25 23:15:20,360 - INFO - Participant 22 (ID=22.0): _reward=0.75, _penalty=0.02
2025-03-25 23:15:20,366 - INFO - Participant 23 (ID=23.0): _reward=0.86, _penalty=0.99
2025-03-25 23:15:20,371 - INFO - Participant 24 (ID=24.0): _reward=0.10, _penalty=0.10
2025-03-25 23:15:20,376 - INFO - Participant 25 (ID=25.0): _reward=0.26, _penalty=0.98
2025-03-25 23:15:20,382 - INFO - Participant 26 (ID=26.0): _reward=0.08, _penalty=0.97
2025-03-25 23:15:20,387 - INFO - Participant 27 (ID=27.0): _reward=0.52, _penalty=0.46
2025-03-25 23:15:20,392 - INFO - Participant 28 (ID=28.0): _reward=0.13, _penalty=0.90
2025-03-25 23:15:20,398 - INFO - Participant 29 (ID=29.0): _reward=0.11, _penalty=0.64
2025-03-25 23:15:20,403 - INFO - Participant 30 (ID=30.0): _reward=0.08, _penalty=0.39
2025-03-25 23:15:20,409 - INFO - Participant 31 (ID=31.0): _reward=0.23, _penalty=0.30
2025-03-25 23:15:20,409 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:15:20,409 - INFO - Combined xs shape after concatenation: torch.Size([32, 200, 5])
2025-03-25 23:15:20,409 - INFO - Combined ys shape after concatenation: torch.Size([32, 200, 2])
2025-03-25 23:15:20,410 - INFO - Combined dataset shape: X=torch.Size([32, 200, 5]), Y=torch.Size([32, 200, 2])
2025-03-25 23:15:20,410 - INFO - Total unique participants: 32
2025-03-25 23:15:20,410 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-25 23:15:20,410 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,410 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,410 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,410 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,410 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,410 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,410 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,410 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,411 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,412 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,412 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,412 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,412 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,412 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,412 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,412 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-25 23:15:20,412 - INFO - Train xs shape: torch.Size([32, 140, 5])
2025-03-25 23:15:20,412 - INFO - Train ys shape: torch.Size([32, 140, 2])
2025-03-25 23:15:20,412 - INFO - Validation xs shape: torch.Size([32, 60, 5])
2025-03-25 23:15:20,412 - INFO - Validation ys shape: torch.Size([32, 60, 2])
2025-03-25 23:15:20,412 - INFO - Train dataset: torch.Size([32, 140, 5]), Validation dataset: torch.Size([32, 60, 5])
2025-03-25 23:15:20,412 - INFO - Starting hyperparameter optimization...
2025-03-25 23:15:20,413 - INFO - Trial 0: dropout=0.121, lr=0.000144, hidden_size=20, embedding_size=8, n_steps=29
2025-03-25 23:15:20,865 - ERROR - Trial 0 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,866 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,867 - INFO - Trial 1: dropout=0.142, lr=0.001448, hidden_size=16, embedding_size=9, n_steps=12
2025-03-25 23:15:20,867 - ERROR - Trial 1 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,868 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,868 - INFO - Trial 2: dropout=0.210, lr=0.000427, hidden_size=26, embedding_size=32, n_steps=3
2025-03-25 23:15:20,869 - ERROR - Trial 2 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,869 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,870 - INFO - Trial 3: dropout=0.170, lr=0.000550, hidden_size=16, embedding_size=16, n_steps=9
2025-03-25 23:15:20,870 - ERROR - Trial 3 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,871 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,871 - INFO - Trial 4: dropout=0.159, lr=0.000376, hidden_size=24, embedding_size=14, n_steps=18
2025-03-25 23:15:20,872 - ERROR - Trial 4 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,872 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,873 - INFO - Trial 5: dropout=0.223, lr=0.000435, hidden_size=12, embedding_size=23, n_steps=2
2025-03-25 23:15:20,874 - ERROR - Trial 5 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,874 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,874 - INFO - Trial 6: dropout=0.218, lr=0.000363, hidden_size=16, embedding_size=23, n_steps=25
2025-03-25 23:15:20,875 - ERROR - Trial 6 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,875 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,876 - INFO - Trial 7: dropout=0.188, lr=0.000221, hidden_size=27, embedding_size=18, n_steps=11
2025-03-25 23:15:20,876 - ERROR - Trial 7 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,877 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,877 - INFO - Trial 8: dropout=0.202, lr=0.005851, hidden_size=16, embedding_size=22, n_steps=16
2025-03-25 23:15:20,878 - ERROR - Trial 8 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,878 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,879 - INFO - Trial 9: dropout=0.290, lr=0.000816, hidden_size=17, embedding_size=16, n_steps=28
2025-03-25 23:15:20,879 - ERROR - Trial 9 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,880 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,890 - INFO - Trial 10: dropout=0.101, lr=0.000127, hidden_size=31, embedding_size=8, n_steps=31
2025-03-25 23:15:20,891 - ERROR - Trial 10 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,891 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,900 - INFO - Trial 11: dropout=0.112, lr=0.002434, hidden_size=22, embedding_size=8, n_steps=24
2025-03-25 23:15:20,901 - ERROR - Trial 11 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,901 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,911 - INFO - Trial 12: dropout=0.140, lr=0.001818, hidden_size=9, embedding_size=12, n_steps=19
2025-03-25 23:15:20,911 - ERROR - Trial 12 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,912 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,921 - INFO - Trial 13: dropout=0.134, lr=0.001730, hidden_size=20, embedding_size=11, n_steps=11
2025-03-25 23:15:20,922 - ERROR - Trial 13 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,922 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,932 - INFO - Trial 14: dropout=0.129, lr=0.005160, hidden_size=12, embedding_size=29, n_steps=22
2025-03-25 23:15:20,933 - ERROR - Trial 14 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,933 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,942 - INFO - Trial 15: dropout=0.254, lr=0.000106, hidden_size=20, embedding_size=11, n_steps=14
2025-03-25 23:15:20,943 - ERROR - Trial 15 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,943 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,953 - INFO - Trial 16: dropout=0.158, lr=0.001074, hidden_size=12, embedding_size=8, n_steps=7
2025-03-25 23:15:20,954 - ERROR - Trial 16 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,954 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,964 - INFO - Trial 17: dropout=0.121, lr=0.009713, hidden_size=19, embedding_size=13, n_steps=31
2025-03-25 23:15:20,965 - ERROR - Trial 17 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,965 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,975 - INFO - Trial 18: dropout=0.179, lr=0.000225, hidden_size=8, embedding_size=26, n_steps=6
2025-03-25 23:15:20,976 - ERROR - Trial 18 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,976 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,986 - INFO - Trial 19: dropout=0.148, lr=0.003187, hidden_size=30, embedding_size=19, n_steps=21
2025-03-25 23:15:20,987 - ERROR - Trial 19 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,987 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:20,997 - INFO - Trial 20: dropout=0.243, lr=0.001040, hidden_size=14, embedding_size=10, n_steps=14
2025-03-25 23:15:20,997 - ERROR - Trial 20 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:20,998 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,009 - INFO - Trial 21: dropout=0.194, lr=0.000187, hidden_size=24, embedding_size=31, n_steps=1
2025-03-25 23:15:21,009 - ERROR - Trial 21 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,009 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,020 - INFO - Trial 22: dropout=0.100, lr=0.000667, hidden_size=27, embedding_size=27, n_steps=4
2025-03-25 23:15:21,021 - ERROR - Trial 22 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,021 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,031 - INFO - Trial 23: dropout=0.241, lr=0.000286, hidden_size=22, embedding_size=16, n_steps=5
2025-03-25 23:15:21,032 - ERROR - Trial 23 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,033 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,043 - INFO - Trial 24: dropout=0.265, lr=0.001323, hidden_size=27, embedding_size=32, n_steps=9
2025-03-25 23:15:21,044 - ERROR - Trial 24 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,044 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,055 - INFO - Trial 25: dropout=0.213, lr=0.000159, hidden_size=18, embedding_size=21, n_steps=27
2025-03-25 23:15:21,055 - ERROR - Trial 25 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,056 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,067 - INFO - Trial 26: dropout=0.173, lr=0.000540, hidden_size=22, embedding_size=10, n_steps=12
2025-03-25 23:15:21,067 - ERROR - Trial 26 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,068 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,078 - INFO - Trial 27: dropout=0.156, lr=0.000296, hidden_size=24, embedding_size=25, n_steps=3
2025-03-25 23:15:21,079 - ERROR - Trial 27 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,079 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,089 - INFO - Trial 28: dropout=0.119, lr=0.000131, hidden_size=14, embedding_size=14, n_steps=8
2025-03-25 23:15:21,090 - ERROR - Trial 28 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,090 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,101 - INFO - Trial 29: dropout=0.167, lr=0.000596, hidden_size=26, embedding_size=17, n_steps=16
2025-03-25 23:15:21,102 - ERROR - Trial 29 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,102 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,112 - INFO - Trial 30: dropout=0.141, lr=0.003369, hidden_size=30, embedding_size=29, n_steps=13
2025-03-25 23:15:21,113 - ERROR - Trial 30 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,113 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,124 - INFO - Trial 31: dropout=0.184, lr=0.000437, hidden_size=15, embedding_size=14, n_steps=9
2025-03-25 23:15:21,125 - ERROR - Trial 31 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,125 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,136 - INFO - Trial 32: dropout=0.170, lr=0.000759, hidden_size=18, embedding_size=10, n_steps=10
2025-03-25 23:15:21,137 - ERROR - Trial 32 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,137 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,148 - INFO - Trial 33: dropout=0.231, lr=0.000464, hidden_size=21, embedding_size=15, n_steps=18
2025-03-25 23:15:21,149 - ERROR - Trial 33 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,149 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,160 - INFO - Trial 34: dropout=0.206, lr=0.000296, hidden_size=24, embedding_size=20, n_steps=1
2025-03-25 23:15:21,160 - ERROR - Trial 34 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,161 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,171 - INFO - Trial 35: dropout=0.149, lr=0.001300, hidden_size=11, embedding_size=24, n_steps=7
2025-03-25 23:15:21,172 - ERROR - Trial 35 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,172 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,183 - INFO - Trial 36: dropout=0.189, lr=0.000370, hidden_size=16, embedding_size=18, n_steps=3
2025-03-25 23:15:21,184 - ERROR - Trial 36 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,184 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,195 - INFO - Trial 37: dropout=0.224, lr=0.000818, hidden_size=18, embedding_size=9, n_steps=15
2025-03-25 23:15:21,196 - ERROR - Trial 37 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,196 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,207 - INFO - Trial 38: dropout=0.126, lr=0.000222, hidden_size=14, embedding_size=12, n_steps=18
2025-03-25 23:15:21,208 - ERROR - Trial 38 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,208 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,219 - INFO - Trial 39: dropout=0.108, lr=0.002446, hidden_size=17, embedding_size=22, n_steps=29
2025-03-25 23:15:21,220 - ERROR - Trial 39 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,220 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,231 - INFO - Trial 40: dropout=0.163, lr=0.001492, hidden_size=32, embedding_size=13, n_steps=12
2025-03-25 23:15:21,232 - ERROR - Trial 40 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,232 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,244 - INFO - Trial 41: dropout=0.140, lr=0.000389, hidden_size=25, embedding_size=16, n_steps=24
2025-03-25 23:15:21,244 - ERROR - Trial 41 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,245 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,256 - INFO - Trial 42: dropout=0.200, lr=0.000505, hidden_size=29, embedding_size=9, n_steps=21
2025-03-25 23:15:21,257 - ERROR - Trial 42 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,257 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,269 - INFO - Trial 43: dropout=0.154, lr=0.000883, hidden_size=23, embedding_size=11, n_steps=27
2025-03-25 23:15:21,270 - ERROR - Trial 43 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,270 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,281 - INFO - Trial 44: dropout=0.179, lr=0.000644, hidden_size=20, embedding_size=8, n_steps=10
2025-03-25 23:15:21,282 - ERROR - Trial 44 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,283 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,294 - INFO - Trial 45: dropout=0.132, lr=0.000315, hidden_size=28, embedding_size=18, n_steps=5
2025-03-25 23:15:21,294 - ERROR - Trial 45 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,295 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,306 - INFO - Trial 46: dropout=0.114, lr=0.000176, hidden_size=16, embedding_size=12, n_steps=32
2025-03-25 23:15:21,307 - ERROR - Trial 46 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,307 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,319 - INFO - Trial 47: dropout=0.293, lr=0.000105, hidden_size=21, embedding_size=14, n_steps=19
2025-03-25 23:15:21,320 - ERROR - Trial 47 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,320 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,332 - INFO - Trial 48: dropout=0.144, lr=0.001110, hidden_size=19, embedding_size=19, n_steps=25
2025-03-25 23:15:21,333 - ERROR - Trial 48 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,333 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,344 - INFO - Trial 49: dropout=0.161, lr=0.000250, hidden_size=13, embedding_size=9, n_steps=14
2025-03-25 23:15:21,345 - ERROR - Trial 49 failed: Expected positive integer T_0, but got 0
2025-03-25 23:15:21,345 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:15:21,346 - INFO - Best hyperparameters: {'dropout': 0.12052507058699541, 'learning_rate': 0.00014418345794400714, 'hidden_size': 20, 'embedding_size': 8, 'n_steps': 29}
2025-03-25 23:15:21,346 - INFO - Best validation loss: inf
2025-03-25 23:16:22,297 - INFO - Final RNN training loss: 0.0000000
2025-03-25 23:16:22,298 - INFO - Evaluating with SINDy - fitting separate models for each participant's validation trials
2025-03-25 23:16:22,298 - INFO - Processing participant 0.0...
2025-03-25 23:16:22,298 - INFO - Fitting SINDy model for participant 0.0
2025-03-25 23:16:31,248 - INFO - ================================================================================
2025-03-25 23:16:31,248 - INFO - EXPERIMENT CONFIG
2025-03-25 23:16:31,248 - INFO - ================================================================================
2025-03-25 23:16:31,248 - INFO - Found 48 data files: ['data_32p_7.csv', 'data_32p_4.csv', 'data_64p_5.csv', 'data_16p_6.csv', 'data_32p_1.csv', 'data_16p_1.csv', 'data_256p_7.csv', 'data_512p_6.csv', 'data_32p_5.csv', 'data_512p_5.csv', 'data_128p_4.csv', 'data_128p_6.csv', 'data_64p_4.csv', 'data_256p_2.csv', 'data_512p_1.csv', 'data_512p_3.csv', 'data_512p_2.csv', 'data_64p_1.csv', 'data_256p_3.csv', 'data_16p_7.csv', 'data_32p_2.csv', 'data_16p_2.csv', 'data_256p_0.csv', 'data_256p_1.csv', 'data_16p_3.csv', 'data_32p_6.csv', 'data_32p_3.csv', 'data_16p_0.csv', 'data_256p_4.csv', 'data_128p_1.csv', 'data_64p_6.csv', 'data_64p_3.csv', 'data_128p_5.csv', 'data_256p_5.csv', 'data_32p_0.csv', 'data_128p_7.csv', 'data_256p_6.csv', 'data_64p_0.csv', 'data_16p_5.csv', 'data_128p_2.csv', 'data_128p_0.csv', 'data_512p_4.csv', 'data_512p_7.csv', 'data_16p_4.csv', 'data_128p_3.csv', 'data_64p_7.csv', 'data_64p_2.csv', 'data_512p_0.csv']
2025-03-25 23:16:31,249 - INFO - Processing dataset: data_32p_7.csv
2025-03-25 23:16:31,249 - INFO - Loading dataset from data/parameter_recovery_participants/data_32p_7.csv
2025-03-25 23:16:31,260 - INFO - Number of participants: 32
2025-03-25 23:16:31,266 - INFO - Participant 0 (ID=0.0): _reward=0.35, _penalty=0.60
2025-03-25 23:16:31,272 - INFO - Participant 1 (ID=1.0): _reward=0.61, _penalty=0.97
2025-03-25 23:16:31,277 - INFO - Participant 2 (ID=2.0): _reward=0.11, _penalty=0.54
2025-03-25 23:16:31,283 - INFO - Participant 3 (ID=3.0): _reward=0.16, _penalty=0.33
2025-03-25 23:16:31,289 - INFO - Participant 4 (ID=4.0): _reward=0.89, _penalty=0.91
2025-03-25 23:16:31,295 - INFO - Participant 5 (ID=5.0): _reward=0.18, _penalty=0.35
2025-03-25 23:16:31,300 - INFO - Participant 6 (ID=6.0): _reward=0.90, _penalty=0.76
2025-03-25 23:16:31,306 - INFO - Participant 7 (ID=7.0): _reward=0.99, _penalty=0.72
2025-03-25 23:16:31,312 - INFO - Participant 8 (ID=8.0): _reward=0.69, _penalty=0.55
2025-03-25 23:16:31,318 - INFO - Participant 9 (ID=9.0): _reward=0.75, _penalty=0.54
2025-03-25 23:16:31,324 - INFO - Participant 10 (ID=10.0): _reward=0.96, _penalty=0.29
2025-03-25 23:16:31,329 - INFO - Participant 11 (ID=11.0): _reward=0.20, _penalty=0.44
2025-03-25 23:16:31,335 - INFO - Participant 12 (ID=12.0): _reward=0.98, _penalty=0.09
2025-03-25 23:16:31,341 - INFO - Participant 13 (ID=13.0): _reward=0.72, _penalty=0.65
2025-03-25 23:16:31,347 - INFO - Participant 14 (ID=14.0): _reward=0.62, _penalty=0.57
2025-03-25 23:16:31,352 - INFO - Participant 15 (ID=15.0): _reward=0.37, _penalty=0.51
2025-03-25 23:16:31,358 - INFO - Participant 16 (ID=16.0): _reward=0.02, _penalty=0.24
2025-03-25 23:16:31,364 - INFO - Participant 17 (ID=17.0): _reward=0.78, _penalty=0.69
2025-03-25 23:16:31,370 - INFO - Participant 18 (ID=18.0): _reward=0.85, _penalty=0.10
2025-03-25 23:16:31,375 - INFO - Participant 19 (ID=19.0): _reward=0.51, _penalty=0.04
2025-03-25 23:16:31,381 - INFO - Participant 20 (ID=20.0): _reward=0.06, _penalty=0.90
2025-03-25 23:16:31,387 - INFO - Participant 21 (ID=21.0): _reward=0.71, _penalty=0.34
2025-03-25 23:16:31,393 - INFO - Participant 22 (ID=22.0): _reward=0.75, _penalty=0.02
2025-03-25 23:16:31,398 - INFO - Participant 23 (ID=23.0): _reward=0.86, _penalty=0.99
2025-03-25 23:16:31,404 - INFO - Participant 24 (ID=24.0): _reward=0.10, _penalty=0.10
2025-03-25 23:16:31,410 - INFO - Participant 25 (ID=25.0): _reward=0.26, _penalty=0.98
2025-03-25 23:16:31,415 - INFO - Participant 26 (ID=26.0): _reward=0.08, _penalty=0.97
2025-03-25 23:16:31,421 - INFO - Participant 27 (ID=27.0): _reward=0.52, _penalty=0.46
2025-03-25 23:16:31,427 - INFO - Participant 28 (ID=28.0): _reward=0.13, _penalty=0.90
2025-03-25 23:16:31,432 - INFO - Participant 29 (ID=29.0): _reward=0.11, _penalty=0.64
2025-03-25 23:16:31,438 - INFO - Participant 30 (ID=30.0): _reward=0.08, _penalty=0.39
2025-03-25 23:16:31,444 - INFO - Participant 31 (ID=31.0): _reward=0.23, _penalty=0.30
2025-03-25 23:16:31,444 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,444 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:16:31,445 - INFO - Combined xs shape after concatenation: torch.Size([32, 200, 5])
2025-03-25 23:16:31,445 - INFO - Combined ys shape after concatenation: torch.Size([32, 200, 2])
2025-03-25 23:16:31,445 - INFO - Combined dataset shape: X=torch.Size([32, 200, 5]), Y=torch.Size([32, 200, 2])
2025-03-25 23:16:31,445 - INFO - Total unique participants: 32
2025-03-25 23:16:31,445 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-25 23:16:31,445 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,445 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,445 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,445 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,445 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,445 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,445 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,445 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,446 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,447 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-25 23:16:31,447 - INFO - Train xs shape: torch.Size([32, 140, 5])
2025-03-25 23:16:31,447 - INFO - Train ys shape: torch.Size([32, 140, 2])
2025-03-25 23:16:31,447 - INFO - Validation xs shape: torch.Size([32, 60, 5])
2025-03-25 23:16:31,447 - INFO - Validation ys shape: torch.Size([32, 60, 2])
2025-03-25 23:16:31,447 - INFO - Train dataset: torch.Size([32, 140, 5]), Validation dataset: torch.Size([32, 60, 5])
2025-03-25 23:16:31,447 - INFO - Starting hyperparameter optimization...
2025-03-25 23:16:31,448 - INFO - Trial 0: dropout=0.250, lr=0.001735, hidden_size=11, embedding_size=15, n_steps=25
2025-03-25 23:16:31,907 - ERROR - Trial 0 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,908 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,908 - INFO - Trial 1: dropout=0.151, lr=0.006113, hidden_size=28, embedding_size=25, n_steps=10
2025-03-25 23:16:31,909 - ERROR - Trial 1 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,910 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,910 - INFO - Trial 2: dropout=0.192, lr=0.000164, hidden_size=31, embedding_size=11, n_steps=4
2025-03-25 23:16:31,911 - ERROR - Trial 2 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,911 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,912 - INFO - Trial 3: dropout=0.239, lr=0.001722, hidden_size=23, embedding_size=14, n_steps=25
2025-03-25 23:16:31,912 - ERROR - Trial 3 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,912 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,913 - INFO - Trial 4: dropout=0.235, lr=0.004797, hidden_size=29, embedding_size=8, n_steps=1
2025-03-25 23:16:31,914 - ERROR - Trial 4 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,914 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,915 - INFO - Trial 5: dropout=0.280, lr=0.001239, hidden_size=10, embedding_size=19, n_steps=7
2025-03-25 23:16:31,915 - ERROR - Trial 5 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,916 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,916 - INFO - Trial 6: dropout=0.234, lr=0.001038, hidden_size=21, embedding_size=22, n_steps=9
2025-03-25 23:16:31,917 - ERROR - Trial 6 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,917 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,918 - INFO - Trial 7: dropout=0.130, lr=0.000213, hidden_size=32, embedding_size=30, n_steps=3
2025-03-25 23:16:31,918 - ERROR - Trial 7 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,918 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,919 - INFO - Trial 8: dropout=0.188, lr=0.009313, hidden_size=14, embedding_size=11, n_steps=2
2025-03-25 23:16:31,920 - ERROR - Trial 8 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,920 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,920 - INFO - Trial 9: dropout=0.163, lr=0.006919, hidden_size=21, embedding_size=23, n_steps=30
2025-03-25 23:16:31,921 - ERROR - Trial 9 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,921 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,931 - INFO - Trial 10: dropout=0.296, lr=0.000349, hidden_size=14, embedding_size=17, n_steps=20
2025-03-25 23:16:31,932 - ERROR - Trial 10 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,932 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,942 - INFO - Trial 11: dropout=0.100, lr=0.003000, hidden_size=25, embedding_size=27, n_steps=15
2025-03-25 23:16:31,943 - ERROR - Trial 11 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,943 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,953 - INFO - Trial 12: dropout=0.150, lr=0.000541, hidden_size=16, embedding_size=26, n_steps=15
2025-03-25 23:16:31,954 - ERROR - Trial 12 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,954 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,963 - INFO - Trial 13: dropout=0.214, lr=0.002455, hidden_size=9, embedding_size=16, n_steps=22
2025-03-25 23:16:31,964 - ERROR - Trial 13 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,964 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,974 - INFO - Trial 14: dropout=0.265, lr=0.004275, hidden_size=26, embedding_size=31, n_steps=32
2025-03-25 23:16:31,975 - ERROR - Trial 14 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,975 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,985 - INFO - Trial 15: dropout=0.173, lr=0.000630, hidden_size=16, embedding_size=24, n_steps=11
2025-03-25 23:16:31,986 - ERROR - Trial 15 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,986 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:31,996 - INFO - Trial 16: dropout=0.126, lr=0.002298, hidden_size=28, embedding_size=20, n_steps=26
2025-03-25 23:16:31,996 - ERROR - Trial 16 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:31,997 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,007 - INFO - Trial 17: dropout=0.217, lr=0.005101, hidden_size=18, embedding_size=27, n_steps=19
2025-03-25 23:16:32,008 - ERROR - Trial 17 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,008 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,017 - INFO - Trial 18: dropout=0.266, lr=0.009542, hidden_size=11, embedding_size=14, n_steps=12
2025-03-25 23:16:32,018 - ERROR - Trial 18 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,018 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,026 - INFO - Trial 19: dropout=0.145, lr=0.001470, hidden_size=8, embedding_size=18, n_steps=25
2025-03-25 23:16:32,027 - ERROR - Trial 19 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,027 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,037 - INFO - Trial 20: dropout=0.103, lr=0.000642, hidden_size=24, embedding_size=21, n_steps=18
2025-03-25 23:16:32,038 - ERROR - Trial 20 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,038 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,048 - INFO - Trial 21: dropout=0.190, lr=0.000114, hidden_size=32, embedding_size=11, n_steps=6
2025-03-25 23:16:32,049 - ERROR - Trial 21 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,049 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,059 - INFO - Trial 22: dropout=0.174, lr=0.000123, hidden_size=29, embedding_size=8, n_steps=6
2025-03-25 23:16:32,060 - ERROR - Trial 22 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,060 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,071 - INFO - Trial 23: dropout=0.208, lr=0.000274, hidden_size=27, embedding_size=11, n_steps=12
2025-03-25 23:16:32,071 - ERROR - Trial 23 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,072 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,082 - INFO - Trial 24: dropout=0.191, lr=0.000185, hidden_size=31, embedding_size=14, n_steps=4
2025-03-25 23:16:32,083 - ERROR - Trial 24 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,083 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,094 - INFO - Trial 25: dropout=0.259, lr=0.000463, hidden_size=30, embedding_size=16, n_steps=9
2025-03-25 23:16:32,094 - ERROR - Trial 25 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,095 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,106 - INFO - Trial 26: dropout=0.156, lr=0.003317, hidden_size=23, embedding_size=12, n_steps=28
2025-03-25 23:16:32,107 - ERROR - Trial 26 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,107 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,117 - INFO - Trial 27: dropout=0.129, lr=0.000755, hidden_size=12, embedding_size=25, n_steps=22
2025-03-25 23:16:32,118 - ERROR - Trial 27 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,118 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,129 - INFO - Trial 28: dropout=0.226, lr=0.001908, hidden_size=19, embedding_size=29, n_steps=15
2025-03-25 23:16:32,130 - ERROR - Trial 28 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,130 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,142 - INFO - Trial 29: dropout=0.248, lr=0.000933, hidden_size=23, embedding_size=14, n_steps=9
2025-03-25 23:16:32,142 - ERROR - Trial 29 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,143 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,153 - INFO - Trial 30: dropout=0.175, lr=0.000389, hidden_size=27, embedding_size=9, n_steps=5
2025-03-25 23:16:32,154 - ERROR - Trial 30 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,155 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,166 - INFO - Trial 31: dropout=0.242, lr=0.001579, hidden_size=29, embedding_size=13, n_steps=25
2025-03-25 23:16:32,167 - ERROR - Trial 31 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,167 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,178 - INFO - Trial 32: dropout=0.288, lr=0.004952, hidden_size=30, embedding_size=9, n_steps=1
2025-03-25 23:16:32,179 - ERROR - Trial 32 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,179 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,190 - INFO - Trial 33: dropout=0.230, lr=0.001156, hidden_size=21, embedding_size=16, n_steps=23
2025-03-25 23:16:32,191 - ERROR - Trial 33 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,191 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,204 - INFO - Trial 34: dropout=0.251, lr=0.003698, hidden_size=23, embedding_size=19, n_steps=27
2025-03-25 23:16:32,205 - ERROR - Trial 34 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,205 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,216 - INFO - Trial 35: dropout=0.273, lr=0.000851, hidden_size=25, embedding_size=15, n_steps=29
2025-03-25 23:16:32,217 - ERROR - Trial 35 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,218 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,229 - INFO - Trial 36: dropout=0.206, lr=0.006043, hidden_size=32, embedding_size=12, n_steps=17
2025-03-25 23:16:32,230 - ERROR - Trial 36 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,230 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,241 - INFO - Trial 37: dropout=0.224, lr=0.001546, hidden_size=27, embedding_size=22, n_steps=8
2025-03-25 23:16:32,242 - ERROR - Trial 37 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,242 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,254 - INFO - Trial 38: dropout=0.235, lr=0.002583, hidden_size=19, embedding_size=18, n_steps=21
2025-03-25 23:16:32,255 - ERROR - Trial 38 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,255 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,267 - INFO - Trial 39: dropout=0.200, lr=0.007044, hidden_size=13, embedding_size=9, n_steps=32
2025-03-25 23:16:32,268 - ERROR - Trial 39 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,268 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,279 - INFO - Trial 40: dropout=0.284, lr=0.001963, hidden_size=16, embedding_size=29, n_steps=3
2025-03-25 23:16:32,280 - ERROR - Trial 40 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,280 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,292 - INFO - Trial 41: dropout=0.250, lr=0.006612, hidden_size=30, embedding_size=10, n_steps=1
2025-03-25 23:16:32,293 - ERROR - Trial 41 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,293 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,305 - INFO - Trial 42: dropout=0.235, lr=0.003951, hidden_size=29, embedding_size=12, n_steps=3
2025-03-25 23:16:32,305 - ERROR - Trial 42 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,306 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,318 - INFO - Trial 43: dropout=0.139, lr=0.007909, hidden_size=25, embedding_size=8, n_steps=24
2025-03-25 23:16:32,318 - ERROR - Trial 43 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,319 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,330 - INFO - Trial 44: dropout=0.222, lr=0.002793, hidden_size=28, embedding_size=10, n_steps=7
2025-03-25 23:16:32,331 - ERROR - Trial 44 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,331 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,343 - INFO - Trial 45: dropout=0.274, lr=0.005368, hidden_size=31, embedding_size=32, n_steps=13
2025-03-25 23:16:32,344 - ERROR - Trial 45 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,344 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,356 - INFO - Trial 46: dropout=0.116, lr=0.001255, hidden_size=21, embedding_size=13, n_steps=4
2025-03-25 23:16:32,357 - ERROR - Trial 46 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,357 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,369 - INFO - Trial 47: dropout=0.166, lr=0.002151, hidden_size=26, embedding_size=23, n_steps=10
2025-03-25 23:16:32,370 - ERROR - Trial 47 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,370 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,382 - INFO - Trial 48: dropout=0.261, lr=0.000184, hidden_size=10, embedding_size=17, n_steps=2
2025-03-25 23:16:32,383 - ERROR - Trial 48 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,383 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,395 - INFO - Trial 49: dropout=0.298, lr=0.008233, hidden_size=28, embedding_size=10, n_steps=19
2025-03-25 23:16:32,396 - ERROR - Trial 49 failed: Expected positive integer T_0, but got 0
2025-03-25 23:16:32,396 - ERROR - Traceback (most recent call last):
  File "/home/daniel/repositories/closedloop_rl/analysis/rnn_withinsubject_finetuning.py", line 235, in objective
    model_rnn, optimizer_rnn, final_train_loss = fit_model(
                                                 ^^^^^^^^^^
  File "/home/daniel/repositories/closedloop_rl/resources/rnn_training.py", line 135, in fit_model
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_steps, T_mult=2)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniel/miniconda3/envs/rl/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 1749, in __init__
    raise ValueError(f"Expected positive integer T_0, but got {T_0}")
ValueError: Expected positive integer T_0, but got 0

2025-03-25 23:16:32,396 - INFO - Best hyperparameters: {'dropout': 0.24994471412439978, 'learning_rate': 0.001734811566291648, 'hidden_size': 11, 'embedding_size': 15, 'n_steps': 25}
2025-03-25 23:16:32,396 - INFO - Best validation loss: inf
2025-03-25 23:17:18,152 - INFO - ================================================================================
2025-03-25 23:17:18,152 - INFO - EXPERIMENT CONFIG
2025-03-25 23:17:18,152 - INFO - ================================================================================
2025-03-25 23:17:18,152 - INFO - Found 48 data files: ['data_32p_7.csv', 'data_32p_4.csv', 'data_64p_5.csv', 'data_16p_6.csv', 'data_32p_1.csv', 'data_16p_1.csv', 'data_256p_7.csv', 'data_512p_6.csv', 'data_32p_5.csv', 'data_512p_5.csv', 'data_128p_4.csv', 'data_128p_6.csv', 'data_64p_4.csv', 'data_256p_2.csv', 'data_512p_1.csv', 'data_512p_3.csv', 'data_512p_2.csv', 'data_64p_1.csv', 'data_256p_3.csv', 'data_16p_7.csv', 'data_32p_2.csv', 'data_16p_2.csv', 'data_256p_0.csv', 'data_256p_1.csv', 'data_16p_3.csv', 'data_32p_6.csv', 'data_32p_3.csv', 'data_16p_0.csv', 'data_256p_4.csv', 'data_128p_1.csv', 'data_64p_6.csv', 'data_64p_3.csv', 'data_128p_5.csv', 'data_256p_5.csv', 'data_32p_0.csv', 'data_128p_7.csv', 'data_256p_6.csv', 'data_64p_0.csv', 'data_16p_5.csv', 'data_128p_2.csv', 'data_128p_0.csv', 'data_512p_4.csv', 'data_512p_7.csv', 'data_16p_4.csv', 'data_128p_3.csv', 'data_64p_7.csv', 'data_64p_2.csv', 'data_512p_0.csv']
2025-03-25 23:17:18,153 - INFO - Processing dataset: data_32p_7.csv
2025-03-25 23:17:18,153 - INFO - Loading dataset from data/parameter_recovery_participants/data_32p_7.csv
2025-03-25 23:17:18,163 - INFO - Number of participants: 32
2025-03-25 23:17:18,169 - INFO - Participant 0 (ID=0.0): _reward=0.35, _penalty=0.60
2025-03-25 23:17:18,174 - INFO - Participant 1 (ID=1.0): _reward=0.61, _penalty=0.97
2025-03-25 23:17:18,179 - INFO - Participant 2 (ID=2.0): _reward=0.11, _penalty=0.54
2025-03-25 23:17:18,184 - INFO - Participant 3 (ID=3.0): _reward=0.16, _penalty=0.33
2025-03-25 23:17:18,190 - INFO - Participant 4 (ID=4.0): _reward=0.89, _penalty=0.91
2025-03-25 23:17:18,195 - INFO - Participant 5 (ID=5.0): _reward=0.18, _penalty=0.35
2025-03-25 23:17:18,200 - INFO - Participant 6 (ID=6.0): _reward=0.90, _penalty=0.76
2025-03-25 23:17:18,205 - INFO - Participant 7 (ID=7.0): _reward=0.99, _penalty=0.72
2025-03-25 23:17:18,210 - INFO - Participant 8 (ID=8.0): _reward=0.69, _penalty=0.55
2025-03-25 23:17:18,215 - INFO - Participant 9 (ID=9.0): _reward=0.75, _penalty=0.54
2025-03-25 23:17:18,221 - INFO - Participant 10 (ID=10.0): _reward=0.96, _penalty=0.29
2025-03-25 23:17:18,226 - INFO - Participant 11 (ID=11.0): _reward=0.20, _penalty=0.44
2025-03-25 23:17:18,231 - INFO - Participant 12 (ID=12.0): _reward=0.98, _penalty=0.09
2025-03-25 23:17:18,236 - INFO - Participant 13 (ID=13.0): _reward=0.72, _penalty=0.65
2025-03-25 23:17:18,241 - INFO - Participant 14 (ID=14.0): _reward=0.62, _penalty=0.57
2025-03-25 23:17:18,246 - INFO - Participant 15 (ID=15.0): _reward=0.37, _penalty=0.51
2025-03-25 23:17:18,252 - INFO - Participant 16 (ID=16.0): _reward=0.02, _penalty=0.24
2025-03-25 23:17:18,259 - INFO - Participant 17 (ID=17.0): _reward=0.78, _penalty=0.69
2025-03-25 23:17:18,265 - INFO - Participant 18 (ID=18.0): _reward=0.85, _penalty=0.10
2025-03-25 23:17:18,271 - INFO - Participant 19 (ID=19.0): _reward=0.51, _penalty=0.04
2025-03-25 23:17:18,277 - INFO - Participant 20 (ID=20.0): _reward=0.06, _penalty=0.90
2025-03-25 23:17:18,283 - INFO - Participant 21 (ID=21.0): _reward=0.71, _penalty=0.34
2025-03-25 23:17:18,288 - INFO - Participant 22 (ID=22.0): _reward=0.75, _penalty=0.02
2025-03-25 23:17:18,295 - INFO - Participant 23 (ID=23.0): _reward=0.86, _penalty=0.99
2025-03-25 23:17:18,301 - INFO - Participant 24 (ID=24.0): _reward=0.10, _penalty=0.10
2025-03-25 23:17:18,306 - INFO - Participant 25 (ID=25.0): _reward=0.26, _penalty=0.98
2025-03-25 23:17:18,311 - INFO - Participant 26 (ID=26.0): _reward=0.08, _penalty=0.97
2025-03-25 23:17:18,317 - INFO - Participant 27 (ID=27.0): _reward=0.52, _penalty=0.46
2025-03-25 23:17:18,323 - INFO - Participant 28 (ID=28.0): _reward=0.13, _penalty=0.90
2025-03-25 23:17:18,328 - INFO - Participant 29 (ID=29.0): _reward=0.11, _penalty=0.64
2025-03-25 23:17:18,333 - INFO - Participant 30 (ID=30.0): _reward=0.08, _penalty=0.39
2025-03-25 23:17:18,339 - INFO - Participant 31 (ID=31.0): _reward=0.23, _penalty=0.30
2025-03-25 23:17:18,339 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,339 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:17:18,340 - INFO - Combined xs shape after concatenation: torch.Size([32, 200, 5])
2025-03-25 23:17:18,340 - INFO - Combined ys shape after concatenation: torch.Size([32, 200, 2])
2025-03-25 23:17:18,340 - INFO - Combined dataset shape: X=torch.Size([32, 200, 5]), Y=torch.Size([32, 200, 2])
2025-03-25 23:17:18,340 - INFO - Total unique participants: 32
2025-03-25 23:17:18,340 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-25 23:17:18,340 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,340 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,340 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,340 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,340 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,340 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,340 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,341 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,342 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,342 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,342 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,342 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-25 23:17:18,342 - INFO - Train xs shape: torch.Size([32, 140, 5])
2025-03-25 23:17:18,342 - INFO - Train ys shape: torch.Size([32, 140, 2])
2025-03-25 23:17:18,342 - INFO - Validation xs shape: torch.Size([32, 60, 5])
2025-03-25 23:17:18,342 - INFO - Validation ys shape: torch.Size([32, 60, 2])
2025-03-25 23:17:18,342 - INFO - Train dataset: torch.Size([32, 140, 5]), Validation dataset: torch.Size([32, 60, 5])
2025-03-25 23:17:18,342 - INFO - Starting hyperparameter optimization...
2025-03-25 23:17:18,343 - INFO - Trial 0: dropout=0.157, lr=0.003686, hidden_size=11, embedding_size=16, n_steps=18
2025-03-25 23:17:23,350 - INFO - Trial 0: RNN Train Loss: 0.3676244
2025-03-25 23:17:23,350 - INFO - Trial 0: Validation set has 32 participants
2025-03-25 23:17:24,228 - INFO - Trial 0: Average Validation Loss: 0.6585, Eval count: 32
2025-03-25 23:17:24,229 - INFO - Trial 1: dropout=0.123, lr=0.001047, hidden_size=30, embedding_size=11, n_steps=29
2025-03-25 23:17:30,092 - INFO - Trial 1: RNN Train Loss: 0.4883483
2025-03-25 23:17:30,092 - INFO - Trial 1: Validation set has 32 participants
2025-03-25 23:17:30,891 - INFO - Trial 1: Average Validation Loss: 0.5817, Eval count: 32
2025-03-25 23:17:30,892 - INFO - Trial 2: dropout=0.260, lr=0.000204, hidden_size=12, embedding_size=19, n_steps=8
2025-03-25 23:17:36,049 - INFO - Trial 2: RNN Train Loss: 0.4819559
2025-03-25 23:17:36,050 - INFO - Trial 2: Validation set has 32 participants
2025-03-25 23:17:36,896 - INFO - Trial 2: Average Validation Loss: 0.6491, Eval count: 32
2025-03-25 23:17:36,897 - INFO - Trial 3: dropout=0.233, lr=0.007586, hidden_size=16, embedding_size=12, n_steps=12
2025-03-25 23:17:42,957 - INFO - Trial 3: RNN Train Loss: 0.4221088
2025-03-25 23:17:42,958 - INFO - Trial 3: Validation set has 32 participants
2025-03-25 23:17:43,814 - INFO - Trial 3: Average Validation Loss: 0.5779, Eval count: 32
2025-03-25 23:17:43,815 - INFO - Trial 4: dropout=0.289, lr=0.001329, hidden_size=15, embedding_size=30, n_steps=26
2025-03-25 23:17:49,806 - INFO - Trial 4: RNN Train Loss: 0.4317782
2025-03-25 23:17:49,807 - INFO - Trial 4: Validation set has 32 participants
2025-03-25 23:17:50,734 - INFO - Trial 4: Average Validation Loss: 1.2997, Eval count: 32
2025-03-25 23:17:50,735 - INFO - Trial 5: dropout=0.249, lr=0.000132, hidden_size=20, embedding_size=23, n_steps=20
2025-03-25 23:17:56,510 - INFO - Trial 5: RNN Train Loss: 0.5701567
2025-03-25 23:17:56,510 - INFO - Trial 5: Validation set has 32 participants
2025-03-25 23:17:57,418 - INFO - Trial 5: Average Validation Loss: 1.1296, Eval count: 32
2025-03-25 23:17:57,419 - INFO - Trial 6: dropout=0.208, lr=0.001060, hidden_size=22, embedding_size=18, n_steps=11
2025-03-25 23:18:03,738 - INFO - Trial 6: RNN Train Loss: 0.4332823
2025-03-25 23:18:03,738 - INFO - Trial 6: Validation set has 32 participants
2025-03-25 23:18:04,611 - INFO - Trial 6: Average Validation Loss: 0.9292, Eval count: 32
2025-03-25 23:18:04,613 - INFO - Trial 7: dropout=0.295, lr=0.004364, hidden_size=31, embedding_size=31, n_steps=30
2025-03-25 23:18:10,777 - INFO - Trial 7: RNN Train Loss: 0.3990797
2025-03-25 23:18:10,777 - INFO - Trial 7: Validation set has 32 participants
2025-03-25 23:18:11,661 - INFO - Trial 7: Average Validation Loss: 0.5547, Eval count: 32
2025-03-25 23:18:11,662 - INFO - Trial 8: dropout=0.294, lr=0.000124, hidden_size=28, embedding_size=18, n_steps=1
2025-03-25 23:18:23,984 - INFO - Trial 8: RNN Train Loss: 0.3948706
2025-03-25 23:18:23,984 - INFO - Trial 8: Validation set has 32 participants
2025-03-25 23:18:24,905 - INFO - Trial 8: Average Validation Loss: 1.4731, Eval count: 32
2025-03-25 23:18:24,906 - INFO - Trial 9: dropout=0.178, lr=0.001411, hidden_size=21, embedding_size=25, n_steps=10
2025-03-25 23:18:31,047 - INFO - Trial 9: RNN Train Loss: 0.3877728
2025-03-25 23:18:31,048 - INFO - Trial 9: Validation set has 32 participants
2025-03-25 23:18:32,005 - INFO - Trial 9: Average Validation Loss: 0.6194, Eval count: 32
2025-03-25 23:18:32,015 - INFO - Trial 10: dropout=0.106, lr=0.008130, hidden_size=32, embedding_size=31, n_steps=31
2025-03-25 23:18:38,060 - INFO - Trial 10: RNN Train Loss: 0.4186913
2025-03-25 23:18:38,061 - INFO - Trial 10: Validation set has 32 participants
2025-03-25 23:18:38,957 - INFO - Trial 10: Average Validation Loss: 0.5458, Eval count: 32
2025-03-25 23:18:38,966 - INFO - Trial 11: dropout=0.103, lr=0.009929, hidden_size=32, embedding_size=32, n_steps=31
2025-03-25 23:18:45,111 - INFO - Trial 11: RNN Train Loss: 0.4117950
2025-03-25 23:18:45,111 - INFO - Trial 11: Validation set has 32 participants
2025-03-25 23:18:46,039 - INFO - Trial 11: Average Validation Loss: 0.5731, Eval count: 32
2025-03-25 23:18:46,048 - INFO - Trial 12: dropout=0.149, lr=0.004060, hidden_size=26, embedding_size=28, n_steps=24
2025-03-25 23:18:52,117 - INFO - Trial 12: RNN Train Loss: 0.4110048
2025-03-25 23:18:52,117 - INFO - Trial 12: Validation set has 32 participants
2025-03-25 23:18:52,960 - INFO - Trial 12: Average Validation Loss: 0.5723, Eval count: 32
2025-03-25 23:18:52,969 - INFO - Trial 13: dropout=0.210, lr=0.003199, hidden_size=27, embedding_size=26, n_steps=32
2025-03-25 23:18:59,119 - INFO - Trial 13: RNN Train Loss: 0.4128643
2025-03-25 23:18:59,119 - INFO - Trial 13: Validation set has 32 participants
2025-03-25 23:19:00,000 - INFO - Trial 13: Average Validation Loss: 0.7781, Eval count: 32
2025-03-25 23:19:00,010 - INFO - Trial 14: dropout=0.179, lr=0.000338, hidden_size=32, embedding_size=32, n_steps=24
2025-03-25 23:19:06,218 - INFO - Trial 14: RNN Train Loss: 0.4914655
2025-03-25 23:19:06,218 - INFO - Trial 14: Validation set has 32 participants
2025-03-25 23:19:07,128 - INFO - Trial 14: Average Validation Loss: 0.7871, Eval count: 32
2025-03-25 23:19:07,137 - INFO - Trial 15: dropout=0.269, lr=0.005837, hidden_size=27, embedding_size=28, n_steps=27
2025-03-25 23:19:13,360 - INFO - Trial 15: RNN Train Loss: 0.4189604
2025-03-25 23:19:13,360 - INFO - Trial 15: Validation set has 32 participants
2025-03-25 23:19:14,229 - INFO - Trial 15: Average Validation Loss: 0.6059, Eval count: 32
2025-03-25 23:19:14,239 - INFO - Trial 16: dropout=0.233, lr=0.002144, hidden_size=24, embedding_size=22, n_steps=21
2025-03-25 23:19:20,350 - INFO - Trial 16: RNN Train Loss: 0.4279175
2025-03-25 23:19:20,350 - INFO - Trial 16: Validation set has 32 participants
2025-03-25 23:19:21,270 - INFO - Trial 16: Average Validation Loss: 0.6955, Eval count: 32
2025-03-25 23:19:21,279 - INFO - Trial 17: dropout=0.133, lr=0.005347, hidden_size=8, embedding_size=29, n_steps=15
2025-03-25 23:19:26,304 - INFO - Trial 17: RNN Train Loss: 0.3758034
2025-03-25 23:19:26,304 - INFO - Trial 17: Validation set has 32 participants
2025-03-25 23:19:27,285 - INFO - Trial 17: Average Validation Loss: 0.5834, Eval count: 32
2025-03-25 23:19:27,295 - INFO - Trial 18: dropout=0.101, lr=0.000484, hidden_size=30, embedding_size=25, n_steps=32
2025-03-25 23:19:33,096 - INFO - Trial 18: RNN Train Loss: 0.5305786
2025-03-25 23:19:33,097 - INFO - Trial 18: Validation set has 32 participants
2025-03-25 23:19:33,978 - INFO - Trial 18: Average Validation Loss: 0.8654, Eval count: 32
2025-03-25 23:19:33,987 - INFO - Trial 19: dropout=0.185, lr=0.002439, hidden_size=24, embedding_size=22, n_steps=28
2025-03-25 23:19:40,055 - INFO - Trial 19: RNN Train Loss: 0.4327149
2025-03-25 23:19:40,055 - INFO - Trial 19: Validation set has 32 participants
2025-03-25 23:19:40,971 - INFO - Trial 19: Average Validation Loss: 0.5544, Eval count: 32
2025-03-25 23:19:40,982 - INFO - Trial 20: dropout=0.183, lr=0.002168, hidden_size=18, embedding_size=15, n_steps=22
2025-03-25 23:19:47,017 - INFO - Trial 20: RNN Train Loss: 0.3714041
2025-03-25 23:19:47,017 - INFO - Trial 20: Validation set has 32 participants
2025-03-25 23:19:47,902 - INFO - Trial 20: Average Validation Loss: 0.7211, Eval count: 32
2025-03-25 23:19:47,912 - INFO - Trial 21: dropout=0.161, lr=0.002452, hidden_size=24, embedding_size=21, n_steps=28
2025-03-25 23:19:53,882 - INFO - Trial 21: RNN Train Loss: 0.4890878
2025-03-25 23:19:53,883 - INFO - Trial 21: Validation set has 32 participants
2025-03-25 23:19:54,768 - INFO - Trial 21: Average Validation Loss: 0.5994, Eval count: 32
2025-03-25 23:19:54,778 - INFO - Trial 22: dropout=0.225, lr=0.009340, hidden_size=30, embedding_size=9, n_steps=29
2025-03-25 23:20:00,696 - INFO - Trial 22: RNN Train Loss: 0.3997440
2025-03-25 23:20:00,697 - INFO - Trial 22: Validation set has 32 participants
2025-03-25 23:20:01,656 - INFO - Trial 22: Average Validation Loss: 0.6109, Eval count: 32
2025-03-25 23:20:01,667 - INFO - Trial 23: dropout=0.130, lr=0.005729, hidden_size=24, embedding_size=31, n_steps=25
2025-03-25 23:20:02,275 - INFO - Trial 23: RNN Train Loss: 0.4532394
2025-03-25 23:20:02,276 - INFO - Trial 23: Validation set has 32 participants
2025-03-25 23:25:01,469 - INFO - ================================================================================
2025-03-25 23:25:01,469 - INFO - EXPERIMENT CONFIG
2025-03-25 23:25:01,469 - INFO - ================================================================================
2025-03-25 23:25:01,469 - INFO - Found 1 data files: ['data_16p_0.csv']
2025-03-25 23:25:01,470 - INFO - Processing dataset: data_16p_0.csv
2025-03-25 23:25:01,470 - INFO - Loading dataset from data/optuna/data_16p_0.csv
2025-03-25 23:25:01,476 - INFO - Number of participants: 16
2025-03-25 23:25:01,482 - INFO - Participant 0 (ID=0.0): _reward=0.69, _penalty=0.25
2025-03-25 23:25:01,488 - INFO - Participant 1 (ID=1.0): _reward=0.93, _penalty=0.61
2025-03-25 23:25:01,493 - INFO - Participant 2 (ID=2.0): _reward=0.67, _penalty=0.78
2025-03-25 23:25:01,499 - INFO - Participant 3 (ID=3.0): _reward=0.43, _penalty=0.85
2025-03-25 23:25:01,504 - INFO - Participant 4 (ID=4.0): _reward=0.47, _penalty=0.44
2025-03-25 23:25:01,509 - INFO - Participant 5 (ID=5.0): _reward=0.48, _penalty=0.38
2025-03-25 23:25:01,515 - INFO - Participant 6 (ID=6.0): _reward=0.89, _penalty=0.25
2025-03-25 23:25:01,520 - INFO - Participant 7 (ID=7.0): _reward=0.27, _penalty=0.72
2025-03-25 23:25:01,526 - INFO - Participant 8 (ID=8.0): _reward=0.70, _penalty=0.69
2025-03-25 23:25:01,531 - INFO - Participant 9 (ID=9.0): _reward=0.01, _penalty=0.64
2025-03-25 23:25:01,536 - INFO - Participant 10 (ID=10.0): _reward=0.27, _penalty=0.48
2025-03-25 23:25:01,542 - INFO - Participant 11 (ID=11.0): _reward=0.65, _penalty=0.74
2025-03-25 23:25:01,547 - INFO - Participant 12 (ID=12.0): _reward=0.18, _penalty=0.08
2025-03-25 23:25:01,553 - INFO - Participant 13 (ID=13.0): _reward=0.54, _penalty=0.45
2025-03-25 23:25:01,558 - INFO - Participant 14 (ID=14.0): _reward=0.69, _penalty=0.39
2025-03-25 23:25:01,563 - INFO - Participant 15 (ID=15.0): _reward=0.28, _penalty=0.68
2025-03-25 23:25:01,564 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-25 23:25:01,564 - INFO - Combined xs shape after concatenation: torch.Size([16, 200, 5])
2025-03-25 23:25:01,564 - INFO - Combined ys shape after concatenation: torch.Size([16, 200, 2])
2025-03-25 23:25:01,564 - INFO - Combined dataset shape: X=torch.Size([16, 200, 5]), Y=torch.Size([16, 200, 2])
2025-03-25 23:25:01,564 - INFO - Total unique participants: 16
2025-03-25 23:25:01,564 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-25 23:25:01,564 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,564 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-25 23:25:01,565 - INFO - Train xs shape: torch.Size([16, 140, 5])
2025-03-25 23:25:01,565 - INFO - Train ys shape: torch.Size([16, 140, 2])
2025-03-25 23:25:01,565 - INFO - Validation xs shape: torch.Size([16, 60, 5])
2025-03-25 23:25:01,565 - INFO - Validation ys shape: torch.Size([16, 60, 2])
2025-03-25 23:25:01,565 - INFO - Train dataset: torch.Size([16, 140, 5]), Validation dataset: torch.Size([16, 60, 5])
2025-03-25 23:25:01,565 - INFO - Starting hyperparameter optimization...
2025-03-25 23:25:01,566 - INFO - Trial 0: dropout=0.187, lr=0.002585, hidden_size=28, embedding_size=27, n_steps=31
2025-03-25 23:25:11,989 - INFO - Trial 0: RNN Train Loss: 0.2821051
2025-03-25 23:25:11,990 - INFO - Trial 0: Validation set has 16 participants
2025-03-25 23:25:12,441 - INFO - Trial 0: Average Validation Loss: 0.6068, Eval count: 16
2025-03-25 23:25:12,442 - INFO - Trial 1: dropout=0.174, lr=0.000279, hidden_size=9, embedding_size=16, n_steps=3
2025-03-25 23:25:25,153 - INFO - Trial 1: RNN Train Loss: 0.2787278
2025-03-25 23:25:25,153 - INFO - Trial 1: Validation set has 16 participants
2025-03-25 23:25:25,588 - INFO - Trial 1: Average Validation Loss: 0.5727, Eval count: 16
2025-03-25 23:25:25,588 - INFO - Best hyperparameters: {'dropout': 0.17357664015332547, 'learning_rate': 0.00027911148629628765, 'hidden_size': 9, 'embedding_size': 16, 'n_steps': 3}
2025-03-25 23:25:25,588 - INFO - Best validation loss: 0.5727
2025-03-25 23:25:39,822 - INFO - Final RNN training loss: 0.4331538
2025-03-25 23:25:39,823 - INFO - Evaluating with SINDy - fitting separate models for each participant's validation trials
2025-03-25 23:25:39,823 - INFO - Processing participant 0.0...
2025-03-25 23:25:39,823 - INFO - Fitting SINDy model for participant 0.0
2025-03-25 23:25:41,051 - INFO - Participant 0.0: LL=-3.4526, BIC=7.5194, Params=9, Val trials=60
2025-03-25 23:25:41,051 - INFO - Processing participant 1.0...
2025-03-25 23:25:41,052 - INFO - Fitting SINDy model for participant 1.0
2025-03-25 23:25:42,322 - INFO - Participant 1.0: LL=-3.4306, BIC=7.5435, Params=10, Val trials=60
2025-03-25 23:25:42,322 - INFO - Processing participant 2.0...
2025-03-25 23:25:42,323 - INFO - Fitting SINDy model for participant 2.0
2025-03-25 23:25:43,569 - INFO - Participant 2.0: LL=-5.0730, BIC=10.6236, Params=7, Val trials=60
2025-03-25 23:25:43,569 - INFO - Processing participant 3.0...
2025-03-25 23:25:43,570 - INFO - Fitting SINDy model for participant 3.0
2025-03-25 23:25:44,762 - INFO - Participant 3.0: LL=-3.6982, BIC=8.0105, Params=9, Val trials=60
2025-03-25 23:25:44,762 - INFO - Processing participant 4.0...
2025-03-25 23:25:44,763 - INFO - Fitting SINDy model for participant 4.0
2025-03-25 23:25:46,005 - INFO - Participant 4.0: LL=-2.5971, BIC=5.8083, Params=9, Val trials=60
2025-03-25 23:25:46,005 - INFO - Processing participant 5.0...
2025-03-25 23:25:46,005 - INFO - Fitting SINDy model for participant 5.0
2025-03-25 23:25:47,246 - INFO - Participant 5.0: LL=-9.1081, BIC=18.6938, Params=7, Val trials=60
2025-03-25 23:25:47,247 - INFO - Processing participant 6.0...
2025-03-25 23:25:47,247 - INFO - Fitting SINDy model for participant 6.0
2025-03-25 23:25:48,494 - INFO - Participant 6.0: LL=-7.1002, BIC=14.8827, Params=10, Val trials=60
2025-03-25 23:25:48,494 - INFO - Processing participant 7.0...
2025-03-25 23:25:48,494 - INFO - Fitting SINDy model for participant 7.0
2025-03-25 23:25:49,672 - INFO - Participant 7.0: LL=-0.7618, BIC=2.2059, Params=10, Val trials=60
2025-03-25 23:25:49,672 - INFO - Processing participant 8.0...
2025-03-25 23:25:49,672 - INFO - Fitting SINDy model for participant 8.0
2025-03-25 23:25:50,932 - INFO - Participant 8.0: LL=-5.5287, BIC=11.5351, Params=7, Val trials=60
2025-03-25 23:25:50,932 - INFO - Processing participant 9.0...
2025-03-25 23:25:50,932 - INFO - Fitting SINDy model for participant 9.0
2025-03-25 23:25:52,167 - INFO - Participant 9.0: LL=-7.2114, BIC=14.9005, Params=7, Val trials=60
2025-03-25 23:25:52,167 - INFO - Processing participant 10.0...
2025-03-25 23:25:52,168 - INFO - Fitting SINDy model for participant 10.0
2025-03-25 23:25:53,391 - INFO - Participant 10.0: LL=-4.2031, BIC=8.8838, Params=7, Val trials=60
2025-03-25 23:25:53,392 - INFO - Processing participant 11.0...
2025-03-25 23:25:53,392 - INFO - Fitting SINDy model for participant 11.0
2025-03-25 23:25:54,645 - INFO - Participant 11.0: LL=-6.8528, BIC=14.1832, Params=7, Val trials=60
2025-03-25 23:25:54,645 - INFO - Processing participant 12.0...
2025-03-25 23:25:54,646 - INFO - Fitting SINDy model for participant 12.0
2025-03-25 23:25:55,823 - INFO - Participant 12.0: LL=-2.1656, BIC=4.9453, Params=9, Val trials=60
2025-03-25 23:25:55,823 - INFO - Processing participant 13.0...
2025-03-25 23:25:55,824 - INFO - Fitting SINDy model for participant 13.0
2025-03-25 23:25:57,085 - INFO - Participant 13.0: LL=-5.8401, BIC=12.2260, Params=8, Val trials=60
2025-03-25 23:25:57,085 - INFO - Processing participant 14.0...
2025-03-25 23:25:57,086 - INFO - Fitting SINDy model for participant 14.0
2025-03-25 23:25:58,353 - INFO - Participant 14.0: LL=-1.0347, BIC=2.7517, Params=10, Val trials=60
2025-03-25 23:25:58,353 - INFO - Processing participant 15.0...
2025-03-25 23:25:58,354 - INFO - Fitting SINDy model for participant 15.0
2025-03-25 23:25:59,594 - INFO - Participant 15.0: LL=-2.5290, BIC=5.6722, Params=9, Val trials=60
2025-03-25 23:25:59,595 - INFO - Number of participants with valid BIC metrics: 16/16
2025-03-25 23:25:59,595 - INFO - Average SINDy BIC: 9.3991
2025-03-25 23:25:59,595 - INFO - Average SINDy LL: -4.4117
2025-03-25 23:25:59,597 - INFO - Completed processing dataset: data_16p_0.csv
2025-03-25 23:26:00,664 - INFO - Created violin plots with 16 participant data points
2025-03-26 00:13:27,667 - INFO - ================================================================================
2025-03-26 00:13:27,668 - INFO - EXPERIMENT CONFIG
2025-03-26 00:13:27,668 - INFO - ================================================================================
2025-03-26 00:13:27,668 - INFO - Found 1 data files: ['data_128p_0.csv']
2025-03-26 00:13:27,668 - INFO - Processing dataset: data_128p_0.csv
2025-03-26 00:13:27,668 - INFO - Loading dataset from data/optuna/data_128p_0.csv
2025-03-26 00:13:27,704 - INFO - Number of participants: 128
2025-03-26 00:13:27,710 - INFO - Participant 0 (ID=0.0): _reward=0.74, _penalty=0.97
2025-03-26 00:13:27,715 - INFO - Participant 1 (ID=1.0): _reward=0.99, _penalty=0.02
2025-03-26 00:13:27,720 - INFO - Participant 2 (ID=2.0): _reward=0.77, _penalty=0.46
2025-03-26 00:13:27,725 - INFO - Participant 3 (ID=3.0): _reward=0.96, _penalty=0.60
2025-03-26 00:13:27,730 - INFO - Participant 4 (ID=4.0): _reward=0.21, _penalty=0.21
2025-03-26 00:13:27,734 - INFO - Participant 5 (ID=5.0): _reward=0.07, _penalty=0.51
2025-03-26 00:13:27,739 - INFO - Participant 6 (ID=6.0): _reward=0.23, _penalty=0.60
2025-03-26 00:13:27,744 - INFO - Participant 7 (ID=7.0): _reward=0.91, _penalty=0.80
2025-03-26 00:13:27,749 - INFO - Participant 8 (ID=8.0): _reward=0.99, _penalty=0.97
2025-03-26 00:13:27,754 - INFO - Participant 9 (ID=9.0): _reward=0.67, _penalty=0.87
2025-03-26 00:13:27,759 - INFO - Participant 10 (ID=10.0): _reward=0.08, _penalty=0.77
2025-03-26 00:13:27,764 - INFO - Participant 11 (ID=11.0): _reward=0.87, _penalty=0.31
2025-03-26 00:13:27,769 - INFO - Participant 12 (ID=12.0): _reward=0.58, _penalty=0.19
2025-03-26 00:13:27,774 - INFO - Participant 13 (ID=13.0): _reward=0.48, _penalty=0.25
2025-03-26 00:13:27,778 - INFO - Participant 14 (ID=14.0): _reward=0.34, _penalty=0.83
2025-03-26 00:13:27,783 - INFO - Participant 15 (ID=15.0): _reward=0.56, _penalty=0.80
2025-03-26 00:13:27,788 - INFO - Participant 16 (ID=16.0): _reward=0.47, _penalty=0.29
2025-03-26 00:13:27,793 - INFO - Participant 17 (ID=17.0): _reward=0.77, _penalty=0.94
2025-03-26 00:13:27,798 - INFO - Participant 18 (ID=18.0): _reward=0.88, _penalty=0.01
2025-03-26 00:13:27,803 - INFO - Participant 19 (ID=19.0): _reward=0.98, _penalty=0.11
2025-03-26 00:13:27,808 - INFO - Participant 20 (ID=20.0): _reward=0.02, _penalty=0.85
2025-03-26 00:13:27,813 - INFO - Participant 21 (ID=21.0): _reward=0.46, _penalty=0.85
2025-03-26 00:13:27,818 - INFO - Participant 22 (ID=22.0): _reward=0.69, _penalty=0.43
2025-03-26 00:13:27,823 - INFO - Participant 23 (ID=23.0): _reward=0.15, _penalty=0.95
2025-03-26 00:13:27,828 - INFO - Participant 24 (ID=24.0): _reward=0.25, _penalty=0.36
2025-03-26 00:13:27,833 - INFO - Participant 25 (ID=25.0): _reward=0.75, _penalty=0.11
2025-03-26 00:13:27,838 - INFO - Participant 26 (ID=26.0): _reward=0.46, _penalty=0.81
2025-03-26 00:13:27,843 - INFO - Participant 27 (ID=27.0): _reward=0.36, _penalty=0.63
2025-03-26 00:13:27,848 - INFO - Participant 28 (ID=28.0): _reward=0.49, _penalty=0.00
2025-03-26 00:13:27,853 - INFO - Participant 29 (ID=29.0): _reward=0.20, _penalty=0.98
2025-03-26 00:13:27,858 - INFO - Participant 30 (ID=30.0): _reward=0.29, _penalty=0.64
2025-03-26 00:13:27,864 - INFO - Participant 31 (ID=31.0): _reward=0.66, _penalty=0.64
2025-03-26 00:13:27,868 - INFO - Participant 32 (ID=32.0): _reward=0.21, _penalty=0.41
2025-03-26 00:13:27,873 - INFO - Participant 33 (ID=33.0): _reward=0.49, _penalty=0.63
2025-03-26 00:13:27,878 - INFO - Participant 34 (ID=34.0): _reward=0.38, _penalty=0.08
2025-03-26 00:13:27,883 - INFO - Participant 35 (ID=35.0): _reward=0.33, _penalty=0.29
2025-03-26 00:13:27,889 - INFO - Participant 36 (ID=36.0): _reward=0.53, _penalty=0.61
2025-03-26 00:13:27,894 - INFO - Participant 37 (ID=37.0): _reward=0.65, _penalty=0.34
2025-03-26 00:13:27,899 - INFO - Participant 38 (ID=38.0): _reward=0.29, _penalty=0.13
2025-03-26 00:13:27,904 - INFO - Participant 39 (ID=39.0): _reward=0.31, _penalty=0.25
2025-03-26 00:13:27,909 - INFO - Participant 40 (ID=40.0): _reward=0.77, _penalty=0.04
2025-03-26 00:13:27,914 - INFO - Participant 41 (ID=41.0): _reward=0.23, _penalty=0.89
2025-03-26 00:13:27,919 - INFO - Participant 42 (ID=42.0): _reward=0.63, _penalty=0.60
2025-03-26 00:13:27,924 - INFO - Participant 43 (ID=43.0): _reward=0.48, _penalty=0.52
2025-03-26 00:13:27,929 - INFO - Participant 44 (ID=44.0): _reward=0.92, _penalty=0.22
2025-03-26 00:13:27,934 - INFO - Participant 45 (ID=45.0): _reward=0.52, _penalty=0.89
2025-03-26 00:13:27,939 - INFO - Participant 46 (ID=46.0): _reward=0.42, _penalty=0.83
2025-03-26 00:13:27,945 - INFO - Participant 47 (ID=47.0): _reward=0.68, _penalty=0.69
2025-03-26 00:13:27,950 - INFO - Participant 48 (ID=48.0): _reward=0.95, _penalty=0.22
2025-03-26 00:13:27,955 - INFO - Participant 49 (ID=49.0): _reward=0.13, _penalty=0.48
2025-03-26 00:13:27,960 - INFO - Participant 50 (ID=50.0): _reward=0.87, _penalty=0.85
2025-03-26 00:13:27,965 - INFO - Participant 51 (ID=51.0): _reward=0.47, _penalty=0.07
2025-03-26 00:13:27,970 - INFO - Participant 52 (ID=52.0): _reward=0.56, _penalty=0.42
2025-03-26 00:13:27,975 - INFO - Participant 53 (ID=53.0): _reward=0.53, _penalty=0.18
2025-03-26 00:13:27,980 - INFO - Participant 54 (ID=54.0): _reward=0.87, _penalty=0.73
2025-03-26 00:13:27,985 - INFO - Participant 55 (ID=55.0): _reward=0.21, _penalty=0.47
2025-03-26 00:13:27,990 - INFO - Participant 56 (ID=56.0): _reward=0.65, _penalty=0.09
2025-03-26 00:13:27,995 - INFO - Participant 57 (ID=57.0): _reward=0.72, _penalty=0.88
2025-03-26 00:13:28,000 - INFO - Participant 58 (ID=58.0): _reward=0.61, _penalty=0.38
2025-03-26 00:13:28,005 - INFO - Participant 59 (ID=59.0): _reward=0.92, _penalty=0.91
2025-03-26 00:13:28,010 - INFO - Participant 60 (ID=60.0): _reward=0.22, _penalty=0.97
2025-03-26 00:13:28,015 - INFO - Participant 61 (ID=61.0): _reward=0.41, _penalty=0.53
2025-03-26 00:13:28,020 - INFO - Participant 62 (ID=62.0): _reward=0.92, _penalty=0.99
2025-03-26 00:13:28,026 - INFO - Participant 63 (ID=63.0): _reward=0.22, _penalty=0.99
2025-03-26 00:13:28,031 - INFO - Participant 64 (ID=64.0): _reward=0.84, _penalty=0.96
2025-03-26 00:13:28,036 - INFO - Participant 65 (ID=65.0): _reward=0.55, _penalty=0.19
2025-03-26 00:13:28,041 - INFO - Participant 66 (ID=66.0): _reward=0.34, _penalty=0.07
2025-03-26 00:13:28,046 - INFO - Participant 67 (ID=67.0): _reward=0.62, _penalty=0.45
2025-03-26 00:13:28,051 - INFO - Participant 68 (ID=68.0): _reward=0.47, _penalty=0.19
2025-03-26 00:13:28,056 - INFO - Participant 69 (ID=69.0): _reward=0.81, _penalty=0.36
2025-03-26 00:13:28,061 - INFO - Participant 70 (ID=70.0): _reward=0.73, _penalty=0.87
2025-03-26 00:13:28,066 - INFO - Participant 71 (ID=71.0): _reward=0.10, _penalty=0.57
2025-03-26 00:13:28,071 - INFO - Participant 72 (ID=72.0): _reward=0.78, _penalty=0.50
2025-03-26 00:13:28,076 - INFO - Participant 73 (ID=73.0): _reward=0.82, _penalty=0.70
2025-03-26 00:13:28,081 - INFO - Participant 74 (ID=74.0): _reward=0.00, _penalty=0.98
2025-03-26 00:13:28,086 - INFO - Participant 75 (ID=75.0): _reward=0.42, _penalty=0.26
2025-03-26 00:13:28,091 - INFO - Participant 76 (ID=76.0): _reward=0.83, _penalty=0.39
2025-03-26 00:13:28,096 - INFO - Participant 77 (ID=77.0): _reward=0.75, _penalty=0.18
2025-03-26 00:13:28,101 - INFO - Participant 78 (ID=78.0): _reward=0.97, _penalty=0.44
2025-03-26 00:13:28,106 - INFO - Participant 79 (ID=79.0): _reward=0.45, _penalty=0.57
2025-03-26 00:13:28,111 - INFO - Participant 80 (ID=80.0): _reward=0.63, _penalty=0.78
2025-03-26 00:13:28,116 - INFO - Participant 81 (ID=81.0): _reward=0.29, _penalty=0.24
2025-03-26 00:13:28,121 - INFO - Participant 82 (ID=82.0): _reward=0.71, _penalty=0.15
2025-03-26 00:13:28,127 - INFO - Participant 83 (ID=83.0): _reward=0.71, _penalty=0.66
2025-03-26 00:13:28,132 - INFO - Participant 84 (ID=84.0): _reward=0.97, _penalty=0.79
2025-03-26 00:13:28,136 - INFO - Participant 85 (ID=85.0): _reward=1.00, _penalty=0.95
2025-03-26 00:13:28,142 - INFO - Participant 86 (ID=86.0): _reward=0.56, _penalty=0.08
2025-03-26 00:13:28,147 - INFO - Participant 87 (ID=87.0): _reward=0.59, _penalty=0.83
2025-03-26 00:13:28,152 - INFO - Participant 88 (ID=88.0): _reward=0.32, _penalty=0.60
2025-03-26 00:13:28,157 - INFO - Participant 89 (ID=89.0): _reward=0.20, _penalty=0.84
2025-03-26 00:13:28,162 - INFO - Participant 90 (ID=90.0): _reward=0.34, _penalty=1.00
2025-03-26 00:13:28,167 - INFO - Participant 91 (ID=91.0): _reward=0.19, _penalty=0.99
2025-03-26 00:13:28,172 - INFO - Participant 92 (ID=92.0): _reward=0.20, _penalty=0.91
2025-03-26 00:13:28,177 - INFO - Participant 93 (ID=93.0): _reward=0.31, _penalty=0.21
2025-03-26 00:13:28,182 - INFO - Participant 94 (ID=94.0): _reward=0.58, _penalty=0.41
2025-03-26 00:13:28,187 - INFO - Participant 95 (ID=95.0): _reward=0.80, _penalty=0.54
2025-03-26 00:13:28,192 - INFO - Participant 96 (ID=96.0): _reward=0.74, _penalty=0.80
2025-03-26 00:13:28,197 - INFO - Participant 97 (ID=97.0): _reward=0.59, _penalty=0.16
2025-03-26 00:13:28,202 - INFO - Participant 98 (ID=98.0): _reward=0.54, _penalty=0.17
2025-03-26 00:13:28,208 - INFO - Participant 99 (ID=99.0): _reward=0.17, _penalty=0.16
2025-03-26 00:13:28,213 - INFO - Participant 100 (ID=100.0): _reward=0.79, _penalty=0.40
2025-03-26 00:13:28,218 - INFO - Participant 101 (ID=101.0): _reward=0.32, _penalty=0.05
2025-03-26 00:13:28,223 - INFO - Participant 102 (ID=102.0): _reward=0.87, _penalty=0.81
2025-03-26 00:13:28,228 - INFO - Participant 103 (ID=103.0): _reward=0.90, _penalty=0.11
2025-03-26 00:13:28,233 - INFO - Participant 104 (ID=104.0): _reward=0.44, _penalty=0.12
2025-03-26 00:13:28,239 - INFO - Participant 105 (ID=105.0): _reward=0.59, _penalty=0.50
2025-03-26 00:13:28,244 - INFO - Participant 106 (ID=106.0): _reward=0.84, _penalty=0.50
2025-03-26 00:13:28,249 - INFO - Participant 107 (ID=107.0): _reward=0.48, _penalty=0.54
2025-03-26 00:13:28,254 - INFO - Participant 108 (ID=108.0): _reward=0.56, _penalty=0.75
2025-03-26 00:13:28,259 - INFO - Participant 109 (ID=109.0): _reward=0.53, _penalty=0.11
2025-03-26 00:13:28,264 - INFO - Participant 110 (ID=110.0): _reward=0.52, _penalty=0.40
2025-03-26 00:13:28,269 - INFO - Participant 111 (ID=111.0): _reward=0.61, _penalty=0.74
2025-03-26 00:13:28,274 - INFO - Participant 112 (ID=112.0): _reward=0.64, _penalty=0.56
2025-03-26 00:13:28,279 - INFO - Participant 113 (ID=113.0): _reward=0.44, _penalty=0.40
2025-03-26 00:13:28,284 - INFO - Participant 114 (ID=114.0): _reward=0.74, _penalty=0.91
2025-03-26 00:13:28,289 - INFO - Participant 115 (ID=115.0): _reward=0.09, _penalty=0.27
2025-03-26 00:13:28,294 - INFO - Participant 116 (ID=116.0): _reward=0.99, _penalty=0.92
2025-03-26 00:13:28,299 - INFO - Participant 117 (ID=117.0): _reward=0.90, _penalty=0.87
2025-03-26 00:13:28,304 - INFO - Participant 118 (ID=118.0): _reward=0.21, _penalty=0.27
2025-03-26 00:13:28,309 - INFO - Participant 119 (ID=119.0): _reward=0.71, _penalty=0.69
2025-03-26 00:13:28,314 - INFO - Participant 120 (ID=120.0): _reward=0.43, _penalty=0.05
2025-03-26 00:13:28,319 - INFO - Participant 121 (ID=121.0): _reward=0.11, _penalty=0.27
2025-03-26 00:13:28,324 - INFO - Participant 122 (ID=122.0): _reward=0.80, _penalty=0.43
2025-03-26 00:13:28,329 - INFO - Participant 123 (ID=123.0): _reward=0.74, _penalty=0.44
2025-03-26 00:13:28,334 - INFO - Participant 124 (ID=124.0): _reward=0.18, _penalty=0.36
2025-03-26 00:13:28,340 - INFO - Participant 125 (ID=125.0): _reward=0.86, _penalty=0.09
2025-03-26 00:13:28,345 - INFO - Participant 126 (ID=126.0): _reward=0.05, _penalty=0.52
2025-03-26 00:13:28,350 - INFO - Participant 127 (ID=127.0): _reward=0.41, _penalty=0.26
2025-03-26 00:13:28,350 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 32 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 33 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 34 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 35 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 36 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,350 - INFO - Participant 37 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 38 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 39 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 40 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 41 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 42 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 43 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 44 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 45 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 46 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 47 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 48 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 49 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 50 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 51 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 52 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 53 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 54 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 55 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 56 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 57 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 58 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 59 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 60 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 61 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 62 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 63 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 64 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 65 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 66 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 67 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 68 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 69 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 70 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 71 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 72 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 73 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 74 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 75 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 76 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 77 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 78 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 79 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 80 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 81 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 82 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 83 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 84 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 85 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 86 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 87 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 88 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 89 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 90 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 91 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 92 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 93 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 94 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 95 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 96 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 97 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 98 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 99 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 100 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 101 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 102 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 103 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 104 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 105 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 106 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,351 - INFO - Participant 107 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 108 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 109 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 110 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 111 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 112 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 113 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 114 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 115 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 116 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 117 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 118 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 119 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 120 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 121 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 122 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 123 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 124 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 125 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 126 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Participant 127 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:28,352 - INFO - Combined xs shape after concatenation: torch.Size([128, 200, 5])
2025-03-26 00:13:28,352 - INFO - Combined ys shape after concatenation: torch.Size([128, 200, 2])
2025-03-26 00:13:28,352 - INFO - Combined dataset shape: X=torch.Size([128, 200, 5]), Y=torch.Size([128, 200, 2])
2025-03-26 00:13:28,353 - INFO - Total unique participants: 128
2025-03-26 00:13:28,353 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-26 00:13:28,353 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,353 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,353 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,353 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,353 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,353 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,353 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,354 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 32.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 33.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 34.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 35.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 36.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 37.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,355 - INFO - Participant 38.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 39.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 40.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 41.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 42.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 43.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 44.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 45.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 46.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 47.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 48.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 49.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 50.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 51.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 52.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 53.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 54.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 55.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 56.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,356 - INFO - Participant 57.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 58.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 59.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 60.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 61.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 62.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 63.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 64.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 65.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 66.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 67.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 68.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 69.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 70.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 71.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 72.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 73.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 74.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 75.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 76.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 77.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 78.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 79.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 80.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,357 - INFO - Participant 81.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 82.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 83.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 84.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 85.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 86.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 87.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 88.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 89.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 90.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 91.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 92.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 93.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 94.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 95.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 96.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 97.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 98.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 99.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 100.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 101.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,358 - INFO - Participant 102.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 103.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 104.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 105.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 106.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 107.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 108.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 109.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 110.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 111.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 112.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 113.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 114.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 115.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 116.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 117.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 118.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 119.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,359 - INFO - Participant 120.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,360 - INFO - Participant 121.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,360 - INFO - Participant 122.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,360 - INFO - Participant 123.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,360 - INFO - Participant 124.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,360 - INFO - Participant 125.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,360 - INFO - Participant 126.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,360 - INFO - Participant 127.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:28,360 - INFO - Train xs shape: torch.Size([128, 140, 5])
2025-03-26 00:13:28,360 - INFO - Train ys shape: torch.Size([128, 140, 2])
2025-03-26 00:13:28,360 - INFO - Validation xs shape: torch.Size([128, 60, 5])
2025-03-26 00:13:28,360 - INFO - Validation ys shape: torch.Size([128, 60, 2])
2025-03-26 00:13:28,360 - INFO - Train dataset: torch.Size([128, 140, 5]), Validation dataset: torch.Size([128, 60, 5])
2025-03-26 00:13:28,361 - INFO - Starting hyperparameter optimization...
2025-03-26 00:13:28,361 - INFO - Trial 0: dropout=0.297, lr=0.006869, hidden_size=15, embedding_size=23, n_steps=122
2025-03-26 00:13:34,940 - INFO - Trial 0: RNN Train Loss: 0.0000000
2025-03-26 00:13:34,942 - INFO - Trial 0: Validation set has 128 participants
2025-03-26 00:13:56,019 - INFO - ================================================================================
2025-03-26 00:13:56,019 - INFO - EXPERIMENT CONFIG
2025-03-26 00:13:56,019 - INFO - ================================================================================
2025-03-26 00:13:56,019 - INFO - Found 1 data files: ['data_128p_0.csv']
2025-03-26 00:13:56,019 - INFO - Processing dataset: data_128p_0.csv
2025-03-26 00:13:56,019 - INFO - Loading dataset from data/optuna/data_128p_0.csv
2025-03-26 00:13:56,055 - INFO - Number of participants: 128
2025-03-26 00:13:56,061 - INFO - Participant 0 (ID=0.0): _reward=0.74, _penalty=0.97
2025-03-26 00:13:56,066 - INFO - Participant 1 (ID=1.0): _reward=0.99, _penalty=0.02
2025-03-26 00:13:56,072 - INFO - Participant 2 (ID=2.0): _reward=0.77, _penalty=0.46
2025-03-26 00:13:56,077 - INFO - Participant 3 (ID=3.0): _reward=0.96, _penalty=0.60
2025-03-26 00:13:56,083 - INFO - Participant 4 (ID=4.0): _reward=0.21, _penalty=0.21
2025-03-26 00:13:56,088 - INFO - Participant 5 (ID=5.0): _reward=0.07, _penalty=0.51
2025-03-26 00:13:56,094 - INFO - Participant 6 (ID=6.0): _reward=0.23, _penalty=0.60
2025-03-26 00:13:56,099 - INFO - Participant 7 (ID=7.0): _reward=0.91, _penalty=0.80
2025-03-26 00:13:56,105 - INFO - Participant 8 (ID=8.0): _reward=0.99, _penalty=0.97
2025-03-26 00:13:56,110 - INFO - Participant 9 (ID=9.0): _reward=0.67, _penalty=0.87
2025-03-26 00:13:56,116 - INFO - Participant 10 (ID=10.0): _reward=0.08, _penalty=0.77
2025-03-26 00:13:56,121 - INFO - Participant 11 (ID=11.0): _reward=0.87, _penalty=0.31
2025-03-26 00:13:56,127 - INFO - Participant 12 (ID=12.0): _reward=0.58, _penalty=0.19
2025-03-26 00:13:56,132 - INFO - Participant 13 (ID=13.0): _reward=0.48, _penalty=0.25
2025-03-26 00:13:56,137 - INFO - Participant 14 (ID=14.0): _reward=0.34, _penalty=0.83
2025-03-26 00:13:56,143 - INFO - Participant 15 (ID=15.0): _reward=0.56, _penalty=0.80
2025-03-26 00:13:56,149 - INFO - Participant 16 (ID=16.0): _reward=0.47, _penalty=0.29
2025-03-26 00:13:56,154 - INFO - Participant 17 (ID=17.0): _reward=0.77, _penalty=0.94
2025-03-26 00:13:56,159 - INFO - Participant 18 (ID=18.0): _reward=0.88, _penalty=0.01
2025-03-26 00:13:56,165 - INFO - Participant 19 (ID=19.0): _reward=0.98, _penalty=0.11
2025-03-26 00:13:56,170 - INFO - Participant 20 (ID=20.0): _reward=0.02, _penalty=0.85
2025-03-26 00:13:56,175 - INFO - Participant 21 (ID=21.0): _reward=0.46, _penalty=0.85
2025-03-26 00:13:56,181 - INFO - Participant 22 (ID=22.0): _reward=0.69, _penalty=0.43
2025-03-26 00:13:56,186 - INFO - Participant 23 (ID=23.0): _reward=0.15, _penalty=0.95
2025-03-26 00:13:56,192 - INFO - Participant 24 (ID=24.0): _reward=0.25, _penalty=0.36
2025-03-26 00:13:56,197 - INFO - Participant 25 (ID=25.0): _reward=0.75, _penalty=0.11
2025-03-26 00:13:56,202 - INFO - Participant 26 (ID=26.0): _reward=0.46, _penalty=0.81
2025-03-26 00:13:56,207 - INFO - Participant 27 (ID=27.0): _reward=0.36, _penalty=0.63
2025-03-26 00:13:56,213 - INFO - Participant 28 (ID=28.0): _reward=0.49, _penalty=0.00
2025-03-26 00:13:56,218 - INFO - Participant 29 (ID=29.0): _reward=0.20, _penalty=0.98
2025-03-26 00:13:56,223 - INFO - Participant 30 (ID=30.0): _reward=0.29, _penalty=0.64
2025-03-26 00:13:56,229 - INFO - Participant 31 (ID=31.0): _reward=0.66, _penalty=0.64
2025-03-26 00:13:56,234 - INFO - Participant 32 (ID=32.0): _reward=0.21, _penalty=0.41
2025-03-26 00:13:56,239 - INFO - Participant 33 (ID=33.0): _reward=0.49, _penalty=0.63
2025-03-26 00:13:56,244 - INFO - Participant 34 (ID=34.0): _reward=0.38, _penalty=0.08
2025-03-26 00:13:56,250 - INFO - Participant 35 (ID=35.0): _reward=0.33, _penalty=0.29
2025-03-26 00:13:56,255 - INFO - Participant 36 (ID=36.0): _reward=0.53, _penalty=0.61
2025-03-26 00:13:56,260 - INFO - Participant 37 (ID=37.0): _reward=0.65, _penalty=0.34
2025-03-26 00:13:56,266 - INFO - Participant 38 (ID=38.0): _reward=0.29, _penalty=0.13
2025-03-26 00:13:56,271 - INFO - Participant 39 (ID=39.0): _reward=0.31, _penalty=0.25
2025-03-26 00:13:56,276 - INFO - Participant 40 (ID=40.0): _reward=0.77, _penalty=0.04
2025-03-26 00:13:56,282 - INFO - Participant 41 (ID=41.0): _reward=0.23, _penalty=0.89
2025-03-26 00:13:56,287 - INFO - Participant 42 (ID=42.0): _reward=0.63, _penalty=0.60
2025-03-26 00:13:56,292 - INFO - Participant 43 (ID=43.0): _reward=0.48, _penalty=0.52
2025-03-26 00:13:56,298 - INFO - Participant 44 (ID=44.0): _reward=0.92, _penalty=0.22
2025-03-26 00:13:56,303 - INFO - Participant 45 (ID=45.0): _reward=0.52, _penalty=0.89
2025-03-26 00:13:56,308 - INFO - Participant 46 (ID=46.0): _reward=0.42, _penalty=0.83
2025-03-26 00:13:56,313 - INFO - Participant 47 (ID=47.0): _reward=0.68, _penalty=0.69
2025-03-26 00:13:56,319 - INFO - Participant 48 (ID=48.0): _reward=0.95, _penalty=0.22
2025-03-26 00:13:56,327 - INFO - Participant 49 (ID=49.0): _reward=0.13, _penalty=0.48
2025-03-26 00:13:56,332 - INFO - Participant 50 (ID=50.0): _reward=0.87, _penalty=0.85
2025-03-26 00:13:56,338 - INFO - Participant 51 (ID=51.0): _reward=0.47, _penalty=0.07
2025-03-26 00:13:56,344 - INFO - Participant 52 (ID=52.0): _reward=0.56, _penalty=0.42
2025-03-26 00:13:56,349 - INFO - Participant 53 (ID=53.0): _reward=0.53, _penalty=0.18
2025-03-26 00:13:56,354 - INFO - Participant 54 (ID=54.0): _reward=0.87, _penalty=0.73
2025-03-26 00:13:56,360 - INFO - Participant 55 (ID=55.0): _reward=0.21, _penalty=0.47
2025-03-26 00:13:56,365 - INFO - Participant 56 (ID=56.0): _reward=0.65, _penalty=0.09
2025-03-26 00:13:56,370 - INFO - Participant 57 (ID=57.0): _reward=0.72, _penalty=0.88
2025-03-26 00:13:56,376 - INFO - Participant 58 (ID=58.0): _reward=0.61, _penalty=0.38
2025-03-26 00:13:56,381 - INFO - Participant 59 (ID=59.0): _reward=0.92, _penalty=0.91
2025-03-26 00:13:56,386 - INFO - Participant 60 (ID=60.0): _reward=0.22, _penalty=0.97
2025-03-26 00:13:56,391 - INFO - Participant 61 (ID=61.0): _reward=0.41, _penalty=0.53
2025-03-26 00:13:56,397 - INFO - Participant 62 (ID=62.0): _reward=0.92, _penalty=0.99
2025-03-26 00:13:56,402 - INFO - Participant 63 (ID=63.0): _reward=0.22, _penalty=0.99
2025-03-26 00:13:56,407 - INFO - Participant 64 (ID=64.0): _reward=0.84, _penalty=0.96
2025-03-26 00:13:56,412 - INFO - Participant 65 (ID=65.0): _reward=0.55, _penalty=0.19
2025-03-26 00:13:56,418 - INFO - Participant 66 (ID=66.0): _reward=0.34, _penalty=0.07
2025-03-26 00:13:56,423 - INFO - Participant 67 (ID=67.0): _reward=0.62, _penalty=0.45
2025-03-26 00:13:56,428 - INFO - Participant 68 (ID=68.0): _reward=0.47, _penalty=0.19
2025-03-26 00:13:56,433 - INFO - Participant 69 (ID=69.0): _reward=0.81, _penalty=0.36
2025-03-26 00:13:56,439 - INFO - Participant 70 (ID=70.0): _reward=0.73, _penalty=0.87
2025-03-26 00:13:56,444 - INFO - Participant 71 (ID=71.0): _reward=0.10, _penalty=0.57
2025-03-26 00:13:56,450 - INFO - Participant 72 (ID=72.0): _reward=0.78, _penalty=0.50
2025-03-26 00:13:56,455 - INFO - Participant 73 (ID=73.0): _reward=0.82, _penalty=0.70
2025-03-26 00:13:56,460 - INFO - Participant 74 (ID=74.0): _reward=0.00, _penalty=0.98
2025-03-26 00:13:56,465 - INFO - Participant 75 (ID=75.0): _reward=0.42, _penalty=0.26
2025-03-26 00:13:56,471 - INFO - Participant 76 (ID=76.0): _reward=0.83, _penalty=0.39
2025-03-26 00:13:56,476 - INFO - Participant 77 (ID=77.0): _reward=0.75, _penalty=0.18
2025-03-26 00:13:56,481 - INFO - Participant 78 (ID=78.0): _reward=0.97, _penalty=0.44
2025-03-26 00:13:56,487 - INFO - Participant 79 (ID=79.0): _reward=0.45, _penalty=0.57
2025-03-26 00:13:56,492 - INFO - Participant 80 (ID=80.0): _reward=0.63, _penalty=0.78
2025-03-26 00:13:56,497 - INFO - Participant 81 (ID=81.0): _reward=0.29, _penalty=0.24
2025-03-26 00:13:56,503 - INFO - Participant 82 (ID=82.0): _reward=0.71, _penalty=0.15
2025-03-26 00:13:56,508 - INFO - Participant 83 (ID=83.0): _reward=0.71, _penalty=0.66
2025-03-26 00:13:56,513 - INFO - Participant 84 (ID=84.0): _reward=0.97, _penalty=0.79
2025-03-26 00:13:56,519 - INFO - Participant 85 (ID=85.0): _reward=1.00, _penalty=0.95
2025-03-26 00:13:56,524 - INFO - Participant 86 (ID=86.0): _reward=0.56, _penalty=0.08
2025-03-26 00:13:56,529 - INFO - Participant 87 (ID=87.0): _reward=0.59, _penalty=0.83
2025-03-26 00:13:56,534 - INFO - Participant 88 (ID=88.0): _reward=0.32, _penalty=0.60
2025-03-26 00:13:56,539 - INFO - Participant 89 (ID=89.0): _reward=0.20, _penalty=0.84
2025-03-26 00:13:56,545 - INFO - Participant 90 (ID=90.0): _reward=0.34, _penalty=1.00
2025-03-26 00:13:56,550 - INFO - Participant 91 (ID=91.0): _reward=0.19, _penalty=0.99
2025-03-26 00:13:56,555 - INFO - Participant 92 (ID=92.0): _reward=0.20, _penalty=0.91
2025-03-26 00:13:56,561 - INFO - Participant 93 (ID=93.0): _reward=0.31, _penalty=0.21
2025-03-26 00:13:56,566 - INFO - Participant 94 (ID=94.0): _reward=0.58, _penalty=0.41
2025-03-26 00:13:56,571 - INFO - Participant 95 (ID=95.0): _reward=0.80, _penalty=0.54
2025-03-26 00:13:56,577 - INFO - Participant 96 (ID=96.0): _reward=0.74, _penalty=0.80
2025-03-26 00:13:56,582 - INFO - Participant 97 (ID=97.0): _reward=0.59, _penalty=0.16
2025-03-26 00:13:56,587 - INFO - Participant 98 (ID=98.0): _reward=0.54, _penalty=0.17
2025-03-26 00:13:56,593 - INFO - Participant 99 (ID=99.0): _reward=0.17, _penalty=0.16
2025-03-26 00:13:56,598 - INFO - Participant 100 (ID=100.0): _reward=0.79, _penalty=0.40
2025-03-26 00:13:56,603 - INFO - Participant 101 (ID=101.0): _reward=0.32, _penalty=0.05
2025-03-26 00:13:56,609 - INFO - Participant 102 (ID=102.0): _reward=0.87, _penalty=0.81
2025-03-26 00:13:56,614 - INFO - Participant 103 (ID=103.0): _reward=0.90, _penalty=0.11
2025-03-26 00:13:56,619 - INFO - Participant 104 (ID=104.0): _reward=0.44, _penalty=0.12
2025-03-26 00:13:56,625 - INFO - Participant 105 (ID=105.0): _reward=0.59, _penalty=0.50
2025-03-26 00:13:56,630 - INFO - Participant 106 (ID=106.0): _reward=0.84, _penalty=0.50
2025-03-26 00:13:56,635 - INFO - Participant 107 (ID=107.0): _reward=0.48, _penalty=0.54
2025-03-26 00:13:56,640 - INFO - Participant 108 (ID=108.0): _reward=0.56, _penalty=0.75
2025-03-26 00:13:56,646 - INFO - Participant 109 (ID=109.0): _reward=0.53, _penalty=0.11
2025-03-26 00:13:56,651 - INFO - Participant 110 (ID=110.0): _reward=0.52, _penalty=0.40
2025-03-26 00:13:56,657 - INFO - Participant 111 (ID=111.0): _reward=0.61, _penalty=0.74
2025-03-26 00:13:56,662 - INFO - Participant 112 (ID=112.0): _reward=0.64, _penalty=0.56
2025-03-26 00:13:56,667 - INFO - Participant 113 (ID=113.0): _reward=0.44, _penalty=0.40
2025-03-26 00:13:56,672 - INFO - Participant 114 (ID=114.0): _reward=0.74, _penalty=0.91
2025-03-26 00:13:56,678 - INFO - Participant 115 (ID=115.0): _reward=0.09, _penalty=0.27
2025-03-26 00:13:56,683 - INFO - Participant 116 (ID=116.0): _reward=0.99, _penalty=0.92
2025-03-26 00:13:56,688 - INFO - Participant 117 (ID=117.0): _reward=0.90, _penalty=0.87
2025-03-26 00:13:56,694 - INFO - Participant 118 (ID=118.0): _reward=0.21, _penalty=0.27
2025-03-26 00:13:56,699 - INFO - Participant 119 (ID=119.0): _reward=0.71, _penalty=0.69
2025-03-26 00:13:56,704 - INFO - Participant 120 (ID=120.0): _reward=0.43, _penalty=0.05
2025-03-26 00:13:56,709 - INFO - Participant 121 (ID=121.0): _reward=0.11, _penalty=0.27
2025-03-26 00:13:56,714 - INFO - Participant 122 (ID=122.0): _reward=0.80, _penalty=0.43
2025-03-26 00:13:56,720 - INFO - Participant 123 (ID=123.0): _reward=0.74, _penalty=0.44
2025-03-26 00:13:56,725 - INFO - Participant 124 (ID=124.0): _reward=0.18, _penalty=0.36
2025-03-26 00:13:56,730 - INFO - Participant 125 (ID=125.0): _reward=0.86, _penalty=0.09
2025-03-26 00:13:56,735 - INFO - Participant 126 (ID=126.0): _reward=0.05, _penalty=0.52
2025-03-26 00:13:56,741 - INFO - Participant 127 (ID=127.0): _reward=0.41, _penalty=0.26
2025-03-26 00:13:56,741 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 32 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 33 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 34 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 35 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 36 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 37 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 38 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 39 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 40 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 41 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 42 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 43 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 44 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 45 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,741 - INFO - Participant 46 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 47 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 48 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 49 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 50 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 51 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 52 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 53 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 54 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 55 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 56 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 57 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 58 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 59 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 60 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 61 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 62 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 63 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 64 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 65 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 66 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 67 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 68 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 69 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 70 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 71 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 72 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 73 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 74 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 75 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 76 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 77 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 78 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 79 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 80 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 81 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 82 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 83 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 84 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 85 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 86 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 87 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 88 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 89 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 90 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 91 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 92 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 93 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 94 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 95 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 96 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 97 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 98 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 99 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 100 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 101 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 102 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 103 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 104 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 105 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 106 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 107 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 108 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 109 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 110 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 111 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 112 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 113 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 114 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 115 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 116 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 117 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 118 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 119 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 120 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,742 - INFO - Participant 121 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,743 - INFO - Participant 122 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,743 - INFO - Participant 123 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,743 - INFO - Participant 124 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,743 - INFO - Participant 125 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,743 - INFO - Participant 126 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,743 - INFO - Participant 127 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:13:56,743 - INFO - Combined xs shape after concatenation: torch.Size([128, 200, 5])
2025-03-26 00:13:56,743 - INFO - Combined ys shape after concatenation: torch.Size([128, 200, 2])
2025-03-26 00:13:56,743 - INFO - Combined dataset shape: X=torch.Size([128, 200, 5]), Y=torch.Size([128, 200, 2])
2025-03-26 00:13:56,743 - INFO - Total unique participants: 128
2025-03-26 00:13:56,743 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-26 00:13:56,744 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,744 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 32.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 33.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 34.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 35.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 36.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 37.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 38.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 39.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 40.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 41.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 42.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,745 - INFO - Participant 43.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 44.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 45.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 46.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 47.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 48.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 49.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 50.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 51.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 52.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 53.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 54.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 55.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 56.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 57.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 58.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 59.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 60.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 61.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 62.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 63.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 64.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,746 - INFO - Participant 65.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 66.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 67.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 68.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 69.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 70.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 71.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 72.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 73.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 74.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 75.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 76.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 77.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 78.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 79.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 80.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 81.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 82.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 83.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 84.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 85.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 86.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 87.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,747 - INFO - Participant 88.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 89.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 90.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 91.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 92.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 93.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 94.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 95.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 96.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 97.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 98.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 99.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 100.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 101.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 102.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 103.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 104.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 105.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 106.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 107.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 108.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 109.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 110.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,748 - INFO - Participant 111.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 112.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 113.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 114.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 115.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 116.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 117.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 118.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 119.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 120.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 121.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 122.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 123.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 124.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 125.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 126.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Participant 127.0: 140 trials for training, 60 trials for validation
2025-03-26 00:13:56,749 - INFO - Train xs shape: torch.Size([128, 140, 5])
2025-03-26 00:13:56,749 - INFO - Train ys shape: torch.Size([128, 140, 2])
2025-03-26 00:13:56,749 - INFO - Validation xs shape: torch.Size([128, 60, 5])
2025-03-26 00:13:56,749 - INFO - Validation ys shape: torch.Size([128, 60, 2])
2025-03-26 00:13:56,750 - INFO - Train dataset: torch.Size([128, 140, 5]), Validation dataset: torch.Size([128, 60, 5])
2025-03-26 00:13:56,750 - INFO - Starting hyperparameter optimization...
2025-03-26 00:13:56,751 - INFO - Trial 0: dropout=0.367, lr=0.000395, hidden_size=29, embedding_size=32, n_steps=100
2025-03-26 00:14:07,103 - INFO - Trial 0: RNN Train Loss: 0.0000000
2025-03-26 00:14:07,105 - INFO - Trial 0: Validation set has 128 participants
2025-03-26 00:16:30,088 - INFO - ================================================================================
2025-03-26 00:16:30,088 - INFO - EXPERIMENT CONFIG
2025-03-26 00:16:30,088 - INFO - ================================================================================
2025-03-26 00:16:30,088 - INFO - Found 1 data files: ['data_128p_0.csv']
2025-03-26 00:16:30,088 - INFO - Processing dataset: data_128p_0.csv
2025-03-26 00:16:30,088 - INFO - Loading dataset from data/optuna/data_128p_0.csv
2025-03-26 00:16:30,139 - INFO - Number of participants: 128
2025-03-26 00:16:30,145 - INFO - Participant 0 (ID=0.0): _reward=0.74, _penalty=0.97
2025-03-26 00:16:30,149 - INFO - Participant 1 (ID=1.0): _reward=0.99, _penalty=0.02
2025-03-26 00:16:30,155 - INFO - Participant 2 (ID=2.0): _reward=0.77, _penalty=0.46
2025-03-26 00:16:30,160 - INFO - Participant 3 (ID=3.0): _reward=0.96, _penalty=0.60
2025-03-26 00:16:30,165 - INFO - Participant 4 (ID=4.0): _reward=0.21, _penalty=0.21
2025-03-26 00:16:30,170 - INFO - Participant 5 (ID=5.0): _reward=0.07, _penalty=0.51
2025-03-26 00:16:30,175 - INFO - Participant 6 (ID=6.0): _reward=0.23, _penalty=0.60
2025-03-26 00:16:30,180 - INFO - Participant 7 (ID=7.0): _reward=0.91, _penalty=0.80
2025-03-26 00:16:30,186 - INFO - Participant 8 (ID=8.0): _reward=0.99, _penalty=0.97
2025-03-26 00:16:30,191 - INFO - Participant 9 (ID=9.0): _reward=0.67, _penalty=0.87
2025-03-26 00:16:30,196 - INFO - Participant 10 (ID=10.0): _reward=0.08, _penalty=0.77
2025-03-26 00:16:30,201 - INFO - Participant 11 (ID=11.0): _reward=0.87, _penalty=0.31
2025-03-26 00:16:30,206 - INFO - Participant 12 (ID=12.0): _reward=0.58, _penalty=0.19
2025-03-26 00:16:30,211 - INFO - Participant 13 (ID=13.0): _reward=0.48, _penalty=0.25
2025-03-26 00:16:30,216 - INFO - Participant 14 (ID=14.0): _reward=0.34, _penalty=0.83
2025-03-26 00:16:30,221 - INFO - Participant 15 (ID=15.0): _reward=0.56, _penalty=0.80
2025-03-26 00:16:30,226 - INFO - Participant 16 (ID=16.0): _reward=0.47, _penalty=0.29
2025-03-26 00:16:30,231 - INFO - Participant 17 (ID=17.0): _reward=0.77, _penalty=0.94
2025-03-26 00:16:30,236 - INFO - Participant 18 (ID=18.0): _reward=0.88, _penalty=0.01
2025-03-26 00:16:30,242 - INFO - Participant 19 (ID=19.0): _reward=0.98, _penalty=0.11
2025-03-26 00:16:30,247 - INFO - Participant 20 (ID=20.0): _reward=0.02, _penalty=0.85
2025-03-26 00:16:30,252 - INFO - Participant 21 (ID=21.0): _reward=0.46, _penalty=0.85
2025-03-26 00:16:30,257 - INFO - Participant 22 (ID=22.0): _reward=0.69, _penalty=0.43
2025-03-26 00:16:30,262 - INFO - Participant 23 (ID=23.0): _reward=0.15, _penalty=0.95
2025-03-26 00:16:30,267 - INFO - Participant 24 (ID=24.0): _reward=0.25, _penalty=0.36
2025-03-26 00:16:30,272 - INFO - Participant 25 (ID=25.0): _reward=0.75, _penalty=0.11
2025-03-26 00:16:30,277 - INFO - Participant 26 (ID=26.0): _reward=0.46, _penalty=0.81
2025-03-26 00:16:30,282 - INFO - Participant 27 (ID=27.0): _reward=0.36, _penalty=0.63
2025-03-26 00:16:30,287 - INFO - Participant 28 (ID=28.0): _reward=0.49, _penalty=0.00
2025-03-26 00:16:30,292 - INFO - Participant 29 (ID=29.0): _reward=0.20, _penalty=0.98
2025-03-26 00:16:30,297 - INFO - Participant 30 (ID=30.0): _reward=0.29, _penalty=0.64
2025-03-26 00:16:30,302 - INFO - Participant 31 (ID=31.0): _reward=0.66, _penalty=0.64
2025-03-26 00:16:30,307 - INFO - Participant 32 (ID=32.0): _reward=0.21, _penalty=0.41
2025-03-26 00:16:30,313 - INFO - Participant 33 (ID=33.0): _reward=0.49, _penalty=0.63
2025-03-26 00:16:30,318 - INFO - Participant 34 (ID=34.0): _reward=0.38, _penalty=0.08
2025-03-26 00:16:30,323 - INFO - Participant 35 (ID=35.0): _reward=0.33, _penalty=0.29
2025-03-26 00:16:30,328 - INFO - Participant 36 (ID=36.0): _reward=0.53, _penalty=0.61
2025-03-26 00:16:30,333 - INFO - Participant 37 (ID=37.0): _reward=0.65, _penalty=0.34
2025-03-26 00:16:30,338 - INFO - Participant 38 (ID=38.0): _reward=0.29, _penalty=0.13
2025-03-26 00:16:30,343 - INFO - Participant 39 (ID=39.0): _reward=0.31, _penalty=0.25
2025-03-26 00:16:30,348 - INFO - Participant 40 (ID=40.0): _reward=0.77, _penalty=0.04
2025-03-26 00:16:30,354 - INFO - Participant 41 (ID=41.0): _reward=0.23, _penalty=0.89
2025-03-26 00:16:30,359 - INFO - Participant 42 (ID=42.0): _reward=0.63, _penalty=0.60
2025-03-26 00:16:30,363 - INFO - Participant 43 (ID=43.0): _reward=0.48, _penalty=0.52
2025-03-26 00:16:30,368 - INFO - Participant 44 (ID=44.0): _reward=0.92, _penalty=0.22
2025-03-26 00:16:30,374 - INFO - Participant 45 (ID=45.0): _reward=0.52, _penalty=0.89
2025-03-26 00:16:30,379 - INFO - Participant 46 (ID=46.0): _reward=0.42, _penalty=0.83
2025-03-26 00:16:30,384 - INFO - Participant 47 (ID=47.0): _reward=0.68, _penalty=0.69
2025-03-26 00:16:30,389 - INFO - Participant 48 (ID=48.0): _reward=0.95, _penalty=0.22
2025-03-26 00:16:30,394 - INFO - Participant 49 (ID=49.0): _reward=0.13, _penalty=0.48
2025-03-26 00:16:30,399 - INFO - Participant 50 (ID=50.0): _reward=0.87, _penalty=0.85
2025-03-26 00:16:30,404 - INFO - Participant 51 (ID=51.0): _reward=0.47, _penalty=0.07
2025-03-26 00:16:30,409 - INFO - Participant 52 (ID=52.0): _reward=0.56, _penalty=0.42
2025-03-26 00:16:30,413 - INFO - Participant 53 (ID=53.0): _reward=0.53, _penalty=0.18
2025-03-26 00:16:30,418 - INFO - Participant 54 (ID=54.0): _reward=0.87, _penalty=0.73
2025-03-26 00:16:30,423 - INFO - Participant 55 (ID=55.0): _reward=0.21, _penalty=0.47
2025-03-26 00:16:30,428 - INFO - Participant 56 (ID=56.0): _reward=0.65, _penalty=0.09
2025-03-26 00:16:30,433 - INFO - Participant 57 (ID=57.0): _reward=0.72, _penalty=0.88
2025-03-26 00:16:30,438 - INFO - Participant 58 (ID=58.0): _reward=0.61, _penalty=0.38
2025-03-26 00:16:30,443 - INFO - Participant 59 (ID=59.0): _reward=0.92, _penalty=0.91
2025-03-26 00:16:30,447 - INFO - Participant 60 (ID=60.0): _reward=0.22, _penalty=0.97
2025-03-26 00:16:30,453 - INFO - Participant 61 (ID=61.0): _reward=0.41, _penalty=0.53
2025-03-26 00:16:30,458 - INFO - Participant 62 (ID=62.0): _reward=0.92, _penalty=0.99
2025-03-26 00:16:30,463 - INFO - Participant 63 (ID=63.0): _reward=0.22, _penalty=0.99
2025-03-26 00:16:30,468 - INFO - Participant 64 (ID=64.0): _reward=0.84, _penalty=0.96
2025-03-26 00:16:30,473 - INFO - Participant 65 (ID=65.0): _reward=0.55, _penalty=0.19
2025-03-26 00:16:30,478 - INFO - Participant 66 (ID=66.0): _reward=0.34, _penalty=0.07
2025-03-26 00:16:30,482 - INFO - Participant 67 (ID=67.0): _reward=0.62, _penalty=0.45
2025-03-26 00:16:30,487 - INFO - Participant 68 (ID=68.0): _reward=0.47, _penalty=0.19
2025-03-26 00:16:30,492 - INFO - Participant 69 (ID=69.0): _reward=0.81, _penalty=0.36
2025-03-26 00:16:30,497 - INFO - Participant 70 (ID=70.0): _reward=0.73, _penalty=0.87
2025-03-26 00:16:30,502 - INFO - Participant 71 (ID=71.0): _reward=0.10, _penalty=0.57
2025-03-26 00:16:30,507 - INFO - Participant 72 (ID=72.0): _reward=0.78, _penalty=0.50
2025-03-26 00:16:30,512 - INFO - Participant 73 (ID=73.0): _reward=0.82, _penalty=0.70
2025-03-26 00:16:30,517 - INFO - Participant 74 (ID=74.0): _reward=0.00, _penalty=0.98
2025-03-26 00:16:30,522 - INFO - Participant 75 (ID=75.0): _reward=0.42, _penalty=0.26
2025-03-26 00:16:30,527 - INFO - Participant 76 (ID=76.0): _reward=0.83, _penalty=0.39
2025-03-26 00:16:30,532 - INFO - Participant 77 (ID=77.0): _reward=0.75, _penalty=0.18
2025-03-26 00:16:30,537 - INFO - Participant 78 (ID=78.0): _reward=0.97, _penalty=0.44
2025-03-26 00:16:30,542 - INFO - Participant 79 (ID=79.0): _reward=0.45, _penalty=0.57
2025-03-26 00:16:30,547 - INFO - Participant 80 (ID=80.0): _reward=0.63, _penalty=0.78
2025-03-26 00:16:30,552 - INFO - Participant 81 (ID=81.0): _reward=0.29, _penalty=0.24
2025-03-26 00:16:30,557 - INFO - Participant 82 (ID=82.0): _reward=0.71, _penalty=0.15
2025-03-26 00:16:30,562 - INFO - Participant 83 (ID=83.0): _reward=0.71, _penalty=0.66
2025-03-26 00:16:30,567 - INFO - Participant 84 (ID=84.0): _reward=0.97, _penalty=0.79
2025-03-26 00:16:30,572 - INFO - Participant 85 (ID=85.0): _reward=1.00, _penalty=0.95
2025-03-26 00:16:30,577 - INFO - Participant 86 (ID=86.0): _reward=0.56, _penalty=0.08
2025-03-26 00:16:30,581 - INFO - Participant 87 (ID=87.0): _reward=0.59, _penalty=0.83
2025-03-26 00:16:30,586 - INFO - Participant 88 (ID=88.0): _reward=0.32, _penalty=0.60
2025-03-26 00:16:30,591 - INFO - Participant 89 (ID=89.0): _reward=0.20, _penalty=0.84
2025-03-26 00:16:30,597 - INFO - Participant 90 (ID=90.0): _reward=0.34, _penalty=1.00
2025-03-26 00:16:30,602 - INFO - Participant 91 (ID=91.0): _reward=0.19, _penalty=0.99
2025-03-26 00:16:30,607 - INFO - Participant 92 (ID=92.0): _reward=0.20, _penalty=0.91
2025-03-26 00:16:30,611 - INFO - Participant 93 (ID=93.0): _reward=0.31, _penalty=0.21
2025-03-26 00:16:30,616 - INFO - Participant 94 (ID=94.0): _reward=0.58, _penalty=0.41
2025-03-26 00:16:30,621 - INFO - Participant 95 (ID=95.0): _reward=0.80, _penalty=0.54
2025-03-26 00:16:30,626 - INFO - Participant 96 (ID=96.0): _reward=0.74, _penalty=0.80
2025-03-26 00:16:30,631 - INFO - Participant 97 (ID=97.0): _reward=0.59, _penalty=0.16
2025-03-26 00:16:30,636 - INFO - Participant 98 (ID=98.0): _reward=0.54, _penalty=0.17
2025-03-26 00:16:30,641 - INFO - Participant 99 (ID=99.0): _reward=0.17, _penalty=0.16
2025-03-26 00:16:30,646 - INFO - Participant 100 (ID=100.0): _reward=0.79, _penalty=0.40
2025-03-26 00:16:30,651 - INFO - Participant 101 (ID=101.0): _reward=0.32, _penalty=0.05
2025-03-26 00:16:30,656 - INFO - Participant 102 (ID=102.0): _reward=0.87, _penalty=0.81
2025-03-26 00:16:30,661 - INFO - Participant 103 (ID=103.0): _reward=0.90, _penalty=0.11
2025-03-26 00:16:30,666 - INFO - Participant 104 (ID=104.0): _reward=0.44, _penalty=0.12
2025-03-26 00:16:30,671 - INFO - Participant 105 (ID=105.0): _reward=0.59, _penalty=0.50
2025-03-26 00:16:30,676 - INFO - Participant 106 (ID=106.0): _reward=0.84, _penalty=0.50
2025-03-26 00:16:30,681 - INFO - Participant 107 (ID=107.0): _reward=0.48, _penalty=0.54
2025-03-26 00:16:30,686 - INFO - Participant 108 (ID=108.0): _reward=0.56, _penalty=0.75
2025-03-26 00:16:30,691 - INFO - Participant 109 (ID=109.0): _reward=0.53, _penalty=0.11
2025-03-26 00:16:30,696 - INFO - Participant 110 (ID=110.0): _reward=0.52, _penalty=0.40
2025-03-26 00:16:30,701 - INFO - Participant 111 (ID=111.0): _reward=0.61, _penalty=0.74
2025-03-26 00:16:30,706 - INFO - Participant 112 (ID=112.0): _reward=0.64, _penalty=0.56
2025-03-26 00:16:30,711 - INFO - Participant 113 (ID=113.0): _reward=0.44, _penalty=0.40
2025-03-26 00:16:30,716 - INFO - Participant 114 (ID=114.0): _reward=0.74, _penalty=0.91
2025-03-26 00:16:30,721 - INFO - Participant 115 (ID=115.0): _reward=0.09, _penalty=0.27
2025-03-26 00:16:30,726 - INFO - Participant 116 (ID=116.0): _reward=0.99, _penalty=0.92
2025-03-26 00:16:30,731 - INFO - Participant 117 (ID=117.0): _reward=0.90, _penalty=0.87
2025-03-26 00:16:30,736 - INFO - Participant 118 (ID=118.0): _reward=0.21, _penalty=0.27
2025-03-26 00:16:30,741 - INFO - Participant 119 (ID=119.0): _reward=0.71, _penalty=0.69
2025-03-26 00:16:30,746 - INFO - Participant 120 (ID=120.0): _reward=0.43, _penalty=0.05
2025-03-26 00:16:30,750 - INFO - Participant 121 (ID=121.0): _reward=0.11, _penalty=0.27
2025-03-26 00:16:30,755 - INFO - Participant 122 (ID=122.0): _reward=0.80, _penalty=0.43
2025-03-26 00:16:30,761 - INFO - Participant 123 (ID=123.0): _reward=0.74, _penalty=0.44
2025-03-26 00:16:30,766 - INFO - Participant 124 (ID=124.0): _reward=0.18, _penalty=0.36
2025-03-26 00:16:30,774 - INFO - Participant 125 (ID=125.0): _reward=0.86, _penalty=0.09
2025-03-26 00:16:30,779 - INFO - Participant 126 (ID=126.0): _reward=0.05, _penalty=0.52
2025-03-26 00:16:30,784 - INFO - Participant 127 (ID=127.0): _reward=0.41, _penalty=0.26
2025-03-26 00:16:30,784 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,784 - INFO - Participant 32 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 33 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 34 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 35 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 36 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 37 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 38 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 39 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 40 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 41 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 42 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 43 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 44 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 45 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 46 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 47 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 48 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 49 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 50 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 51 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 52 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 53 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 54 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 55 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 56 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 57 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 58 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 59 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 60 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 61 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 62 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 63 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 64 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 65 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 66 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 67 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 68 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 69 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 70 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 71 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 72 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 73 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 74 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 75 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 76 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 77 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 78 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 79 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 80 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,785 - INFO - Participant 81 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 82 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 83 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 84 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 85 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 86 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 87 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 88 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 89 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 90 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 91 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 92 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 93 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 94 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 95 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 96 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 97 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 98 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 99 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 100 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 101 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 102 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 103 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 104 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 105 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 106 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 107 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 108 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 109 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 110 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 111 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 112 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 113 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 114 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 115 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 116 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 117 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 118 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 119 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 120 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 121 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,786 - INFO - Participant 122 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,787 - INFO - Participant 123 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,787 - INFO - Participant 124 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,787 - INFO - Participant 125 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,787 - INFO - Participant 126 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,787 - INFO - Participant 127 xs shape: torch.Size([1, 200, 5])
2025-03-26 00:16:30,787 - INFO - Combined xs shape after concatenation: torch.Size([128, 200, 5])
2025-03-26 00:16:30,787 - INFO - Combined ys shape after concatenation: torch.Size([128, 200, 2])
2025-03-26 00:16:30,787 - INFO - Combined dataset shape: X=torch.Size([128, 200, 5]), Y=torch.Size([128, 200, 2])
2025-03-26 00:16:30,787 - INFO - Total unique participants: 128
2025-03-26 00:16:30,787 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-26 00:16:30,788 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,788 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,789 - INFO - Participant 32.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 33.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 34.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 35.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 36.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 37.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 38.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 39.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 40.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 41.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 42.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 43.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 44.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 45.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 46.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 47.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 48.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 49.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 50.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 51.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,790 - INFO - Participant 52.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 53.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 54.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 55.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 56.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 57.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 58.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 59.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 60.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 61.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 62.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 63.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 64.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 65.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 66.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 67.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 68.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 69.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 70.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 71.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 72.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 73.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 74.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,791 - INFO - Participant 75.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 76.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 77.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 78.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 79.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 80.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 81.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 82.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 83.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 84.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 85.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 86.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 87.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 88.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 89.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 90.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 91.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 92.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 93.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 94.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 95.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 96.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 97.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,792 - INFO - Participant 98.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 99.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 100.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 101.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 102.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 103.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 104.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 105.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 106.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 107.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 108.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 109.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 110.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 111.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 112.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 113.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 114.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 115.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 116.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,793 - INFO - Participant 117.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,794 - INFO - Participant 118.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,794 - INFO - Participant 119.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,794 - INFO - Participant 120.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,794 - INFO - Participant 121.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,794 - INFO - Participant 122.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,794 - INFO - Participant 123.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,794 - INFO - Participant 124.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,794 - INFO - Participant 125.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,794 - INFO - Participant 126.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,794 - INFO - Participant 127.0: 140 trials for training, 60 trials for validation
2025-03-26 00:16:30,794 - INFO - Train xs shape: torch.Size([128, 140, 5])
2025-03-26 00:16:30,794 - INFO - Train ys shape: torch.Size([128, 140, 2])
2025-03-26 00:16:30,794 - INFO - Validation xs shape: torch.Size([128, 60, 5])
2025-03-26 00:16:30,794 - INFO - Validation ys shape: torch.Size([128, 60, 2])
2025-03-26 00:16:30,794 - INFO - Train dataset: torch.Size([128, 140, 5]), Validation dataset: torch.Size([128, 60, 5])
2025-03-26 00:16:30,795 - INFO - Starting hyperparameter optimization...
2025-03-26 00:16:30,795 - INFO - Trial 0: dropout=0.251, lr=0.009783, hidden_size=21, embedding_size=27, n_steps=64
2025-03-26 00:26:28,134 - INFO - Trial 0: RNN Train Loss: 0.3062871
2025-03-26 00:26:28,135 - INFO - Trial 0: Validation set has 128 participants
2025-03-26 00:26:33,019 - INFO - Trial 0: Average Validation Loss: 0.4266, Eval count: 128
2025-03-26 00:26:33,020 - INFO - Trial 1: dropout=0.024, lr=0.000158, hidden_size=16, embedding_size=28, n_steps=80
2025-03-26 00:34:58,837 - INFO - Trial 1: RNN Train Loss: 0.3353783
2025-03-26 00:34:58,838 - INFO - Trial 1: Validation set has 128 participants
2025-03-26 00:35:03,263 - INFO - Trial 1: Average Validation Loss: 0.4218, Eval count: 128
2025-03-26 00:35:03,264 - INFO - Trial 2: dropout=0.046, lr=0.000423, hidden_size=23, embedding_size=17, n_steps=69
2025-03-26 00:43:43,058 - INFO - Trial 2: RNN Train Loss: 0.3401218
2025-03-26 00:43:43,058 - INFO - Trial 2: Validation set has 128 participants
2025-03-26 00:43:47,579 - INFO - Trial 2: Average Validation Loss: 0.4642, Eval count: 128
2025-03-26 00:43:47,580 - INFO - Trial 3: dropout=0.152, lr=0.003123, hidden_size=28, embedding_size=30, n_steps=80
2025-03-26 00:55:00,390 - INFO - Trial 3: RNN Train Loss: 0.2994010
2025-03-26 00:55:00,391 - INFO - Trial 3: Validation set has 128 participants
2025-03-26 00:55:05,025 - INFO - Trial 3: Average Validation Loss: 0.4180, Eval count: 128
2025-03-26 00:55:05,027 - INFO - Trial 4: dropout=0.236, lr=0.000421, hidden_size=32, embedding_size=24, n_steps=79
2025-03-26 01:06:06,158 - INFO - Trial 4: RNN Train Loss: 0.2985820
2025-03-26 01:06:06,159 - INFO - Trial 4: Validation set has 128 participants
2025-03-26 01:06:10,690 - INFO - Trial 4: Average Validation Loss: 0.4053, Eval count: 128
2025-03-26 01:06:10,691 - INFO - Trial 5: dropout=0.125, lr=0.000183, hidden_size=8, embedding_size=30, n_steps=4
2025-03-26 01:15:28,462 - INFO - Trial 5: RNN Train Loss: 0.2978247
2025-03-26 01:15:28,463 - INFO - Trial 5: Validation set has 128 participants
2025-03-26 01:15:32,769 - INFO - Trial 5: Average Validation Loss: 0.4188, Eval count: 128
2025-03-26 01:15:32,770 - INFO - Trial 6: dropout=0.106, lr=0.000407, hidden_size=8, embedding_size=21, n_steps=88
2025-03-26 01:23:01,911 - INFO - Trial 6: RNN Train Loss: 0.2894148
2025-03-26 01:23:01,912 - INFO - Trial 6: Validation set has 128 participants
2025-03-26 01:23:06,512 - INFO - Trial 6: Average Validation Loss: 0.4039, Eval count: 128
2025-03-26 01:23:06,513 - INFO - Trial 7: dropout=0.249, lr=0.000191, hidden_size=29, embedding_size=26, n_steps=84
2025-03-26 01:34:11,327 - INFO - Trial 7: RNN Train Loss: 0.3388580
2025-03-26 01:34:11,327 - INFO - Trial 7: Validation set has 128 participants
2025-03-26 01:34:15,988 - INFO - Trial 7: Average Validation Loss: 0.4203, Eval count: 128
2025-03-26 01:34:15,989 - INFO - Trial 8: dropout=0.412, lr=0.002428, hidden_size=13, embedding_size=14, n_steps=9
2025-03-26 01:43:02,867 - INFO - Trial 8: RNN Train Loss: 0.2622686
2025-03-26 01:43:02,868 - INFO - Trial 8: Validation set has 128 participants
2025-03-26 01:43:07,522 - INFO - Trial 8: Average Validation Loss: 0.3979, Eval count: 128
2025-03-26 01:43:07,523 - INFO - Trial 9: dropout=0.062, lr=0.001737, hidden_size=30, embedding_size=13, n_steps=34
2025-03-26 01:52:59,867 - INFO - Trial 9: RNN Train Loss: 0.2761261
2025-03-26 01:52:59,868 - INFO - Trial 9: Validation set has 128 participants
2025-03-26 01:53:04,504 - INFO - Trial 9: Average Validation Loss: 0.4235, Eval count: 128
2025-03-26 01:53:04,514 - INFO - Trial 10: dropout=0.472, lr=0.006457, hidden_size=14, embedding_size=8, n_steps=1
2025-03-26 02:07:26,704 - INFO - Trial 10: RNN Train Loss: 0.2516354
2025-03-26 02:07:26,705 - INFO - Trial 10: Validation set has 128 participants
2025-03-26 02:07:31,399 - INFO - Trial 10: Average Validation Loss: 0.3939, Eval count: 128
2025-03-26 02:07:31,408 - INFO - Trial 11: dropout=0.493, lr=0.006256, hidden_size=14, embedding_size=8, n_steps=1
2025-03-26 02:21:53,883 - INFO - Trial 11: RNN Train Loss: 0.2510610
2025-03-26 02:21:53,883 - INFO - Trial 11: Validation set has 128 participants
2025-03-26 02:21:58,287 - INFO - Trial 11: Average Validation Loss: 0.3951, Eval count: 128
2025-03-26 02:21:58,296 - INFO - Trial 12: dropout=0.498, lr=0.009560, hidden_size=15, embedding_size=8, n_steps=29
2025-03-26 02:30:12,795 - INFO - Trial 12: RNN Train Loss: 0.3143349
2025-03-26 02:30:12,795 - INFO - Trial 12: Validation set has 128 participants
2025-03-26 02:30:17,270 - INFO - Trial 12: Average Validation Loss: 0.4362, Eval count: 128
2025-03-26 02:30:17,279 - INFO - Trial 13: dropout=0.412, lr=0.004918, hidden_size=12, embedding_size=8, n_steps=19
2025-03-26 02:38:27,624 - INFO - Trial 13: RNN Train Loss: 0.2639503
2025-03-26 02:38:27,624 - INFO - Trial 13: Validation set has 128 participants
2025-03-26 02:38:32,394 - INFO - Trial 13: Average Validation Loss: 0.3992, Eval count: 128
2025-03-26 02:38:32,404 - INFO - Trial 14: dropout=0.493, lr=0.001350, hidden_size=18, embedding_size=12, n_steps=47
2025-03-26 02:47:00,051 - INFO - Trial 14: RNN Train Loss: 0.2702281
2025-03-26 02:47:00,052 - INFO - Trial 14: Validation set has 128 participants
2025-03-26 02:47:04,721 - INFO - Trial 14: Average Validation Loss: 0.3944, Eval count: 128
2025-03-26 02:47:04,731 - INFO - Trial 15: dropout=0.382, lr=0.001444, hidden_size=18, embedding_size=12, n_steps=45
2025-03-26 02:55:35,933 - INFO - Trial 15: RNN Train Loss: 0.2549158
2025-03-26 02:55:35,934 - INFO - Trial 15: Validation set has 128 participants
2025-03-26 02:55:40,287 - INFO - Trial 15: Average Validation Loss: 0.3991, Eval count: 128
2025-03-26 02:55:40,297 - INFO - Trial 16: dropout=0.342, lr=0.000866, hidden_size=24, embedding_size=16, n_steps=52
2025-03-26 03:05:09,341 - INFO - Trial 16: RNN Train Loss: 0.2864769
2025-03-26 03:05:09,341 - INFO - Trial 16: Validation set has 128 participants
2025-03-26 03:05:14,061 - INFO - Trial 16: Average Validation Loss: 0.4019, Eval count: 128
2025-03-26 03:05:14,071 - INFO - Trial 17: dropout=0.329, lr=0.001068, hidden_size=19, embedding_size=11, n_steps=100
2025-03-26 03:13:36,257 - INFO - Trial 17: RNN Train Loss: 0.2597888
2025-03-26 03:13:36,258 - INFO - Trial 17: Validation set has 128 participants
2025-03-26 03:13:40,637 - INFO - Trial 17: Average Validation Loss: 0.3889, Eval count: 128
2025-03-26 03:13:40,646 - INFO - Trial 18: dropout=0.321, lr=0.004328, hidden_size=11, embedding_size=20, n_steps=93
2025-03-26 03:21:51,882 - INFO - Trial 18: RNN Train Loss: 0.2930164
2025-03-26 03:21:51,883 - INFO - Trial 18: Validation set has 128 participants
2025-03-26 03:21:56,307 - INFO - Trial 18: Average Validation Loss: 0.4132, Eval count: 128
2025-03-26 03:21:56,317 - INFO - Trial 19: dropout=0.309, lr=0.000773, hidden_size=25, embedding_size=10, n_steps=98
2025-03-26 03:31:16,896 - INFO - Trial 19: RNN Train Loss: 0.2951507
2025-03-26 03:31:16,897 - INFO - Trial 19: Validation set has 128 participants
2025-03-26 03:31:21,245 - INFO - Trial 19: Average Validation Loss: 0.3918, Eval count: 128
2025-03-26 03:31:21,254 - INFO - Trial 20: dropout=0.197, lr=0.000660, hidden_size=26, embedding_size=11, n_steps=94
2025-03-26 03:40:46,256 - INFO - Trial 20: RNN Train Loss: 0.3462122
2025-03-26 03:40:46,257 - INFO - Trial 20: Validation set has 128 participants
2025-03-26 03:40:50,905 - INFO - Trial 20: Average Validation Loss: 0.4419, Eval count: 128
2025-03-26 03:40:50,915 - INFO - Trial 21: dropout=0.305, lr=0.000103, hidden_size=21, embedding_size=10, n_steps=97
2025-03-26 03:49:15,236 - INFO - Trial 21: RNN Train Loss: 0.3526955
2025-03-26 03:49:15,236 - INFO - Trial 21: Validation set has 128 participants
2025-03-26 03:49:19,872 - INFO - Trial 21: Average Validation Loss: 0.4317, Eval count: 128
2025-03-26 03:49:19,882 - INFO - Trial 22: dropout=0.427, lr=0.000733, hidden_size=18, embedding_size=15, n_steps=59
2025-03-26 03:57:51,698 - INFO - Trial 22: RNN Train Loss: 0.2951263
2025-03-26 03:57:51,699 - INFO - Trial 22: Validation set has 128 participants
2025-03-26 03:57:56,096 - INFO - Trial 22: Average Validation Loss: 0.4136, Eval count: 128
2025-03-26 03:57:56,107 - INFO - Trial 23: dropout=0.357, lr=0.002331, hidden_size=23, embedding_size=10, n_steps=99
2025-03-26 04:06:22,844 - INFO - Trial 23: RNN Train Loss: 0.2969588
2025-03-26 04:06:22,845 - INFO - Trial 23: Validation set has 128 participants
2025-03-26 04:06:27,614 - INFO - Trial 23: Average Validation Loss: 0.4068, Eval count: 128
2025-03-26 04:06:27,624 - INFO - Trial 24: dropout=0.283, lr=0.000320, hidden_size=20, embedding_size=18, n_steps=72
2025-03-26 04:14:58,702 - INFO - Trial 24: RNN Train Loss: 0.3098313
2025-03-26 04:14:58,703 - INFO - Trial 24: Validation set has 128 participants
2025-03-26 04:15:03,090 - INFO - Trial 24: Average Validation Loss: 0.4111, Eval count: 128
2025-03-26 04:15:03,100 - INFO - Trial 25: dropout=0.454, lr=0.001113, hidden_size=26, embedding_size=10, n_steps=34
2025-03-26 04:24:39,254 - INFO - Trial 25: RNN Train Loss: 0.3412496
2025-03-26 04:24:39,255 - INFO - Trial 25: Validation set has 128 participants
2025-03-26 04:24:43,685 - INFO - Trial 25: Average Validation Loss: 0.4513, Eval count: 128
2025-03-26 04:24:43,695 - INFO - Trial 26: dropout=0.366, lr=0.002103, hidden_size=11, embedding_size=14, n_steps=19
2025-03-26 04:33:06,602 - INFO - Trial 26: RNN Train Loss: 0.2950439
2025-03-26 04:33:06,603 - INFO - Trial 26: Validation set has 128 participants
2025-03-26 04:33:10,950 - INFO - Trial 26: Average Validation Loss: 0.4189, Eval count: 128
2025-03-26 04:33:10,960 - INFO - Trial 27: dropout=0.286, lr=0.000587, hidden_size=16, embedding_size=22, n_steps=89
2025-03-26 04:41:37,318 - INFO - Trial 27: RNN Train Loss: 0.3216563
2025-03-26 04:41:37,318 - INFO - Trial 27: Validation set has 128 participants
2025-03-26 04:41:42,197 - INFO - Trial 27: Average Validation Loss: 0.4268, Eval count: 128
2025-03-26 04:41:42,208 - INFO - Trial 28: dropout=0.194, lr=0.000933, hidden_size=25, embedding_size=9, n_steps=100
2025-03-26 04:51:01,015 - INFO - Trial 28: RNN Train Loss: 0.2679572
2025-03-26 04:51:01,016 - INFO - Trial 28: Validation set has 128 participants
2025-03-26 04:51:05,502 - INFO - Trial 28: Average Validation Loss: 0.3928, Eval count: 128
2025-03-26 04:51:05,512 - INFO - Trial 29: dropout=0.204, lr=0.001079, hidden_size=25, embedding_size=18, n_steps=99
2025-03-26 05:01:09,712 - INFO - Trial 29: RNN Train Loss: 0.2865256
2025-03-26 05:01:09,713 - INFO - Trial 29: Validation set has 128 participants
2025-03-26 05:01:14,355 - INFO - Trial 29: Average Validation Loss: 0.3975, Eval count: 128
2025-03-26 05:01:14,366 - INFO - Trial 30: dropout=0.188, lr=0.000281, hidden_size=21, embedding_size=10, n_steps=71
2025-03-26 05:09:37,395 - INFO - Trial 30: RNN Train Loss: 0.2887034
2025-03-26 05:09:37,396 - INFO - Trial 30: Validation set has 128 participants
2025-03-26 05:09:41,756 - INFO - Trial 30: Average Validation Loss: 0.3874, Eval count: 128
2025-03-26 05:09:41,766 - INFO - Trial 31: dropout=0.186, lr=0.000268, hidden_size=20, embedding_size=10, n_steps=72
2025-03-26 05:18:02,094 - INFO - Trial 31: RNN Train Loss: 0.3008404
2025-03-26 05:18:02,095 - INFO - Trial 31: Validation set has 128 participants
2025-03-26 05:18:06,524 - INFO - Trial 31: Average Validation Loss: 0.3943, Eval count: 128
2025-03-26 05:18:06,535 - INFO - Trial 32: dropout=0.269, lr=0.000577, hidden_size=22, embedding_size=12, n_steps=90
2025-03-26 05:26:35,281 - INFO - Trial 32: RNN Train Loss: 0.3061644
2025-03-26 05:26:35,282 - INFO - Trial 32: Validation set has 128 participants
2025-03-26 05:26:39,697 - INFO - Trial 32: Average Validation Loss: 0.4066, Eval count: 128
2025-03-26 05:26:39,708 - INFO - Trial 33: dropout=0.217, lr=0.000891, hidden_size=27, embedding_size=9, n_steps=84
2025-03-26 05:36:03,845 - INFO - Trial 33: RNN Train Loss: 0.2828233
2025-03-26 05:36:03,846 - INFO - Trial 33: Validation set has 128 participants
2025-03-26 05:36:08,497 - INFO - Trial 33: Average Validation Loss: 0.3956, Eval count: 128
2025-03-26 05:36:08,508 - INFO - Trial 34: dropout=0.140, lr=0.000127, hidden_size=22, embedding_size=13, n_steps=76
2025-03-26 05:44:39,801 - INFO - Trial 34: RNN Train Loss: 0.3735715
2025-03-26 05:44:39,801 - INFO - Trial 34: Validation set has 128 participants
2025-03-26 05:44:44,240 - INFO - Trial 34: Average Validation Loss: 0.4434, Eval count: 128
2025-03-26 05:44:44,250 - INFO - Trial 35: dropout=0.173, lr=0.000274, hidden_size=24, embedding_size=11, n_steps=64
2025-03-26 05:54:08,759 - INFO - Trial 35: RNN Train Loss: 0.2974135
2025-03-26 05:54:08,759 - INFO - Trial 35: Validation set has 128 participants
2025-03-26 05:54:13,294 - INFO - Trial 35: Average Validation Loss: 0.3928, Eval count: 128
2025-03-26 05:54:13,305 - INFO - Trial 36: dropout=0.162, lr=0.000273, hidden_size=19, embedding_size=32, n_steps=66
2025-03-26 06:04:10,165 - INFO - Trial 36: RNN Train Loss: 0.3087388
2025-03-26 06:04:10,165 - INFO - Trial 36: Validation set has 128 participants
2025-03-26 06:04:14,641 - INFO - Trial 36: Average Validation Loss: 0.4175, Eval count: 128
2025-03-26 06:04:14,651 - INFO - Trial 37: dropout=0.087, lr=0.000497, hidden_size=23, embedding_size=17, n_steps=63
2025-03-26 06:12:55,889 - INFO - Trial 37: RNN Train Loss: 0.2762978
2025-03-26 06:12:55,890 - INFO - Trial 37: Validation set has 128 participants
2025-03-26 06:13:00,291 - INFO - Trial 37: Average Validation Loss: 0.4043, Eval count: 128
2025-03-26 06:13:00,301 - INFO - Trial 38: dropout=0.001, lr=0.000212, hidden_size=30, embedding_size=15, n_steps=55
2025-03-26 06:23:22,582 - INFO - Trial 38: RNN Train Loss: 0.3717794
2025-03-26 06:23:22,583 - INFO - Trial 38: Validation set has 128 participants
2025-03-26 06:23:27,156 - INFO - Trial 38: Average Validation Loss: 0.4612, Eval count: 128
2025-03-26 06:23:27,167 - INFO - Trial 39: dropout=0.226, lr=0.000367, hidden_size=21, embedding_size=11, n_steps=83
2025-03-26 06:31:52,927 - INFO - Trial 39: RNN Train Loss: 0.3526672
2025-03-26 06:31:52,927 - INFO - Trial 39: Validation set has 128 participants
2025-03-26 06:31:57,299 - INFO - Trial 39: Average Validation Loss: 0.4485, Eval count: 128
2025-03-26 06:31:57,310 - INFO - Trial 40: dropout=0.249, lr=0.000147, hidden_size=28, embedding_size=13, n_steps=77
2025-03-26 06:41:29,770 - INFO - Trial 40: RNN Train Loss: 0.4313514
2025-03-26 06:41:29,770 - INFO - Trial 40: Validation set has 128 participants
2025-03-26 06:41:34,391 - INFO - Trial 40: Average Validation Loss: 0.4952, Eval count: 128
2025-03-26 06:41:34,403 - INFO - Trial 41: dropout=0.176, lr=0.000504, hidden_size=25, embedding_size=11, n_steps=93
2025-03-26 06:50:56,987 - INFO - Trial 41: RNN Train Loss: 0.2791863
2025-03-26 06:50:56,987 - INFO - Trial 41: Validation set has 128 participants
2025-03-26 06:51:01,651 - INFO - Trial 41: Average Validation Loss: 0.3891, Eval count: 128
2025-03-26 06:51:01,663 - INFO - Trial 42: dropout=0.156, lr=0.000469, hidden_size=24, embedding_size=11, n_steps=87
2025-03-26 07:00:21,338 - INFO - Trial 42: RNN Train Loss: 0.3573315
2025-03-26 07:00:21,339 - INFO - Trial 42: Validation set has 128 participants
2025-03-26 07:00:25,743 - INFO - Trial 42: Average Validation Loss: 0.4398, Eval count: 128
2025-03-26 07:00:25,754 - INFO - Trial 43: dropout=0.175, lr=0.000249, hidden_size=24, embedding_size=14, n_steps=92
2025-03-26 07:09:51,951 - INFO - Trial 43: RNN Train Loss: 0.3091077
2025-03-26 07:09:51,951 - INFO - Trial 43: Validation set has 128 participants
2025-03-26 07:09:56,586 - INFO - Trial 43: Average Validation Loss: 0.4046, Eval count: 128
2025-03-26 07:09:56,597 - INFO - Trial 44: dropout=0.319, lr=0.000364, hidden_size=22, embedding_size=9, n_steps=62
2025-03-26 07:18:25,650 - INFO - Trial 44: RNN Train Loss: 0.2820987
2025-03-26 07:18:25,650 - INFO - Trial 44: Validation set has 128 participants
2025-03-26 07:18:30,315 - INFO - Trial 44: Average Validation Loss: 0.3836, Eval count: 128
2025-03-26 07:18:30,327 - INFO - Trial 45: dropout=0.320, lr=0.000388, hidden_size=22, embedding_size=9, n_steps=80
2025-03-26 07:26:55,868 - INFO - Trial 45: RNN Train Loss: 0.3186821
2025-03-26 07:26:55,869 - INFO - Trial 45: Validation set has 128 participants
2025-03-26 07:27:00,248 - INFO - Trial 45: Average Validation Loss: 0.4070, Eval count: 128
2025-03-26 07:27:00,260 - INFO - Trial 46: dropout=0.118, lr=0.000725, hidden_size=17, embedding_size=23, n_steps=95
2025-03-26 07:35:36,363 - INFO - Trial 46: RNN Train Loss: 0.3156630
2025-03-26 07:35:36,363 - INFO - Trial 46: Validation set has 128 participants
2025-03-26 07:35:40,708 - INFO - Trial 46: Average Validation Loss: 0.4149, Eval count: 128
2025-03-26 07:35:40,719 - INFO - Trial 47: dropout=0.267, lr=0.000529, hidden_size=21, embedding_size=26, n_steps=73
2025-03-26 07:45:29,383 - INFO - Trial 47: RNN Train Loss: 0.3202254
2025-03-26 07:45:29,383 - INFO - Trial 47: Validation set has 128 participants
2025-03-26 07:45:34,244 - INFO - Trial 47: Average Validation Loss: 0.4227, Eval count: 128
2025-03-26 07:45:34,256 - INFO - Trial 48: dropout=0.340, lr=0.001354, hidden_size=19, embedding_size=8, n_steps=85
2025-03-26 07:53:50,935 - INFO - Trial 48: RNN Train Loss: 0.2829345
2025-03-26 07:53:50,935 - INFO - Trial 48: Validation set has 128 participants
2025-03-26 07:53:55,324 - INFO - Trial 48: Average Validation Loss: 0.3997, Eval count: 128
2025-03-26 07:53:55,335 - INFO - Trial 49: dropout=0.394, lr=0.000351, hidden_size=28, embedding_size=13, n_steps=42
2025-03-26 08:03:39,386 - INFO - Trial 49: RNN Train Loss: 0.2729142
2025-03-26 08:03:39,387 - INFO - Trial 49: Validation set has 128 participants
2025-03-26 08:03:43,712 - INFO - Trial 49: Average Validation Loss: 0.3845, Eval count: 128
2025-03-26 08:03:43,713 - INFO - Best hyperparameters: {'dropout': 0.31905877051758935, 'learning_rate': 0.0003638666906537081, 'hidden_size': 22, 'embedding_size': 9, 'n_steps': 62}
2025-03-26 08:03:43,713 - INFO - Best validation loss: 0.3836
2025-03-26 08:12:14,051 - INFO - Final RNN training loss: 0.3158555
2025-03-26 08:12:14,052 - INFO - Evaluating with SINDy - fitting separate models for each participant's validation trials
2025-03-26 08:12:14,052 - INFO - Processing participant 0.0...
2025-03-26 08:12:14,052 - INFO - Fitting SINDy model for participant 0.0
2025-03-26 08:12:15,370 - INFO - Participant 0.0: LL=-0.3442, BIC=1.3709, Params=10, Val trials=60
2025-03-26 08:12:15,370 - INFO - Processing participant 1.0...
2025-03-26 08:12:15,370 - INFO - Fitting SINDy model for participant 1.0
2025-03-26 08:12:16,761 - INFO - Participant 1.0: LL=-4.5789, BIC=10.1131, Params=14, Val trials=60
2025-03-26 08:12:16,761 - INFO - Processing participant 2.0...
2025-03-26 08:12:16,762 - INFO - Fitting SINDy model for participant 2.0
2025-03-26 08:12:18,155 - INFO - Participant 2.0: LL=-0.7012, BIC=2.0165, Params=9, Val trials=60
2025-03-26 08:12:18,155 - INFO - Processing participant 3.0...
2025-03-26 08:12:18,156 - INFO - Fitting SINDy model for participant 3.0
2025-03-26 08:12:19,588 - INFO - Participant 3.0: LL=-2.6777, BIC=6.1061, Params=11, Val trials=60
2025-03-26 08:12:19,588 - INFO - Processing participant 4.0...
2025-03-26 08:12:19,588 - INFO - Fitting SINDy model for participant 4.0
2025-03-26 08:12:20,910 - INFO - Participant 4.0: LL=-0.4580, BIC=1.4619, Params=8, Val trials=60
2025-03-26 08:12:20,911 - INFO - Processing participant 5.0...
2025-03-26 08:12:20,911 - INFO - Fitting SINDy model for participant 5.0
2025-03-26 08:12:22,294 - INFO - Participant 5.0: LL=-0.6699, BIC=2.0222, Params=10, Val trials=60
2025-03-26 08:12:22,294 - INFO - Processing participant 6.0...
2025-03-26 08:12:22,294 - INFO - Fitting SINDy model for participant 6.0
2025-03-26 08:12:23,753 - INFO - Participant 6.0: LL=-3.6153, BIC=8.3224, Params=16, Val trials=60
2025-03-26 08:12:23,753 - INFO - Processing participant 7.0...
2025-03-26 08:12:23,754 - INFO - Fitting SINDy model for participant 7.0
2025-03-26 08:12:25,219 - INFO - Participant 7.0: LL=-0.1818, BIC=0.9096, Params=8, Val trials=60
2025-03-26 08:12:25,219 - INFO - Processing participant 8.0...
2025-03-26 08:12:25,219 - INFO - Fitting SINDy model for participant 8.0
2025-03-26 08:12:26,631 - INFO - Participant 8.0: LL=-0.0182, BIC=0.6506, Params=9, Val trials=60
2025-03-26 08:12:26,632 - INFO - Processing participant 9.0...
2025-03-26 08:12:26,632 - INFO - Fitting SINDy model for participant 9.0
2025-03-26 08:12:27,976 - INFO - Participant 9.0: LL=-0.6931, BIC=2.2052, Params=12, Val trials=60
2025-03-26 08:12:27,976 - INFO - Processing participant 10.0...
2025-03-26 08:12:27,977 - INFO - Fitting SINDy model for participant 10.0
2025-03-26 08:12:29,434 - INFO - Participant 10.0: LL=-0.3716, BIC=1.5621, Params=12, Val trials=60
2025-03-26 08:12:29,434 - INFO - Processing participant 11.0...
2025-03-26 08:12:29,434 - INFO - Fitting SINDy model for participant 11.0
2025-03-26 08:12:30,833 - INFO - Participant 11.0: LL=-0.3414, BIC=1.2969, Params=9, Val trials=60
2025-03-26 08:12:30,833 - INFO - Processing participant 12.0...
2025-03-26 08:12:30,834 - INFO - Fitting SINDy model for participant 12.0
2025-03-26 08:12:32,198 - INFO - Participant 12.0: LL=-0.0301, BIC=0.6743, Params=9, Val trials=60
2025-03-26 08:12:32,198 - INFO - Processing participant 13.0...
2025-03-26 08:12:32,198 - INFO - Fitting SINDy model for participant 13.0
2025-03-26 08:12:33,491 - INFO - Participant 13.0: LL=-1.3708, BIC=3.4923, Params=11, Val trials=60
2025-03-26 08:12:33,491 - INFO - Processing participant 14.0...
2025-03-26 08:12:33,492 - INFO - Fitting SINDy model for participant 14.0
2025-03-26 08:12:34,871 - INFO - Participant 14.0: LL=-0.6977, BIC=2.0095, Params=9, Val trials=60
2025-03-26 08:12:34,871 - INFO - Processing participant 15.0...
2025-03-26 08:12:34,872 - INFO - Fitting SINDy model for participant 15.0
2025-03-26 08:12:36,300 - INFO - Participant 15.0: LL=-10.6364, BIC=22.2282, Params=14, Val trials=60
2025-03-26 08:12:36,300 - INFO - Processing participant 16.0...
2025-03-26 08:12:36,301 - INFO - Fitting SINDy model for participant 16.0
2025-03-26 08:12:37,726 - INFO - Participant 16.0: LL=-0.5017, BIC=1.9587, Params=14, Val trials=60
2025-03-26 08:12:37,726 - INFO - Processing participant 17.0...
2025-03-26 08:12:37,727 - INFO - Fitting SINDy model for participant 17.0
2025-03-26 08:12:39,104 - INFO - Participant 17.0: LL=-0.9170, BIC=2.5164, Params=10, Val trials=60
2025-03-26 08:12:39,104 - INFO - Processing participant 18.0...
2025-03-26 08:12:39,105 - INFO - Fitting SINDy model for participant 18.0
2025-03-26 08:12:40,545 - INFO - Participant 18.0: LL=-0.7107, BIC=2.0356, Params=9, Val trials=60
2025-03-26 08:12:40,545 - INFO - Processing participant 19.0...
2025-03-26 08:12:40,546 - INFO - Fitting SINDy model for participant 19.0
2025-03-26 08:12:41,963 - INFO - Participant 19.0: LL=-2.4471, BIC=5.7814, Params=13, Val trials=60
2025-03-26 08:12:41,963 - INFO - Processing participant 20.0...
2025-03-26 08:12:41,964 - INFO - Fitting SINDy model for participant 20.0
2025-03-26 08:12:43,323 - INFO - Participant 20.0: LL=-0.6419, BIC=1.8980, Params=9, Val trials=60
2025-03-26 08:12:43,323 - INFO - Processing participant 21.0...
2025-03-26 08:12:43,324 - INFO - Fitting SINDy model for participant 21.0
2025-03-26 08:12:44,702 - INFO - Participant 21.0: LL=-0.6931, BIC=2.1369, Params=11, Val trials=60
2025-03-26 08:12:44,702 - INFO - Processing participant 22.0...
2025-03-26 08:12:44,703 - INFO - Fitting SINDy model for participant 22.0
2025-03-26 08:12:46,095 - INFO - Participant 22.0: LL=-0.3990, BIC=1.4122, Params=9, Val trials=60
2025-03-26 08:12:46,095 - INFO - Processing participant 23.0...
2025-03-26 08:12:46,096 - INFO - Fitting SINDy model for participant 23.0
2025-03-26 08:12:47,440 - INFO - Participant 23.0: LL=-0.6931, BIC=2.2734, Params=13, Val trials=60
2025-03-26 08:12:47,440 - INFO - Processing participant 24.0...
2025-03-26 08:12:47,441 - INFO - Fitting SINDy model for participant 24.0
2025-03-26 08:12:48,714 - INFO - Participant 24.0: LL=-0.7809, BIC=2.1759, Params=9, Val trials=60
2025-03-26 08:12:48,714 - INFO - Processing participant 25.0...
2025-03-26 08:12:48,715 - INFO - Fitting SINDy model for participant 25.0
2025-03-26 08:12:50,109 - INFO - Participant 25.0: LL=-3.8409, BIC=8.5006, Params=12, Val trials=60
2025-03-26 08:12:50,109 - INFO - Processing participant 26.0...
2025-03-26 08:12:50,110 - INFO - Fitting SINDy model for participant 26.0
2025-03-26 08:12:51,470 - INFO - Participant 26.0: LL=-0.6666, BIC=2.0156, Params=10, Val trials=60
2025-03-26 08:12:51,470 - INFO - Processing participant 27.0...
2025-03-26 08:12:51,471 - INFO - Fitting SINDy model for participant 27.0
2025-03-26 08:12:52,810 - INFO - Participant 27.0: LL=-0.6931, BIC=2.2734, Params=13, Val trials=60
2025-03-26 08:12:52,810 - INFO - Processing participant 28.0...
2025-03-26 08:12:52,811 - INFO - Fitting SINDy model for participant 28.0
2025-03-26 08:12:54,159 - INFO - Participant 28.0: LL=-0.0237, BIC=0.8663, Params=12, Val trials=60
2025-03-26 08:12:54,159 - INFO - Processing participant 29.0...
2025-03-26 08:12:54,160 - INFO - Fitting SINDy model for participant 29.0
2025-03-26 08:12:55,437 - INFO - Participant 29.0: LL=-0.6149, BIC=1.9123, Params=10, Val trials=60
2025-03-26 08:12:55,437 - INFO - Processing participant 30.0...
2025-03-26 08:12:55,438 - INFO - Fitting SINDy model for participant 30.0
2025-03-26 08:12:56,802 - INFO - Participant 30.0: LL=-0.1951, BIC=1.0043, Params=9, Val trials=60
2025-03-26 08:12:56,802 - INFO - Processing participant 31.0...
2025-03-26 08:12:56,803 - INFO - Fitting SINDy model for participant 31.0
2025-03-26 08:12:58,228 - INFO - Participant 31.0: LL=-0.5622, BIC=1.7385, Params=9, Val trials=60
2025-03-26 08:12:58,228 - INFO - Processing participant 32.0...
2025-03-26 08:12:58,229 - INFO - Fitting SINDy model for participant 32.0
2025-03-26 08:12:59,653 - INFO - Participant 32.0: LL=-0.6931, BIC=2.0687, Params=10, Val trials=60
2025-03-26 08:12:59,653 - INFO - Processing participant 33.0...
2025-03-26 08:12:59,653 - INFO - Fitting SINDy model for participant 33.0
2025-03-26 08:13:00,996 - INFO - Participant 33.0: LL=-0.4601, BIC=1.7391, Params=12, Val trials=60
2025-03-26 08:13:00,996 - INFO - Processing participant 34.0...
2025-03-26 08:13:00,996 - INFO - Fitting SINDy model for participant 34.0
2025-03-26 08:13:02,371 - INFO - Participant 34.0: LL=-0.1578, BIC=0.8614, Params=8, Val trials=60
2025-03-26 08:13:02,371 - INFO - Processing participant 35.0...
2025-03-26 08:13:02,371 - INFO - Fitting SINDy model for participant 35.0
2025-03-26 08:13:03,778 - INFO - Participant 35.0: LL=-0.9020, BIC=2.4181, Params=9, Val trials=60
2025-03-26 08:13:03,778 - INFO - Processing participant 36.0...
2025-03-26 08:13:03,779 - INFO - Fitting SINDy model for participant 36.0
2025-03-26 08:13:05,182 - INFO - Participant 36.0: LL=-0.6988, BIC=2.0118, Params=9, Val trials=60
2025-03-26 08:13:05,182 - INFO - Processing participant 37.0...
2025-03-26 08:13:05,182 - INFO - Fitting SINDy model for participant 37.0
2025-03-26 08:13:06,448 - INFO - Participant 37.0: LL=-5.2158, BIC=11.3869, Params=14, Val trials=60
2025-03-26 08:13:06,448 - INFO - Processing participant 38.0...
2025-03-26 08:13:06,449 - INFO - Fitting SINDy model for participant 38.0
2025-03-26 08:13:07,794 - INFO - Participant 38.0: LL=-0.1583, BIC=1.0672, Params=11, Val trials=60
2025-03-26 08:13:07,795 - INFO - Processing participant 39.0...
2025-03-26 08:13:07,795 - INFO - Fitting SINDy model for participant 39.0
2025-03-26 08:13:09,213 - INFO - Participant 39.0: LL=-9.0932, BIC=19.1417, Params=14, Val trials=60
2025-03-26 08:13:09,213 - INFO - Processing participant 40.0...
2025-03-26 08:13:09,213 - INFO - Fitting SINDy model for participant 40.0
2025-03-26 08:13:10,563 - INFO - Participant 40.0: LL=-0.5505, BIC=1.7152, Params=9, Val trials=60
2025-03-26 08:13:10,563 - INFO - Processing participant 41.0...
2025-03-26 08:13:10,563 - INFO - Fitting SINDy model for participant 41.0
2025-03-26 08:13:11,856 - INFO - Participant 41.0: LL=-0.6931, BIC=2.0687, Params=10, Val trials=60
2025-03-26 08:13:11,856 - INFO - Processing participant 42.0...
2025-03-26 08:13:11,857 - INFO - Fitting SINDy model for participant 42.0
2025-03-26 08:13:13,200 - INFO - Participant 42.0: LL=-0.0382, BIC=0.6905, Params=9, Val trials=60
2025-03-26 08:13:13,200 - INFO - Processing participant 43.0...
2025-03-26 08:13:13,201 - INFO - Fitting SINDy model for participant 43.0
2025-03-26 08:13:14,546 - INFO - Participant 43.0: LL=-0.2567, BIC=1.1275, Params=9, Val trials=60
2025-03-26 08:13:14,546 - INFO - Processing participant 44.0...
2025-03-26 08:13:14,546 - INFO - Fitting SINDy model for participant 44.0
2025-03-26 08:13:15,881 - INFO - Participant 44.0: LL=-0.0141, BIC=0.6424, Params=9, Val trials=60
2025-03-26 08:13:15,881 - INFO - Processing participant 45.0...
2025-03-26 08:13:15,882 - INFO - Fitting SINDy model for participant 45.0
2025-03-26 08:13:17,207 - INFO - Participant 45.0: LL=-1.3923, BIC=3.6035, Params=12, Val trials=60
2025-03-26 08:13:17,207 - INFO - Processing participant 46.0...
2025-03-26 08:13:17,207 - INFO - Fitting SINDy model for participant 46.0
2025-03-26 08:13:18,616 - INFO - Participant 46.0: LL=-5.8090, BIC=12.5052, Params=13, Val trials=60
2025-03-26 08:13:18,616 - INFO - Processing participant 47.0...
2025-03-26 08:13:18,616 - INFO - Fitting SINDy model for participant 47.0
2025-03-26 08:13:19,995 - INFO - Participant 47.0: LL=-0.6542, BIC=1.9225, Params=9, Val trials=60
2025-03-26 08:13:19,995 - INFO - Processing participant 48.0...
2025-03-26 08:13:19,996 - INFO - Fitting SINDy model for participant 48.0
2025-03-26 08:13:21,259 - INFO - Participant 48.0: LL=-0.7278, BIC=2.1381, Params=10, Val trials=60
2025-03-26 08:13:21,259 - INFO - Processing participant 49.0...
2025-03-26 08:13:21,259 - INFO - Fitting SINDy model for participant 49.0
2025-03-26 08:13:22,591 - INFO - Participant 49.0: LL=-2.5165, BIC=6.0567, Params=15, Val trials=60
2025-03-26 08:13:22,591 - INFO - Processing participant 50.0...
2025-03-26 08:13:22,591 - INFO - Fitting SINDy model for participant 50.0
2025-03-26 08:13:23,939 - INFO - Participant 50.0: LL=-0.2648, BIC=1.2120, Params=10, Val trials=60
2025-03-26 08:13:23,940 - INFO - Processing participant 51.0...
2025-03-26 08:13:23,940 - INFO - Fitting SINDy model for participant 51.0
2025-03-26 08:13:25,342 - INFO - Participant 51.0: LL=-0.0180, BIC=0.6501, Params=9, Val trials=60
2025-03-26 08:13:25,342 - INFO - Processing participant 52.0...
2025-03-26 08:13:25,343 - INFO - Fitting SINDy model for participant 52.0
2025-03-26 08:13:26,685 - INFO - Participant 52.0: LL=-6.5176, BIC=13.9906, Params=14, Val trials=60
2025-03-26 08:13:26,685 - INFO - Processing participant 53.0...
2025-03-26 08:13:26,686 - INFO - Fitting SINDy model for participant 53.0
2025-03-26 08:13:27,952 - INFO - Participant 53.0: LL=-3.7425, BIC=8.5767, Params=16, Val trials=60
2025-03-26 08:13:27,952 - INFO - Processing participant 54.0...
2025-03-26 08:13:27,953 - INFO - Fitting SINDy model for participant 54.0
2025-03-26 08:13:29,291 - INFO - Participant 54.0: LL=-0.0333, BIC=0.8854, Params=12, Val trials=60
2025-03-26 08:13:29,292 - INFO - Processing participant 55.0...
2025-03-26 08:13:29,292 - INFO - Fitting SINDy model for participant 55.0
2025-03-26 08:13:30,635 - INFO - Participant 55.0: LL=-0.1815, BIC=0.7725, Params=6, Val trials=60
2025-03-26 08:13:30,636 - INFO - Processing participant 56.0...
2025-03-26 08:13:30,636 - INFO - Fitting SINDy model for participant 56.0
2025-03-26 08:13:31,981 - INFO - Participant 56.0: LL=-0.4457, BIC=1.5056, Params=9, Val trials=60
2025-03-26 08:13:31,987 - INFO - Processing participant 57.0...
2025-03-26 08:13:31,988 - INFO - Fitting SINDy model for participant 57.0
2025-03-26 08:13:33,262 - INFO - Participant 57.0: LL=-0.3146, BIC=1.2433, Params=9, Val trials=60
2025-03-26 08:13:33,262 - INFO - Processing participant 58.0...
2025-03-26 08:13:33,263 - INFO - Fitting SINDy model for participant 58.0
2025-03-26 08:13:34,606 - INFO - Participant 58.0: LL=-0.1950, BIC=1.0041, Params=9, Val trials=60
2025-03-26 08:13:34,606 - INFO - Processing participant 59.0...
2025-03-26 08:13:34,606 - INFO - Fitting SINDy model for participant 59.0
2025-03-26 08:13:35,954 - INFO - Participant 59.0: LL=-0.6875, BIC=1.9891, Params=9, Val trials=60
2025-03-26 08:13:35,954 - INFO - Processing participant 60.0...
2025-03-26 08:13:35,955 - INFO - Fitting SINDy model for participant 60.0
2025-03-26 08:13:37,303 - INFO - Participant 60.0: LL=-6.7972, BIC=14.4815, Params=13, Val trials=60
2025-03-26 08:13:37,303 - INFO - Processing participant 61.0...
2025-03-26 08:13:37,303 - INFO - Fitting SINDy model for participant 61.0
2025-03-26 08:13:38,609 - INFO - Participant 61.0: LL=-0.6344, BIC=1.8830, Params=9, Val trials=60
2025-03-26 08:13:38,609 - INFO - Processing participant 62.0...
2025-03-26 08:13:38,610 - INFO - Fitting SINDy model for participant 62.0
2025-03-26 08:13:39,998 - INFO - Participant 62.0: LL=-3.3153, BIC=7.6541, Params=15, Val trials=60
2025-03-26 08:13:39,999 - INFO - Processing participant 63.0...
2025-03-26 08:13:39,999 - INFO - Fitting SINDy model for participant 63.0
2025-03-26 08:13:41,336 - INFO - Participant 63.0: LL=-0.0348, BIC=0.6156, Params=8, Val trials=60
2025-03-26 08:13:41,336 - INFO - Processing participant 64.0...
2025-03-26 08:13:41,336 - INFO - Fitting SINDy model for participant 64.0
2025-03-26 08:13:42,690 - INFO - Participant 64.0: LL=-1.4374, BIC=3.4890, Params=9, Val trials=60
2025-03-26 08:13:42,690 - INFO - Processing participant 65.0...
2025-03-26 08:13:42,691 - INFO - Fitting SINDy model for participant 65.0
2025-03-26 08:13:43,977 - INFO - Participant 65.0: LL=-0.3961, BIC=1.2700, Params=7, Val trials=60
2025-03-26 08:13:43,977 - INFO - Processing participant 66.0...
2025-03-26 08:13:43,978 - INFO - Fitting SINDy model for participant 66.0
2025-03-26 08:13:45,297 - INFO - Participant 66.0: LL=-1.9418, BIC=4.8389, Params=14, Val trials=60
2025-03-26 08:13:45,297 - INFO - Processing participant 67.0...
2025-03-26 08:13:45,298 - INFO - Fitting SINDy model for participant 67.0
2025-03-26 08:13:46,637 - INFO - Participant 67.0: LL=-0.5519, BIC=1.9227, Params=12, Val trials=60
2025-03-26 08:13:46,637 - INFO - Processing participant 68.0...
2025-03-26 08:13:46,638 - INFO - Fitting SINDy model for participant 68.0
2025-03-26 08:13:47,987 - INFO - Participant 68.0: LL=-0.0156, BIC=0.6453, Params=9, Val trials=60
2025-03-26 08:13:47,987 - INFO - Processing participant 69.0...
2025-03-26 08:13:47,988 - INFO - Fitting SINDy model for participant 69.0
2025-03-26 08:13:49,270 - INFO - Participant 69.0: LL=-9.9841, BIC=20.7188, Params=11, Val trials=60
2025-03-26 08:13:49,270 - INFO - Processing participant 70.0...
2025-03-26 08:13:49,271 - INFO - Fitting SINDy model for participant 70.0
2025-03-26 08:13:50,614 - INFO - Participant 70.0: LL=-1.7731, BIC=4.5698, Params=15, Val trials=60
2025-03-26 08:13:50,614 - INFO - Processing participant 71.0...
2025-03-26 08:13:50,615 - INFO - Fitting SINDy model for participant 71.0
2025-03-26 08:13:51,975 - INFO - Participant 71.0: LL=-0.0225, BIC=0.6591, Params=9, Val trials=60
2025-03-26 08:13:51,975 - INFO - Processing participant 72.0...
2025-03-26 08:13:51,976 - INFO - Fitting SINDy model for participant 72.0
2025-03-26 08:13:53,302 - INFO - Participant 72.0: LL=-0.0192, BIC=0.7208, Params=10, Val trials=60
2025-03-26 08:13:53,302 - INFO - Processing participant 73.0...
2025-03-26 08:13:53,303 - INFO - Fitting SINDy model for participant 73.0
2025-03-26 08:13:54,641 - INFO - Participant 73.0: LL=-0.6733, BIC=1.8926, Params=8, Val trials=60
2025-03-26 08:13:54,642 - INFO - Processing participant 74.0...
2025-03-26 08:13:54,642 - INFO - Fitting SINDy model for participant 74.0
2025-03-26 08:13:55,976 - INFO - Participant 74.0: LL=-5.2714, BIC=11.3616, Params=12, Val trials=60
2025-03-26 08:13:55,976 - INFO - Processing participant 75.0...
2025-03-26 08:13:55,977 - INFO - Fitting SINDy model for participant 75.0
2025-03-26 08:13:57,318 - INFO - Participant 75.0: LL=-4.8072, BIC=10.5014, Params=13, Val trials=60
2025-03-26 08:13:57,319 - INFO - Processing participant 76.0...
2025-03-26 08:13:57,319 - INFO - Fitting SINDy model for participant 76.0
2025-03-26 08:13:58,670 - INFO - Participant 76.0: LL=-6.5212, BIC=14.2024, Params=17, Val trials=60
2025-03-26 08:13:58,670 - INFO - Processing participant 77.0...
2025-03-26 08:13:58,671 - INFO - Fitting SINDy model for participant 77.0
2025-03-26 08:13:59,949 - INFO - Participant 77.0: LL=-3.4956, BIC=8.0148, Params=15, Val trials=60
2025-03-26 08:13:59,949 - INFO - Processing participant 78.0...
2025-03-26 08:13:59,949 - INFO - Fitting SINDy model for participant 78.0
2025-03-26 08:14:01,291 - INFO - Participant 78.0: LL=-0.6854, BIC=2.0531, Params=10, Val trials=60
2025-03-26 08:14:01,291 - INFO - Processing participant 79.0...
2025-03-26 08:14:01,291 - INFO - Fitting SINDy model for participant 79.0
2025-03-26 08:14:02,635 - INFO - Participant 79.0: LL=-0.4948, BIC=1.6038, Params=9, Val trials=60
2025-03-26 08:14:02,635 - INFO - Processing participant 80.0...
2025-03-26 08:14:02,636 - INFO - Fitting SINDy model for participant 80.0
2025-03-26 08:14:03,995 - INFO - Participant 80.0: LL=-5.4807, BIC=11.8484, Params=13, Val trials=60
2025-03-26 08:14:03,995 - INFO - Processing participant 81.0...
2025-03-26 08:14:03,996 - INFO - Fitting SINDy model for participant 81.0
2025-03-26 08:14:05,331 - INFO - Participant 81.0: LL=-0.0267, BIC=0.5994, Params=8, Val trials=60
2025-03-26 08:14:05,331 - INFO - Processing participant 82.0...
2025-03-26 08:14:05,331 - INFO - Fitting SINDy model for participant 82.0
2025-03-26 08:14:06,678 - INFO - Participant 82.0: LL=-0.3991, BIC=1.4123, Params=9, Val trials=60
2025-03-26 08:14:06,678 - INFO - Processing participant 83.0...
2025-03-26 08:14:06,679 - INFO - Fitting SINDy model for participant 83.0
2025-03-26 08:14:08,045 - INFO - Participant 83.0: LL=-0.1578, BIC=0.7934, Params=7, Val trials=60
2025-03-26 08:14:08,045 - INFO - Processing participant 84.0...
2025-03-26 08:14:08,046 - INFO - Fitting SINDy model for participant 84.0
2025-03-26 08:14:09,421 - INFO - Participant 84.0: LL=-1.6189, BIC=3.8519, Params=9, Val trials=60
2025-03-26 08:14:09,421 - INFO - Processing participant 85.0...
2025-03-26 08:14:09,421 - INFO - Fitting SINDy model for participant 85.0
2025-03-26 08:14:10,692 - INFO - Participant 85.0: LL=-0.6931, BIC=2.0004, Params=9, Val trials=60
2025-03-26 08:14:10,692 - INFO - Processing participant 86.0...
2025-03-26 08:14:10,692 - INFO - Fitting SINDy model for participant 86.0
2025-03-26 08:14:12,032 - INFO - Participant 86.0: LL=-4.4573, BIC=9.6653, Params=11, Val trials=60
2025-03-26 08:14:12,032 - INFO - Processing participant 87.0...
2025-03-26 08:14:12,033 - INFO - Fitting SINDy model for participant 87.0
2025-03-26 08:14:13,394 - INFO - Participant 87.0: LL=-7.4546, BIC=16.0010, Params=16, Val trials=60
2025-03-26 08:14:13,394 - INFO - Processing participant 88.0...
2025-03-26 08:14:13,395 - INFO - Fitting SINDy model for participant 88.0
2025-03-26 08:14:14,844 - INFO - Participant 88.0: LL=-0.8406, BIC=2.3636, Params=10, Val trials=60
2025-03-26 08:14:14,844 - INFO - Processing participant 89.0...
2025-03-26 08:14:14,845 - INFO - Fitting SINDy model for participant 89.0
2025-03-26 08:14:16,226 - INFO - Participant 89.0: LL=-0.6701, BIC=1.9543, Params=9, Val trials=60
2025-03-26 08:14:16,226 - INFO - Processing participant 90.0...
2025-03-26 08:14:16,227 - INFO - Fitting SINDy model for participant 90.0
2025-03-26 08:14:17,657 - INFO - Participant 90.0: LL=-0.1501, BIC=0.9144, Params=9, Val trials=60
2025-03-26 08:14:17,657 - INFO - Processing participant 91.0...
2025-03-26 08:14:17,658 - INFO - Fitting SINDy model for participant 91.0
2025-03-26 08:14:19,096 - INFO - Participant 91.0: LL=-0.1580, BIC=0.7938, Params=7, Val trials=60
2025-03-26 08:14:19,096 - INFO - Processing participant 92.0...
2025-03-26 08:14:19,097 - INFO - Fitting SINDy model for participant 92.0
2025-03-26 08:14:20,526 - INFO - Participant 92.0: LL=-0.7157, BIC=2.0455, Params=9, Val trials=60
2025-03-26 08:14:20,526 - INFO - Processing participant 93.0...
2025-03-26 08:14:20,527 - INFO - Fitting SINDy model for participant 93.0
2025-03-26 08:14:21,887 - INFO - Participant 93.0: LL=-0.4206, BIC=1.6601, Params=12, Val trials=60
2025-03-26 08:14:21,888 - INFO - Processing participant 94.0...
2025-03-26 08:14:21,888 - INFO - Fitting SINDy model for participant 94.0
2025-03-26 08:14:23,322 - INFO - Participant 94.0: LL=-0.5870, BIC=1.7882, Params=9, Val trials=60
2025-03-26 08:14:23,322 - INFO - Processing participant 95.0...
2025-03-26 08:14:23,323 - INFO - Fitting SINDy model for participant 95.0
2025-03-26 08:14:24,742 - INFO - Participant 95.0: LL=-0.2619, BIC=1.0697, Params=8, Val trials=60
2025-03-26 08:14:24,742 - INFO - Processing participant 96.0...
2025-03-26 08:14:24,743 - INFO - Fitting SINDy model for participant 96.0
2025-03-26 08:14:26,092 - INFO - Participant 96.0: LL=-0.5822, BIC=1.7785, Params=9, Val trials=60
2025-03-26 08:14:26,092 - INFO - Processing participant 97.0...
2025-03-26 08:14:26,093 - INFO - Fitting SINDy model for participant 97.0
2025-03-26 08:14:27,515 - INFO - Participant 97.0: LL=-4.3531, BIC=9.4567, Params=11, Val trials=60
2025-03-26 08:14:27,515 - INFO - Processing participant 98.0...
2025-03-26 08:14:27,516 - INFO - Fitting SINDy model for participant 98.0
2025-03-26 08:14:28,946 - INFO - Participant 98.0: LL=-0.1576, BIC=0.8611, Params=8, Val trials=60
2025-03-26 08:14:28,946 - INFO - Processing participant 99.0...
2025-03-26 08:14:28,947 - INFO - Fitting SINDy model for participant 99.0
2025-03-26 08:14:30,371 - INFO - Participant 99.0: LL=-0.2552, BIC=1.1927, Params=10, Val trials=60
2025-03-26 08:14:30,371 - INFO - Processing participant 100.0...
2025-03-26 08:14:30,371 - INFO - Fitting SINDy model for participant 100.0
2025-03-26 08:14:31,702 - INFO - Participant 100.0: LL=-0.0263, BIC=0.8033, Params=11, Val trials=60
2025-03-26 08:14:31,702 - INFO - Processing participant 101.0...
2025-03-26 08:14:31,703 - INFO - Fitting SINDy model for participant 101.0
2025-03-26 08:14:32,962 - INFO - Participant 101.0: LL=-14.5691, BIC=29.8889, Params=11, Val trials=60
2025-03-26 08:14:32,962 - INFO - Processing participant 102.0...
2025-03-26 08:14:32,963 - INFO - Fitting SINDy model for participant 102.0
2025-03-26 08:14:34,283 - INFO - Participant 102.0: LL=-15.6283, BIC=32.0754, Params=12, Val trials=60
2025-03-26 08:14:34,284 - INFO - Processing participant 103.0...
2025-03-26 08:14:34,284 - INFO - Fitting SINDy model for participant 103.0
2025-03-26 08:14:35,621 - INFO - Participant 103.0: LL=-0.6931, BIC=2.2052, Params=12, Val trials=60
2025-03-26 08:14:35,621 - INFO - Processing participant 104.0...
2025-03-26 08:14:35,622 - INFO - Fitting SINDy model for participant 104.0
2025-03-26 08:14:36,965 - INFO - Participant 104.0: LL=-0.6931, BIC=2.0687, Params=10, Val trials=60
2025-03-26 08:14:36,966 - INFO - Processing participant 105.0...
2025-03-26 08:14:36,966 - INFO - Fitting SINDy model for participant 105.0
2025-03-26 08:14:38,252 - INFO - Participant 105.0: LL=-0.7033, BIC=2.2937, Params=13, Val trials=60
2025-03-26 08:14:38,252 - INFO - Processing participant 106.0...
2025-03-26 08:14:38,253 - INFO - Fitting SINDy model for participant 106.0
2025-03-26 08:14:39,602 - INFO - Participant 106.0: LL=-0.6931, BIC=2.0004, Params=9, Val trials=60
2025-03-26 08:14:39,602 - INFO - Processing participant 107.0...
2025-03-26 08:14:39,603 - INFO - Fitting SINDy model for participant 107.0
2025-03-26 08:14:40,990 - INFO - Participant 107.0: LL=-0.7841, BIC=2.1824, Params=9, Val trials=60
2025-03-26 08:14:40,990 - INFO - Processing participant 108.0...
2025-03-26 08:14:40,990 - INFO - Fitting SINDy model for participant 108.0
2025-03-26 08:14:42,344 - INFO - Participant 108.0: LL=-0.2041, BIC=1.0223, Params=9, Val trials=60
2025-03-26 08:14:42,344 - INFO - Processing participant 109.0...
2025-03-26 08:14:42,345 - INFO - Fitting SINDy model for participant 109.0
2025-03-26 08:14:43,623 - INFO - Participant 109.0: LL=-0.6931, BIC=2.4099, Params=15, Val trials=60
2025-03-26 08:14:43,623 - INFO - Processing participant 110.0...
2025-03-26 08:14:43,623 - INFO - Fitting SINDy model for participant 110.0
2025-03-26 08:14:44,961 - INFO - Participant 110.0: LL=-5.4804, BIC=11.7115, Params=11, Val trials=60
2025-03-26 08:14:44,961 - INFO - Processing participant 111.0...
2025-03-26 08:14:44,962 - INFO - Fitting SINDy model for participant 111.0
2025-03-26 08:14:46,299 - INFO - Participant 111.0: LL=-0.6931, BIC=2.1369, Params=11, Val trials=60
2025-03-26 08:14:46,299 - INFO - Processing participant 112.0...
2025-03-26 08:14:46,300 - INFO - Fitting SINDy model for participant 112.0
2025-03-26 08:14:47,638 - INFO - Participant 112.0: LL=-5.3267, BIC=11.4722, Params=12, Val trials=60
2025-03-26 08:14:47,638 - INFO - Processing participant 113.0...
2025-03-26 08:14:47,639 - INFO - Fitting SINDy model for participant 113.0
2025-03-26 08:14:48,918 - INFO - Participant 113.0: LL=-4.9503, BIC=10.8559, Params=14, Val trials=60
2025-03-26 08:14:48,918 - INFO - Processing participant 114.0...
2025-03-26 08:14:48,919 - INFO - Fitting SINDy model for participant 114.0
2025-03-26 08:14:50,260 - INFO - Participant 114.0: LL=-0.7002, BIC=1.8781, Params=7, Val trials=60
2025-03-26 08:14:50,260 - INFO - Processing participant 115.0...
2025-03-26 08:14:50,261 - INFO - Fitting SINDy model for participant 115.0
2025-03-26 08:14:51,601 - INFO - Participant 115.0: LL=-8.9165, BIC=18.6518, Params=12, Val trials=60
2025-03-26 08:14:51,601 - INFO - Processing participant 116.0...
2025-03-26 08:14:51,601 - INFO - Fitting SINDy model for participant 116.0
2025-03-26 08:14:52,898 - INFO - Participant 116.0: LL=-0.3002, BIC=1.2146, Params=9, Val trials=60
2025-03-26 08:14:52,899 - INFO - Processing participant 117.0...
2025-03-26 08:14:52,900 - INFO - Fitting SINDy model for participant 117.0
2025-03-26 08:14:54,234 - INFO - Participant 117.0: LL=-2.9522, BIC=6.7232, Params=12, Val trials=60
2025-03-26 08:14:54,234 - INFO - Processing participant 118.0...
2025-03-26 08:14:54,235 - INFO - Fitting SINDy model for participant 118.0
2025-03-26 08:14:55,571 - INFO - Participant 118.0: LL=-0.1625, BIC=0.9392, Params=9, Val trials=60
2025-03-26 08:14:55,571 - INFO - Processing participant 119.0...
2025-03-26 08:14:55,572 - INFO - Fitting SINDy model for participant 119.0
2025-03-26 08:14:56,913 - INFO - Participant 119.0: LL=-0.3916, BIC=1.3973, Params=9, Val trials=60
2025-03-26 08:14:56,913 - INFO - Processing participant 120.0...
2025-03-26 08:14:56,914 - INFO - Fitting SINDy model for participant 120.0
2025-03-26 08:14:58,181 - INFO - Participant 120.0: LL=-0.1850, BIC=0.9842, Params=9, Val trials=60
2025-03-26 08:14:58,181 - INFO - Processing participant 121.0...
2025-03-26 08:14:58,182 - INFO - Fitting SINDy model for participant 121.0
2025-03-26 08:14:59,521 - INFO - Participant 121.0: LL=-0.7889, BIC=2.1919, Params=9, Val trials=60
2025-03-26 08:14:59,521 - INFO - Processing participant 122.0...
2025-03-26 08:14:59,522 - INFO - Fitting SINDy model for participant 122.0
2025-03-26 08:15:00,868 - INFO - Participant 122.0: LL=-7.8332, BIC=16.5535, Params=13, Val trials=60
2025-03-26 08:15:00,868 - INFO - Processing participant 123.0...
2025-03-26 08:15:00,869 - INFO - Fitting SINDy model for participant 123.0
2025-03-26 08:15:02,209 - INFO - Participant 123.0: LL=-0.6931, BIC=2.0004, Params=9, Val trials=60
2025-03-26 08:15:02,209 - INFO - Processing participant 124.0...
2025-03-26 08:15:02,210 - INFO - Fitting SINDy model for participant 124.0
2025-03-26 08:15:03,547 - INFO - Participant 124.0: LL=-0.6931, BIC=1.8640, Params=7, Val trials=60
2025-03-26 08:15:03,547 - INFO - Processing participant 125.0...
2025-03-26 08:15:03,548 - INFO - Fitting SINDy model for participant 125.0
2025-03-26 08:15:04,822 - INFO - Participant 125.0: LL=-0.0116, BIC=0.6373, Params=9, Val trials=60
2025-03-26 08:15:04,822 - INFO - Processing participant 126.0...
2025-03-26 08:15:04,823 - INFO - Fitting SINDy model for participant 126.0
2025-03-26 08:15:06,185 - INFO - Participant 126.0: LL=-0.7590, BIC=2.1321, Params=9, Val trials=60
2025-03-26 08:15:06,185 - INFO - Processing participant 127.0...
2025-03-26 08:15:06,186 - INFO - Fitting SINDy model for participant 127.0
2025-03-26 08:15:07,520 - INFO - Participant 127.0: LL=-0.6918, BIC=1.8613, Params=7, Val trials=60
2025-03-26 08:15:07,521 - INFO - Number of participants with valid BIC metrics: 128/128
2025-03-26 08:15:07,521 - INFO - Average SINDy BIC: 4.4472
2025-03-26 08:15:07,521 - INFO - Average SINDy LL: -1.8651
2025-03-26 08:15:07,532 - INFO - Completed processing dataset: data_128p_0.csv
2025-03-26 08:15:08,597 - INFO - Created violin plots with 128 participant data points
2025-03-27 23:50:05,592 - INFO - ================================================================================
2025-03-27 23:50:05,592 - INFO - EXPERIMENT CONFIG
2025-03-27 23:50:05,592 - INFO - ================================================================================
2025-03-27 23:50:05,592 - INFO - Found 1 data files: ['data_128p_0.csv']
2025-03-27 23:50:05,592 - INFO - Processing dataset: data_128p_0.csv
2025-03-27 23:50:05,592 - INFO - Loading dataset from data/optuna/data_128p_0.csv
2025-03-27 23:50:05,627 - INFO - Number of participants: 128
2025-03-27 23:50:05,632 - INFO - Participant 0 (ID=0.0): _reward=0.74, _penalty=0.97
2025-03-27 23:50:05,637 - INFO - Participant 1 (ID=1.0): _reward=0.99, _penalty=0.02
2025-03-27 23:50:05,642 - INFO - Participant 2 (ID=2.0): _reward=0.77, _penalty=0.46
2025-03-27 23:50:05,647 - INFO - Participant 3 (ID=3.0): _reward=0.96, _penalty=0.60
2025-03-27 23:50:05,652 - INFO - Participant 4 (ID=4.0): _reward=0.21, _penalty=0.21
2025-03-27 23:50:05,656 - INFO - Participant 5 (ID=5.0): _reward=0.07, _penalty=0.51
2025-03-27 23:50:05,661 - INFO - Participant 6 (ID=6.0): _reward=0.23, _penalty=0.60
2025-03-27 23:50:05,666 - INFO - Participant 7 (ID=7.0): _reward=0.91, _penalty=0.80
2025-03-27 23:50:05,671 - INFO - Participant 8 (ID=8.0): _reward=0.99, _penalty=0.97
2025-03-27 23:50:05,676 - INFO - Participant 9 (ID=9.0): _reward=0.67, _penalty=0.87
2025-03-27 23:50:05,680 - INFO - Participant 10 (ID=10.0): _reward=0.08, _penalty=0.77
2025-03-27 23:50:05,685 - INFO - Participant 11 (ID=11.0): _reward=0.87, _penalty=0.31
2025-03-27 23:50:05,690 - INFO - Participant 12 (ID=12.0): _reward=0.58, _penalty=0.19
2025-03-27 23:50:05,695 - INFO - Participant 13 (ID=13.0): _reward=0.48, _penalty=0.25
2025-03-27 23:50:05,700 - INFO - Participant 14 (ID=14.0): _reward=0.34, _penalty=0.83
2025-03-27 23:50:05,705 - INFO - Participant 15 (ID=15.0): _reward=0.56, _penalty=0.80
2025-03-27 23:50:05,710 - INFO - Participant 16 (ID=16.0): _reward=0.47, _penalty=0.29
2025-03-27 23:50:05,715 - INFO - Participant 17 (ID=17.0): _reward=0.77, _penalty=0.94
2025-03-27 23:50:05,720 - INFO - Participant 18 (ID=18.0): _reward=0.88, _penalty=0.01
2025-03-27 23:50:05,724 - INFO - Participant 19 (ID=19.0): _reward=0.98, _penalty=0.11
2025-03-27 23:50:05,729 - INFO - Participant 20 (ID=20.0): _reward=0.02, _penalty=0.85
2025-03-27 23:50:05,734 - INFO - Participant 21 (ID=21.0): _reward=0.46, _penalty=0.85
2025-03-27 23:50:05,739 - INFO - Participant 22 (ID=22.0): _reward=0.69, _penalty=0.43
2025-03-27 23:50:05,743 - INFO - Participant 23 (ID=23.0): _reward=0.15, _penalty=0.95
2025-03-27 23:50:05,748 - INFO - Participant 24 (ID=24.0): _reward=0.25, _penalty=0.36
2025-03-27 23:50:05,753 - INFO - Participant 25 (ID=25.0): _reward=0.75, _penalty=0.11
2025-03-27 23:50:05,758 - INFO - Participant 26 (ID=26.0): _reward=0.46, _penalty=0.81
2025-03-27 23:50:05,763 - INFO - Participant 27 (ID=27.0): _reward=0.36, _penalty=0.63
2025-03-27 23:50:05,768 - INFO - Participant 28 (ID=28.0): _reward=0.49, _penalty=0.00
2025-03-27 23:50:05,773 - INFO - Participant 29 (ID=29.0): _reward=0.20, _penalty=0.98
2025-03-27 23:50:05,777 - INFO - Participant 30 (ID=30.0): _reward=0.29, _penalty=0.64
2025-03-27 23:50:05,782 - INFO - Participant 31 (ID=31.0): _reward=0.66, _penalty=0.64
2025-03-27 23:50:05,787 - INFO - Participant 32 (ID=32.0): _reward=0.21, _penalty=0.41
2025-03-27 23:50:05,792 - INFO - Participant 33 (ID=33.0): _reward=0.49, _penalty=0.63
2025-03-27 23:50:05,797 - INFO - Participant 34 (ID=34.0): _reward=0.38, _penalty=0.08
2025-03-27 23:50:05,802 - INFO - Participant 35 (ID=35.0): _reward=0.33, _penalty=0.29
2025-03-27 23:50:05,806 - INFO - Participant 36 (ID=36.0): _reward=0.53, _penalty=0.61
2025-03-27 23:50:05,811 - INFO - Participant 37 (ID=37.0): _reward=0.65, _penalty=0.34
2025-03-27 23:50:05,816 - INFO - Participant 38 (ID=38.0): _reward=0.29, _penalty=0.13
2025-03-27 23:50:05,821 - INFO - Participant 39 (ID=39.0): _reward=0.31, _penalty=0.25
2025-03-27 23:50:05,826 - INFO - Participant 40 (ID=40.0): _reward=0.77, _penalty=0.04
2025-03-27 23:50:05,831 - INFO - Participant 41 (ID=41.0): _reward=0.23, _penalty=0.89
2025-03-27 23:50:05,835 - INFO - Participant 42 (ID=42.0): _reward=0.63, _penalty=0.60
2025-03-27 23:50:05,840 - INFO - Participant 43 (ID=43.0): _reward=0.48, _penalty=0.52
2025-03-27 23:50:05,845 - INFO - Participant 44 (ID=44.0): _reward=0.92, _penalty=0.22
2025-03-27 23:50:05,849 - INFO - Participant 45 (ID=45.0): _reward=0.52, _penalty=0.89
2025-03-27 23:50:05,854 - INFO - Participant 46 (ID=46.0): _reward=0.42, _penalty=0.83
2025-03-27 23:50:05,859 - INFO - Participant 47 (ID=47.0): _reward=0.68, _penalty=0.69
2025-03-27 23:50:05,864 - INFO - Participant 48 (ID=48.0): _reward=0.95, _penalty=0.22
2025-03-27 23:50:05,869 - INFO - Participant 49 (ID=49.0): _reward=0.13, _penalty=0.48
2025-03-27 23:50:05,873 - INFO - Participant 50 (ID=50.0): _reward=0.87, _penalty=0.85
2025-03-27 23:50:05,878 - INFO - Participant 51 (ID=51.0): _reward=0.47, _penalty=0.07
2025-03-27 23:50:05,883 - INFO - Participant 52 (ID=52.0): _reward=0.56, _penalty=0.42
2025-03-27 23:50:05,888 - INFO - Participant 53 (ID=53.0): _reward=0.53, _penalty=0.18
2025-03-27 23:50:05,892 - INFO - Participant 54 (ID=54.0): _reward=0.87, _penalty=0.73
2025-03-27 23:50:05,897 - INFO - Participant 55 (ID=55.0): _reward=0.21, _penalty=0.47
2025-03-27 23:50:05,902 - INFO - Participant 56 (ID=56.0): _reward=0.65, _penalty=0.09
2025-03-27 23:50:05,906 - INFO - Participant 57 (ID=57.0): _reward=0.72, _penalty=0.88
2025-03-27 23:50:05,911 - INFO - Participant 58 (ID=58.0): _reward=0.61, _penalty=0.38
2025-03-27 23:50:05,916 - INFO - Participant 59 (ID=59.0): _reward=0.92, _penalty=0.91
2025-03-27 23:50:05,921 - INFO - Participant 60 (ID=60.0): _reward=0.22, _penalty=0.97
2025-03-27 23:50:05,925 - INFO - Participant 61 (ID=61.0): _reward=0.41, _penalty=0.53
2025-03-27 23:50:05,930 - INFO - Participant 62 (ID=62.0): _reward=0.92, _penalty=0.99
2025-03-27 23:50:05,935 - INFO - Participant 63 (ID=63.0): _reward=0.22, _penalty=0.99
2025-03-27 23:50:05,940 - INFO - Participant 64 (ID=64.0): _reward=0.84, _penalty=0.96
2025-03-27 23:50:05,944 - INFO - Participant 65 (ID=65.0): _reward=0.55, _penalty=0.19
2025-03-27 23:50:05,949 - INFO - Participant 66 (ID=66.0): _reward=0.34, _penalty=0.07
2025-03-27 23:50:05,954 - INFO - Participant 67 (ID=67.0): _reward=0.62, _penalty=0.45
2025-03-27 23:50:05,959 - INFO - Participant 68 (ID=68.0): _reward=0.47, _penalty=0.19
2025-03-27 23:50:05,964 - INFO - Participant 69 (ID=69.0): _reward=0.81, _penalty=0.36
2025-03-27 23:50:05,968 - INFO - Participant 70 (ID=70.0): _reward=0.73, _penalty=0.87
2025-03-27 23:50:05,973 - INFO - Participant 71 (ID=71.0): _reward=0.10, _penalty=0.57
2025-03-27 23:50:05,978 - INFO - Participant 72 (ID=72.0): _reward=0.78, _penalty=0.50
2025-03-27 23:50:05,983 - INFO - Participant 73 (ID=73.0): _reward=0.82, _penalty=0.70
2025-03-27 23:50:05,988 - INFO - Participant 74 (ID=74.0): _reward=0.00, _penalty=0.98
2025-03-27 23:50:05,992 - INFO - Participant 75 (ID=75.0): _reward=0.42, _penalty=0.26
2025-03-27 23:50:05,997 - INFO - Participant 76 (ID=76.0): _reward=0.83, _penalty=0.39
2025-03-27 23:50:06,002 - INFO - Participant 77 (ID=77.0): _reward=0.75, _penalty=0.18
2025-03-27 23:50:06,006 - INFO - Participant 78 (ID=78.0): _reward=0.97, _penalty=0.44
2025-03-27 23:50:06,011 - INFO - Participant 79 (ID=79.0): _reward=0.45, _penalty=0.57
2025-03-27 23:50:06,017 - INFO - Participant 80 (ID=80.0): _reward=0.63, _penalty=0.78
2025-03-27 23:50:06,021 - INFO - Participant 81 (ID=81.0): _reward=0.29, _penalty=0.24
2025-03-27 23:50:06,026 - INFO - Participant 82 (ID=82.0): _reward=0.71, _penalty=0.15
2025-03-27 23:50:06,031 - INFO - Participant 83 (ID=83.0): _reward=0.71, _penalty=0.66
2025-03-27 23:50:06,036 - INFO - Participant 84 (ID=84.0): _reward=0.97, _penalty=0.79
2025-03-27 23:50:06,040 - INFO - Participant 85 (ID=85.0): _reward=1.00, _penalty=0.95
2025-03-27 23:50:06,045 - INFO - Participant 86 (ID=86.0): _reward=0.56, _penalty=0.08
2025-03-27 23:50:06,050 - INFO - Participant 87 (ID=87.0): _reward=0.59, _penalty=0.83
2025-03-27 23:50:06,055 - INFO - Participant 88 (ID=88.0): _reward=0.32, _penalty=0.60
2025-03-27 23:50:06,059 - INFO - Participant 89 (ID=89.0): _reward=0.20, _penalty=0.84
2025-03-27 23:50:06,064 - INFO - Participant 90 (ID=90.0): _reward=0.34, _penalty=1.00
2025-03-27 23:50:06,069 - INFO - Participant 91 (ID=91.0): _reward=0.19, _penalty=0.99
2025-03-27 23:50:06,074 - INFO - Participant 92 (ID=92.0): _reward=0.20, _penalty=0.91
2025-03-27 23:50:06,078 - INFO - Participant 93 (ID=93.0): _reward=0.31, _penalty=0.21
2025-03-27 23:50:06,083 - INFO - Participant 94 (ID=94.0): _reward=0.58, _penalty=0.41
2025-03-27 23:50:06,088 - INFO - Participant 95 (ID=95.0): _reward=0.80, _penalty=0.54
2025-03-27 23:50:06,093 - INFO - Participant 96 (ID=96.0): _reward=0.74, _penalty=0.80
2025-03-27 23:50:06,098 - INFO - Participant 97 (ID=97.0): _reward=0.59, _penalty=0.16
2025-03-27 23:50:06,103 - INFO - Participant 98 (ID=98.0): _reward=0.54, _penalty=0.17
2025-03-27 23:50:06,115 - INFO - Participant 99 (ID=99.0): _reward=0.17, _penalty=0.16
2025-03-27 23:50:06,121 - INFO - Participant 100 (ID=100.0): _reward=0.79, _penalty=0.40
2025-03-27 23:50:06,126 - INFO - Participant 101 (ID=101.0): _reward=0.32, _penalty=0.05
2025-03-27 23:50:06,131 - INFO - Participant 102 (ID=102.0): _reward=0.87, _penalty=0.81
2025-03-27 23:50:06,136 - INFO - Participant 103 (ID=103.0): _reward=0.90, _penalty=0.11
2025-03-27 23:50:06,140 - INFO - Participant 104 (ID=104.0): _reward=0.44, _penalty=0.12
2025-03-27 23:50:06,145 - INFO - Participant 105 (ID=105.0): _reward=0.59, _penalty=0.50
2025-03-27 23:50:06,151 - INFO - Participant 106 (ID=106.0): _reward=0.84, _penalty=0.50
2025-03-27 23:50:06,156 - INFO - Participant 107 (ID=107.0): _reward=0.48, _penalty=0.54
2025-03-27 23:50:06,161 - INFO - Participant 108 (ID=108.0): _reward=0.56, _penalty=0.75
2025-03-27 23:50:06,166 - INFO - Participant 109 (ID=109.0): _reward=0.53, _penalty=0.11
2025-03-27 23:50:06,171 - INFO - Participant 110 (ID=110.0): _reward=0.52, _penalty=0.40
2025-03-27 23:50:06,175 - INFO - Participant 111 (ID=111.0): _reward=0.61, _penalty=0.74
2025-03-27 23:50:06,180 - INFO - Participant 112 (ID=112.0): _reward=0.64, _penalty=0.56
2025-03-27 23:50:06,185 - INFO - Participant 113 (ID=113.0): _reward=0.44, _penalty=0.40
2025-03-27 23:50:06,190 - INFO - Participant 114 (ID=114.0): _reward=0.74, _penalty=0.91
2025-03-27 23:50:06,195 - INFO - Participant 115 (ID=115.0): _reward=0.09, _penalty=0.27
2025-03-27 23:50:06,200 - INFO - Participant 116 (ID=116.0): _reward=0.99, _penalty=0.92
2025-03-27 23:50:06,205 - INFO - Participant 117 (ID=117.0): _reward=0.90, _penalty=0.87
2025-03-27 23:50:06,210 - INFO - Participant 118 (ID=118.0): _reward=0.21, _penalty=0.27
2025-03-27 23:50:06,215 - INFO - Participant 119 (ID=119.0): _reward=0.71, _penalty=0.69
2025-03-27 23:50:06,220 - INFO - Participant 120 (ID=120.0): _reward=0.43, _penalty=0.05
2025-03-27 23:50:06,225 - INFO - Participant 121 (ID=121.0): _reward=0.11, _penalty=0.27
2025-03-27 23:50:06,230 - INFO - Participant 122 (ID=122.0): _reward=0.80, _penalty=0.43
2025-03-27 23:50:06,235 - INFO - Participant 123 (ID=123.0): _reward=0.74, _penalty=0.44
2025-03-27 23:50:06,240 - INFO - Participant 124 (ID=124.0): _reward=0.18, _penalty=0.36
2025-03-27 23:50:06,245 - INFO - Participant 125 (ID=125.0): _reward=0.86, _penalty=0.09
2025-03-27 23:50:06,250 - INFO - Participant 126 (ID=126.0): _reward=0.05, _penalty=0.52
2025-03-27 23:50:06,255 - INFO - Participant 127 (ID=127.0): _reward=0.41, _penalty=0.26
2025-03-27 23:50:06,255 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,255 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,255 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,255 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,255 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,255 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,255 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,255 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,255 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,255 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,255 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,255 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 32 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 33 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 34 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 35 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 36 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 37 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 38 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 39 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 40 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 41 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 42 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 43 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 44 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 45 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 46 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 47 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 48 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 49 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 50 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 51 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 52 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 53 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 54 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 55 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 56 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 57 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 58 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 59 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 60 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 61 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 62 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 63 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 64 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 65 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 66 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 67 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 68 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 69 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 70 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 71 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 72 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 73 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 74 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 75 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 76 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 77 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 78 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 79 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 80 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 81 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 82 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 83 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 84 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 85 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 86 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 87 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 88 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 89 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,256 - INFO - Participant 90 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 91 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 92 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 93 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 94 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 95 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 96 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 97 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 98 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 99 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 100 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 101 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 102 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 103 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 104 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 105 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 106 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 107 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 108 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 109 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 110 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 111 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 112 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 113 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 114 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 115 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 116 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 117 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 118 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 119 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 120 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 121 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 122 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 123 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 124 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 125 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 126 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Participant 127 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:06,257 - INFO - Combined xs shape after concatenation: torch.Size([128, 200, 5])
2025-03-27 23:50:06,257 - INFO - Combined ys shape after concatenation: torch.Size([128, 200, 2])
2025-03-27 23:50:06,257 - INFO - Combined dataset shape: X=torch.Size([128, 200, 5]), Y=torch.Size([128, 200, 2])
2025-03-27 23:50:06,258 - INFO - Total unique participants: 128
2025-03-27 23:50:06,258 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-27 23:50:06,258 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,258 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 32.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 33.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 34.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 35.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,259 - INFO - Participant 36.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 37.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 38.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 39.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 40.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 41.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 42.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 43.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 44.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 45.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 46.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 47.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 48.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 49.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 50.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 51.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 52.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 53.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 54.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 55.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 56.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 57.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 58.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 59.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,260 - INFO - Participant 60.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 61.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 62.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 63.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 64.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 65.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 66.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 67.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 68.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 69.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 70.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 71.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 72.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 73.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 74.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 75.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 76.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 77.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 78.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 79.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 80.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 81.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 82.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 83.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 84.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,261 - INFO - Participant 85.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 86.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 87.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 88.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 89.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 90.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 91.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 92.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 93.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 94.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 95.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 96.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 97.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 98.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 99.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 100.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 101.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 102.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 103.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 104.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 105.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 106.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 107.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,262 - INFO - Participant 108.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 109.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 110.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 111.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 112.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 113.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 114.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 115.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 116.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 117.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 118.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 119.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 120.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 121.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 122.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 123.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 124.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,263 - INFO - Participant 125.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,264 - INFO - Participant 126.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,264 - INFO - Participant 127.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:06,264 - INFO - Train xs shape: torch.Size([128, 140, 5])
2025-03-27 23:50:06,264 - INFO - Train ys shape: torch.Size([128, 140, 2])
2025-03-27 23:50:06,264 - INFO - Validation xs shape: torch.Size([128, 60, 5])
2025-03-27 23:50:06,264 - INFO - Validation ys shape: torch.Size([128, 60, 2])
2025-03-27 23:50:06,264 - INFO - Train dataset: torch.Size([128, 140, 5]), Validation dataset: torch.Size([128, 60, 5])
2025-03-27 23:50:06,264 - INFO - Starting hyperparameter optimization...
2025-03-27 23:50:06,265 - INFO - Trial 0: lr=0.006593, embedding_size=12, n_steps=24
2025-03-27 23:50:19,533 - INFO - Trial 0: RNN Train Loss: 0.0000000
2025-03-27 23:50:19,535 - INFO - Trial 0: Validation set has 128 participants
2025-03-27 23:50:35,268 - INFO - ================================================================================
2025-03-27 23:50:35,268 - INFO - EXPERIMENT CONFIG
2025-03-27 23:50:35,268 - INFO - ================================================================================
2025-03-27 23:50:35,268 - INFO - Found 1 data files: ['data_128p_0.csv']
2025-03-27 23:50:35,268 - INFO - Processing dataset: data_128p_0.csv
2025-03-27 23:50:35,268 - INFO - Loading dataset from data/optuna/data_128p_0.csv
2025-03-27 23:50:35,314 - INFO - Number of participants: 128
2025-03-27 23:50:35,321 - INFO - Participant 0 (ID=0.0): _reward=0.74, _penalty=0.97
2025-03-27 23:50:35,326 - INFO - Participant 1 (ID=1.0): _reward=0.99, _penalty=0.02
2025-03-27 23:50:35,331 - INFO - Participant 2 (ID=2.0): _reward=0.77, _penalty=0.46
2025-03-27 23:50:35,336 - INFO - Participant 3 (ID=3.0): _reward=0.96, _penalty=0.60
2025-03-27 23:50:35,341 - INFO - Participant 4 (ID=4.0): _reward=0.21, _penalty=0.21
2025-03-27 23:50:35,345 - INFO - Participant 5 (ID=5.0): _reward=0.07, _penalty=0.51
2025-03-27 23:50:35,350 - INFO - Participant 6 (ID=6.0): _reward=0.23, _penalty=0.60
2025-03-27 23:50:35,355 - INFO - Participant 7 (ID=7.0): _reward=0.91, _penalty=0.80
2025-03-27 23:50:35,360 - INFO - Participant 8 (ID=8.0): _reward=0.99, _penalty=0.97
2025-03-27 23:50:35,365 - INFO - Participant 9 (ID=9.0): _reward=0.67, _penalty=0.87
2025-03-27 23:50:35,370 - INFO - Participant 10 (ID=10.0): _reward=0.08, _penalty=0.77
2025-03-27 23:50:35,375 - INFO - Participant 11 (ID=11.0): _reward=0.87, _penalty=0.31
2025-03-27 23:50:35,380 - INFO - Participant 12 (ID=12.0): _reward=0.58, _penalty=0.19
2025-03-27 23:50:35,385 - INFO - Participant 13 (ID=13.0): _reward=0.48, _penalty=0.25
2025-03-27 23:50:35,391 - INFO - Participant 14 (ID=14.0): _reward=0.34, _penalty=0.83
2025-03-27 23:50:35,396 - INFO - Participant 15 (ID=15.0): _reward=0.56, _penalty=0.80
2025-03-27 23:50:35,401 - INFO - Participant 16 (ID=16.0): _reward=0.47, _penalty=0.29
2025-03-27 23:50:35,407 - INFO - Participant 17 (ID=17.0): _reward=0.77, _penalty=0.94
2025-03-27 23:50:35,412 - INFO - Participant 18 (ID=18.0): _reward=0.88, _penalty=0.01
2025-03-27 23:50:35,417 - INFO - Participant 19 (ID=19.0): _reward=0.98, _penalty=0.11
2025-03-27 23:50:35,422 - INFO - Participant 20 (ID=20.0): _reward=0.02, _penalty=0.85
2025-03-27 23:50:35,427 - INFO - Participant 21 (ID=21.0): _reward=0.46, _penalty=0.85
2025-03-27 23:50:35,432 - INFO - Participant 22 (ID=22.0): _reward=0.69, _penalty=0.43
2025-03-27 23:50:35,438 - INFO - Participant 23 (ID=23.0): _reward=0.15, _penalty=0.95
2025-03-27 23:50:35,443 - INFO - Participant 24 (ID=24.0): _reward=0.25, _penalty=0.36
2025-03-27 23:50:35,448 - INFO - Participant 25 (ID=25.0): _reward=0.75, _penalty=0.11
2025-03-27 23:50:35,453 - INFO - Participant 26 (ID=26.0): _reward=0.46, _penalty=0.81
2025-03-27 23:50:35,459 - INFO - Participant 27 (ID=27.0): _reward=0.36, _penalty=0.63
2025-03-27 23:50:35,464 - INFO - Participant 28 (ID=28.0): _reward=0.49, _penalty=0.00
2025-03-27 23:50:35,469 - INFO - Participant 29 (ID=29.0): _reward=0.20, _penalty=0.98
2025-03-27 23:50:35,475 - INFO - Participant 30 (ID=30.0): _reward=0.29, _penalty=0.64
2025-03-27 23:50:35,480 - INFO - Participant 31 (ID=31.0): _reward=0.66, _penalty=0.64
2025-03-27 23:50:35,485 - INFO - Participant 32 (ID=32.0): _reward=0.21, _penalty=0.41
2025-03-27 23:50:35,490 - INFO - Participant 33 (ID=33.0): _reward=0.49, _penalty=0.63
2025-03-27 23:50:35,496 - INFO - Participant 34 (ID=34.0): _reward=0.38, _penalty=0.08
2025-03-27 23:50:35,501 - INFO - Participant 35 (ID=35.0): _reward=0.33, _penalty=0.29
2025-03-27 23:50:35,506 - INFO - Participant 36 (ID=36.0): _reward=0.53, _penalty=0.61
2025-03-27 23:50:35,511 - INFO - Participant 37 (ID=37.0): _reward=0.65, _penalty=0.34
2025-03-27 23:50:35,516 - INFO - Participant 38 (ID=38.0): _reward=0.29, _penalty=0.13
2025-03-27 23:50:35,522 - INFO - Participant 39 (ID=39.0): _reward=0.31, _penalty=0.25
2025-03-27 23:50:35,527 - INFO - Participant 40 (ID=40.0): _reward=0.77, _penalty=0.04
2025-03-27 23:50:35,532 - INFO - Participant 41 (ID=41.0): _reward=0.23, _penalty=0.89
2025-03-27 23:50:35,537 - INFO - Participant 42 (ID=42.0): _reward=0.63, _penalty=0.60
2025-03-27 23:50:35,542 - INFO - Participant 43 (ID=43.0): _reward=0.48, _penalty=0.52
2025-03-27 23:50:35,548 - INFO - Participant 44 (ID=44.0): _reward=0.92, _penalty=0.22
2025-03-27 23:50:35,553 - INFO - Participant 45 (ID=45.0): _reward=0.52, _penalty=0.89
2025-03-27 23:50:35,558 - INFO - Participant 46 (ID=46.0): _reward=0.42, _penalty=0.83
2025-03-27 23:50:35,563 - INFO - Participant 47 (ID=47.0): _reward=0.68, _penalty=0.69
2025-03-27 23:50:35,568 - INFO - Participant 48 (ID=48.0): _reward=0.95, _penalty=0.22
2025-03-27 23:50:35,573 - INFO - Participant 49 (ID=49.0): _reward=0.13, _penalty=0.48
2025-03-27 23:50:35,578 - INFO - Participant 50 (ID=50.0): _reward=0.87, _penalty=0.85
2025-03-27 23:50:35,584 - INFO - Participant 51 (ID=51.0): _reward=0.47, _penalty=0.07
2025-03-27 23:50:35,589 - INFO - Participant 52 (ID=52.0): _reward=0.56, _penalty=0.42
2025-03-27 23:50:35,594 - INFO - Participant 53 (ID=53.0): _reward=0.53, _penalty=0.18
2025-03-27 23:50:35,599 - INFO - Participant 54 (ID=54.0): _reward=0.87, _penalty=0.73
2025-03-27 23:50:35,605 - INFO - Participant 55 (ID=55.0): _reward=0.21, _penalty=0.47
2025-03-27 23:50:35,610 - INFO - Participant 56 (ID=56.0): _reward=0.65, _penalty=0.09
2025-03-27 23:50:35,615 - INFO - Participant 57 (ID=57.0): _reward=0.72, _penalty=0.88
2025-03-27 23:50:35,620 - INFO - Participant 58 (ID=58.0): _reward=0.61, _penalty=0.38
2025-03-27 23:50:35,625 - INFO - Participant 59 (ID=59.0): _reward=0.92, _penalty=0.91
2025-03-27 23:50:35,630 - INFO - Participant 60 (ID=60.0): _reward=0.22, _penalty=0.97
2025-03-27 23:50:35,635 - INFO - Participant 61 (ID=61.0): _reward=0.41, _penalty=0.53
2025-03-27 23:50:35,641 - INFO - Participant 62 (ID=62.0): _reward=0.92, _penalty=0.99
2025-03-27 23:50:35,646 - INFO - Participant 63 (ID=63.0): _reward=0.22, _penalty=0.99
2025-03-27 23:50:35,651 - INFO - Participant 64 (ID=64.0): _reward=0.84, _penalty=0.96
2025-03-27 23:50:35,656 - INFO - Participant 65 (ID=65.0): _reward=0.55, _penalty=0.19
2025-03-27 23:50:35,661 - INFO - Participant 66 (ID=66.0): _reward=0.34, _penalty=0.07
2025-03-27 23:50:35,666 - INFO - Participant 67 (ID=67.0): _reward=0.62, _penalty=0.45
2025-03-27 23:50:35,671 - INFO - Participant 68 (ID=68.0): _reward=0.47, _penalty=0.19
2025-03-27 23:50:35,677 - INFO - Participant 69 (ID=69.0): _reward=0.81, _penalty=0.36
2025-03-27 23:50:35,682 - INFO - Participant 70 (ID=70.0): _reward=0.73, _penalty=0.87
2025-03-27 23:50:35,687 - INFO - Participant 71 (ID=71.0): _reward=0.10, _penalty=0.57
2025-03-27 23:50:35,692 - INFO - Participant 72 (ID=72.0): _reward=0.78, _penalty=0.50
2025-03-27 23:50:35,697 - INFO - Participant 73 (ID=73.0): _reward=0.82, _penalty=0.70
2025-03-27 23:50:35,702 - INFO - Participant 74 (ID=74.0): _reward=0.00, _penalty=0.98
2025-03-27 23:50:35,707 - INFO - Participant 75 (ID=75.0): _reward=0.42, _penalty=0.26
2025-03-27 23:50:35,712 - INFO - Participant 76 (ID=76.0): _reward=0.83, _penalty=0.39
2025-03-27 23:50:35,717 - INFO - Participant 77 (ID=77.0): _reward=0.75, _penalty=0.18
2025-03-27 23:50:35,723 - INFO - Participant 78 (ID=78.0): _reward=0.97, _penalty=0.44
2025-03-27 23:50:35,728 - INFO - Participant 79 (ID=79.0): _reward=0.45, _penalty=0.57
2025-03-27 23:50:35,733 - INFO - Participant 80 (ID=80.0): _reward=0.63, _penalty=0.78
2025-03-27 23:50:35,738 - INFO - Participant 81 (ID=81.0): _reward=0.29, _penalty=0.24
2025-03-27 23:50:35,743 - INFO - Participant 82 (ID=82.0): _reward=0.71, _penalty=0.15
2025-03-27 23:50:35,748 - INFO - Participant 83 (ID=83.0): _reward=0.71, _penalty=0.66
2025-03-27 23:50:35,753 - INFO - Participant 84 (ID=84.0): _reward=0.97, _penalty=0.79
2025-03-27 23:50:35,759 - INFO - Participant 85 (ID=85.0): _reward=1.00, _penalty=0.95
2025-03-27 23:50:35,763 - INFO - Participant 86 (ID=86.0): _reward=0.56, _penalty=0.08
2025-03-27 23:50:35,768 - INFO - Participant 87 (ID=87.0): _reward=0.59, _penalty=0.83
2025-03-27 23:50:35,774 - INFO - Participant 88 (ID=88.0): _reward=0.32, _penalty=0.60
2025-03-27 23:50:35,779 - INFO - Participant 89 (ID=89.0): _reward=0.20, _penalty=0.84
2025-03-27 23:50:35,784 - INFO - Participant 90 (ID=90.0): _reward=0.34, _penalty=1.00
2025-03-27 23:50:35,789 - INFO - Participant 91 (ID=91.0): _reward=0.19, _penalty=0.99
2025-03-27 23:50:35,795 - INFO - Participant 92 (ID=92.0): _reward=0.20, _penalty=0.91
2025-03-27 23:50:35,800 - INFO - Participant 93 (ID=93.0): _reward=0.31, _penalty=0.21
2025-03-27 23:50:35,805 - INFO - Participant 94 (ID=94.0): _reward=0.58, _penalty=0.41
2025-03-27 23:50:35,810 - INFO - Participant 95 (ID=95.0): _reward=0.80, _penalty=0.54
2025-03-27 23:50:35,815 - INFO - Participant 96 (ID=96.0): _reward=0.74, _penalty=0.80
2025-03-27 23:50:35,820 - INFO - Participant 97 (ID=97.0): _reward=0.59, _penalty=0.16
2025-03-27 23:50:35,825 - INFO - Participant 98 (ID=98.0): _reward=0.54, _penalty=0.17
2025-03-27 23:50:35,830 - INFO - Participant 99 (ID=99.0): _reward=0.17, _penalty=0.16
2025-03-27 23:50:35,835 - INFO - Participant 100 (ID=100.0): _reward=0.79, _penalty=0.40
2025-03-27 23:50:35,841 - INFO - Participant 101 (ID=101.0): _reward=0.32, _penalty=0.05
2025-03-27 23:50:35,846 - INFO - Participant 102 (ID=102.0): _reward=0.87, _penalty=0.81
2025-03-27 23:50:35,851 - INFO - Participant 103 (ID=103.0): _reward=0.90, _penalty=0.11
2025-03-27 23:50:35,856 - INFO - Participant 104 (ID=104.0): _reward=0.44, _penalty=0.12
2025-03-27 23:50:35,861 - INFO - Participant 105 (ID=105.0): _reward=0.59, _penalty=0.50
2025-03-27 23:50:35,866 - INFO - Participant 106 (ID=106.0): _reward=0.84, _penalty=0.50
2025-03-27 23:50:35,871 - INFO - Participant 107 (ID=107.0): _reward=0.48, _penalty=0.54
2025-03-27 23:50:35,876 - INFO - Participant 108 (ID=108.0): _reward=0.56, _penalty=0.75
2025-03-27 23:50:35,882 - INFO - Participant 109 (ID=109.0): _reward=0.53, _penalty=0.11
2025-03-27 23:50:35,887 - INFO - Participant 110 (ID=110.0): _reward=0.52, _penalty=0.40
2025-03-27 23:50:35,892 - INFO - Participant 111 (ID=111.0): _reward=0.61, _penalty=0.74
2025-03-27 23:50:35,897 - INFO - Participant 112 (ID=112.0): _reward=0.64, _penalty=0.56
2025-03-27 23:50:35,902 - INFO - Participant 113 (ID=113.0): _reward=0.44, _penalty=0.40
2025-03-27 23:50:35,907 - INFO - Participant 114 (ID=114.0): _reward=0.74, _penalty=0.91
2025-03-27 23:50:35,913 - INFO - Participant 115 (ID=115.0): _reward=0.09, _penalty=0.27
2025-03-27 23:50:35,918 - INFO - Participant 116 (ID=116.0): _reward=0.99, _penalty=0.92
2025-03-27 23:50:35,923 - INFO - Participant 117 (ID=117.0): _reward=0.90, _penalty=0.87
2025-03-27 23:50:35,928 - INFO - Participant 118 (ID=118.0): _reward=0.21, _penalty=0.27
2025-03-27 23:50:35,934 - INFO - Participant 119 (ID=119.0): _reward=0.71, _penalty=0.69
2025-03-27 23:50:35,939 - INFO - Participant 120 (ID=120.0): _reward=0.43, _penalty=0.05
2025-03-27 23:50:35,944 - INFO - Participant 121 (ID=121.0): _reward=0.11, _penalty=0.27
2025-03-27 23:50:35,949 - INFO - Participant 122 (ID=122.0): _reward=0.80, _penalty=0.43
2025-03-27 23:50:35,954 - INFO - Participant 123 (ID=123.0): _reward=0.74, _penalty=0.44
2025-03-27 23:50:35,959 - INFO - Participant 124 (ID=124.0): _reward=0.18, _penalty=0.36
2025-03-27 23:50:35,964 - INFO - Participant 125 (ID=125.0): _reward=0.86, _penalty=0.09
2025-03-27 23:50:35,969 - INFO - Participant 126 (ID=126.0): _reward=0.05, _penalty=0.52
2025-03-27 23:50:35,975 - INFO - Participant 127 (ID=127.0): _reward=0.41, _penalty=0.26
2025-03-27 23:50:35,975 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 32 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 33 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 34 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 35 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 36 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 37 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 38 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 39 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 40 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 41 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 42 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 43 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 44 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 45 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 46 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 47 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 48 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 49 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 50 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 51 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 52 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 53 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 54 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 55 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 56 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 57 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 58 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 59 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 60 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 61 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 62 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 63 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,975 - INFO - Participant 64 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 65 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 66 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 67 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 68 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 69 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 70 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 71 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 72 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 73 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 74 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 75 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 76 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 77 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 78 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 79 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 80 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 81 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 82 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 83 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 84 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 85 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 86 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 87 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 88 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 89 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 90 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 91 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 92 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 93 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 94 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 95 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 96 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 97 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 98 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 99 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 100 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 101 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 102 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 103 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 104 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 105 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 106 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 107 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 108 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 109 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 110 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 111 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 112 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 113 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 114 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 115 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 116 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 117 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 118 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 119 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 120 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 121 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 122 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 123 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 124 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 125 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 126 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,976 - INFO - Participant 127 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:50:35,977 - INFO - Combined xs shape after concatenation: torch.Size([128, 200, 5])
2025-03-27 23:50:35,977 - INFO - Combined ys shape after concatenation: torch.Size([128, 200, 2])
2025-03-27 23:50:35,977 - INFO - Combined dataset shape: X=torch.Size([128, 200, 5]), Y=torch.Size([128, 200, 2])
2025-03-27 23:50:35,977 - INFO - Total unique participants: 128
2025-03-27 23:50:35,977 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-27 23:50:35,977 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,977 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,977 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,978 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 32.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 33.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 34.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 35.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 36.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 37.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 38.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 39.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 40.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 41.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 42.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 43.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 44.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 45.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,979 - INFO - Participant 46.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 47.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 48.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 49.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 50.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 51.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 52.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 53.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 54.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 55.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 56.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 57.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 58.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 59.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 60.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 61.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 62.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 63.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 64.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 65.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 66.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 67.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 68.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 69.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,980 - INFO - Participant 70.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 71.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 72.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 73.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 74.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 75.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 76.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 77.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 78.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 79.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 80.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 81.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 82.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 83.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 84.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 85.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 86.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 87.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 88.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 89.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 90.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 91.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 92.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 93.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,981 - INFO - Participant 94.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 95.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 96.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 97.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 98.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 99.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 100.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 101.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 102.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 103.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 104.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 105.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 106.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 107.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 108.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 109.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 110.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 111.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 112.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 113.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 114.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 115.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 116.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 117.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,982 - INFO - Participant 118.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,983 - INFO - Participant 119.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,983 - INFO - Participant 120.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,983 - INFO - Participant 121.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,983 - INFO - Participant 122.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,983 - INFO - Participant 123.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,983 - INFO - Participant 124.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,983 - INFO - Participant 125.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,983 - INFO - Participant 126.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,983 - INFO - Participant 127.0: 140 trials for training, 60 trials for validation
2025-03-27 23:50:35,983 - INFO - Train xs shape: torch.Size([128, 140, 5])
2025-03-27 23:50:35,983 - INFO - Train ys shape: torch.Size([128, 140, 2])
2025-03-27 23:50:35,983 - INFO - Validation xs shape: torch.Size([128, 60, 5])
2025-03-27 23:50:35,983 - INFO - Validation ys shape: torch.Size([128, 60, 2])
2025-03-27 23:50:35,983 - INFO - Train dataset: torch.Size([128, 140, 5]), Validation dataset: torch.Size([128, 60, 5])
2025-03-27 23:50:35,983 - INFO - Starting hyperparameter optimization...
2025-03-27 23:50:35,984 - INFO - Trial 0: lr=0.000770, embedding_size=16, n_steps=38
2025-03-27 23:51:11,823 - INFO - Trial 0: RNN Train Loss: 0.0000000
2025-03-27 23:51:11,826 - INFO - Trial 0: Validation set has 128 participants
2025-03-27 23:52:34,124 - INFO - ================================================================================
2025-03-27 23:52:34,125 - INFO - EXPERIMENT CONFIG
2025-03-27 23:52:34,125 - INFO - ================================================================================
2025-03-27 23:52:34,125 - INFO - Found 1 data files: ['data_128p_0.csv']
2025-03-27 23:52:34,125 - INFO - Processing dataset: data_128p_0.csv
2025-03-27 23:52:34,125 - INFO - Loading dataset from data/optuna/data_128p_0.csv
2025-03-27 23:52:34,167 - INFO - Number of participants: 128
2025-03-27 23:52:34,180 - INFO - Participant 0 (ID=0.0): _reward=0.74, _penalty=0.97
2025-03-27 23:52:34,185 - INFO - Participant 1 (ID=1.0): _reward=0.99, _penalty=0.02
2025-03-27 23:52:34,191 - INFO - Participant 2 (ID=2.0): _reward=0.77, _penalty=0.46
2025-03-27 23:52:34,197 - INFO - Participant 3 (ID=3.0): _reward=0.96, _penalty=0.60
2025-03-27 23:52:34,203 - INFO - Participant 4 (ID=4.0): _reward=0.21, _penalty=0.21
2025-03-27 23:52:34,209 - INFO - Participant 5 (ID=5.0): _reward=0.07, _penalty=0.51
2025-03-27 23:52:34,214 - INFO - Participant 6 (ID=6.0): _reward=0.23, _penalty=0.60
2025-03-27 23:52:34,220 - INFO - Participant 7 (ID=7.0): _reward=0.91, _penalty=0.80
2025-03-27 23:52:34,228 - INFO - Participant 8 (ID=8.0): _reward=0.99, _penalty=0.97
2025-03-27 23:52:34,234 - INFO - Participant 9 (ID=9.0): _reward=0.67, _penalty=0.87
2025-03-27 23:52:34,240 - INFO - Participant 10 (ID=10.0): _reward=0.08, _penalty=0.77
2025-03-27 23:52:34,248 - INFO - Participant 11 (ID=11.0): _reward=0.87, _penalty=0.31
2025-03-27 23:52:34,254 - INFO - Participant 12 (ID=12.0): _reward=0.58, _penalty=0.19
2025-03-27 23:52:34,260 - INFO - Participant 13 (ID=13.0): _reward=0.48, _penalty=0.25
2025-03-27 23:52:34,266 - INFO - Participant 14 (ID=14.0): _reward=0.34, _penalty=0.83
2025-03-27 23:52:34,272 - INFO - Participant 15 (ID=15.0): _reward=0.56, _penalty=0.80
2025-03-27 23:52:34,279 - INFO - Participant 16 (ID=16.0): _reward=0.47, _penalty=0.29
2025-03-27 23:52:34,285 - INFO - Participant 17 (ID=17.0): _reward=0.77, _penalty=0.94
2025-03-27 23:52:34,291 - INFO - Participant 18 (ID=18.0): _reward=0.88, _penalty=0.01
2025-03-27 23:52:34,297 - INFO - Participant 19 (ID=19.0): _reward=0.98, _penalty=0.11
2025-03-27 23:52:34,303 - INFO - Participant 20 (ID=20.0): _reward=0.02, _penalty=0.85
2025-03-27 23:52:34,309 - INFO - Participant 21 (ID=21.0): _reward=0.46, _penalty=0.85
2025-03-27 23:52:34,315 - INFO - Participant 22 (ID=22.0): _reward=0.69, _penalty=0.43
2025-03-27 23:52:34,321 - INFO - Participant 23 (ID=23.0): _reward=0.15, _penalty=0.95
2025-03-27 23:52:34,328 - INFO - Participant 24 (ID=24.0): _reward=0.25, _penalty=0.36
2025-03-27 23:52:34,334 - INFO - Participant 25 (ID=25.0): _reward=0.75, _penalty=0.11
2025-03-27 23:52:34,340 - INFO - Participant 26 (ID=26.0): _reward=0.46, _penalty=0.81
2025-03-27 23:52:34,346 - INFO - Participant 27 (ID=27.0): _reward=0.36, _penalty=0.63
2025-03-27 23:52:34,352 - INFO - Participant 28 (ID=28.0): _reward=0.49, _penalty=0.00
2025-03-27 23:52:34,358 - INFO - Participant 29 (ID=29.0): _reward=0.20, _penalty=0.98
2025-03-27 23:52:34,364 - INFO - Participant 30 (ID=30.0): _reward=0.29, _penalty=0.64
2025-03-27 23:52:34,370 - INFO - Participant 31 (ID=31.0): _reward=0.66, _penalty=0.64
2025-03-27 23:52:34,376 - INFO - Participant 32 (ID=32.0): _reward=0.21, _penalty=0.41
2025-03-27 23:52:34,382 - INFO - Participant 33 (ID=33.0): _reward=0.49, _penalty=0.63
2025-03-27 23:52:34,388 - INFO - Participant 34 (ID=34.0): _reward=0.38, _penalty=0.08
2025-03-27 23:52:34,394 - INFO - Participant 35 (ID=35.0): _reward=0.33, _penalty=0.29
2025-03-27 23:52:34,400 - INFO - Participant 36 (ID=36.0): _reward=0.53, _penalty=0.61
2025-03-27 23:52:34,407 - INFO - Participant 37 (ID=37.0): _reward=0.65, _penalty=0.34
2025-03-27 23:52:34,413 - INFO - Participant 38 (ID=38.0): _reward=0.29, _penalty=0.13
2025-03-27 23:52:34,419 - INFO - Participant 39 (ID=39.0): _reward=0.31, _penalty=0.25
2025-03-27 23:52:34,425 - INFO - Participant 40 (ID=40.0): _reward=0.77, _penalty=0.04
2025-03-27 23:52:34,431 - INFO - Participant 41 (ID=41.0): _reward=0.23, _penalty=0.89
2025-03-27 23:52:34,438 - INFO - Participant 42 (ID=42.0): _reward=0.63, _penalty=0.60
2025-03-27 23:52:34,444 - INFO - Participant 43 (ID=43.0): _reward=0.48, _penalty=0.52
2025-03-27 23:52:34,450 - INFO - Participant 44 (ID=44.0): _reward=0.92, _penalty=0.22
2025-03-27 23:52:34,456 - INFO - Participant 45 (ID=45.0): _reward=0.52, _penalty=0.89
2025-03-27 23:52:34,462 - INFO - Participant 46 (ID=46.0): _reward=0.42, _penalty=0.83
2025-03-27 23:52:34,468 - INFO - Participant 47 (ID=47.0): _reward=0.68, _penalty=0.69
2025-03-27 23:52:34,474 - INFO - Participant 48 (ID=48.0): _reward=0.95, _penalty=0.22
2025-03-27 23:52:34,480 - INFO - Participant 49 (ID=49.0): _reward=0.13, _penalty=0.48
2025-03-27 23:52:34,486 - INFO - Participant 50 (ID=50.0): _reward=0.87, _penalty=0.85
2025-03-27 23:52:34,492 - INFO - Participant 51 (ID=51.0): _reward=0.47, _penalty=0.07
2025-03-27 23:52:34,498 - INFO - Participant 52 (ID=52.0): _reward=0.56, _penalty=0.42
2025-03-27 23:52:34,504 - INFO - Participant 53 (ID=53.0): _reward=0.53, _penalty=0.18
2025-03-27 23:52:34,509 - INFO - Participant 54 (ID=54.0): _reward=0.87, _penalty=0.73
2025-03-27 23:52:34,515 - INFO - Participant 55 (ID=55.0): _reward=0.21, _penalty=0.47
2025-03-27 23:52:34,521 - INFO - Participant 56 (ID=56.0): _reward=0.65, _penalty=0.09
2025-03-27 23:52:34,527 - INFO - Participant 57 (ID=57.0): _reward=0.72, _penalty=0.88
2025-03-27 23:52:34,534 - INFO - Participant 58 (ID=58.0): _reward=0.61, _penalty=0.38
2025-03-27 23:52:34,540 - INFO - Participant 59 (ID=59.0): _reward=0.92, _penalty=0.91
2025-03-27 23:52:34,546 - INFO - Participant 60 (ID=60.0): _reward=0.22, _penalty=0.97
2025-03-27 23:52:34,552 - INFO - Participant 61 (ID=61.0): _reward=0.41, _penalty=0.53
2025-03-27 23:52:34,558 - INFO - Participant 62 (ID=62.0): _reward=0.92, _penalty=0.99
2025-03-27 23:52:34,564 - INFO - Participant 63 (ID=63.0): _reward=0.22, _penalty=0.99
2025-03-27 23:52:34,570 - INFO - Participant 64 (ID=64.0): _reward=0.84, _penalty=0.96
2025-03-27 23:52:34,577 - INFO - Participant 65 (ID=65.0): _reward=0.55, _penalty=0.19
2025-03-27 23:52:34,583 - INFO - Participant 66 (ID=66.0): _reward=0.34, _penalty=0.07
2025-03-27 23:52:34,589 - INFO - Participant 67 (ID=67.0): _reward=0.62, _penalty=0.45
2025-03-27 23:52:34,595 - INFO - Participant 68 (ID=68.0): _reward=0.47, _penalty=0.19
2025-03-27 23:52:34,601 - INFO - Participant 69 (ID=69.0): _reward=0.81, _penalty=0.36
2025-03-27 23:52:34,607 - INFO - Participant 70 (ID=70.0): _reward=0.73, _penalty=0.87
2025-03-27 23:52:34,613 - INFO - Participant 71 (ID=71.0): _reward=0.10, _penalty=0.57
2025-03-27 23:52:34,619 - INFO - Participant 72 (ID=72.0): _reward=0.78, _penalty=0.50
2025-03-27 23:52:34,625 - INFO - Participant 73 (ID=73.0): _reward=0.82, _penalty=0.70
2025-03-27 23:52:34,631 - INFO - Participant 74 (ID=74.0): _reward=0.00, _penalty=0.98
2025-03-27 23:52:34,638 - INFO - Participant 75 (ID=75.0): _reward=0.42, _penalty=0.26
2025-03-27 23:52:34,644 - INFO - Participant 76 (ID=76.0): _reward=0.83, _penalty=0.39
2025-03-27 23:52:34,649 - INFO - Participant 77 (ID=77.0): _reward=0.75, _penalty=0.18
2025-03-27 23:52:34,656 - INFO - Participant 78 (ID=78.0): _reward=0.97, _penalty=0.44
2025-03-27 23:52:34,662 - INFO - Participant 79 (ID=79.0): _reward=0.45, _penalty=0.57
2025-03-27 23:52:34,668 - INFO - Participant 80 (ID=80.0): _reward=0.63, _penalty=0.78
2025-03-27 23:52:34,674 - INFO - Participant 81 (ID=81.0): _reward=0.29, _penalty=0.24
2025-03-27 23:52:34,680 - INFO - Participant 82 (ID=82.0): _reward=0.71, _penalty=0.15
2025-03-27 23:52:34,686 - INFO - Participant 83 (ID=83.0): _reward=0.71, _penalty=0.66
2025-03-27 23:52:34,692 - INFO - Participant 84 (ID=84.0): _reward=0.97, _penalty=0.79
2025-03-27 23:52:34,698 - INFO - Participant 85 (ID=85.0): _reward=1.00, _penalty=0.95
2025-03-27 23:52:34,705 - INFO - Participant 86 (ID=86.0): _reward=0.56, _penalty=0.08
2025-03-27 23:52:34,711 - INFO - Participant 87 (ID=87.0): _reward=0.59, _penalty=0.83
2025-03-27 23:52:34,717 - INFO - Participant 88 (ID=88.0): _reward=0.32, _penalty=0.60
2025-03-27 23:52:34,723 - INFO - Participant 89 (ID=89.0): _reward=0.20, _penalty=0.84
2025-03-27 23:52:34,729 - INFO - Participant 90 (ID=90.0): _reward=0.34, _penalty=1.00
2025-03-27 23:52:34,736 - INFO - Participant 91 (ID=91.0): _reward=0.19, _penalty=0.99
2025-03-27 23:52:34,742 - INFO - Participant 92 (ID=92.0): _reward=0.20, _penalty=0.91
2025-03-27 23:52:34,748 - INFO - Participant 93 (ID=93.0): _reward=0.31, _penalty=0.21
2025-03-27 23:52:34,754 - INFO - Participant 94 (ID=94.0): _reward=0.58, _penalty=0.41
2025-03-27 23:52:34,760 - INFO - Participant 95 (ID=95.0): _reward=0.80, _penalty=0.54
2025-03-27 23:52:34,767 - INFO - Participant 96 (ID=96.0): _reward=0.74, _penalty=0.80
2025-03-27 23:52:34,773 - INFO - Participant 97 (ID=97.0): _reward=0.59, _penalty=0.16
2025-03-27 23:52:34,780 - INFO - Participant 98 (ID=98.0): _reward=0.54, _penalty=0.17
2025-03-27 23:52:34,786 - INFO - Participant 99 (ID=99.0): _reward=0.17, _penalty=0.16
2025-03-27 23:52:34,794 - INFO - Participant 100 (ID=100.0): _reward=0.79, _penalty=0.40
2025-03-27 23:52:34,800 - INFO - Participant 101 (ID=101.0): _reward=0.32, _penalty=0.05
2025-03-27 23:52:34,807 - INFO - Participant 102 (ID=102.0): _reward=0.87, _penalty=0.81
2025-03-27 23:52:34,813 - INFO - Participant 103 (ID=103.0): _reward=0.90, _penalty=0.11
2025-03-27 23:52:34,820 - INFO - Participant 104 (ID=104.0): _reward=0.44, _penalty=0.12
2025-03-27 23:52:34,826 - INFO - Participant 105 (ID=105.0): _reward=0.59, _penalty=0.50
2025-03-27 23:52:34,833 - INFO - Participant 106 (ID=106.0): _reward=0.84, _penalty=0.50
2025-03-27 23:52:34,839 - INFO - Participant 107 (ID=107.0): _reward=0.48, _penalty=0.54
2025-03-27 23:52:34,845 - INFO - Participant 108 (ID=108.0): _reward=0.56, _penalty=0.75
2025-03-27 23:52:34,852 - INFO - Participant 109 (ID=109.0): _reward=0.53, _penalty=0.11
2025-03-27 23:52:34,858 - INFO - Participant 110 (ID=110.0): _reward=0.52, _penalty=0.40
2025-03-27 23:52:34,864 - INFO - Participant 111 (ID=111.0): _reward=0.61, _penalty=0.74
2025-03-27 23:52:34,871 - INFO - Participant 112 (ID=112.0): _reward=0.64, _penalty=0.56
2025-03-27 23:52:34,877 - INFO - Participant 113 (ID=113.0): _reward=0.44, _penalty=0.40
2025-03-27 23:52:34,883 - INFO - Participant 114 (ID=114.0): _reward=0.74, _penalty=0.91
2025-03-27 23:52:34,889 - INFO - Participant 115 (ID=115.0): _reward=0.09, _penalty=0.27
2025-03-27 23:52:34,895 - INFO - Participant 116 (ID=116.0): _reward=0.99, _penalty=0.92
2025-03-27 23:52:34,902 - INFO - Participant 117 (ID=117.0): _reward=0.90, _penalty=0.87
2025-03-27 23:52:34,908 - INFO - Participant 118 (ID=118.0): _reward=0.21, _penalty=0.27
2025-03-27 23:52:34,914 - INFO - Participant 119 (ID=119.0): _reward=0.71, _penalty=0.69
2025-03-27 23:52:34,920 - INFO - Participant 120 (ID=120.0): _reward=0.43, _penalty=0.05
2025-03-27 23:52:34,926 - INFO - Participant 121 (ID=121.0): _reward=0.11, _penalty=0.27
2025-03-27 23:52:34,933 - INFO - Participant 122 (ID=122.0): _reward=0.80, _penalty=0.43
2025-03-27 23:52:34,939 - INFO - Participant 123 (ID=123.0): _reward=0.74, _penalty=0.44
2025-03-27 23:52:34,945 - INFO - Participant 124 (ID=124.0): _reward=0.18, _penalty=0.36
2025-03-27 23:52:34,951 - INFO - Participant 125 (ID=125.0): _reward=0.86, _penalty=0.09
2025-03-27 23:52:34,957 - INFO - Participant 126 (ID=126.0): _reward=0.05, _penalty=0.52
2025-03-27 23:52:34,963 - INFO - Participant 127 (ID=127.0): _reward=0.41, _penalty=0.26
2025-03-27 23:52:34,963 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,963 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,963 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,963 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,963 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,963 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,963 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,963 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,963 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,963 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,963 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 32 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 33 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 34 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 35 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 36 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 37 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 38 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 39 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 40 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 41 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 42 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 43 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 44 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 45 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 46 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 47 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 48 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 49 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 50 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 51 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 52 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 53 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 54 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 55 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 56 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 57 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 58 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 59 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 60 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 61 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 62 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 63 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 64 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 65 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 66 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 67 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 68 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 69 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 70 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 71 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,964 - INFO - Participant 72 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 73 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 74 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 75 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 76 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 77 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 78 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 79 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 80 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 81 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 82 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 83 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 84 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 85 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 86 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 87 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 88 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 89 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 90 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 91 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 92 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 93 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 94 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 95 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 96 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 97 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 98 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 99 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 100 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 101 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 102 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 103 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 104 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 105 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 106 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 107 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 108 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 109 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 110 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 111 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 112 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 113 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 114 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 115 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 116 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 117 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 118 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 119 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 120 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 121 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 122 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 123 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 124 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 125 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 126 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,965 - INFO - Participant 127 xs shape: torch.Size([1, 200, 5])
2025-03-27 23:52:34,967 - INFO - Combined xs shape after concatenation: torch.Size([128, 200, 5])
2025-03-27 23:52:34,967 - INFO - Combined ys shape after concatenation: torch.Size([128, 200, 2])
2025-03-27 23:52:34,967 - INFO - Combined dataset shape: X=torch.Size([128, 200, 5]), Y=torch.Size([128, 200, 2])
2025-03-27 23:52:34,971 - INFO - Total unique participants: 128
2025-03-27 23:52:34,971 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-27 23:52:34,973 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,974 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,974 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,974 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,974 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,974 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,975 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,975 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,975 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,975 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,975 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,975 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,976 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,976 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,976 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,976 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,976 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,976 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,976 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,977 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,977 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,977 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,977 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,977 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,978 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,978 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,978 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,978 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,978 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,978 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,979 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,979 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,979 - INFO - Participant 32.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,979 - INFO - Participant 33.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,979 - INFO - Participant 34.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,979 - INFO - Participant 35.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,980 - INFO - Participant 36.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,980 - INFO - Participant 37.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,980 - INFO - Participant 38.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,980 - INFO - Participant 39.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,980 - INFO - Participant 40.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,981 - INFO - Participant 41.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,981 - INFO - Participant 42.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,981 - INFO - Participant 43.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,981 - INFO - Participant 44.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,981 - INFO - Participant 45.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,982 - INFO - Participant 46.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,982 - INFO - Participant 47.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,982 - INFO - Participant 48.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,982 - INFO - Participant 49.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,982 - INFO - Participant 50.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,982 - INFO - Participant 51.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,983 - INFO - Participant 52.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,983 - INFO - Participant 53.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,983 - INFO - Participant 54.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,983 - INFO - Participant 55.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,983 - INFO - Participant 56.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,983 - INFO - Participant 57.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,983 - INFO - Participant 58.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,984 - INFO - Participant 59.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,984 - INFO - Participant 60.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,984 - INFO - Participant 61.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,984 - INFO - Participant 62.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,984 - INFO - Participant 63.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,984 - INFO - Participant 64.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,984 - INFO - Participant 65.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,985 - INFO - Participant 66.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,985 - INFO - Participant 67.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,985 - INFO - Participant 68.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,985 - INFO - Participant 69.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,985 - INFO - Participant 70.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,985 - INFO - Participant 71.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,986 - INFO - Participant 72.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,986 - INFO - Participant 73.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,986 - INFO - Participant 74.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,986 - INFO - Participant 75.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,986 - INFO - Participant 76.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,986 - INFO - Participant 77.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,986 - INFO - Participant 78.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,986 - INFO - Participant 79.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,987 - INFO - Participant 80.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,987 - INFO - Participant 81.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,987 - INFO - Participant 82.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,987 - INFO - Participant 83.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,987 - INFO - Participant 84.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,987 - INFO - Participant 85.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,987 - INFO - Participant 86.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,988 - INFO - Participant 87.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,988 - INFO - Participant 88.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,988 - INFO - Participant 89.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,988 - INFO - Participant 90.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,988 - INFO - Participant 91.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,988 - INFO - Participant 92.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,988 - INFO - Participant 93.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,988 - INFO - Participant 94.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,988 - INFO - Participant 95.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,988 - INFO - Participant 96.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,988 - INFO - Participant 97.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,988 - INFO - Participant 98.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 99.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 100.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 101.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 102.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 103.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 104.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 105.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 106.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 107.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 108.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 109.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 110.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 111.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 112.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 113.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 114.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 115.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 116.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 117.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 118.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 119.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 120.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 121.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 122.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,989 - INFO - Participant 123.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,990 - INFO - Participant 124.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,990 - INFO - Participant 125.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,990 - INFO - Participant 126.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,990 - INFO - Participant 127.0: 140 trials for training, 60 trials for validation
2025-03-27 23:52:34,990 - INFO - Train xs shape: torch.Size([128, 140, 5])
2025-03-27 23:52:34,990 - INFO - Train ys shape: torch.Size([128, 140, 2])
2025-03-27 23:52:34,990 - INFO - Validation xs shape: torch.Size([128, 60, 5])
2025-03-27 23:52:34,990 - INFO - Validation ys shape: torch.Size([128, 60, 2])
2025-03-27 23:52:34,990 - INFO - Train dataset: torch.Size([128, 140, 5]), Validation dataset: torch.Size([128, 60, 5])
2025-03-27 23:52:34,990 - INFO - Starting hyperparameter optimization...
2025-03-27 23:52:34,991 - INFO - Trial 0: lr=0.008094, embedding_size=17, n_steps=29
2025-03-28 00:03:05,339 - INFO - Trial 0: RNN Train Loss: 0.3055655
2025-03-28 00:03:05,339 - INFO - Trial 0: Validation set has 128 participants
2025-03-28 00:03:11,014 - INFO - Trial 0: Average Validation Loss: 0.4258, Eval count: 128
2025-03-28 00:03:11,015 - INFO - Trial 1: lr=0.000141, embedding_size=10, n_steps=94
2025-03-28 00:13:08,369 - INFO - Trial 1: RNN Train Loss: 0.3898890
2025-03-28 00:13:08,370 - INFO - Trial 1: Validation set has 128 participants
2025-03-28 00:13:14,231 - INFO - Trial 1: Average Validation Loss: 0.4647, Eval count: 128
2025-03-28 00:13:14,231 - INFO - Trial 2: lr=0.000198, embedding_size=10, n_steps=58
2025-03-28 00:23:18,459 - INFO - Trial 2: RNN Train Loss: 0.3953502
2025-03-28 00:23:18,459 - INFO - Trial 2: Validation set has 128 participants
2025-03-28 00:23:24,214 - INFO - Trial 2: Average Validation Loss: 0.4558, Eval count: 128
2025-03-28 00:23:24,215 - INFO - Trial 3: lr=0.000166, embedding_size=20, n_steps=22
2025-03-28 00:33:58,814 - INFO - Trial 3: RNN Train Loss: 0.3048513
2025-03-28 00:33:58,815 - INFO - Trial 3: Validation set has 128 participants
2025-03-28 00:34:05,034 - INFO - Trial 3: Average Validation Loss: 0.4044, Eval count: 128
2025-03-28 00:34:05,035 - INFO - Trial 4: lr=0.003569, embedding_size=18, n_steps=18
2025-03-28 00:44:39,056 - INFO - Trial 4: RNN Train Loss: 0.3380273
2025-03-28 00:44:39,057 - INFO - Trial 4: Validation set has 128 participants
2025-03-28 00:44:45,287 - INFO - Trial 4: Average Validation Loss: 0.4528, Eval count: 128
2025-03-28 00:44:45,287 - INFO - Trial 5: lr=0.000708, embedding_size=22, n_steps=70
2025-03-28 00:54:58,948 - INFO - Trial 5: RNN Train Loss: 0.3156643
2025-03-28 00:54:58,948 - INFO - Trial 5: Validation set has 128 participants
2025-03-28 00:55:05,119 - INFO - Trial 5: Average Validation Loss: 0.4044, Eval count: 128
2025-03-28 00:55:05,119 - INFO - Trial 6: lr=0.001450, embedding_size=11, n_steps=73
2025-03-28 01:05:05,802 - INFO - Trial 6: RNN Train Loss: 0.3940863
2025-03-28 01:05:05,803 - INFO - Trial 6: Validation set has 128 participants
2025-03-28 01:05:11,552 - INFO - Trial 6: Average Validation Loss: 0.4712, Eval count: 128
2025-03-28 01:05:11,553 - INFO - Trial 7: lr=0.005086, embedding_size=17, n_steps=42
2025-03-28 01:15:30,466 - INFO - Trial 7: RNN Train Loss: 0.3279899
2025-03-28 01:15:30,467 - INFO - Trial 7: Validation set has 128 participants
2025-03-28 01:15:36,457 - INFO - Trial 7: Average Validation Loss: 0.4529, Eval count: 128
2025-03-28 01:15:36,458 - INFO - Trial 8: lr=0.006244, embedding_size=19, n_steps=46
2025-03-28 01:25:57,889 - INFO - Trial 8: RNN Train Loss: 0.3827702
2025-03-28 01:25:57,889 - INFO - Trial 8: Validation set has 128 participants
2025-03-28 01:26:04,111 - INFO - Trial 8: Average Validation Loss: 0.5009, Eval count: 128
2025-03-28 01:26:04,111 - INFO - Trial 9: lr=0.005298, embedding_size=30, n_steps=76
2025-03-28 01:36:25,292 - INFO - Trial 9: RNN Train Loss: 0.2928104
2025-03-28 01:36:25,292 - INFO - Trial 9: Validation set has 128 participants
2025-03-28 01:36:30,979 - INFO - Trial 9: Average Validation Loss: 0.4118, Eval count: 128
2025-03-28 01:36:30,994 - INFO - Trial 10: lr=0.000518, embedding_size=28, n_steps=4
2025-03-28 01:49:13,966 - INFO - Trial 10: RNN Train Loss: 0.3507945
2025-03-28 01:49:13,966 - INFO - Trial 10: Validation set has 128 participants
2025-03-28 01:49:19,680 - INFO - Trial 10: Average Validation Loss: 0.4569, Eval count: 128
2025-03-28 01:49:19,685 - INFO - Trial 11: lr=0.000374, embedding_size=24, n_steps=67
2025-03-28 01:59:36,846 - INFO - Trial 11: RNN Train Loss: 0.4083113
2025-03-28 01:59:36,846 - INFO - Trial 11: Validation set has 128 participants
2025-03-28 01:59:42,483 - INFO - Trial 11: Average Validation Loss: 0.5042, Eval count: 128
2025-03-28 01:59:42,489 - INFO - Trial 12: lr=0.001361, embedding_size=24, n_steps=97
2025-03-28 02:09:52,281 - INFO - Trial 12: RNN Train Loss: 0.2989635
2025-03-28 02:09:52,282 - INFO - Trial 12: Validation set has 128 participants
2025-03-28 02:09:58,512 - INFO - Trial 12: Average Validation Loss: 0.4191, Eval count: 128
2025-03-28 02:09:58,518 - INFO - Trial 13: lr=0.000547, embedding_size=23, n_steps=31
2025-03-28 02:12:29,575 - INFO - Trial 13: RNN Train Loss: 0.6931173
2025-03-28 02:12:29,576 - INFO - Trial 13: Validation set has 128 participants
2025-03-28 02:12:35,719 - INFO - Trial 13: Average Validation Loss: 0.6930, Eval count: 128
2025-03-28 02:12:35,725 - INFO - Trial 14: lr=0.000243, embedding_size=22, n_steps=2
2025-03-28 02:27:36,223 - INFO - Trial 14: RNN Train Loss: 0.3042054
2025-03-28 02:27:36,224 - INFO - Trial 14: Validation set has 128 participants
2025-03-28 02:27:42,440 - INFO - Trial 14: Average Validation Loss: 0.4175, Eval count: 128
2025-03-28 02:27:42,447 - INFO - Trial 15: lr=0.000120, embedding_size=27, n_steps=86
2025-03-28 02:37:58,689 - INFO - Trial 15: RNN Train Loss: 0.3466890
2025-03-28 02:37:58,690 - INFO - Trial 15: Validation set has 128 participants
2025-03-28 02:38:04,964 - INFO - Trial 15: Average Validation Loss: 0.4290, Eval count: 128
2025-03-28 02:38:04,970 - INFO - Trial 16: lr=0.000886, embedding_size=15, n_steps=54
2025-03-28 02:48:17,905 - INFO - Trial 16: RNN Train Loss: 0.3764417
2025-03-28 02:48:17,906 - INFO - Trial 16: Validation set has 128 participants
2025-03-28 02:48:24,137 - INFO - Trial 16: Average Validation Loss: 0.4652, Eval count: 128
2025-03-28 02:48:24,144 - INFO - Trial 17: lr=0.002793, embedding_size=14, n_steps=22
2025-03-28 02:58:53,187 - INFO - Trial 17: RNN Train Loss: 0.3190832
2025-03-28 02:58:53,188 - INFO - Trial 17: Validation set has 128 participants
2025-03-28 02:58:59,414 - INFO - Trial 17: Average Validation Loss: 0.4450, Eval count: 128
2025-03-28 02:58:59,420 - INFO - Trial 18: lr=0.000280, embedding_size=20, n_steps=36
2025-03-28 03:09:20,353 - INFO - Trial 18: RNN Train Loss: 0.5330143
2025-03-28 03:09:20,354 - INFO - Trial 18: Validation set has 128 participants
2025-03-28 03:09:26,000 - INFO - Trial 18: Average Validation Loss: 0.5856, Eval count: 128
2025-03-28 03:09:26,006 - INFO - Trial 19: lr=0.000902, embedding_size=26, n_steps=61
2025-03-28 03:19:46,571 - INFO - Trial 19: RNN Train Loss: 0.2969034
2025-03-28 03:19:46,571 - INFO - Trial 19: Validation set has 128 participants
2025-03-28 03:19:52,661 - INFO - Trial 19: Average Validation Loss: 0.4176, Eval count: 128
2025-03-28 03:19:52,667 - INFO - Trial 20: lr=0.000570, embedding_size=31, n_steps=13
2025-03-28 03:30:58,800 - INFO - Trial 20: RNN Train Loss: 0.3143929
2025-03-28 03:30:58,800 - INFO - Trial 20: Validation set has 128 participants
2025-03-28 03:31:04,457 - INFO - Trial 20: Average Validation Loss: 0.4285, Eval count: 128
2025-03-28 03:31:04,463 - INFO - Trial 21: lr=0.001895, embedding_size=32, n_steps=78
2025-03-28 03:41:19,460 - INFO - Trial 21: RNN Train Loss: 0.3252456
2025-03-28 03:41:19,461 - INFO - Trial 21: Validation set has 128 participants
2025-03-28 03:41:25,173 - INFO - Trial 21: Average Validation Loss: 0.4368, Eval count: 128
2025-03-28 03:41:25,179 - INFO - Trial 22: lr=0.002670, embedding_size=30, n_steps=81
2025-03-28 03:51:46,681 - INFO - Trial 22: RNN Train Loss: 0.3908713
2025-03-28 03:51:46,681 - INFO - Trial 22: Validation set has 128 participants
2025-03-28 03:51:52,430 - INFO - Trial 22: Average Validation Loss: 0.4912, Eval count: 128
2025-03-28 03:51:52,436 - INFO - Trial 23: lr=0.000178, embedding_size=21, n_steps=68
2025-03-28 04:02:11,835 - INFO - Trial 23: RNN Train Loss: 0.4545772
2025-03-28 04:02:11,836 - INFO - Trial 23: Validation set has 128 participants
2025-03-28 04:02:18,060 - INFO - Trial 23: Average Validation Loss: 0.5410, Eval count: 128
2025-03-28 04:02:18,067 - INFO - Trial 24: lr=0.009581, embedding_size=25, n_steps=84
2025-03-28 04:12:31,005 - INFO - Trial 24: RNN Train Loss: 0.2814410
2025-03-28 04:12:31,005 - INFO - Trial 24: Validation set has 128 participants
2025-03-28 04:12:36,767 - INFO - Trial 24: Average Validation Loss: 0.5037, Eval count: 128
2025-03-28 04:12:36,773 - INFO - Trial 25: lr=0.000351, embedding_size=29, n_steps=65
2025-03-28 04:23:05,513 - INFO - Trial 25: RNN Train Loss: 0.3532373
2025-03-28 04:23:05,513 - INFO - Trial 25: Validation set has 128 participants
2025-03-28 04:23:11,256 - INFO - Trial 25: Average Validation Loss: 0.4433, Eval count: 128
2025-03-28 04:23:11,263 - INFO - Trial 26: lr=0.000103, embedding_size=15, n_steps=51
2025-03-28 04:33:24,765 - INFO - Trial 26: RNN Train Loss: 0.3926585
2025-03-28 04:33:24,765 - INFO - Trial 26: Validation set has 128 participants
2025-03-28 04:33:31,036 - INFO - Trial 26: Average Validation Loss: 0.4581, Eval count: 128
2025-03-28 04:33:31,043 - INFO - Trial 27: lr=0.004324, embedding_size=21, n_steps=91
2025-03-28 04:43:44,992 - INFO - Trial 27: RNN Train Loss: 0.2635210
2025-03-28 04:43:44,992 - INFO - Trial 27: Validation set has 128 participants
2025-03-28 04:43:51,102 - INFO - Trial 27: Average Validation Loss: 0.4191, Eval count: 128
2025-03-28 04:43:51,109 - INFO - Trial 28: lr=0.000793, embedding_size=8, n_steps=74
2025-03-28 04:53:46,992 - INFO - Trial 28: RNN Train Loss: 0.2809315
2025-03-28 04:53:46,992 - INFO - Trial 28: Validation set has 128 participants
2025-03-28 04:53:53,123 - INFO - Trial 28: Average Validation Loss: 0.3811, Eval count: 128
2025-03-28 04:53:53,130 - INFO - Trial 29: lr=0.000778, embedding_size=13, n_steps=45
2025-03-28 05:04:10,149 - INFO - Trial 29: RNN Train Loss: 0.3522761
2025-03-28 05:04:10,149 - INFO - Trial 29: Validation set has 128 participants
2025-03-28 05:04:15,838 - INFO - Trial 29: Average Validation Loss: 0.4683, Eval count: 128
2025-03-28 05:04:15,844 - INFO - Trial 30: lr=0.001277, embedding_size=8, n_steps=71
2025-03-28 05:14:12,147 - INFO - Trial 30: RNN Train Loss: 0.4182340
2025-03-28 05:14:12,148 - INFO - Trial 30: Validation set has 128 participants
2025-03-28 05:14:17,898 - INFO - Trial 30: Average Validation Loss: 0.4835, Eval count: 128
2025-03-28 05:14:17,905 - INFO - Trial 31: lr=0.001928, embedding_size=8, n_steps=77
2025-03-28 05:24:15,831 - INFO - Trial 31: RNN Train Loss: 0.3251657
2025-03-28 05:24:15,831 - INFO - Trial 31: Validation set has 128 participants
2025-03-28 05:24:22,037 - INFO - Trial 31: Average Validation Loss: 0.4343, Eval count: 128
2025-03-28 05:24:22,043 - INFO - Trial 32: lr=0.000746, embedding_size=17, n_steps=88
2025-03-28 05:34:29,938 - INFO - Trial 32: RNN Train Loss: 0.2987788
2025-03-28 05:34:29,938 - INFO - Trial 32: Validation set has 128 participants
2025-03-28 05:34:36,140 - INFO - Trial 32: Average Validation Loss: 0.4128, Eval count: 128
2025-03-28 05:34:36,147 - INFO - Trial 33: lr=0.000406, embedding_size=12, n_steps=60
2025-03-28 05:44:47,432 - INFO - Trial 33: RNN Train Loss: 0.2862374
2025-03-28 05:44:47,433 - INFO - Trial 33: Validation set has 128 participants
2025-03-28 05:44:53,180 - INFO - Trial 33: Average Validation Loss: 0.3956, Eval count: 128
2025-03-28 05:44:53,187 - INFO - Trial 34: lr=0.000388, embedding_size=11, n_steps=59
2025-03-28 05:55:02,557 - INFO - Trial 34: RNN Train Loss: 0.2934246
2025-03-28 05:55:02,558 - INFO - Trial 34: Validation set has 128 participants
2025-03-28 05:55:08,701 - INFO - Trial 34: Average Validation Loss: 0.4019, Eval count: 128
2025-03-28 05:55:08,708 - INFO - Trial 35: lr=0.000375, embedding_size=11, n_steps=60
2025-03-28 06:05:16,452 - INFO - Trial 35: RNN Train Loss: 0.3210172
2025-03-28 06:05:16,453 - INFO - Trial 35: Validation set has 128 participants
2025-03-28 06:05:22,679 - INFO - Trial 35: Average Validation Loss: 0.4269, Eval count: 128
2025-03-28 06:05:22,686 - INFO - Trial 36: lr=0.000636, embedding_size=12, n_steps=55
2025-03-28 06:15:32,135 - INFO - Trial 36: RNN Train Loss: 0.3633932
2025-03-28 06:15:32,136 - INFO - Trial 36: Validation set has 128 participants
2025-03-28 06:15:38,249 - INFO - Trial 36: Average Validation Loss: 0.4507, Eval count: 128
2025-03-28 06:15:38,256 - INFO - Trial 37: lr=0.000465, embedding_size=9, n_steps=60
2025-03-28 06:25:42,295 - INFO - Trial 37: RNN Train Loss: 0.6132651
2025-03-28 06:25:42,296 - INFO - Trial 37: Validation set has 128 participants
2025-03-28 06:25:48,484 - INFO - Trial 37: Average Validation Loss: 0.6418, Eval count: 128
2025-03-28 06:25:48,491 - INFO - Trial 38: lr=0.000262, embedding_size=10, n_steps=65
2025-03-28 06:35:55,966 - INFO - Trial 38: RNN Train Loss: 0.4381460
2025-03-28 06:35:55,967 - INFO - Trial 38: Validation set has 128 participants
2025-03-28 06:36:02,136 - INFO - Trial 38: Average Validation Loss: 0.5039, Eval count: 128
2025-03-28 06:36:02,143 - INFO - Trial 39: lr=0.001024, embedding_size=10, n_steps=73
2025-03-28 06:46:02,554 - INFO - Trial 39: RNN Train Loss: 0.2904452
2025-03-28 06:46:02,555 - INFO - Trial 39: Validation set has 128 participants
2025-03-28 06:46:08,260 - INFO - Trial 39: Average Validation Loss: 0.4027, Eval count: 128
2025-03-28 06:46:08,267 - INFO - Trial 40: lr=0.001132, embedding_size=12, n_steps=49
2025-03-28 06:56:17,756 - INFO - Trial 40: RNN Train Loss: 0.2826755
2025-03-28 06:56:17,757 - INFO - Trial 40: Validation set has 128 participants
2025-03-28 06:56:23,931 - INFO - Trial 40: Average Validation Loss: 0.3944, Eval count: 128
2025-03-28 06:56:23,938 - INFO - Trial 41: lr=0.001160, embedding_size=12, n_steps=40
2025-03-28 07:06:38,774 - INFO - Trial 41: RNN Train Loss: 0.3931299
2025-03-28 07:06:38,774 - INFO - Trial 41: Validation set has 128 participants
2025-03-28 07:06:44,565 - INFO - Trial 41: Average Validation Loss: 0.4847, Eval count: 128
2025-03-28 07:06:44,572 - INFO - Trial 42: lr=0.000982, embedding_size=10, n_steps=49
2025-03-28 07:16:46,083 - INFO - Trial 42: RNN Train Loss: 0.3076040
2025-03-28 07:16:46,084 - INFO - Trial 42: Validation set has 128 participants
2025-03-28 07:16:51,834 - INFO - Trial 42: Average Validation Loss: 0.4239, Eval count: 128
2025-03-28 07:16:51,841 - INFO - Trial 43: lr=0.000436, embedding_size=9, n_steps=56
2025-03-28 07:26:58,080 - INFO - Trial 43: RNN Train Loss: 0.2934962
2025-03-28 07:26:58,080 - INFO - Trial 43: Validation set has 128 participants
2025-03-28 07:27:03,885 - INFO - Trial 43: Average Validation Loss: 0.3940, Eval count: 128
2025-03-28 07:27:03,891 - INFO - Trial 44: lr=0.000419, embedding_size=8, n_steps=49
2025-03-28 07:37:06,613 - INFO - Trial 44: RNN Train Loss: 0.2889658
2025-03-28 07:37:06,613 - INFO - Trial 44: Validation set has 128 participants
2025-03-28 07:37:12,826 - INFO - Trial 44: Average Validation Loss: 0.3893, Eval count: 128
2025-03-28 07:37:12,833 - INFO - Trial 45: lr=0.000472, embedding_size=8, n_steps=38
2025-03-28 07:47:18,783 - INFO - Trial 45: RNN Train Loss: 0.3901349
2025-03-28 07:47:18,783 - INFO - Trial 45: Validation set has 128 participants
2025-03-28 07:47:24,714 - INFO - Trial 45: Average Validation Loss: 0.4810, Eval count: 128
2025-03-28 07:47:24,721 - INFO - Trial 46: lr=0.001676, embedding_size=9, n_steps=47
2025-03-28 07:57:28,548 - INFO - Trial 46: RNN Train Loss: 0.3311479
2025-03-28 07:57:28,549 - INFO - Trial 46: Validation set has 128 participants
2025-03-28 07:57:34,703 - INFO - Trial 46: Average Validation Loss: 0.4236, Eval count: 128
2025-03-28 07:57:34,711 - INFO - Trial 47: lr=0.000237, embedding_size=13, n_steps=34
2025-03-28 08:07:57,495 - INFO - Trial 47: RNN Train Loss: 0.3473415
2025-03-28 08:07:57,496 - INFO - Trial 47: Validation set has 128 participants
2025-03-28 08:08:03,644 - INFO - Trial 47: Average Validation Loss: 0.4412, Eval count: 128
2025-03-28 08:08:03,651 - INFO - Trial 48: lr=0.000298, embedding_size=9, n_steps=53
2025-03-28 08:18:08,576 - INFO - Trial 48: RNN Train Loss: 0.3425839
2025-03-28 08:18:08,577 - INFO - Trial 48: Validation set has 128 participants
2025-03-28 08:18:14,312 - INFO - Trial 48: Average Validation Loss: 0.4194, Eval count: 128
2025-03-28 08:18:14,319 - INFO - Trial 49: lr=0.000678, embedding_size=16, n_steps=43
2025-03-28 08:28:31,277 - INFO - Trial 49: RNN Train Loss: 0.3538851
2025-03-28 08:28:31,278 - INFO - Trial 49: Validation set has 128 participants
2025-03-28 08:28:37,509 - INFO - Trial 49: Average Validation Loss: 0.4519, Eval count: 128
2025-03-28 08:28:37,510 - INFO - Best hyperparameters: {'learning_rate': 0.0007930516165427202, 'embedding_size': 8, 'n_steps': 74}
2025-03-28 08:28:37,510 - INFO - Best validation loss: 0.3811
2025-03-28 09:28:48,423 - INFO - ================================================================================
2025-03-28 09:28:48,423 - INFO - EXPERIMENT CONFIG
2025-03-28 09:28:48,423 - INFO - ================================================================================
2025-03-28 09:28:48,423 - INFO - Found 1 data files: ['data_128p_0.csv']
2025-03-28 09:28:48,423 - INFO - Processing dataset: data_128p_0.csv
2025-03-28 09:28:48,423 - INFO - Loading dataset from data/optuna/data_128p_0.csv
2025-03-28 09:28:48,457 - INFO - Number of participants: 128
2025-03-28 09:28:48,462 - INFO - Participant 0 (ID=0.0): _reward=0.74, _penalty=0.97
2025-03-28 09:28:48,467 - INFO - Participant 1 (ID=1.0): _reward=0.99, _penalty=0.02
2025-03-28 09:28:48,473 - INFO - Participant 2 (ID=2.0): _reward=0.77, _penalty=0.46
2025-03-28 09:28:48,478 - INFO - Participant 3 (ID=3.0): _reward=0.96, _penalty=0.60
2025-03-28 09:28:48,483 - INFO - Participant 4 (ID=4.0): _reward=0.21, _penalty=0.21
2025-03-28 09:28:48,487 - INFO - Participant 5 (ID=5.0): _reward=0.07, _penalty=0.51
2025-03-28 09:28:48,492 - INFO - Participant 6 (ID=6.0): _reward=0.23, _penalty=0.60
2025-03-28 09:28:48,497 - INFO - Participant 7 (ID=7.0): _reward=0.91, _penalty=0.80
2025-03-28 09:28:48,502 - INFO - Participant 8 (ID=8.0): _reward=0.99, _penalty=0.97
2025-03-28 09:28:48,507 - INFO - Participant 9 (ID=9.0): _reward=0.67, _penalty=0.87
2025-03-28 09:28:48,512 - INFO - Participant 10 (ID=10.0): _reward=0.08, _penalty=0.77
2025-03-28 09:28:48,517 - INFO - Participant 11 (ID=11.0): _reward=0.87, _penalty=0.31
2025-03-28 09:28:48,522 - INFO - Participant 12 (ID=12.0): _reward=0.58, _penalty=0.19
2025-03-28 09:28:48,527 - INFO - Participant 13 (ID=13.0): _reward=0.48, _penalty=0.25
2025-03-28 09:28:48,532 - INFO - Participant 14 (ID=14.0): _reward=0.34, _penalty=0.83
2025-03-28 09:28:48,537 - INFO - Participant 15 (ID=15.0): _reward=0.56, _penalty=0.80
2025-03-28 09:28:48,542 - INFO - Participant 16 (ID=16.0): _reward=0.47, _penalty=0.29
2025-03-28 09:28:48,547 - INFO - Participant 17 (ID=17.0): _reward=0.77, _penalty=0.94
2025-03-28 09:28:48,552 - INFO - Participant 18 (ID=18.0): _reward=0.88, _penalty=0.01
2025-03-28 09:28:48,557 - INFO - Participant 19 (ID=19.0): _reward=0.98, _penalty=0.11
2025-03-28 09:28:48,562 - INFO - Participant 20 (ID=20.0): _reward=0.02, _penalty=0.85
2025-03-28 09:28:48,567 - INFO - Participant 21 (ID=21.0): _reward=0.46, _penalty=0.85
2025-03-28 09:28:48,571 - INFO - Participant 22 (ID=22.0): _reward=0.69, _penalty=0.43
2025-03-28 09:28:48,576 - INFO - Participant 23 (ID=23.0): _reward=0.15, _penalty=0.95
2025-03-28 09:28:48,581 - INFO - Participant 24 (ID=24.0): _reward=0.25, _penalty=0.36
2025-03-28 09:28:48,586 - INFO - Participant 25 (ID=25.0): _reward=0.75, _penalty=0.11
2025-03-28 09:28:48,591 - INFO - Participant 26 (ID=26.0): _reward=0.46, _penalty=0.81
2025-03-28 09:28:48,596 - INFO - Participant 27 (ID=27.0): _reward=0.36, _penalty=0.63
2025-03-28 09:28:48,601 - INFO - Participant 28 (ID=28.0): _reward=0.49, _penalty=0.00
2025-03-28 09:28:48,606 - INFO - Participant 29 (ID=29.0): _reward=0.20, _penalty=0.98
2025-03-28 09:28:48,611 - INFO - Participant 30 (ID=30.0): _reward=0.29, _penalty=0.64
2025-03-28 09:28:48,616 - INFO - Participant 31 (ID=31.0): _reward=0.66, _penalty=0.64
2025-03-28 09:28:48,621 - INFO - Participant 32 (ID=32.0): _reward=0.21, _penalty=0.41
2025-03-28 09:28:48,626 - INFO - Participant 33 (ID=33.0): _reward=0.49, _penalty=0.63
2025-03-28 09:28:48,631 - INFO - Participant 34 (ID=34.0): _reward=0.38, _penalty=0.08
2025-03-28 09:28:48,635 - INFO - Participant 35 (ID=35.0): _reward=0.33, _penalty=0.29
2025-03-28 09:28:48,640 - INFO - Participant 36 (ID=36.0): _reward=0.53, _penalty=0.61
2025-03-28 09:28:48,645 - INFO - Participant 37 (ID=37.0): _reward=0.65, _penalty=0.34
2025-03-28 09:28:48,650 - INFO - Participant 38 (ID=38.0): _reward=0.29, _penalty=0.13
2025-03-28 09:28:48,655 - INFO - Participant 39 (ID=39.0): _reward=0.31, _penalty=0.25
2025-03-28 09:28:48,660 - INFO - Participant 40 (ID=40.0): _reward=0.77, _penalty=0.04
2025-03-28 09:28:48,665 - INFO - Participant 41 (ID=41.0): _reward=0.23, _penalty=0.89
2025-03-28 09:28:48,670 - INFO - Participant 42 (ID=42.0): _reward=0.63, _penalty=0.60
2025-03-28 09:28:48,675 - INFO - Participant 43 (ID=43.0): _reward=0.48, _penalty=0.52
2025-03-28 09:28:48,680 - INFO - Participant 44 (ID=44.0): _reward=0.92, _penalty=0.22
2025-03-28 09:28:48,684 - INFO - Participant 45 (ID=45.0): _reward=0.52, _penalty=0.89
2025-03-28 09:28:48,690 - INFO - Participant 46 (ID=46.0): _reward=0.42, _penalty=0.83
2025-03-28 09:28:48,695 - INFO - Participant 47 (ID=47.0): _reward=0.68, _penalty=0.69
2025-03-28 09:28:48,699 - INFO - Participant 48 (ID=48.0): _reward=0.95, _penalty=0.22
2025-03-28 09:28:48,704 - INFO - Participant 49 (ID=49.0): _reward=0.13, _penalty=0.48
2025-03-28 09:28:48,709 - INFO - Participant 50 (ID=50.0): _reward=0.87, _penalty=0.85
2025-03-28 09:28:48,714 - INFO - Participant 51 (ID=51.0): _reward=0.47, _penalty=0.07
2025-03-28 09:28:48,719 - INFO - Participant 52 (ID=52.0): _reward=0.56, _penalty=0.42
2025-03-28 09:28:48,724 - INFO - Participant 53 (ID=53.0): _reward=0.53, _penalty=0.18
2025-03-28 09:28:48,729 - INFO - Participant 54 (ID=54.0): _reward=0.87, _penalty=0.73
2025-03-28 09:28:48,734 - INFO - Participant 55 (ID=55.0): _reward=0.21, _penalty=0.47
2025-03-28 09:28:48,738 - INFO - Participant 56 (ID=56.0): _reward=0.65, _penalty=0.09
2025-03-28 09:28:48,743 - INFO - Participant 57 (ID=57.0): _reward=0.72, _penalty=0.88
2025-03-28 09:28:48,748 - INFO - Participant 58 (ID=58.0): _reward=0.61, _penalty=0.38
2025-03-28 09:28:48,753 - INFO - Participant 59 (ID=59.0): _reward=0.92, _penalty=0.91
2025-03-28 09:28:48,758 - INFO - Participant 60 (ID=60.0): _reward=0.22, _penalty=0.97
2025-03-28 09:28:48,763 - INFO - Participant 61 (ID=61.0): _reward=0.41, _penalty=0.53
2025-03-28 09:28:48,768 - INFO - Participant 62 (ID=62.0): _reward=0.92, _penalty=0.99
2025-03-28 09:28:48,772 - INFO - Participant 63 (ID=63.0): _reward=0.22, _penalty=0.99
2025-03-28 09:28:48,777 - INFO - Participant 64 (ID=64.0): _reward=0.84, _penalty=0.96
2025-03-28 09:28:48,782 - INFO - Participant 65 (ID=65.0): _reward=0.55, _penalty=0.19
2025-03-28 09:28:48,787 - INFO - Participant 66 (ID=66.0): _reward=0.34, _penalty=0.07
2025-03-28 09:28:48,792 - INFO - Participant 67 (ID=67.0): _reward=0.62, _penalty=0.45
2025-03-28 09:28:48,797 - INFO - Participant 68 (ID=68.0): _reward=0.47, _penalty=0.19
2025-03-28 09:28:48,802 - INFO - Participant 69 (ID=69.0): _reward=0.81, _penalty=0.36
2025-03-28 09:28:48,806 - INFO - Participant 70 (ID=70.0): _reward=0.73, _penalty=0.87
2025-03-28 09:28:48,811 - INFO - Participant 71 (ID=71.0): _reward=0.10, _penalty=0.57
2025-03-28 09:28:48,816 - INFO - Participant 72 (ID=72.0): _reward=0.78, _penalty=0.50
2025-03-28 09:28:48,821 - INFO - Participant 73 (ID=73.0): _reward=0.82, _penalty=0.70
2025-03-28 09:28:48,826 - INFO - Participant 74 (ID=74.0): _reward=0.00, _penalty=0.98
2025-03-28 09:28:48,831 - INFO - Participant 75 (ID=75.0): _reward=0.42, _penalty=0.26
2025-03-28 09:28:48,836 - INFO - Participant 76 (ID=76.0): _reward=0.83, _penalty=0.39
2025-03-28 09:28:48,840 - INFO - Participant 77 (ID=77.0): _reward=0.75, _penalty=0.18
2025-03-28 09:28:48,845 - INFO - Participant 78 (ID=78.0): _reward=0.97, _penalty=0.44
2025-03-28 09:28:48,850 - INFO - Participant 79 (ID=79.0): _reward=0.45, _penalty=0.57
2025-03-28 09:28:48,855 - INFO - Participant 80 (ID=80.0): _reward=0.63, _penalty=0.78
2025-03-28 09:28:48,860 - INFO - Participant 81 (ID=81.0): _reward=0.29, _penalty=0.24
2025-03-28 09:28:48,865 - INFO - Participant 82 (ID=82.0): _reward=0.71, _penalty=0.15
2025-03-28 09:28:48,870 - INFO - Participant 83 (ID=83.0): _reward=0.71, _penalty=0.66
2025-03-28 09:28:48,874 - INFO - Participant 84 (ID=84.0): _reward=0.97, _penalty=0.79
2025-03-28 09:28:48,880 - INFO - Participant 85 (ID=85.0): _reward=1.00, _penalty=0.95
2025-03-28 09:28:48,884 - INFO - Participant 86 (ID=86.0): _reward=0.56, _penalty=0.08
2025-03-28 09:28:48,889 - INFO - Participant 87 (ID=87.0): _reward=0.59, _penalty=0.83
2025-03-28 09:28:48,894 - INFO - Participant 88 (ID=88.0): _reward=0.32, _penalty=0.60
2025-03-28 09:28:48,899 - INFO - Participant 89 (ID=89.0): _reward=0.20, _penalty=0.84
2025-03-28 09:28:48,904 - INFO - Participant 90 (ID=90.0): _reward=0.34, _penalty=1.00
2025-03-28 09:28:48,909 - INFO - Participant 91 (ID=91.0): _reward=0.19, _penalty=0.99
2025-03-28 09:28:48,914 - INFO - Participant 92 (ID=92.0): _reward=0.20, _penalty=0.91
2025-03-28 09:28:48,919 - INFO - Participant 93 (ID=93.0): _reward=0.31, _penalty=0.21
2025-03-28 09:28:48,924 - INFO - Participant 94 (ID=94.0): _reward=0.58, _penalty=0.41
2025-03-28 09:28:48,935 - INFO - Participant 95 (ID=95.0): _reward=0.80, _penalty=0.54
2025-03-28 09:28:48,952 - INFO - Participant 96 (ID=96.0): _reward=0.74, _penalty=0.80
2025-03-28 09:28:48,969 - INFO - Participant 97 (ID=97.0): _reward=0.59, _penalty=0.16
2025-03-28 09:28:48,975 - INFO - Participant 98 (ID=98.0): _reward=0.54, _penalty=0.17
2025-03-28 09:28:48,980 - INFO - Participant 99 (ID=99.0): _reward=0.17, _penalty=0.16
2025-03-28 09:28:48,984 - INFO - Participant 100 (ID=100.0): _reward=0.79, _penalty=0.40
2025-03-28 09:28:48,989 - INFO - Participant 101 (ID=101.0): _reward=0.32, _penalty=0.05
2025-03-28 09:28:48,996 - INFO - Participant 102 (ID=102.0): _reward=0.87, _penalty=0.81
2025-03-28 09:28:49,000 - INFO - Participant 103 (ID=103.0): _reward=0.90, _penalty=0.11
2025-03-28 09:28:49,005 - INFO - Participant 104 (ID=104.0): _reward=0.44, _penalty=0.12
2025-03-28 09:28:49,012 - INFO - Participant 105 (ID=105.0): _reward=0.59, _penalty=0.50
2025-03-28 09:28:49,016 - INFO - Participant 106 (ID=106.0): _reward=0.84, _penalty=0.50
2025-03-28 09:28:49,022 - INFO - Participant 107 (ID=107.0): _reward=0.48, _penalty=0.54
2025-03-28 09:28:49,027 - INFO - Participant 108 (ID=108.0): _reward=0.56, _penalty=0.75
2025-03-28 09:28:49,032 - INFO - Participant 109 (ID=109.0): _reward=0.53, _penalty=0.11
2025-03-28 09:28:49,036 - INFO - Participant 110 (ID=110.0): _reward=0.52, _penalty=0.40
2025-03-28 09:28:49,041 - INFO - Participant 111 (ID=111.0): _reward=0.61, _penalty=0.74
2025-03-28 09:28:49,046 - INFO - Participant 112 (ID=112.0): _reward=0.64, _penalty=0.56
2025-03-28 09:28:49,050 - INFO - Participant 113 (ID=113.0): _reward=0.44, _penalty=0.40
2025-03-28 09:28:49,055 - INFO - Participant 114 (ID=114.0): _reward=0.74, _penalty=0.91
2025-03-28 09:28:49,061 - INFO - Participant 115 (ID=115.0): _reward=0.09, _penalty=0.27
2025-03-28 09:28:49,065 - INFO - Participant 116 (ID=116.0): _reward=0.99, _penalty=0.92
2025-03-28 09:28:49,070 - INFO - Participant 117 (ID=117.0): _reward=0.90, _penalty=0.87
2025-03-28 09:28:49,075 - INFO - Participant 118 (ID=118.0): _reward=0.21, _penalty=0.27
2025-03-28 09:28:49,080 - INFO - Participant 119 (ID=119.0): _reward=0.71, _penalty=0.69
2025-03-28 09:28:49,084 - INFO - Participant 120 (ID=120.0): _reward=0.43, _penalty=0.05
2025-03-28 09:28:49,090 - INFO - Participant 121 (ID=121.0): _reward=0.11, _penalty=0.27
2025-03-28 09:28:49,095 - INFO - Participant 122 (ID=122.0): _reward=0.80, _penalty=0.43
2025-03-28 09:28:49,100 - INFO - Participant 123 (ID=123.0): _reward=0.74, _penalty=0.44
2025-03-28 09:28:49,105 - INFO - Participant 124 (ID=124.0): _reward=0.18, _penalty=0.36
2025-03-28 09:28:49,110 - INFO - Participant 125 (ID=125.0): _reward=0.86, _penalty=0.09
2025-03-28 09:28:49,115 - INFO - Participant 126 (ID=126.0): _reward=0.05, _penalty=0.52
2025-03-28 09:28:49,119 - INFO - Participant 127 (ID=127.0): _reward=0.41, _penalty=0.26
2025-03-28 09:28:49,120 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 32 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 33 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 34 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 35 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 36 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 37 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 38 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 39 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 40 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 41 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 42 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 43 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 44 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 45 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 46 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 47 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 48 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 49 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 50 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 51 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 52 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 53 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 54 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 55 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 56 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 57 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 58 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 59 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 60 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 61 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 62 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 63 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 64 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 65 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 66 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 67 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 68 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 69 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 70 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 71 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 72 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 73 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,120 - INFO - Participant 74 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 75 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 76 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 77 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 78 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 79 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 80 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 81 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 82 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 83 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 84 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 85 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 86 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 87 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 88 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 89 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 90 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 91 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 92 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 93 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 94 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 95 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 96 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 97 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 98 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 99 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 100 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 101 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 102 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 103 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 104 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 105 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 106 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 107 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 108 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 109 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 110 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 111 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 112 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 113 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 114 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 115 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 116 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 117 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 118 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 119 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 120 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 121 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 122 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 123 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 124 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 125 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 126 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,121 - INFO - Participant 127 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:28:49,122 - INFO - Combined xs shape after concatenation: torch.Size([128, 200, 5])
2025-03-28 09:28:49,122 - INFO - Combined ys shape after concatenation: torch.Size([128, 200, 2])
2025-03-28 09:28:49,122 - INFO - Combined dataset shape: X=torch.Size([128, 200, 5]), Y=torch.Size([128, 200, 2])
2025-03-28 09:28:49,122 - INFO - Total unique participants: 128
2025-03-28 09:28:49,122 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-28 09:28:49,123 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,123 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,123 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,123 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,123 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,123 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,123 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,123 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,123 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,123 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,123 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,124 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,125 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,125 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,125 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,125 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,125 - INFO - Participant 32.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,125 - INFO - Participant 33.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,125 - INFO - Participant 34.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,125 - INFO - Participant 35.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,125 - INFO - Participant 36.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,125 - INFO - Participant 37.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,125 - INFO - Participant 38.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,125 - INFO - Participant 39.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,125 - INFO - Participant 40.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 41.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 42.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 43.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 44.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 45.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 46.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 47.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 48.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 49.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 50.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 51.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 52.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 53.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 54.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 55.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 56.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 57.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 58.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 59.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,126 - INFO - Participant 60.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 61.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 62.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 63.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 64.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 65.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 66.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 67.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 68.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 69.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 70.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 71.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 72.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 73.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 74.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 75.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 76.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 77.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 78.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 79.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 80.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 81.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 82.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 83.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,127 - INFO - Participant 84.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 85.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 86.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 87.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 88.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 89.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 90.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 91.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 92.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 93.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 94.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 95.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 96.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 97.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 98.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 99.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 100.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 101.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 102.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 103.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 104.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 105.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 106.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 107.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 108.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 109.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 110.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 111.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,128 - INFO - Participant 112.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 113.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 114.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 115.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 116.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 117.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 118.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 119.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 120.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 121.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 122.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 123.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 124.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 125.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 126.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Participant 127.0: 140 trials for training, 60 trials for validation
2025-03-28 09:28:49,129 - INFO - Train xs shape: torch.Size([128, 140, 5])
2025-03-28 09:28:49,129 - INFO - Train ys shape: torch.Size([128, 140, 2])
2025-03-28 09:28:49,129 - INFO - Validation xs shape: torch.Size([128, 60, 5])
2025-03-28 09:28:49,129 - INFO - Validation ys shape: torch.Size([128, 60, 2])
2025-03-28 09:28:49,129 - INFO - Train dataset: torch.Size([128, 140, 5]), Validation dataset: torch.Size([128, 60, 5])
2025-03-28 09:28:49,130 - INFO - Starting hyperparameter optimization...
2025-03-28 09:28:49,130 - INFO - Trial 0: lr=0.002190, embedding_size=28, n_steps=49
2025-03-28 09:28:49,847 - INFO - Trial 0: RNN Train Loss: 0.7409798
2025-03-28 09:28:49,848 - INFO - Trial 0: Validation set has 128 participants
2025-03-28 09:28:55,171 - INFO - Trial 0: Average Validation Loss: 0.7254, Eval count: 128
2025-03-28 09:28:55,171 - INFO - Best hyperparameters: {'learning_rate': 0.0021901016842206093, 'embedding_size': 28, 'n_steps': 49}
2025-03-28 09:28:55,171 - INFO - Best validation loss: 0.7254
2025-03-28 09:29:27,934 - INFO - ================================================================================
2025-03-28 09:29:27,935 - INFO - EXPERIMENT CONFIG
2025-03-28 09:29:27,935 - INFO - ================================================================================
2025-03-28 09:29:27,935 - INFO - Found 1 data files: ['data_128p_0.csv']
2025-03-28 09:29:27,935 - INFO - Processing dataset: data_128p_0.csv
2025-03-28 09:29:27,935 - INFO - Loading dataset from data/optuna/data_128p_0.csv
2025-03-28 09:29:27,970 - INFO - Number of participants: 128
2025-03-28 09:29:27,975 - INFO - Participant 0 (ID=0.0): _reward=0.74, _penalty=0.97
2025-03-28 09:29:27,981 - INFO - Participant 1 (ID=1.0): _reward=0.99, _penalty=0.02
2025-03-28 09:29:27,987 - INFO - Participant 2 (ID=2.0): _reward=0.77, _penalty=0.46
2025-03-28 09:29:27,992 - INFO - Participant 3 (ID=3.0): _reward=0.96, _penalty=0.60
2025-03-28 09:29:27,998 - INFO - Participant 4 (ID=4.0): _reward=0.21, _penalty=0.21
2025-03-28 09:29:28,003 - INFO - Participant 5 (ID=5.0): _reward=0.07, _penalty=0.51
2025-03-28 09:29:28,009 - INFO - Participant 6 (ID=6.0): _reward=0.23, _penalty=0.60
2025-03-28 09:29:28,015 - INFO - Participant 7 (ID=7.0): _reward=0.91, _penalty=0.80
2025-03-28 09:29:28,020 - INFO - Participant 8 (ID=8.0): _reward=0.99, _penalty=0.97
2025-03-28 09:29:28,026 - INFO - Participant 9 (ID=9.0): _reward=0.67, _penalty=0.87
2025-03-28 09:29:28,031 - INFO - Participant 10 (ID=10.0): _reward=0.08, _penalty=0.77
2025-03-28 09:29:28,037 - INFO - Participant 11 (ID=11.0): _reward=0.87, _penalty=0.31
2025-03-28 09:29:28,042 - INFO - Participant 12 (ID=12.0): _reward=0.58, _penalty=0.19
2025-03-28 09:29:28,048 - INFO - Participant 13 (ID=13.0): _reward=0.48, _penalty=0.25
2025-03-28 09:29:28,053 - INFO - Participant 14 (ID=14.0): _reward=0.34, _penalty=0.83
2025-03-28 09:29:28,059 - INFO - Participant 15 (ID=15.0): _reward=0.56, _penalty=0.80
2025-03-28 09:29:28,064 - INFO - Participant 16 (ID=16.0): _reward=0.47, _penalty=0.29
2025-03-28 09:29:28,070 - INFO - Participant 17 (ID=17.0): _reward=0.77, _penalty=0.94
2025-03-28 09:29:28,075 - INFO - Participant 18 (ID=18.0): _reward=0.88, _penalty=0.01
2025-03-28 09:29:28,081 - INFO - Participant 19 (ID=19.0): _reward=0.98, _penalty=0.11
2025-03-28 09:29:28,086 - INFO - Participant 20 (ID=20.0): _reward=0.02, _penalty=0.85
2025-03-28 09:29:28,092 - INFO - Participant 21 (ID=21.0): _reward=0.46, _penalty=0.85
2025-03-28 09:29:28,097 - INFO - Participant 22 (ID=22.0): _reward=0.69, _penalty=0.43
2025-03-28 09:29:28,103 - INFO - Participant 23 (ID=23.0): _reward=0.15, _penalty=0.95
2025-03-28 09:29:28,108 - INFO - Participant 24 (ID=24.0): _reward=0.25, _penalty=0.36
2025-03-28 09:29:28,113 - INFO - Participant 25 (ID=25.0): _reward=0.75, _penalty=0.11
2025-03-28 09:29:28,119 - INFO - Participant 26 (ID=26.0): _reward=0.46, _penalty=0.81
2025-03-28 09:29:28,124 - INFO - Participant 27 (ID=27.0): _reward=0.36, _penalty=0.63
2025-03-28 09:29:28,130 - INFO - Participant 28 (ID=28.0): _reward=0.49, _penalty=0.00
2025-03-28 09:29:28,135 - INFO - Participant 29 (ID=29.0): _reward=0.20, _penalty=0.98
2025-03-28 09:29:28,141 - INFO - Participant 30 (ID=30.0): _reward=0.29, _penalty=0.64
2025-03-28 09:29:28,146 - INFO - Participant 31 (ID=31.0): _reward=0.66, _penalty=0.64
2025-03-28 09:29:28,152 - INFO - Participant 32 (ID=32.0): _reward=0.21, _penalty=0.41
2025-03-28 09:29:28,157 - INFO - Participant 33 (ID=33.0): _reward=0.49, _penalty=0.63
2025-03-28 09:29:28,162 - INFO - Participant 34 (ID=34.0): _reward=0.38, _penalty=0.08
2025-03-28 09:29:28,168 - INFO - Participant 35 (ID=35.0): _reward=0.33, _penalty=0.29
2025-03-28 09:29:28,173 - INFO - Participant 36 (ID=36.0): _reward=0.53, _penalty=0.61
2025-03-28 09:29:28,178 - INFO - Participant 37 (ID=37.0): _reward=0.65, _penalty=0.34
2025-03-28 09:29:28,184 - INFO - Participant 38 (ID=38.0): _reward=0.29, _penalty=0.13
2025-03-28 09:29:28,189 - INFO - Participant 39 (ID=39.0): _reward=0.31, _penalty=0.25
2025-03-28 09:29:28,195 - INFO - Participant 40 (ID=40.0): _reward=0.77, _penalty=0.04
2025-03-28 09:29:28,200 - INFO - Participant 41 (ID=41.0): _reward=0.23, _penalty=0.89
2025-03-28 09:29:28,206 - INFO - Participant 42 (ID=42.0): _reward=0.63, _penalty=0.60
2025-03-28 09:29:28,211 - INFO - Participant 43 (ID=43.0): _reward=0.48, _penalty=0.52
2025-03-28 09:29:28,217 - INFO - Participant 44 (ID=44.0): _reward=0.92, _penalty=0.22
2025-03-28 09:29:28,222 - INFO - Participant 45 (ID=45.0): _reward=0.52, _penalty=0.89
2025-03-28 09:29:28,227 - INFO - Participant 46 (ID=46.0): _reward=0.42, _penalty=0.83
2025-03-28 09:29:28,233 - INFO - Participant 47 (ID=47.0): _reward=0.68, _penalty=0.69
2025-03-28 09:29:28,238 - INFO - Participant 48 (ID=48.0): _reward=0.95, _penalty=0.22
2025-03-28 09:29:28,244 - INFO - Participant 49 (ID=49.0): _reward=0.13, _penalty=0.48
2025-03-28 09:29:28,249 - INFO - Participant 50 (ID=50.0): _reward=0.87, _penalty=0.85
2025-03-28 09:29:28,255 - INFO - Participant 51 (ID=51.0): _reward=0.47, _penalty=0.07
2025-03-28 09:29:28,260 - INFO - Participant 52 (ID=52.0): _reward=0.56, _penalty=0.42
2025-03-28 09:29:28,266 - INFO - Participant 53 (ID=53.0): _reward=0.53, _penalty=0.18
2025-03-28 09:29:28,271 - INFO - Participant 54 (ID=54.0): _reward=0.87, _penalty=0.73
2025-03-28 09:29:28,277 - INFO - Participant 55 (ID=55.0): _reward=0.21, _penalty=0.47
2025-03-28 09:29:28,282 - INFO - Participant 56 (ID=56.0): _reward=0.65, _penalty=0.09
2025-03-28 09:29:28,288 - INFO - Participant 57 (ID=57.0): _reward=0.72, _penalty=0.88
2025-03-28 09:29:28,293 - INFO - Participant 58 (ID=58.0): _reward=0.61, _penalty=0.38
2025-03-28 09:29:28,298 - INFO - Participant 59 (ID=59.0): _reward=0.92, _penalty=0.91
2025-03-28 09:29:28,304 - INFO - Participant 60 (ID=60.0): _reward=0.22, _penalty=0.97
2025-03-28 09:29:28,309 - INFO - Participant 61 (ID=61.0): _reward=0.41, _penalty=0.53
2025-03-28 09:29:28,315 - INFO - Participant 62 (ID=62.0): _reward=0.92, _penalty=0.99
2025-03-28 09:29:28,320 - INFO - Participant 63 (ID=63.0): _reward=0.22, _penalty=0.99
2025-03-28 09:29:28,326 - INFO - Participant 64 (ID=64.0): _reward=0.84, _penalty=0.96
2025-03-28 09:29:28,331 - INFO - Participant 65 (ID=65.0): _reward=0.55, _penalty=0.19
2025-03-28 09:29:28,337 - INFO - Participant 66 (ID=66.0): _reward=0.34, _penalty=0.07
2025-03-28 09:29:28,342 - INFO - Participant 67 (ID=67.0): _reward=0.62, _penalty=0.45
2025-03-28 09:29:28,348 - INFO - Participant 68 (ID=68.0): _reward=0.47, _penalty=0.19
2025-03-28 09:29:28,353 - INFO - Participant 69 (ID=69.0): _reward=0.81, _penalty=0.36
2025-03-28 09:29:28,359 - INFO - Participant 70 (ID=70.0): _reward=0.73, _penalty=0.87
2025-03-28 09:29:28,364 - INFO - Participant 71 (ID=71.0): _reward=0.10, _penalty=0.57
2025-03-28 09:29:28,369 - INFO - Participant 72 (ID=72.0): _reward=0.78, _penalty=0.50
2025-03-28 09:29:28,375 - INFO - Participant 73 (ID=73.0): _reward=0.82, _penalty=0.70
2025-03-28 09:29:28,380 - INFO - Participant 74 (ID=74.0): _reward=0.00, _penalty=0.98
2025-03-28 09:29:28,385 - INFO - Participant 75 (ID=75.0): _reward=0.42, _penalty=0.26
2025-03-28 09:29:28,391 - INFO - Participant 76 (ID=76.0): _reward=0.83, _penalty=0.39
2025-03-28 09:29:28,396 - INFO - Participant 77 (ID=77.0): _reward=0.75, _penalty=0.18
2025-03-28 09:29:28,402 - INFO - Participant 78 (ID=78.0): _reward=0.97, _penalty=0.44
2025-03-28 09:29:28,407 - INFO - Participant 79 (ID=79.0): _reward=0.45, _penalty=0.57
2025-03-28 09:29:28,413 - INFO - Participant 80 (ID=80.0): _reward=0.63, _penalty=0.78
2025-03-28 09:29:28,418 - INFO - Participant 81 (ID=81.0): _reward=0.29, _penalty=0.24
2025-03-28 09:29:28,424 - INFO - Participant 82 (ID=82.0): _reward=0.71, _penalty=0.15
2025-03-28 09:29:28,429 - INFO - Participant 83 (ID=83.0): _reward=0.71, _penalty=0.66
2025-03-28 09:29:28,434 - INFO - Participant 84 (ID=84.0): _reward=0.97, _penalty=0.79
2025-03-28 09:29:28,440 - INFO - Participant 85 (ID=85.0): _reward=1.00, _penalty=0.95
2025-03-28 09:29:28,445 - INFO - Participant 86 (ID=86.0): _reward=0.56, _penalty=0.08
2025-03-28 09:29:28,451 - INFO - Participant 87 (ID=87.0): _reward=0.59, _penalty=0.83
2025-03-28 09:29:28,456 - INFO - Participant 88 (ID=88.0): _reward=0.32, _penalty=0.60
2025-03-28 09:29:28,462 - INFO - Participant 89 (ID=89.0): _reward=0.20, _penalty=0.84
2025-03-28 09:29:28,467 - INFO - Participant 90 (ID=90.0): _reward=0.34, _penalty=1.00
2025-03-28 09:29:28,473 - INFO - Participant 91 (ID=91.0): _reward=0.19, _penalty=0.99
2025-03-28 09:29:28,478 - INFO - Participant 92 (ID=92.0): _reward=0.20, _penalty=0.91
2025-03-28 09:29:28,484 - INFO - Participant 93 (ID=93.0): _reward=0.31, _penalty=0.21
2025-03-28 09:29:28,489 - INFO - Participant 94 (ID=94.0): _reward=0.58, _penalty=0.41
2025-03-28 09:29:28,495 - INFO - Participant 95 (ID=95.0): _reward=0.80, _penalty=0.54
2025-03-28 09:29:28,501 - INFO - Participant 96 (ID=96.0): _reward=0.74, _penalty=0.80
2025-03-28 09:29:28,507 - INFO - Participant 97 (ID=97.0): _reward=0.59, _penalty=0.16
2025-03-28 09:29:28,513 - INFO - Participant 98 (ID=98.0): _reward=0.54, _penalty=0.17
2025-03-28 09:29:28,519 - INFO - Participant 99 (ID=99.0): _reward=0.17, _penalty=0.16
2025-03-28 09:29:28,525 - INFO - Participant 100 (ID=100.0): _reward=0.79, _penalty=0.40
2025-03-28 09:29:28,531 - INFO - Participant 101 (ID=101.0): _reward=0.32, _penalty=0.05
2025-03-28 09:29:28,537 - INFO - Participant 102 (ID=102.0): _reward=0.87, _penalty=0.81
2025-03-28 09:29:28,542 - INFO - Participant 103 (ID=103.0): _reward=0.90, _penalty=0.11
2025-03-28 09:29:28,548 - INFO - Participant 104 (ID=104.0): _reward=0.44, _penalty=0.12
2025-03-28 09:29:28,554 - INFO - Participant 105 (ID=105.0): _reward=0.59, _penalty=0.50
2025-03-28 09:29:28,559 - INFO - Participant 106 (ID=106.0): _reward=0.84, _penalty=0.50
2025-03-28 09:29:28,565 - INFO - Participant 107 (ID=107.0): _reward=0.48, _penalty=0.54
2025-03-28 09:29:28,570 - INFO - Participant 108 (ID=108.0): _reward=0.56, _penalty=0.75
2025-03-28 09:29:28,576 - INFO - Participant 109 (ID=109.0): _reward=0.53, _penalty=0.11
2025-03-28 09:29:28,581 - INFO - Participant 110 (ID=110.0): _reward=0.52, _penalty=0.40
2025-03-28 09:29:28,587 - INFO - Participant 111 (ID=111.0): _reward=0.61, _penalty=0.74
2025-03-28 09:29:28,592 - INFO - Participant 112 (ID=112.0): _reward=0.64, _penalty=0.56
2025-03-28 09:29:28,598 - INFO - Participant 113 (ID=113.0): _reward=0.44, _penalty=0.40
2025-03-28 09:29:28,603 - INFO - Participant 114 (ID=114.0): _reward=0.74, _penalty=0.91
2025-03-28 09:29:28,609 - INFO - Participant 115 (ID=115.0): _reward=0.09, _penalty=0.27
2025-03-28 09:29:28,614 - INFO - Participant 116 (ID=116.0): _reward=0.99, _penalty=0.92
2025-03-28 09:29:28,619 - INFO - Participant 117 (ID=117.0): _reward=0.90, _penalty=0.87
2025-03-28 09:29:28,625 - INFO - Participant 118 (ID=118.0): _reward=0.21, _penalty=0.27
2025-03-28 09:29:28,630 - INFO - Participant 119 (ID=119.0): _reward=0.71, _penalty=0.69
2025-03-28 09:29:28,636 - INFO - Participant 120 (ID=120.0): _reward=0.43, _penalty=0.05
2025-03-28 09:29:28,641 - INFO - Participant 121 (ID=121.0): _reward=0.11, _penalty=0.27
2025-03-28 09:29:28,647 - INFO - Participant 122 (ID=122.0): _reward=0.80, _penalty=0.43
2025-03-28 09:29:28,652 - INFO - Participant 123 (ID=123.0): _reward=0.74, _penalty=0.44
2025-03-28 09:29:28,657 - INFO - Participant 124 (ID=124.0): _reward=0.18, _penalty=0.36
2025-03-28 09:29:28,663 - INFO - Participant 125 (ID=125.0): _reward=0.86, _penalty=0.09
2025-03-28 09:29:28,668 - INFO - Participant 126 (ID=126.0): _reward=0.05, _penalty=0.52
2025-03-28 09:29:28,674 - INFO - Participant 127 (ID=127.0): _reward=0.41, _penalty=0.26
2025-03-28 09:29:28,674 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 32 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 33 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 34 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 35 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 36 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 37 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 38 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 39 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 40 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 41 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 42 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 43 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 44 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 45 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,674 - INFO - Participant 46 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 47 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 48 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 49 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 50 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 51 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 52 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 53 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 54 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 55 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 56 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 57 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 58 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 59 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 60 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 61 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 62 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 63 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 64 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 65 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 66 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 67 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 68 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 69 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 70 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 71 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 72 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 73 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 74 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 75 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 76 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 77 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 78 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 79 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 80 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 81 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 82 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 83 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 84 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 85 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 86 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 87 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 88 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 89 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 90 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 91 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 92 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 93 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 94 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 95 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 96 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 97 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 98 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 99 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 100 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 101 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 102 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 103 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 104 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 105 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 106 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 107 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 108 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 109 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 110 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 111 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 112 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 113 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 114 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 115 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 116 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 117 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 118 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 119 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 120 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,675 - INFO - Participant 121 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,676 - INFO - Participant 122 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,676 - INFO - Participant 123 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,676 - INFO - Participant 124 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,676 - INFO - Participant 125 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,676 - INFO - Participant 126 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,676 - INFO - Participant 127 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:29:28,676 - INFO - Combined xs shape after concatenation: torch.Size([128, 200, 5])
2025-03-28 09:29:28,676 - INFO - Combined ys shape after concatenation: torch.Size([128, 200, 2])
2025-03-28 09:29:28,676 - INFO - Combined dataset shape: X=torch.Size([128, 200, 5]), Y=torch.Size([128, 200, 2])
2025-03-28 09:29:28,676 - INFO - Total unique participants: 128
2025-03-28 09:29:28,676 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-28 09:29:28,676 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,677 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 32.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 33.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 34.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 35.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 36.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 37.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 38.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 39.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 40.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 41.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 42.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 43.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,678 - INFO - Participant 44.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 45.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 46.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 47.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 48.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 49.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 50.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 51.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 52.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 53.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 54.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 55.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 56.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 57.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 58.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 59.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 60.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 61.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 62.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 63.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 64.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 65.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,679 - INFO - Participant 66.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 67.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 68.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 69.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 70.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 71.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 72.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 73.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 74.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 75.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 76.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 77.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 78.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 79.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 80.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 81.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 82.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 83.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 84.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 85.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 86.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 87.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 88.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,680 - INFO - Participant 89.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 90.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 91.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 92.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 93.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 94.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 95.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 96.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 97.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 98.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 99.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 100.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 101.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 102.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 103.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 104.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 105.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 106.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 107.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 108.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 109.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 110.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,681 - INFO - Participant 111.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 112.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 113.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 114.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 115.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 116.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 117.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 118.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 119.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 120.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 121.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 122.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 123.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 124.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 125.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 126.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,682 - INFO - Participant 127.0: 140 trials for training, 60 trials for validation
2025-03-28 09:29:28,683 - INFO - Train xs shape: torch.Size([128, 140, 5])
2025-03-28 09:29:28,683 - INFO - Train ys shape: torch.Size([128, 140, 2])
2025-03-28 09:29:28,683 - INFO - Validation xs shape: torch.Size([128, 60, 5])
2025-03-28 09:29:28,683 - INFO - Validation ys shape: torch.Size([128, 60, 2])
2025-03-28 09:29:28,683 - INFO - Train dataset: torch.Size([128, 140, 5]), Validation dataset: torch.Size([128, 60, 5])
2025-03-28 09:29:28,683 - INFO - Starting hyperparameter optimization...
2025-03-28 09:29:28,684 - INFO - Trial 0: lr=0.002153, embedding_size=25, n_steps=28
2025-03-28 09:29:29,415 - INFO - Trial 0: RNN Train Loss: 0.6156288
2025-03-28 09:29:29,416 - INFO - Trial 0: Validation set has 128 participants
2025-03-28 09:29:35,113 - INFO - Trial 0: Average Validation Loss: 0.6491, Eval count: 128
2025-03-28 09:29:35,114 - INFO - Best hyperparameters: {'learning_rate': 0.0021533651630079986, 'embedding_size': 25, 'n_steps': 28}
2025-03-28 09:29:35,114 - INFO - Best validation loss: 0.6491
2025-03-28 09:29:35,418 - INFO - Final RNN training loss: 0.8406710
2025-03-28 09:29:35,418 - INFO - Evaluating with SINDy - fitting separate models for each participant's validation trials
2025-03-28 09:29:35,418 - INFO - Processing participant 0.0...
2025-03-28 09:29:35,419 - INFO - Fitting SINDy model for participant 0.0
2025-03-28 09:29:36,996 - INFO - Participant 0.0: LL=-0.6868, BIC=1.8512, Params=7, Val trials=60
2025-03-28 09:29:36,996 - INFO - Processing participant 1.0...
2025-03-28 09:29:36,996 - INFO - Fitting SINDy model for participant 1.0
2025-03-28 09:29:38,538 - INFO - Participant 1.0: LL=-2.8129, BIC=6.1717, Params=8, Val trials=60
2025-03-28 09:29:38,538 - INFO - Processing participant 2.0...
2025-03-28 09:29:38,539 - INFO - Fitting SINDy model for participant 2.0
2025-03-28 09:29:40,051 - INFO - Participant 2.0: LL=-0.7063, BIC=1.8902, Params=7, Val trials=60
2025-03-28 09:29:40,051 - INFO - Processing participant 3.0...
2025-03-28 09:29:40,052 - INFO - Fitting SINDy model for participant 3.0
2025-03-28 09:29:41,429 - INFO - Participant 3.0: LL=-0.7957, BIC=2.1373, Params=8, Val trials=60
2025-03-28 09:29:41,429 - INFO - Processing participant 4.0...
2025-03-28 09:29:41,430 - INFO - Fitting SINDy model for participant 4.0
2025-03-28 09:29:42,963 - INFO - Participant 4.0: LL=-0.9018, BIC=2.2813, Params=7, Val trials=60
2025-03-28 09:29:42,963 - INFO - Processing participant 5.0...
2025-03-28 09:29:42,963 - INFO - Fitting SINDy model for participant 5.0
2025-03-28 09:29:44,452 - INFO - Participant 5.0: LL=-0.7938, BIC=2.1335, Params=8, Val trials=60
2025-03-28 09:29:44,452 - INFO - Processing participant 6.0...
2025-03-28 09:29:44,453 - INFO - Fitting SINDy model for participant 6.0
2025-03-28 09:29:45,937 - INFO - Participant 6.0: LL=-0.6931, BIC=1.9322, Params=8, Val trials=60
2025-03-28 09:29:45,937 - INFO - Processing participant 7.0...
2025-03-28 09:29:45,938 - INFO - Fitting SINDy model for participant 7.0
2025-03-28 09:29:47,452 - INFO - Participant 7.0: LL=-0.8300, BIC=2.2059, Params=8, Val trials=60
2025-03-28 09:29:47,452 - INFO - Processing participant 8.0...
2025-03-28 09:29:47,453 - INFO - Fitting SINDy model for participant 8.0
2025-03-28 09:29:49,075 - INFO - Participant 8.0: LL=-0.8033, BIC=2.0843, Params=7, Val trials=60
2025-03-28 09:29:49,075 - INFO - Processing participant 9.0...
2025-03-28 09:29:49,076 - INFO - Fitting SINDy model for participant 9.0
2025-03-28 09:29:50,709 - INFO - Participant 9.0: LL=-0.7077, BIC=1.9614, Params=8, Val trials=60
2025-03-28 09:29:50,709 - INFO - Processing participant 10.0...
2025-03-28 09:29:50,710 - INFO - Fitting SINDy model for participant 10.0
2025-03-28 09:29:52,211 - INFO - Participant 10.0: LL=-0.4906, BIC=1.5272, Params=8, Val trials=60
2025-03-28 09:29:52,211 - INFO - Processing participant 11.0...
2025-03-28 09:29:52,212 - INFO - Fitting SINDy model for participant 11.0
2025-03-28 09:29:53,707 - INFO - Participant 11.0: LL=-0.5970, BIC=1.8081, Params=9, Val trials=60
2025-03-28 09:29:53,707 - INFO - Processing participant 12.0...
2025-03-28 09:29:53,708 - INFO - Fitting SINDy model for participant 12.0
2025-03-28 09:29:55,225 - INFO - Participant 12.0: LL=-0.7891, BIC=2.1242, Params=8, Val trials=60
2025-03-28 09:29:55,225 - INFO - Processing participant 13.0...
2025-03-28 09:29:55,226 - INFO - Fitting SINDy model for participant 13.0
2025-03-28 09:29:56,710 - INFO - Participant 13.0: LL=-0.7057, BIC=1.9574, Params=8, Val trials=60
2025-03-28 09:29:56,710 - INFO - Processing participant 14.0...
2025-03-28 09:29:56,711 - INFO - Fitting SINDy model for participant 14.0
2025-03-28 09:29:58,249 - INFO - Participant 14.0: LL=-0.6919, BIC=1.8616, Params=7, Val trials=60
2025-03-28 09:29:58,249 - INFO - Processing participant 15.0...
2025-03-28 09:29:58,250 - INFO - Fitting SINDy model for participant 15.0
2025-03-28 09:29:59,775 - INFO - Participant 15.0: LL=-0.8695, BIC=2.2166, Params=7, Val trials=60
2025-03-28 09:29:59,776 - INFO - Processing participant 16.0...
2025-03-28 09:29:59,776 - INFO - Fitting SINDy model for participant 16.0
2025-03-28 09:30:01,346 - INFO - Participant 16.0: LL=-0.6931, BIC=1.8640, Params=7, Val trials=60
2025-03-28 09:30:01,346 - INFO - Processing participant 17.0...
2025-03-28 09:30:01,347 - INFO - Fitting SINDy model for participant 17.0
2025-03-28 09:30:02,888 - INFO - Participant 17.0: LL=-0.6931, BIC=1.8640, Params=7, Val trials=60
2025-03-28 09:30:02,888 - INFO - Processing participant 18.0...
2025-03-28 09:30:02,889 - INFO - Fitting SINDy model for participant 18.0
2025-03-28 09:30:04,426 - INFO - Participant 18.0: LL=-0.7097, BIC=1.8972, Params=7, Val trials=60
2025-03-28 09:30:04,426 - INFO - Processing participant 19.0...
2025-03-28 09:30:04,426 - INFO - Fitting SINDy model for participant 19.0
2025-03-28 09:30:05,962 - INFO - Participant 19.0: LL=-0.6051, BIC=1.7561, Params=8, Val trials=60
2025-03-28 09:30:05,962 - INFO - Processing participant 20.0...
2025-03-28 09:30:05,963 - INFO - Fitting SINDy model for participant 20.0
2025-03-28 09:30:07,559 - INFO - Participant 20.0: LL=-0.6737, BIC=1.7569, Params=6, Val trials=60
2025-03-28 09:30:07,559 - INFO - Processing participant 21.0...
2025-03-28 09:30:07,560 - INFO - Fitting SINDy model for participant 21.0
2025-03-28 09:30:09,144 - INFO - Participant 21.0: LL=-0.8844, BIC=2.3148, Params=8, Val trials=60
2025-03-28 09:30:09,144 - INFO - Processing participant 22.0...
2025-03-28 09:30:09,144 - INFO - Fitting SINDy model for participant 22.0
2025-03-28 09:30:10,613 - INFO - Participant 22.0: LL=-0.7098, BIC=1.9654, Params=8, Val trials=60
2025-03-28 09:30:10,613 - INFO - Processing participant 23.0...
2025-03-28 09:30:10,613 - INFO - Fitting SINDy model for participant 23.0
2025-03-28 09:30:12,091 - INFO - Participant 23.0: LL=-0.6727, BIC=1.8913, Params=8, Val trials=60
2025-03-28 09:30:12,091 - INFO - Processing participant 24.0...
2025-03-28 09:30:12,092 - INFO - Fitting SINDy model for participant 24.0
2025-03-28 09:30:13,684 - INFO - Participant 24.0: LL=-0.6999, BIC=1.8775, Params=7, Val trials=60
2025-03-28 09:30:13,684 - INFO - Processing participant 25.0...
2025-03-28 09:30:13,685 - INFO - Fitting SINDy model for participant 25.0
2025-03-28 09:30:15,393 - INFO - Participant 25.0: LL=-0.6457, BIC=1.7691, Params=7, Val trials=60
2025-03-28 09:30:15,393 - INFO - Processing participant 26.0...
2025-03-28 09:30:15,393 - INFO - Fitting SINDy model for participant 26.0
2025-03-28 09:30:17,029 - INFO - Participant 26.0: LL=-0.6931, BIC=1.9322, Params=8, Val trials=60
2025-03-28 09:30:17,029 - INFO - Processing participant 27.0...
2025-03-28 09:30:17,030 - INFO - Fitting SINDy model for participant 27.0
2025-03-28 09:30:18,615 - INFO - Participant 27.0: LL=-0.6931, BIC=1.9322, Params=8, Val trials=60
2025-03-28 09:30:18,615 - INFO - Processing participant 28.0...
2025-03-28 09:30:18,615 - INFO - Fitting SINDy model for participant 28.0
2025-03-28 09:30:20,240 - INFO - Participant 28.0: LL=-0.3696, BIC=1.2170, Params=7, Val trials=60
2025-03-28 09:30:20,240 - INFO - Processing participant 29.0...
2025-03-28 09:30:20,241 - INFO - Fitting SINDy model for participant 29.0
2025-03-28 09:30:21,972 - INFO - Participant 29.0: LL=-0.6464, BIC=1.8388, Params=8, Val trials=60
2025-03-28 09:30:21,972 - INFO - Processing participant 30.0...
2025-03-28 09:30:21,973 - INFO - Fitting SINDy model for participant 30.0
2025-03-28 09:30:23,554 - INFO - Participant 30.0: LL=-1.1308, BIC=2.8075, Params=8, Val trials=60
2025-03-28 09:30:23,554 - INFO - Processing participant 31.0...
2025-03-28 09:30:23,555 - INFO - Fitting SINDy model for participant 31.0
2025-03-28 09:30:25,023 - INFO - Participant 31.0: LL=-0.6952, BIC=1.9364, Params=8, Val trials=60
2025-03-28 09:30:25,023 - INFO - Processing participant 32.0...
2025-03-28 09:30:25,024 - INFO - Fitting SINDy model for participant 32.0
2025-03-28 09:30:26,634 - INFO - Participant 32.0: LL=-0.7199, BIC=1.9174, Params=7, Val trials=60
2025-03-28 09:30:26,634 - INFO - Processing participant 33.0...
2025-03-28 09:30:26,634 - INFO - Fitting SINDy model for participant 33.0
2025-03-28 09:30:28,200 - INFO - Participant 33.0: LL=-0.5374, BIC=1.6207, Params=8, Val trials=60
2025-03-28 09:30:28,200 - INFO - Processing participant 34.0...
2025-03-28 09:30:28,200 - INFO - Fitting SINDy model for participant 34.0
2025-03-28 09:30:29,731 - INFO - Participant 34.0: LL=-0.3217, BIC=1.1894, Params=8, Val trials=60
2025-03-28 09:30:29,731 - INFO - Processing participant 35.0...
2025-03-28 09:30:29,732 - INFO - Fitting SINDy model for participant 35.0
2025-03-28 09:30:31,251 - INFO - Participant 35.0: LL=-0.7683, BIC=2.0825, Params=8, Val trials=60
2025-03-28 09:30:31,251 - INFO - Processing participant 36.0...
2025-03-28 09:30:31,252 - INFO - Fitting SINDy model for participant 36.0
2025-03-28 09:30:32,748 - INFO - Participant 36.0: LL=-0.7033, BIC=1.9524, Params=8, Val trials=60
2025-03-28 09:30:32,748 - INFO - Processing participant 37.0...
2025-03-28 09:30:32,749 - INFO - Fitting SINDy model for participant 37.0
2025-03-28 09:30:34,284 - INFO - Participant 37.0: LL=-0.6931, BIC=1.9322, Params=8, Val trials=60
2025-03-28 09:30:34,285 - INFO - Processing participant 38.0...
2025-03-28 09:30:34,285 - INFO - Fitting SINDy model for participant 38.0
2025-03-28 09:30:35,846 - INFO - Participant 38.0: LL=-0.4016, BIC=1.2808, Params=7, Val trials=60
2025-03-28 09:30:35,846 - INFO - Processing participant 39.0...
2025-03-28 09:30:35,846 - INFO - Fitting SINDy model for participant 39.0
2025-03-28 09:30:37,317 - INFO - Participant 39.0: LL=-1.2273, BIC=3.0005, Params=8, Val trials=60
2025-03-28 09:30:37,317 - INFO - Processing participant 40.0...
2025-03-28 09:30:37,318 - INFO - Fitting SINDy model for participant 40.0
2025-03-28 09:30:38,888 - INFO - Participant 40.0: LL=-0.8209, BIC=2.1878, Params=8, Val trials=60
2025-03-28 09:30:38,888 - INFO - Processing participant 41.0...
2025-03-28 09:30:38,889 - INFO - Fitting SINDy model for participant 41.0
2025-03-28 09:30:40,377 - INFO - Participant 41.0: LL=-0.7561, BIC=1.9898, Params=7, Val trials=60
2025-03-28 09:30:40,377 - INFO - Processing participant 42.0...
2025-03-28 09:30:40,378 - INFO - Fitting SINDy model for participant 42.0
2025-03-28 09:30:41,867 - INFO - Participant 42.0: LL=-0.6932, BIC=1.9323, Params=8, Val trials=60
2025-03-28 09:30:41,867 - INFO - Processing participant 43.0...
2025-03-28 09:30:41,868 - INFO - Fitting SINDy model for participant 43.0
2025-03-28 09:30:43,348 - INFO - Participant 43.0: LL=-0.8794, BIC=2.3046, Params=8, Val trials=60
2025-03-28 09:30:43,348 - INFO - Processing participant 44.0...
2025-03-28 09:30:43,348 - INFO - Fitting SINDy model for participant 44.0
2025-03-28 09:30:44,969 - INFO - Participant 44.0: LL=-1.1370, BIC=2.7517, Params=7, Val trials=60
2025-03-28 09:30:44,969 - INFO - Processing participant 45.0...
2025-03-28 09:30:44,970 - INFO - Fitting SINDy model for participant 45.0
2025-03-28 09:30:46,586 - INFO - Participant 45.0: LL=-0.6257, BIC=1.7973, Params=8, Val trials=60
2025-03-28 09:30:46,586 - INFO - Processing participant 46.0...
2025-03-28 09:30:46,587 - INFO - Fitting SINDy model for participant 46.0
2025-03-28 09:30:48,190 - INFO - Participant 46.0: LL=-0.9251, BIC=2.3961, Params=8, Val trials=60
2025-03-28 09:30:48,190 - INFO - Processing participant 47.0...
2025-03-28 09:30:48,190 - INFO - Fitting SINDy model for participant 47.0
2025-03-28 09:30:49,734 - INFO - Participant 47.0: LL=-0.6730, BIC=1.8920, Params=8, Val trials=60
2025-03-28 09:30:49,734 - INFO - Processing participant 48.0...
2025-03-28 09:30:49,735 - INFO - Fitting SINDy model for participant 48.0
2025-03-28 09:30:51,326 - INFO - Participant 48.0: LL=-0.7086, BIC=1.9630, Params=8, Val trials=60
2025-03-28 09:30:51,326 - INFO - Processing participant 49.0...
2025-03-28 09:30:51,327 - INFO - Fitting SINDy model for participant 49.0
2025-03-28 09:30:52,802 - INFO - Participant 49.0: LL=-0.7659, BIC=2.0777, Params=8, Val trials=60
2025-03-28 09:30:52,802 - INFO - Processing participant 50.0...
2025-03-28 09:30:52,803 - INFO - Fitting SINDy model for participant 50.0
2025-03-28 09:30:54,279 - INFO - Participant 50.0: LL=-0.6931, BIC=1.8640, Params=7, Val trials=60
2025-03-28 09:30:54,279 - INFO - Processing participant 51.0...
2025-03-28 09:30:54,279 - INFO - Fitting SINDy model for participant 51.0
2025-03-28 09:30:55,726 - INFO - Participant 51.0: LL=-0.6931, BIC=2.0687, Params=10, Val trials=60
2025-03-28 09:30:55,726 - INFO - Processing participant 52.0...
2025-03-28 09:30:55,726 - INFO - Fitting SINDy model for participant 52.0
2025-03-28 09:30:57,237 - INFO - Participant 52.0: LL=-0.8243, BIC=2.1944, Params=8, Val trials=60
2025-03-28 09:30:57,237 - INFO - Processing participant 53.0...
2025-03-28 09:30:57,238 - INFO - Fitting SINDy model for participant 53.0
2025-03-28 09:30:58,787 - INFO - Participant 53.0: LL=-0.7106, BIC=1.9671, Params=8, Val trials=60
2025-03-28 09:30:58,787 - INFO - Processing participant 54.0...
2025-03-28 09:30:58,788 - INFO - Fitting SINDy model for participant 54.0
2025-03-28 09:31:00,331 - INFO - Participant 54.0: LL=-0.8690, BIC=2.2840, Params=8, Val trials=60
2025-03-28 09:31:00,331 - INFO - Processing participant 55.0...
2025-03-28 09:31:00,332 - INFO - Fitting SINDy model for participant 55.0
2025-03-28 09:31:01,859 - INFO - Participant 55.0: LL=-0.7459, BIC=2.0376, Params=8, Val trials=60
2025-03-28 09:31:01,859 - INFO - Processing participant 56.0...
2025-03-28 09:31:01,860 - INFO - Fitting SINDy model for participant 56.0
2025-03-28 09:31:03,386 - INFO - Participant 56.0: LL=-1.6563, BIC=3.7904, Params=7, Val trials=60
2025-03-28 09:31:03,386 - INFO - Processing participant 57.0...
2025-03-28 09:31:03,387 - INFO - Fitting SINDy model for participant 57.0
2025-03-28 09:31:04,949 - INFO - Participant 57.0: LL=-0.5404, BIC=1.6268, Params=8, Val trials=60
2025-03-28 09:31:04,949 - INFO - Processing participant 58.0...
2025-03-28 09:31:04,950 - INFO - Fitting SINDy model for participant 58.0
2025-03-28 09:31:06,480 - INFO - Participant 58.0: LL=-0.6931, BIC=2.0687, Params=10, Val trials=60
2025-03-28 09:31:06,480 - INFO - Processing participant 59.0...
2025-03-28 09:31:06,481 - INFO - Fitting SINDy model for participant 59.0
2025-03-28 09:31:08,011 - INFO - Participant 59.0: LL=-0.9196, BIC=2.3851, Params=8, Val trials=60
2025-03-28 09:31:08,011 - INFO - Processing participant 60.0...
2025-03-28 09:31:08,012 - INFO - Fitting SINDy model for participant 60.0
2025-03-28 09:31:09,582 - INFO - Participant 60.0: LL=-0.8103, BIC=2.1665, Params=8, Val trials=60
2025-03-28 09:31:09,582 - INFO - Processing participant 61.0...
2025-03-28 09:31:09,583 - INFO - Fitting SINDy model for participant 61.0
2025-03-28 09:31:11,077 - INFO - Participant 61.0: LL=-0.6931, BIC=1.8640, Params=7, Val trials=60
2025-03-28 09:31:11,077 - INFO - Processing participant 62.0...
2025-03-28 09:31:11,078 - INFO - Fitting SINDy model for participant 62.0
2025-03-28 09:31:12,575 - INFO - Participant 62.0: LL=-0.7101, BIC=1.9661, Params=8, Val trials=60
2025-03-28 09:31:12,575 - INFO - Processing participant 63.0...
2025-03-28 09:31:12,576 - INFO - Fitting SINDy model for participant 63.0
2025-03-28 09:31:14,047 - INFO - Participant 63.0: LL=-0.6931, BIC=2.0687, Params=10, Val trials=60
2025-03-28 09:31:14,047 - INFO - Processing participant 64.0...
2025-03-28 09:31:14,047 - INFO - Fitting SINDy model for participant 64.0
2025-03-28 09:31:15,541 - INFO - Participant 64.0: LL=-0.6931, BIC=1.9322, Params=8, Val trials=60
2025-03-28 09:31:15,542 - INFO - Processing participant 65.0...
2025-03-28 09:31:15,542 - INFO - Fitting SINDy model for participant 65.0
2025-03-28 09:31:17,036 - INFO - Participant 65.0: LL=-0.9035, BIC=2.2847, Params=7, Val trials=60
2025-03-28 09:31:17,036 - INFO - Processing participant 66.0...
2025-03-28 09:31:17,036 - INFO - Fitting SINDy model for participant 66.0
2025-03-28 09:31:18,540 - INFO - Participant 66.0: LL=-0.6633, BIC=1.8725, Params=8, Val trials=60
2025-03-28 09:31:18,540 - INFO - Processing participant 67.0...
2025-03-28 09:31:18,541 - INFO - Fitting SINDy model for participant 67.0
2025-03-28 09:31:20,082 - INFO - Participant 67.0: LL=-0.7706, BIC=2.0870, Params=8, Val trials=60
2025-03-28 09:31:20,082 - INFO - Processing participant 68.0...
2025-03-28 09:31:20,082 - INFO - Fitting SINDy model for participant 68.0
2025-03-28 09:31:21,645 - INFO - Participant 68.0: LL=-0.8385, BIC=2.2229, Params=8, Val trials=60
2025-03-28 09:31:21,645 - INFO - Processing participant 69.0...
2025-03-28 09:31:21,645 - INFO - Fitting SINDy model for participant 69.0
2025-03-28 09:31:23,188 - INFO - Participant 69.0: LL=-0.5062, BIC=1.5583, Params=8, Val trials=60
2025-03-28 09:31:23,188 - INFO - Processing participant 70.0...
2025-03-28 09:31:23,189 - INFO - Fitting SINDy model for participant 70.0
2025-03-28 09:31:24,775 - INFO - Participant 70.0: LL=-0.6931, BIC=1.7957, Params=6, Val trials=60
2025-03-28 09:31:24,775 - INFO - Processing participant 71.0...
2025-03-28 09:31:24,776 - INFO - Fitting SINDy model for participant 71.0
2025-03-28 09:31:26,188 - INFO - Participant 71.0: LL=-0.6587, BIC=1.8634, Params=8, Val trials=60
2025-03-28 09:31:26,188 - INFO - Processing participant 72.0...
2025-03-28 09:31:26,189 - INFO - Fitting SINDy model for participant 72.0
2025-03-28 09:31:27,671 - INFO - Participant 72.0: LL=-0.6653, BIC=1.8766, Params=8, Val trials=60
2025-03-28 09:31:27,671 - INFO - Processing participant 73.0...
2025-03-28 09:31:27,672 - INFO - Fitting SINDy model for participant 73.0
2025-03-28 09:31:29,157 - INFO - Participant 73.0: LL=-0.7066, BIC=1.8908, Params=7, Val trials=60
2025-03-28 09:31:29,157 - INFO - Processing participant 74.0...
2025-03-28 09:31:29,158 - INFO - Fitting SINDy model for participant 74.0
2025-03-28 09:31:30,643 - INFO - Participant 74.0: LL=-0.7136, BIC=1.9732, Params=8, Val trials=60
2025-03-28 09:31:30,643 - INFO - Processing participant 75.0...
2025-03-28 09:31:30,644 - INFO - Fitting SINDy model for participant 75.0
2025-03-28 09:31:32,161 - INFO - Participant 75.0: LL=-0.6270, BIC=1.7999, Params=8, Val trials=60
2025-03-28 09:31:32,161 - INFO - Processing participant 76.0...
2025-03-28 09:31:32,162 - INFO - Fitting SINDy model for participant 76.0
2025-03-28 09:31:33,764 - INFO - Participant 76.0: LL=-0.9059, BIC=2.3576, Params=8, Val trials=60
2025-03-28 09:31:33,764 - INFO - Processing participant 77.0...
2025-03-28 09:31:33,764 - INFO - Fitting SINDy model for participant 77.0
2025-03-28 09:31:35,347 - INFO - Participant 77.0: LL=-0.5898, BIC=1.7255, Params=8, Val trials=60
2025-03-28 09:31:35,347 - INFO - Processing participant 78.0...
2025-03-28 09:31:35,348 - INFO - Fitting SINDy model for participant 78.0
2025-03-28 09:31:36,821 - INFO - Participant 78.0: LL=-0.6788, BIC=1.9034, Params=8, Val trials=60
2025-03-28 09:31:36,821 - INFO - Processing participant 79.0...
2025-03-28 09:31:36,822 - INFO - Fitting SINDy model for participant 79.0
2025-03-28 09:31:38,230 - INFO - Participant 79.0: LL=-0.7254, BIC=1.9967, Params=8, Val trials=60
2025-03-28 09:31:38,230 - INFO - Processing participant 80.0...
2025-03-28 09:31:38,231 - INFO - Fitting SINDy model for participant 80.0
2025-03-28 09:31:39,715 - INFO - Participant 80.0: LL=-0.7520, BIC=1.9818, Params=7, Val trials=60
2025-03-28 09:31:39,715 - INFO - Processing participant 81.0...
2025-03-28 09:31:39,716 - INFO - Fitting SINDy model for participant 81.0
2025-03-28 09:31:41,241 - INFO - Participant 81.0: LL=-0.6931, BIC=1.9322, Params=8, Val trials=60
2025-03-28 09:31:41,241 - INFO - Processing participant 82.0...
2025-03-28 09:31:41,242 - INFO - Fitting SINDy model for participant 82.0
2025-03-28 09:31:42,786 - INFO - Participant 82.0: LL=-0.7531, BIC=2.0522, Params=8, Val trials=60
2025-03-28 09:31:42,786 - INFO - Processing participant 83.0...
2025-03-28 09:31:42,787 - INFO - Fitting SINDy model for participant 83.0
2025-03-28 09:31:44,383 - INFO - Participant 83.0: LL=-0.7528, BIC=2.0515, Params=8, Val trials=60
2025-03-28 09:31:44,383 - INFO - Processing participant 84.0...
2025-03-28 09:31:44,383 - INFO - Fitting SINDy model for participant 84.0
2025-03-28 09:31:45,849 - INFO - Participant 84.0: LL=-0.6403, BIC=1.8265, Params=8, Val trials=60
2025-03-28 09:31:45,849 - INFO - Processing participant 85.0...
2025-03-28 09:31:45,850 - INFO - Fitting SINDy model for participant 85.0
2025-03-28 09:31:47,366 - INFO - Participant 85.0: LL=-0.7973, BIC=2.0723, Params=7, Val trials=60
2025-03-28 09:31:47,366 - INFO - Processing participant 86.0...
2025-03-28 09:31:47,367 - INFO - Fitting SINDy model for participant 86.0
2025-03-28 09:31:48,922 - INFO - Participant 86.0: LL=-0.9293, BIC=2.4044, Params=8, Val trials=60
2025-03-28 09:31:48,922 - INFO - Processing participant 87.0...
2025-03-28 09:31:48,922 - INFO - Fitting SINDy model for participant 87.0
2025-03-28 09:31:50,370 - INFO - Participant 87.0: LL=-0.6944, BIC=1.9346, Params=8, Val trials=60
2025-03-28 09:31:50,370 - INFO - Processing participant 88.0...
2025-03-28 09:31:50,371 - INFO - Fitting SINDy model for participant 88.0
2025-03-28 09:31:51,979 - INFO - Participant 88.0: LL=-0.6997, BIC=1.8772, Params=7, Val trials=60
2025-03-28 09:31:51,979 - INFO - Processing participant 89.0...
2025-03-28 09:31:51,979 - INFO - Fitting SINDy model for participant 89.0
2025-03-28 09:31:53,582 - INFO - Participant 89.0: LL=-0.7701, BIC=2.0861, Params=8, Val trials=60
2025-03-28 09:31:53,582 - INFO - Processing participant 90.0...
2025-03-28 09:31:53,582 - INFO - Fitting SINDy model for participant 90.0
2025-03-28 09:31:55,187 - INFO - Participant 90.0: LL=-0.5969, BIC=1.7397, Params=8, Val trials=60
2025-03-28 09:31:55,187 - INFO - Processing participant 91.0...
2025-03-28 09:31:55,187 - INFO - Fitting SINDy model for participant 91.0
2025-03-28 09:31:56,712 - INFO - Participant 91.0: LL=-0.6933, BIC=1.9326, Params=8, Val trials=60
2025-03-28 09:31:56,712 - INFO - Processing participant 92.0...
2025-03-28 09:31:56,712 - INFO - Fitting SINDy model for participant 92.0
2025-03-28 09:31:58,247 - INFO - Participant 92.0: LL=-0.6931, BIC=1.9321, Params=8, Val trials=60
2025-03-28 09:31:58,247 - INFO - Processing participant 93.0...
2025-03-28 09:31:58,248 - INFO - Fitting SINDy model for participant 93.0
2025-03-28 09:31:59,727 - INFO - Participant 93.0: LL=-0.6721, BIC=1.8902, Params=8, Val trials=60
2025-03-28 09:31:59,727 - INFO - Processing participant 94.0...
2025-03-28 09:31:59,727 - INFO - Fitting SINDy model for participant 94.0
2025-03-28 09:32:01,239 - INFO - Participant 94.0: LL=-0.6932, BIC=1.9323, Params=8, Val trials=60
2025-03-28 09:32:01,239 - INFO - Processing participant 95.0...
2025-03-28 09:32:01,239 - INFO - Fitting SINDy model for participant 95.0
2025-03-28 09:32:02,748 - INFO - Participant 95.0: LL=-0.7142, BIC=2.0425, Params=9, Val trials=60
2025-03-28 09:32:02,748 - INFO - Processing participant 96.0...
2025-03-28 09:32:02,748 - INFO - Fitting SINDy model for participant 96.0
2025-03-28 09:32:04,241 - INFO - Participant 96.0: LL=-0.6931, BIC=1.8640, Params=7, Val trials=60
2025-03-28 09:32:04,241 - INFO - Processing participant 97.0...
2025-03-28 09:32:04,241 - INFO - Fitting SINDy model for participant 97.0
2025-03-28 09:32:05,833 - INFO - Participant 97.0: LL=-0.7744, BIC=2.0947, Params=8, Val trials=60
2025-03-28 09:32:05,833 - INFO - Processing participant 98.0...
2025-03-28 09:32:05,834 - INFO - Fitting SINDy model for participant 98.0
2025-03-28 09:32:07,296 - INFO - Participant 98.0: LL=-0.6931, BIC=1.9322, Params=8, Val trials=60
2025-03-28 09:32:07,297 - INFO - Processing participant 99.0...
2025-03-28 09:32:07,297 - INFO - Fitting SINDy model for participant 99.0
2025-03-28 09:32:08,724 - INFO - Participant 99.0: LL=-0.6931, BIC=1.9322, Params=8, Val trials=60
2025-03-28 09:32:08,724 - INFO - Processing participant 100.0...
2025-03-28 09:32:08,724 - INFO - Fitting SINDy model for participant 100.0
2025-03-28 09:32:10,232 - INFO - Participant 100.0: LL=-0.9360, BIC=2.4179, Params=8, Val trials=60
2025-03-28 09:32:10,232 - INFO - Processing participant 101.0...
2025-03-28 09:32:10,232 - INFO - Fitting SINDy model for participant 101.0
2025-03-28 09:32:11,832 - INFO - Participant 101.0: LL=-0.7726, BIC=2.0229, Params=7, Val trials=60
2025-03-28 09:32:11,832 - INFO - Processing participant 102.0...
2025-03-28 09:32:11,833 - INFO - Fitting SINDy model for participant 102.0
2025-03-28 09:32:13,403 - INFO - Participant 102.0: LL=-0.6911, BIC=1.9963, Params=9, Val trials=60
2025-03-28 09:32:13,403 - INFO - Processing participant 103.0...
2025-03-28 09:32:13,404 - INFO - Fitting SINDy model for participant 103.0
2025-03-28 09:32:14,939 - INFO - Participant 103.0: LL=-0.6931, BIC=1.9322, Params=8, Val trials=60
2025-03-28 09:32:14,939 - INFO - Processing participant 104.0...
2025-03-28 09:32:14,940 - INFO - Fitting SINDy model for participant 104.0
2025-03-28 09:32:16,507 - INFO - Participant 104.0: LL=-0.7103, BIC=1.8984, Params=7, Val trials=60
2025-03-28 09:32:16,507 - INFO - Processing participant 105.0...
2025-03-28 09:32:16,507 - INFO - Fitting SINDy model for participant 105.0
2025-03-28 09:32:18,089 - INFO - Participant 105.0: LL=-0.6961, BIC=1.9382, Params=8, Val trials=60
2025-03-28 09:32:18,089 - INFO - Processing participant 106.0...
2025-03-28 09:32:18,089 - INFO - Fitting SINDy model for participant 106.0
2025-03-28 09:32:19,626 - INFO - Participant 106.0: LL=-0.6920, BIC=1.9298, Params=8, Val trials=60
2025-03-28 09:32:19,626 - INFO - Processing participant 107.0...
2025-03-28 09:32:19,626 - INFO - Fitting SINDy model for participant 107.0
2025-03-28 09:32:21,227 - INFO - Participant 107.0: LL=-0.6869, BIC=1.9196, Params=8, Val trials=60
2025-03-28 09:32:21,227 - INFO - Processing participant 108.0...
2025-03-28 09:32:21,228 - INFO - Fitting SINDy model for participant 108.0
2025-03-28 09:32:22,832 - INFO - Participant 108.0: LL=-0.3026, BIC=1.1512, Params=8, Val trials=60
2025-03-28 09:32:22,832 - INFO - Processing participant 109.0...
2025-03-28 09:32:22,832 - INFO - Fitting SINDy model for participant 109.0
2025-03-28 09:32:24,437 - INFO - Participant 109.0: LL=-0.7288, BIC=2.0036, Params=8, Val trials=60
2025-03-28 09:32:24,438 - INFO - Processing participant 110.0...
2025-03-28 09:32:24,438 - INFO - Fitting SINDy model for participant 110.0
2025-03-28 09:32:26,046 - INFO - Participant 110.0: LL=-0.7104, BIC=1.8986, Params=7, Val trials=60
2025-03-28 09:32:26,046 - INFO - Processing participant 111.0...
2025-03-28 09:32:26,047 - INFO - Fitting SINDy model for participant 111.0
2025-03-28 09:32:27,581 - INFO - Participant 111.0: LL=-0.6931, BIC=1.9322, Params=8, Val trials=60
2025-03-28 09:32:27,581 - INFO - Processing participant 112.0...
2025-03-28 09:32:27,582 - INFO - Fitting SINDy model for participant 112.0
2025-03-28 09:32:29,179 - INFO - Participant 112.0: LL=-0.7405, BIC=2.0268, Params=8, Val trials=60
2025-03-28 09:32:29,179 - INFO - Processing participant 113.0...
2025-03-28 09:32:29,180 - INFO - Fitting SINDy model for participant 113.0
2025-03-28 09:32:30,779 - INFO - Participant 113.0: LL=-0.7444, BIC=2.0347, Params=8, Val trials=60
2025-03-28 09:32:30,779 - INFO - Processing participant 114.0...
2025-03-28 09:32:30,779 - INFO - Fitting SINDy model for participant 114.0
2025-03-28 09:32:32,377 - INFO - Participant 114.0: LL=-0.6931, BIC=1.9322, Params=8, Val trials=60
2025-03-28 09:32:32,377 - INFO - Processing participant 115.0...
2025-03-28 09:32:32,378 - INFO - Fitting SINDy model for participant 115.0
2025-03-28 09:32:33,918 - INFO - Participant 115.0: LL=-2.2186, BIC=4.9832, Params=8, Val trials=60
2025-03-28 09:32:33,918 - INFO - Processing participant 116.0...
2025-03-28 09:32:33,919 - INFO - Fitting SINDy model for participant 116.0
2025-03-28 09:32:35,513 - INFO - Participant 116.0: LL=-0.8380, BIC=2.2219, Params=8, Val trials=60
2025-03-28 09:32:35,513 - INFO - Processing participant 117.0...
2025-03-28 09:32:35,514 - INFO - Fitting SINDy model for participant 117.0
2025-03-28 09:32:37,111 - INFO - Participant 117.0: LL=-0.7052, BIC=1.9562, Params=8, Val trials=60
2025-03-28 09:32:37,111 - INFO - Processing participant 118.0...
2025-03-28 09:32:37,112 - INFO - Fitting SINDy model for participant 118.0
2025-03-28 09:32:38,687 - INFO - Participant 118.0: LL=-1.9865, BIC=4.5188, Params=8, Val trials=60
2025-03-28 09:32:38,687 - INFO - Processing participant 119.0...
2025-03-28 09:32:38,688 - INFO - Fitting SINDy model for participant 119.0
2025-03-28 09:32:40,091 - INFO - Participant 119.0: LL=-0.7046, BIC=1.9552, Params=8, Val trials=60
2025-03-28 09:32:40,091 - INFO - Processing participant 120.0...
2025-03-28 09:32:40,091 - INFO - Fitting SINDy model for participant 120.0
2025-03-28 09:32:41,568 - INFO - Participant 120.0: LL=-0.6240, BIC=1.7940, Params=8, Val trials=60
2025-03-28 09:32:41,568 - INFO - Processing participant 121.0...
2025-03-28 09:32:41,568 - INFO - Fitting SINDy model for participant 121.0
2025-03-28 09:32:43,041 - INFO - Participant 121.0: LL=-0.6562, BIC=1.8584, Params=8, Val trials=60
2025-03-28 09:32:43,041 - INFO - Processing participant 122.0...
2025-03-28 09:32:43,041 - INFO - Fitting SINDy model for participant 122.0
2025-03-28 09:32:44,542 - INFO - Participant 122.0: LL=-0.5250, BIC=1.5959, Params=8, Val trials=60
2025-03-28 09:32:44,542 - INFO - Processing participant 123.0...
2025-03-28 09:32:44,543 - INFO - Fitting SINDy model for participant 123.0
2025-03-28 09:32:45,986 - INFO - Participant 123.0: LL=-0.6011, BIC=1.7481, Params=8, Val trials=60
2025-03-28 09:32:45,986 - INFO - Processing participant 124.0...
2025-03-28 09:32:45,987 - INFO - Fitting SINDy model for participant 124.0
2025-03-28 09:32:47,562 - INFO - Participant 124.0: LL=-0.7786, BIC=2.1031, Params=8, Val trials=60
2025-03-28 09:32:47,562 - INFO - Processing participant 125.0...
2025-03-28 09:32:47,563 - INFO - Fitting SINDy model for participant 125.0
2025-03-28 09:32:49,181 - INFO - Participant 125.0: LL=-0.4912, BIC=1.4601, Params=7, Val trials=60
2025-03-28 09:32:49,181 - INFO - Processing participant 126.0...
2025-03-28 09:32:49,182 - INFO - Fitting SINDy model for participant 126.0
2025-03-28 09:32:50,661 - INFO - Participant 126.0: LL=-0.7954, BIC=2.1367, Params=8, Val trials=60
2025-03-28 09:32:50,661 - INFO - Processing participant 127.0...
2025-03-28 09:32:50,661 - INFO - Fitting SINDy model for participant 127.0
2025-03-28 09:32:52,180 - INFO - Participant 127.0: LL=-0.6931, BIC=1.8640, Params=7, Val trials=60
2025-03-28 09:32:52,180 - INFO - Number of participants with valid BIC metrics: 128/128
2025-03-28 09:32:52,180 - INFO - Average SINDy BIC: 2.0568
2025-03-28 09:32:52,180 - INFO - Average SINDy LL: -0.7621
2025-03-28 09:32:52,191 - INFO - Completed processing dataset: data_128p_0.csv
2025-03-28 09:32:53,306 - INFO - Created violin plots with 128 participant data points
2025-03-28 09:34:22,757 - INFO - ================================================================================
2025-03-28 09:34:22,757 - INFO - EXPERIMENT CONFIG
2025-03-28 09:34:22,757 - INFO - ================================================================================
2025-03-28 09:34:22,757 - INFO - Found 1 data files: ['data_128p_0.csv']
2025-03-28 09:34:22,757 - INFO - Processing dataset: data_128p_0.csv
2025-03-28 09:34:22,757 - INFO - Loading dataset from data/optuna/data_128p_0.csv
2025-03-28 09:34:22,790 - INFO - Number of participants: 128
2025-03-28 09:34:22,796 - INFO - Participant 0 (ID=0.0): _reward=0.74, _penalty=0.97
2025-03-28 09:34:22,801 - INFO - Participant 1 (ID=1.0): _reward=0.99, _penalty=0.02
2025-03-28 09:34:22,806 - INFO - Participant 2 (ID=2.0): _reward=0.77, _penalty=0.46
2025-03-28 09:34:22,811 - INFO - Participant 3 (ID=3.0): _reward=0.96, _penalty=0.60
2025-03-28 09:34:22,816 - INFO - Participant 4 (ID=4.0): _reward=0.21, _penalty=0.21
2025-03-28 09:34:22,822 - INFO - Participant 5 (ID=5.0): _reward=0.07, _penalty=0.51
2025-03-28 09:34:22,827 - INFO - Participant 6 (ID=6.0): _reward=0.23, _penalty=0.60
2025-03-28 09:34:22,832 - INFO - Participant 7 (ID=7.0): _reward=0.91, _penalty=0.80
2025-03-28 09:34:22,837 - INFO - Participant 8 (ID=8.0): _reward=0.99, _penalty=0.97
2025-03-28 09:34:22,842 - INFO - Participant 9 (ID=9.0): _reward=0.67, _penalty=0.87
2025-03-28 09:34:22,847 - INFO - Participant 10 (ID=10.0): _reward=0.08, _penalty=0.77
2025-03-28 09:34:22,852 - INFO - Participant 11 (ID=11.0): _reward=0.87, _penalty=0.31
2025-03-28 09:34:22,857 - INFO - Participant 12 (ID=12.0): _reward=0.58, _penalty=0.19
2025-03-28 09:34:22,862 - INFO - Participant 13 (ID=13.0): _reward=0.48, _penalty=0.25
2025-03-28 09:34:22,867 - INFO - Participant 14 (ID=14.0): _reward=0.34, _penalty=0.83
2025-03-28 09:34:22,872 - INFO - Participant 15 (ID=15.0): _reward=0.56, _penalty=0.80
2025-03-28 09:34:22,877 - INFO - Participant 16 (ID=16.0): _reward=0.47, _penalty=0.29
2025-03-28 09:34:22,882 - INFO - Participant 17 (ID=17.0): _reward=0.77, _penalty=0.94
2025-03-28 09:34:22,887 - INFO - Participant 18 (ID=18.0): _reward=0.88, _penalty=0.01
2025-03-28 09:34:22,892 - INFO - Participant 19 (ID=19.0): _reward=0.98, _penalty=0.11
2025-03-28 09:34:22,897 - INFO - Participant 20 (ID=20.0): _reward=0.02, _penalty=0.85
2025-03-28 09:34:22,902 - INFO - Participant 21 (ID=21.0): _reward=0.46, _penalty=0.85
2025-03-28 09:34:22,907 - INFO - Participant 22 (ID=22.0): _reward=0.69, _penalty=0.43
2025-03-28 09:34:22,912 - INFO - Participant 23 (ID=23.0): _reward=0.15, _penalty=0.95
2025-03-28 09:34:22,917 - INFO - Participant 24 (ID=24.0): _reward=0.25, _penalty=0.36
2025-03-28 09:34:22,922 - INFO - Participant 25 (ID=25.0): _reward=0.75, _penalty=0.11
2025-03-28 09:34:22,927 - INFO - Participant 26 (ID=26.0): _reward=0.46, _penalty=0.81
2025-03-28 09:34:22,932 - INFO - Participant 27 (ID=27.0): _reward=0.36, _penalty=0.63
2025-03-28 09:34:22,937 - INFO - Participant 28 (ID=28.0): _reward=0.49, _penalty=0.00
2025-03-28 09:34:22,941 - INFO - Participant 29 (ID=29.0): _reward=0.20, _penalty=0.98
2025-03-28 09:34:22,946 - INFO - Participant 30 (ID=30.0): _reward=0.29, _penalty=0.64
2025-03-28 09:34:22,951 - INFO - Participant 31 (ID=31.0): _reward=0.66, _penalty=0.64
2025-03-28 09:34:22,956 - INFO - Participant 32 (ID=32.0): _reward=0.21, _penalty=0.41
2025-03-28 09:34:22,961 - INFO - Participant 33 (ID=33.0): _reward=0.49, _penalty=0.63
2025-03-28 09:34:22,966 - INFO - Participant 34 (ID=34.0): _reward=0.38, _penalty=0.08
2025-03-28 09:34:22,971 - INFO - Participant 35 (ID=35.0): _reward=0.33, _penalty=0.29
2025-03-28 09:34:22,976 - INFO - Participant 36 (ID=36.0): _reward=0.53, _penalty=0.61
2025-03-28 09:34:22,981 - INFO - Participant 37 (ID=37.0): _reward=0.65, _penalty=0.34
2025-03-28 09:34:22,986 - INFO - Participant 38 (ID=38.0): _reward=0.29, _penalty=0.13
2025-03-28 09:34:22,991 - INFO - Participant 39 (ID=39.0): _reward=0.31, _penalty=0.25
2025-03-28 09:34:22,996 - INFO - Participant 40 (ID=40.0): _reward=0.77, _penalty=0.04
2025-03-28 09:34:23,001 - INFO - Participant 41 (ID=41.0): _reward=0.23, _penalty=0.89
2025-03-28 09:34:23,006 - INFO - Participant 42 (ID=42.0): _reward=0.63, _penalty=0.60
2025-03-28 09:34:23,011 - INFO - Participant 43 (ID=43.0): _reward=0.48, _penalty=0.52
2025-03-28 09:34:23,016 - INFO - Participant 44 (ID=44.0): _reward=0.92, _penalty=0.22
2025-03-28 09:34:23,021 - INFO - Participant 45 (ID=45.0): _reward=0.52, _penalty=0.89
2025-03-28 09:34:23,026 - INFO - Participant 46 (ID=46.0): _reward=0.42, _penalty=0.83
2025-03-28 09:34:23,031 - INFO - Participant 47 (ID=47.0): _reward=0.68, _penalty=0.69
2025-03-28 09:34:23,036 - INFO - Participant 48 (ID=48.0): _reward=0.95, _penalty=0.22
2025-03-28 09:34:23,041 - INFO - Participant 49 (ID=49.0): _reward=0.13, _penalty=0.48
2025-03-28 09:34:23,046 - INFO - Participant 50 (ID=50.0): _reward=0.87, _penalty=0.85
2025-03-28 09:34:23,051 - INFO - Participant 51 (ID=51.0): _reward=0.47, _penalty=0.07
2025-03-28 09:34:23,056 - INFO - Participant 52 (ID=52.0): _reward=0.56, _penalty=0.42
2025-03-28 09:34:23,061 - INFO - Participant 53 (ID=53.0): _reward=0.53, _penalty=0.18
2025-03-28 09:34:23,066 - INFO - Participant 54 (ID=54.0): _reward=0.87, _penalty=0.73
2025-03-28 09:34:23,071 - INFO - Participant 55 (ID=55.0): _reward=0.21, _penalty=0.47
2025-03-28 09:34:23,076 - INFO - Participant 56 (ID=56.0): _reward=0.65, _penalty=0.09
2025-03-28 09:34:23,081 - INFO - Participant 57 (ID=57.0): _reward=0.72, _penalty=0.88
2025-03-28 09:34:23,086 - INFO - Participant 58 (ID=58.0): _reward=0.61, _penalty=0.38
2025-03-28 09:34:23,091 - INFO - Participant 59 (ID=59.0): _reward=0.92, _penalty=0.91
2025-03-28 09:34:23,096 - INFO - Participant 60 (ID=60.0): _reward=0.22, _penalty=0.97
2025-03-28 09:34:23,101 - INFO - Participant 61 (ID=61.0): _reward=0.41, _penalty=0.53
2025-03-28 09:34:23,106 - INFO - Participant 62 (ID=62.0): _reward=0.92, _penalty=0.99
2025-03-28 09:34:23,111 - INFO - Participant 63 (ID=63.0): _reward=0.22, _penalty=0.99
2025-03-28 09:34:23,116 - INFO - Participant 64 (ID=64.0): _reward=0.84, _penalty=0.96
2025-03-28 09:34:23,121 - INFO - Participant 65 (ID=65.0): _reward=0.55, _penalty=0.19
2025-03-28 09:34:23,126 - INFO - Participant 66 (ID=66.0): _reward=0.34, _penalty=0.07
2025-03-28 09:34:23,131 - INFO - Participant 67 (ID=67.0): _reward=0.62, _penalty=0.45
2025-03-28 09:34:23,136 - INFO - Participant 68 (ID=68.0): _reward=0.47, _penalty=0.19
2025-03-28 09:34:23,141 - INFO - Participant 69 (ID=69.0): _reward=0.81, _penalty=0.36
2025-03-28 09:34:23,146 - INFO - Participant 70 (ID=70.0): _reward=0.73, _penalty=0.87
2025-03-28 09:34:23,151 - INFO - Participant 71 (ID=71.0): _reward=0.10, _penalty=0.57
2025-03-28 09:34:23,156 - INFO - Participant 72 (ID=72.0): _reward=0.78, _penalty=0.50
2025-03-28 09:34:23,161 - INFO - Participant 73 (ID=73.0): _reward=0.82, _penalty=0.70
2025-03-28 09:34:23,166 - INFO - Participant 74 (ID=74.0): _reward=0.00, _penalty=0.98
2025-03-28 09:34:23,171 - INFO - Participant 75 (ID=75.0): _reward=0.42, _penalty=0.26
2025-03-28 09:34:23,176 - INFO - Participant 76 (ID=76.0): _reward=0.83, _penalty=0.39
2025-03-28 09:34:23,181 - INFO - Participant 77 (ID=77.0): _reward=0.75, _penalty=0.18
2025-03-28 09:34:23,186 - INFO - Participant 78 (ID=78.0): _reward=0.97, _penalty=0.44
2025-03-28 09:34:23,191 - INFO - Participant 79 (ID=79.0): _reward=0.45, _penalty=0.57
2025-03-28 09:34:23,196 - INFO - Participant 80 (ID=80.0): _reward=0.63, _penalty=0.78
2025-03-28 09:34:23,201 - INFO - Participant 81 (ID=81.0): _reward=0.29, _penalty=0.24
2025-03-28 09:34:23,206 - INFO - Participant 82 (ID=82.0): _reward=0.71, _penalty=0.15
2025-03-28 09:34:23,211 - INFO - Participant 83 (ID=83.0): _reward=0.71, _penalty=0.66
2025-03-28 09:34:23,216 - INFO - Participant 84 (ID=84.0): _reward=0.97, _penalty=0.79
2025-03-28 09:34:23,221 - INFO - Participant 85 (ID=85.0): _reward=1.00, _penalty=0.95
2025-03-28 09:34:23,226 - INFO - Participant 86 (ID=86.0): _reward=0.56, _penalty=0.08
2025-03-28 09:34:23,231 - INFO - Participant 87 (ID=87.0): _reward=0.59, _penalty=0.83
2025-03-28 09:34:23,236 - INFO - Participant 88 (ID=88.0): _reward=0.32, _penalty=0.60
2025-03-28 09:34:23,241 - INFO - Participant 89 (ID=89.0): _reward=0.20, _penalty=0.84
2025-03-28 09:34:23,245 - INFO - Participant 90 (ID=90.0): _reward=0.34, _penalty=1.00
2025-03-28 09:34:23,250 - INFO - Participant 91 (ID=91.0): _reward=0.19, _penalty=0.99
2025-03-28 09:34:23,255 - INFO - Participant 92 (ID=92.0): _reward=0.20, _penalty=0.91
2025-03-28 09:34:23,260 - INFO - Participant 93 (ID=93.0): _reward=0.31, _penalty=0.21
2025-03-28 09:34:23,265 - INFO - Participant 94 (ID=94.0): _reward=0.58, _penalty=0.41
2025-03-28 09:34:23,270 - INFO - Participant 95 (ID=95.0): _reward=0.80, _penalty=0.54
2025-03-28 09:34:23,275 - INFO - Participant 96 (ID=96.0): _reward=0.74, _penalty=0.80
2025-03-28 09:34:23,280 - INFO - Participant 97 (ID=97.0): _reward=0.59, _penalty=0.16
2025-03-28 09:34:23,285 - INFO - Participant 98 (ID=98.0): _reward=0.54, _penalty=0.17
2025-03-28 09:34:23,290 - INFO - Participant 99 (ID=99.0): _reward=0.17, _penalty=0.16
2025-03-28 09:34:23,295 - INFO - Participant 100 (ID=100.0): _reward=0.79, _penalty=0.40
2025-03-28 09:34:23,300 - INFO - Participant 101 (ID=101.0): _reward=0.32, _penalty=0.05
2025-03-28 09:34:23,305 - INFO - Participant 102 (ID=102.0): _reward=0.87, _penalty=0.81
2025-03-28 09:34:23,310 - INFO - Participant 103 (ID=103.0): _reward=0.90, _penalty=0.11
2025-03-28 09:34:23,315 - INFO - Participant 104 (ID=104.0): _reward=0.44, _penalty=0.12
2025-03-28 09:34:23,320 - INFO - Participant 105 (ID=105.0): _reward=0.59, _penalty=0.50
2025-03-28 09:34:23,325 - INFO - Participant 106 (ID=106.0): _reward=0.84, _penalty=0.50
2025-03-28 09:34:23,330 - INFO - Participant 107 (ID=107.0): _reward=0.48, _penalty=0.54
2025-03-28 09:34:23,335 - INFO - Participant 108 (ID=108.0): _reward=0.56, _penalty=0.75
2025-03-28 09:34:23,340 - INFO - Participant 109 (ID=109.0): _reward=0.53, _penalty=0.11
2025-03-28 09:34:23,345 - INFO - Participant 110 (ID=110.0): _reward=0.52, _penalty=0.40
2025-03-28 09:34:23,350 - INFO - Participant 111 (ID=111.0): _reward=0.61, _penalty=0.74
2025-03-28 09:34:23,355 - INFO - Participant 112 (ID=112.0): _reward=0.64, _penalty=0.56
2025-03-28 09:34:23,360 - INFO - Participant 113 (ID=113.0): _reward=0.44, _penalty=0.40
2025-03-28 09:34:23,365 - INFO - Participant 114 (ID=114.0): _reward=0.74, _penalty=0.91
2025-03-28 09:34:23,370 - INFO - Participant 115 (ID=115.0): _reward=0.09, _penalty=0.27
2025-03-28 09:34:23,375 - INFO - Participant 116 (ID=116.0): _reward=0.99, _penalty=0.92
2025-03-28 09:34:23,380 - INFO - Participant 117 (ID=117.0): _reward=0.90, _penalty=0.87
2025-03-28 09:34:23,385 - INFO - Participant 118 (ID=118.0): _reward=0.21, _penalty=0.27
2025-03-28 09:34:23,390 - INFO - Participant 119 (ID=119.0): _reward=0.71, _penalty=0.69
2025-03-28 09:34:23,395 - INFO - Participant 120 (ID=120.0): _reward=0.43, _penalty=0.05
2025-03-28 09:34:23,400 - INFO - Participant 121 (ID=121.0): _reward=0.11, _penalty=0.27
2025-03-28 09:34:23,405 - INFO - Participant 122 (ID=122.0): _reward=0.80, _penalty=0.43
2025-03-28 09:34:23,410 - INFO - Participant 123 (ID=123.0): _reward=0.74, _penalty=0.44
2025-03-28 09:34:23,415 - INFO - Participant 124 (ID=124.0): _reward=0.18, _penalty=0.36
2025-03-28 09:34:23,420 - INFO - Participant 125 (ID=125.0): _reward=0.86, _penalty=0.09
2025-03-28 09:34:23,425 - INFO - Participant 126 (ID=126.0): _reward=0.05, _penalty=0.52
2025-03-28 09:34:23,430 - INFO - Participant 127 (ID=127.0): _reward=0.41, _penalty=0.26
2025-03-28 09:34:23,430 - INFO - Participant 0 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 1 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 2 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 3 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 4 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 5 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 6 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 7 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 8 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 9 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 10 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 11 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 12 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 13 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 14 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 15 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 16 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 17 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 18 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 19 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 20 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 21 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 22 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 23 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 24 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 25 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 26 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 27 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 28 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 29 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 30 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 31 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 32 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 33 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 34 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 35 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 36 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 37 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 38 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 39 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 40 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 41 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 42 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 43 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 44 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 45 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 46 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 47 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 48 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 49 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 50 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 51 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,430 - INFO - Participant 52 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 53 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 54 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 55 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 56 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 57 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 58 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 59 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 60 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 61 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 62 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 63 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 64 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 65 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 66 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 67 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 68 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 69 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 70 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 71 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 72 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 73 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 74 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 75 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 76 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 77 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 78 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 79 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 80 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 81 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 82 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 83 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 84 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 85 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 86 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 87 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 88 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 89 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 90 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 91 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 92 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 93 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 94 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 95 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 96 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 97 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 98 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 99 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 100 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 101 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 102 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 103 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 104 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 105 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 106 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 107 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 108 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 109 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 110 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 111 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 112 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 113 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 114 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 115 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 116 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 117 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 118 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 119 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 120 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 121 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 122 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 123 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 124 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 125 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 126 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,431 - INFO - Participant 127 xs shape: torch.Size([1, 200, 5])
2025-03-28 09:34:23,432 - INFO - Combined xs shape after concatenation: torch.Size([128, 200, 5])
2025-03-28 09:34:23,432 - INFO - Combined ys shape after concatenation: torch.Size([128, 200, 2])
2025-03-28 09:34:23,432 - INFO - Combined dataset shape: X=torch.Size([128, 200, 5]), Y=torch.Size([128, 200, 2])
2025-03-28 09:34:23,432 - INFO - Total unique participants: 128
2025-03-28 09:34:23,432 - INFO - Train/test split ratio: 0.7/0.30000000000000004 of trials within each participant
2025-03-28 09:34:23,433 - INFO - Participant 0.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 1.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 2.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 3.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 4.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 5.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 6.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 7.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 8.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 9.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 10.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 11.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 12.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 13.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 14.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 15.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 16.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 17.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 18.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 19.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 20.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,433 - INFO - Participant 21.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 22.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 23.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 24.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 25.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 26.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 27.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 28.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 29.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 30.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 31.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 32.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 33.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 34.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 35.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 36.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 37.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 38.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 39.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 40.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 41.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 42.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 43.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 44.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,434 - INFO - Participant 45.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 46.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 47.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 48.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 49.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 50.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 51.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 52.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 53.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 54.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 55.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 56.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 57.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 58.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 59.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 60.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 61.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 62.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 63.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 64.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 65.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 66.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 67.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,435 - INFO - Participant 68.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 69.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 70.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 71.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 72.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 73.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 74.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 75.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 76.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 77.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 78.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 79.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 80.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 81.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 82.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 83.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 84.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 85.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 86.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 87.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 88.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 89.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 90.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 91.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 92.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 93.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,436 - INFO - Participant 94.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 95.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 96.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 97.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 98.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 99.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 100.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 101.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 102.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 103.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 104.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 105.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 106.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 107.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 108.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 109.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 110.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 111.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 112.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 113.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 114.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 115.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 116.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 117.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 118.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,437 - INFO - Participant 119.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,438 - INFO - Participant 120.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,438 - INFO - Participant 121.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,438 - INFO - Participant 122.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,438 - INFO - Participant 123.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,438 - INFO - Participant 124.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,438 - INFO - Participant 125.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,438 - INFO - Participant 126.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,438 - INFO - Participant 127.0: 140 trials for training, 60 trials for validation
2025-03-28 09:34:23,438 - INFO - Train xs shape: torch.Size([128, 140, 5])
2025-03-28 09:34:23,438 - INFO - Train ys shape: torch.Size([128, 140, 2])
2025-03-28 09:34:23,438 - INFO - Validation xs shape: torch.Size([128, 60, 5])
2025-03-28 09:34:23,438 - INFO - Validation ys shape: torch.Size([128, 60, 2])
2025-03-28 09:34:23,438 - INFO - Train dataset: torch.Size([128, 140, 5]), Validation dataset: torch.Size([128, 60, 5])
2025-03-28 09:34:23,438 - INFO - Starting hyperparameter optimization...
2025-03-28 09:34:23,439 - INFO - Trial 0: lr=0.004175, embedding_size=14, n_steps=45
2025-03-28 09:44:38,518 - INFO - Trial 0: RNN Train Loss: 0.4660401
2025-03-28 09:44:38,518 - INFO - Trial 0: Validation set has 128 participants
2025-03-28 09:44:44,742 - INFO - Trial 0: Average Validation Loss: 0.5592, Eval count: 128
2025-03-28 09:44:44,743 - INFO - Trial 1: lr=0.003683, embedding_size=18, n_steps=32
2025-03-28 09:55:06,998 - INFO - Trial 1: RNN Train Loss: 0.2741637
2025-03-28 09:55:06,998 - INFO - Trial 1: Validation set has 128 participants
2025-03-28 09:55:12,728 - INFO - Trial 1: Average Validation Loss: 0.4194, Eval count: 128
2025-03-28 09:55:12,729 - INFO - Trial 2: lr=0.001390, embedding_size=12, n_steps=79
2025-03-28 10:05:14,194 - INFO - Trial 2: RNN Train Loss: 0.3131511
2025-03-28 10:05:14,195 - INFO - Trial 2: Validation set has 128 participants
2025-03-28 10:05:19,941 - INFO - Trial 2: Average Validation Loss: 0.4296, Eval count: 128
2025-03-28 10:05:19,942 - INFO - Trial 3: lr=0.001131, embedding_size=19, n_steps=9
2025-03-28 10:16:31,541 - INFO - Trial 3: RNN Train Loss: 0.3163869
2025-03-28 10:16:31,542 - INFO - Trial 3: Validation set has 128 participants
2025-03-28 10:16:37,648 - INFO - Trial 3: Average Validation Loss: 0.4392, Eval count: 128
2025-03-28 10:16:37,649 - INFO - Trial 4: lr=0.000190, embedding_size=27, n_steps=29
2025-03-28 10:27:07,468 - INFO - Trial 4: RNN Train Loss: 0.2967211
2025-03-28 10:27:07,469 - INFO - Trial 4: Validation set has 128 participants
2025-03-28 10:27:13,746 - INFO - Trial 4: Average Validation Loss: 0.3970, Eval count: 128
2025-03-28 10:27:13,747 - INFO - Trial 5: lr=0.000793, embedding_size=16, n_steps=45
2025-03-28 10:37:23,880 - INFO - Trial 5: RNN Train Loss: 0.3728946
2025-03-28 10:37:23,881 - INFO - Trial 5: Validation set has 128 participants
2025-03-28 10:37:30,034 - INFO - Trial 5: Average Validation Loss: 0.4517, Eval count: 128
2025-03-28 10:37:30,035 - INFO - Trial 6: lr=0.000808, embedding_size=11, n_steps=74
2025-03-28 10:47:33,570 - INFO - Trial 6: RNN Train Loss: 0.3607337
2025-03-28 10:47:33,571 - INFO - Trial 6: Validation set has 128 participants
2025-03-28 10:47:39,553 - INFO - Trial 6: Average Validation Loss: 0.4489, Eval count: 128
2025-03-28 10:47:39,554 - INFO - Trial 7: lr=0.000554, embedding_size=24, n_steps=6
2025-03-28 10:59:54,188 - INFO - Trial 7: RNN Train Loss: 0.3018698
2025-03-28 10:59:54,188 - INFO - Trial 7: Validation set has 128 participants
2025-03-28 11:00:00,370 - INFO - Trial 7: Average Validation Loss: 0.4161, Eval count: 128
2025-03-28 11:00:00,370 - INFO - Trial 8: lr=0.000208, embedding_size=28, n_steps=19
2025-03-28 11:10:44,044 - INFO - Trial 8: RNN Train Loss: 0.3243329
2025-03-28 11:10:44,044 - INFO - Trial 8: Validation set has 128 participants
2025-03-28 11:10:50,142 - INFO - Trial 8: Average Validation Loss: 0.4193, Eval count: 128
2025-03-28 11:10:50,143 - INFO - Trial 9: lr=0.000498, embedding_size=23, n_steps=6
2025-03-28 11:22:44,568 - INFO - Trial 9: RNN Train Loss: 0.3022630
2025-03-28 11:22:44,569 - INFO - Trial 9: Validation set has 128 participants
2025-03-28 11:22:50,319 - INFO - Trial 9: Average Validation Loss: 0.4346, Eval count: 128
2025-03-28 11:22:50,326 - INFO - Trial 10: lr=0.000104, embedding_size=31, n_steps=98
2025-03-28 11:33:10,985 - INFO - Trial 10: RNN Train Loss: 0.3517808
2025-03-28 11:33:10,986 - INFO - Trial 10: Validation set has 128 participants
2025-03-28 11:33:17,160 - INFO - Trial 10: Average Validation Loss: 0.4327, Eval count: 128
2025-03-28 11:33:17,166 - INFO - Trial 11: lr=0.000256, embedding_size=24, n_steps=24
2025-03-28 11:43:42,230 - INFO - Trial 11: RNN Train Loss: 0.3616405
2025-03-28 11:43:42,230 - INFO - Trial 11: Validation set has 128 participants
2025-03-28 11:43:47,908 - INFO - Trial 11: Average Validation Loss: 0.4580, Eval count: 128
2025-03-28 11:43:47,914 - INFO - Trial 12: lr=0.000284, embedding_size=26, n_steps=1
2025-03-28 12:03:00,134 - INFO - Trial 12: RNN Train Loss: 0.3230723
2025-03-28 12:03:00,135 - INFO - Trial 12: Validation set has 128 participants
2025-03-28 12:03:05,713 - INFO - Trial 12: Average Validation Loss: 0.4227, Eval count: 128
2025-03-28 12:03:05,719 - INFO - Trial 13: lr=0.000120, embedding_size=32, n_steps=32
2025-03-28 12:13:33,228 - INFO - Trial 13: RNN Train Loss: 0.5226304
2025-03-28 12:13:33,228 - INFO - Trial 13: Validation set has 128 participants
2025-03-28 12:13:39,453 - INFO - Trial 13: Average Validation Loss: 0.5631, Eval count: 128
2025-03-28 12:13:39,459 - INFO - Trial 14: lr=0.000446, embedding_size=22, n_steps=60
2025-03-28 12:23:58,371 - INFO - Trial 14: RNN Train Loss: 0.3875428
2025-03-28 12:23:58,372 - INFO - Trial 14: Validation set has 128 participants
2025-03-28 12:24:04,129 - INFO - Trial 14: Average Validation Loss: 0.4733, Eval count: 128
2025-03-28 12:24:04,134 - INFO - Trial 15: lr=0.009303, embedding_size=28, n_steps=17
2025-03-28 12:34:52,810 - INFO - Trial 15: RNN Train Loss: 0.2554776
2025-03-28 12:34:52,810 - INFO - Trial 15: Validation set has 128 participants
2025-03-28 12:34:58,388 - INFO - Trial 15: Average Validation Loss: 0.4353, Eval count: 128
2025-03-28 12:34:58,394 - INFO - Trial 16: lr=0.000184, embedding_size=27, n_steps=33
2025-03-28 12:45:29,117 - INFO - Trial 16: RNN Train Loss: 0.3875211
2025-03-28 12:45:29,117 - INFO - Trial 16: Validation set has 128 participants
2025-03-28 12:45:35,200 - INFO - Trial 16: Average Validation Loss: 0.4747, Eval count: 128
2025-03-28 12:45:35,207 - INFO - Trial 17: lr=0.000449, embedding_size=20, n_steps=60
2025-03-28 12:55:51,023 - INFO - Trial 17: RNN Train Loss: 0.3442411
2025-03-28 12:55:51,024 - INFO - Trial 17: Validation set has 128 participants
2025-03-28 12:55:56,727 - INFO - Trial 17: Average Validation Loss: 0.4693, Eval count: 128
2025-03-28 12:55:56,733 - INFO - Trial 18: lr=0.001474, embedding_size=8, n_steps=14
2025-03-28 13:06:26,462 - INFO - Trial 18: RNN Train Loss: 0.2482918
2025-03-28 13:06:26,463 - INFO - Trial 18: Validation set has 128 participants
2025-03-28 13:06:32,595 - INFO - Trial 18: Average Validation Loss: 0.5065, Eval count: 128
2025-03-28 13:06:32,602 - INFO - Trial 19: lr=0.001959, embedding_size=25, n_steps=25
2025-03-28 13:17:02,688 - INFO - Trial 19: RNN Train Loss: 0.2789976
2025-03-28 13:17:02,689 - INFO - Trial 19: Validation set has 128 participants
2025-03-28 13:17:08,893 - INFO - Trial 19: Average Validation Loss: 0.4440, Eval count: 128
2025-03-28 13:17:08,899 - INFO - Trial 20: lr=0.000340, embedding_size=30, n_steps=41
2025-03-28 13:27:37,038 - INFO - Trial 20: RNN Train Loss: 0.3135338
2025-03-28 13:27:37,039 - INFO - Trial 20: Validation set has 128 participants
2025-03-28 13:27:42,994 - INFO - Trial 20: Average Validation Loss: 0.4067, Eval count: 128
2025-03-28 13:27:43,000 - INFO - Trial 21: lr=0.000398, embedding_size=30, n_steps=39
2025-03-28 13:38:13,194 - INFO - Trial 21: RNN Train Loss: 0.4008887
2025-03-28 13:38:13,194 - INFO - Trial 21: Validation set has 128 participants
2025-03-28 13:38:18,811 - INFO - Trial 21: Average Validation Loss: 0.4768, Eval count: 128
2025-03-28 13:38:18,817 - INFO - Trial 22: lr=0.000162, embedding_size=29, n_steps=60
2025-03-28 13:48:42,181 - INFO - Trial 22: RNN Train Loss: 0.3389647
2025-03-28 13:48:42,182 - INFO - Trial 22: Validation set has 128 participants
2025-03-28 13:48:47,800 - INFO - Trial 22: Average Validation Loss: 0.4251, Eval count: 128
2025-03-28 13:48:47,806 - INFO - Trial 23: lr=0.000582, embedding_size=22, n_steps=51
2025-03-28 13:59:05,455 - INFO - Trial 23: RNN Train Loss: 0.2965623
2025-03-28 13:59:05,455 - INFO - Trial 23: Validation set has 128 participants
2025-03-28 13:59:11,239 - INFO - Trial 23: Average Validation Loss: 0.3936, Eval count: 128
2025-03-28 13:59:11,246 - INFO - Trial 24: lr=0.000293, embedding_size=22, n_steps=51
2025-03-28 14:09:29,234 - INFO - Trial 24: RNN Train Loss: 0.3912797
2025-03-28 14:09:29,235 - INFO - Trial 24: Validation set has 128 participants
2025-03-28 14:09:34,823 - INFO - Trial 24: Average Validation Loss: 0.4723, Eval count: 128
2025-03-28 14:09:34,830 - INFO - Trial 25: lr=0.000731, embedding_size=32, n_steps=53
2025-03-28 14:19:55,983 - INFO - Trial 25: RNN Train Loss: 0.2732307
2025-03-28 14:19:55,984 - INFO - Trial 25: Validation set has 128 participants
2025-03-28 14:20:01,579 - INFO - Trial 25: Average Validation Loss: 0.3992, Eval count: 128
2025-03-28 14:20:01,585 - INFO - Trial 26: lr=0.002547, embedding_size=32, n_steps=71
2025-03-28 14:30:12,787 - INFO - Trial 26: RNN Train Loss: 0.3529398
2025-03-28 14:30:12,787 - INFO - Trial 26: Validation set has 128 participants
2025-03-28 14:30:18,957 - INFO - Trial 26: Average Validation Loss: 0.4687, Eval count: 128
2025-03-28 14:30:18,964 - INFO - Trial 27: lr=0.000710, embedding_size=26, n_steps=51
2025-03-28 14:40:34,626 - INFO - Trial 27: RNN Train Loss: 0.3094540
2025-03-28 14:40:34,627 - INFO - Trial 27: Validation set has 128 participants
2025-03-28 14:40:40,678 - INFO - Trial 27: Average Validation Loss: 0.4049, Eval count: 128
2025-03-28 14:40:40,684 - INFO - Trial 28: lr=0.000627, embedding_size=21, n_steps=67
2025-03-28 14:50:57,722 - INFO - Trial 28: RNN Train Loss: 0.4804111
2025-03-28 14:50:57,723 - INFO - Trial 28: Validation set has 128 participants
2025-03-28 14:51:03,421 - INFO - Trial 28: Average Validation Loss: 0.5285, Eval count: 128
2025-03-28 14:51:03,428 - INFO - Trial 29: lr=0.000960, embedding_size=17, n_steps=88
2025-03-28 15:01:25,545 - INFO - Trial 29: RNN Train Loss: 0.3379351
2025-03-28 15:01:25,546 - INFO - Trial 29: Validation set has 128 participants
2025-03-28 15:01:32,509 - INFO - Trial 29: Average Validation Loss: 0.4635, Eval count: 128
2025-03-28 15:01:32,517 - INFO - Trial 30: lr=0.003270, embedding_size=29, n_steps=47
2025-03-28 15:14:32,178 - INFO - Trial 30: RNN Train Loss: 0.3089050
2025-03-28 15:14:32,178 - INFO - Trial 30: Validation set has 128 participants
2025-03-28 15:14:38,654 - INFO - Trial 30: Average Validation Loss: 0.4262, Eval count: 128
2025-03-28 15:14:38,661 - INFO - Trial 31: lr=0.000669, embedding_size=26, n_steps=54
2025-03-28 15:27:08,864 - INFO - Trial 31: RNN Train Loss: 0.2827677
2025-03-28 15:27:08,864 - INFO - Trial 31: Validation set has 128 participants
2025-03-28 15:27:15,385 - INFO - Trial 31: Average Validation Loss: 0.3923, Eval count: 128
2025-03-28 15:27:15,392 - INFO - Trial 32: lr=0.005906, embedding_size=25, n_steps=54
2025-03-28 15:40:18,495 - INFO - Trial 32: RNN Train Loss: 0.2943559
2025-03-28 15:40:18,496 - INFO - Trial 32: Validation set has 128 participants
2025-03-28 15:40:25,898 - INFO - Trial 32: Average Validation Loss: 0.4421, Eval count: 128
2025-03-28 15:40:25,906 - INFO - Trial 33: lr=0.001388, embedding_size=27, n_steps=40
2025-03-28 15:54:33,909 - INFO - Trial 33: RNN Train Loss: 0.3025238
2025-03-28 15:54:33,909 - INFO - Trial 33: Validation set has 128 participants
2025-03-28 15:54:41,037 - INFO - Trial 33: Average Validation Loss: 0.4255, Eval count: 128
2025-03-28 15:54:41,045 - INFO - Trial 34: lr=0.000993, embedding_size=20, n_steps=64
2025-03-28 16:08:14,866 - INFO - Trial 34: RNN Train Loss: 0.3216538
2025-03-28 16:08:14,867 - INFO - Trial 34: Validation set has 128 participants
2025-03-28 16:08:21,910 - INFO - Trial 34: Average Validation Loss: 0.4329, Eval count: 128
2025-03-28 16:08:21,918 - INFO - Trial 35: lr=0.000149, embedding_size=23, n_steps=54
2025-03-28 16:21:52,238 - INFO - Trial 35: RNN Train Loss: 0.3594574
2025-03-28 16:21:52,239 - INFO - Trial 35: Validation set has 128 participants
2025-03-28 16:22:00,148 - INFO - Trial 35: Average Validation Loss: 0.4455, Eval count: 128
2025-03-28 16:22:00,155 - INFO - Trial 36: lr=0.001260, embedding_size=30, n_steps=80
2025-03-28 16:35:42,212 - INFO - Trial 36: RNN Train Loss: 0.2976293
2025-03-28 16:35:42,213 - INFO - Trial 36: Validation set has 128 participants
2025-03-28 16:35:49,808 - INFO - Trial 36: Average Validation Loss: 0.4141, Eval count: 128
2025-03-28 16:35:49,817 - INFO - Trial 37: lr=0.001845, embedding_size=18, n_steps=35
2025-03-28 16:49:38,442 - INFO - Trial 37: RNN Train Loss: 0.2927833
2025-03-28 16:49:38,443 - INFO - Trial 37: Validation set has 128 participants
2025-03-28 16:49:45,421 - INFO - Trial 37: Average Validation Loss: 0.5079, Eval count: 128
2025-03-28 16:49:45,428 - INFO - Trial 38: lr=0.000750, embedding_size=13, n_steps=45
2025-03-28 17:03:25,053 - INFO - Trial 38: RNN Train Loss: 0.2812044
2025-03-28 17:03:25,053 - INFO - Trial 38: Validation set has 128 participants
2025-03-28 17:03:31,928 - INFO - Trial 38: Average Validation Loss: 0.4069, Eval count: 128
2025-03-28 17:03:31,935 - INFO - Trial 39: lr=0.000599, embedding_size=26, n_steps=28
2025-03-28 17:16:29,370 - INFO - Trial 39: RNN Train Loss: 0.3508362
2025-03-28 17:16:29,371 - INFO - Trial 39: Validation set has 128 participants
2025-03-28 17:16:34,977 - INFO - Trial 39: Average Validation Loss: 0.4531, Eval count: 128
2025-03-28 17:16:34,984 - INFO - Trial 40: lr=0.000212, embedding_size=16, n_steps=78
2025-03-28 17:26:37,580 - INFO - Trial 40: RNN Train Loss: 0.3884524
2025-03-28 17:26:37,581 - INFO - Trial 40: Validation set has 128 participants
2025-03-28 17:26:43,898 - INFO - Trial 40: Average Validation Loss: 0.4680, Eval count: 128
2025-03-28 17:26:43,905 - INFO - Trial 41: lr=0.000681, embedding_size=27, n_steps=55
2025-03-28 17:37:34,462 - INFO - Trial 41: RNN Train Loss: 0.3436673
2025-03-28 17:37:34,462 - INFO - Trial 41: Validation set has 128 participants
2025-03-28 17:37:40,183 - INFO - Trial 41: Average Validation Loss: 0.4405, Eval count: 128
2025-03-28 17:37:40,190 - INFO - Trial 42: lr=0.000874, embedding_size=25, n_steps=50
2025-03-28 17:48:25,788 - INFO - Trial 42: RNN Train Loss: 0.2958332
2025-03-28 17:48:25,789 - INFO - Trial 42: Validation set has 128 participants
2025-03-28 17:48:32,838 - INFO - Trial 42: Average Validation Loss: 0.4019, Eval count: 128
2025-03-28 17:48:32,846 - INFO - Trial 43: lr=0.000869, embedding_size=23, n_steps=44
2025-03-28 18:00:05,080 - INFO - Trial 43: RNN Train Loss: 0.3837501
2025-03-28 18:00:05,081 - INFO - Trial 43: Validation set has 128 participants
2025-03-28 18:00:11,064 - INFO - Trial 43: Average Validation Loss: 0.4824, Eval count: 128
2025-03-28 18:00:11,071 - INFO - Trial 44: lr=0.001043, embedding_size=24, n_steps=66
2025-03-28 18:11:17,595 - INFO - Trial 44: RNN Train Loss: 0.4123015
2025-03-28 18:11:17,596 - INFO - Trial 44: Validation set has 128 participants
2025-03-28 18:11:23,837 - INFO - Trial 44: Average Validation Loss: 0.4935, Eval count: 128
2025-03-28 18:11:23,844 - INFO - Trial 45: lr=0.000369, embedding_size=25, n_steps=48
2025-03-28 18:23:00,307 - INFO - Trial 45: RNN Train Loss: 0.3218735
2025-03-28 18:23:00,307 - INFO - Trial 45: Validation set has 128 participants
2025-03-28 18:23:06,496 - INFO - Trial 45: Average Validation Loss: 0.4216, Eval count: 128
2025-03-28 18:23:06,504 - INFO - Trial 46: lr=0.000510, embedding_size=28, n_steps=57
2025-03-28 18:35:22,106 - INFO - Trial 46: RNN Train Loss: 0.3003217
2025-03-28 18:35:22,107 - INFO - Trial 46: Validation set has 128 participants
2025-03-28 18:35:28,513 - INFO - Trial 46: Average Validation Loss: 0.4174, Eval count: 128
2025-03-28 18:35:28,521 - INFO - Trial 47: lr=0.000232, embedding_size=22, n_steps=36
2025-03-28 18:48:03,939 - INFO - Trial 47: RNN Train Loss: 0.2841730
2025-03-28 18:48:03,940 - INFO - Trial 47: Validation set has 128 participants
2025-03-28 18:48:10,407 - INFO - Trial 47: Average Validation Loss: 0.3829, Eval count: 128
2025-03-28 18:48:10,415 - INFO - Trial 48: lr=0.000214, embedding_size=21, n_steps=29
2025-03-28 19:00:17,463 - INFO - Trial 48: RNN Train Loss: 0.3708983
2025-03-28 19:00:17,463 - INFO - Trial 48: Validation set has 128 participants
2025-03-28 19:00:23,222 - INFO - Trial 48: Average Validation Loss: 0.4526, Eval count: 128
2025-03-28 19:00:23,229 - INFO - Trial 49: lr=0.000123, embedding_size=19, n_steps=37
2025-03-28 19:10:40,367 - INFO - Trial 49: RNN Train Loss: 0.3852634
2025-03-28 19:10:40,368 - INFO - Trial 49: Validation set has 128 participants
2025-03-28 19:10:46,516 - INFO - Trial 49: Average Validation Loss: 0.4541, Eval count: 128
2025-03-28 19:10:46,517 - INFO - Best hyperparameters: {'learning_rate': 0.0002319349038571159, 'embedding_size': 22, 'n_steps': 36}
2025-03-28 19:10:46,517 - INFO - Best validation loss: 0.3829
2025-03-28 19:21:11,699 - INFO - Final RNN training loss: 0.3051871
2025-03-28 19:21:11,699 - INFO - Evaluating with SINDy - fitting separate models for each participant's validation trials
2025-03-28 19:21:11,699 - INFO - Processing participant 0.0...
2025-03-28 19:21:11,699 - INFO - Fitting SINDy model for participant 0.0
2025-03-28 19:21:13,258 - INFO - Participant 0.0: LL=-0.3812, BIC=1.5130, Params=11, Val trials=60
2025-03-28 19:21:13,258 - INFO - Processing participant 1.0...
2025-03-28 19:21:13,259 - INFO - Fitting SINDy model for participant 1.0
2025-03-28 19:21:14,807 - INFO - Participant 1.0: LL=-0.0141, BIC=0.7788, Params=11, Val trials=60
2025-03-28 19:21:14,807 - INFO - Processing participant 2.0...
2025-03-28 19:21:14,808 - INFO - Fitting SINDy model for participant 2.0
2025-03-28 19:21:16,346 - INFO - Participant 2.0: LL=-0.6139, BIC=1.9785, Params=11, Val trials=60
2025-03-28 19:21:16,346 - INFO - Processing participant 3.0...
2025-03-28 19:21:16,346 - INFO - Fitting SINDy model for participant 3.0
2025-03-28 19:21:17,876 - INFO - Participant 3.0: LL=-0.6897, BIC=2.1300, Params=11, Val trials=60
2025-03-28 19:21:17,876 - INFO - Processing participant 4.0...
2025-03-28 19:21:17,877 - INFO - Fitting SINDy model for participant 4.0
2025-03-28 19:21:19,386 - INFO - Participant 4.0: LL=-0.4546, BIC=1.6598, Params=11, Val trials=60
2025-03-28 19:21:19,386 - INFO - Processing participant 5.0...
2025-03-28 19:21:19,386 - INFO - Fitting SINDy model for participant 5.0
2025-03-28 19:21:20,921 - INFO - Participant 5.0: LL=-0.6629, BIC=2.0764, Params=11, Val trials=60
2025-03-28 19:21:20,921 - INFO - Processing participant 6.0...
2025-03-28 19:21:20,922 - INFO - Fitting SINDy model for participant 6.0
2025-03-28 19:21:22,395 - INFO - Participant 6.0: LL=-0.0252, BIC=0.8011, Params=11, Val trials=60
2025-03-28 19:21:22,395 - INFO - Processing participant 7.0...
2025-03-28 19:21:22,396 - INFO - Fitting SINDy model for participant 7.0
2025-03-28 19:21:23,934 - INFO - Participant 7.0: LL=-0.1564, BIC=0.9953, Params=10, Val trials=60
2025-03-28 19:21:23,934 - INFO - Processing participant 8.0...
2025-03-28 19:21:23,934 - INFO - Fitting SINDy model for participant 8.0
2025-03-28 19:21:25,527 - INFO - Participant 8.0: LL=-0.0215, BIC=0.6571, Params=9, Val trials=60
2025-03-28 19:21:25,527 - INFO - Processing participant 9.0...
2025-03-28 19:21:25,527 - INFO - Fitting SINDy model for participant 9.0
2025-03-28 19:21:27,013 - INFO - Participant 9.0: LL=-0.2135, BIC=1.1094, Params=10, Val trials=60
2025-03-28 19:21:27,013 - INFO - Processing participant 10.0...
2025-03-28 19:21:27,014 - INFO - Fitting SINDy model for participant 10.0
2025-03-28 19:21:28,675 - INFO - Participant 10.0: LL=-0.4007, BIC=1.5519, Params=11, Val trials=60
2025-03-28 19:21:28,675 - INFO - Processing participant 11.0...
2025-03-28 19:21:28,676 - INFO - Fitting SINDy model for participant 11.0
2025-03-28 19:21:30,289 - INFO - Participant 11.0: LL=-0.2531, BIC=1.1886, Params=10, Val trials=60
2025-03-28 19:21:30,289 - INFO - Processing participant 12.0...
2025-03-28 19:21:30,289 - INFO - Fitting SINDy model for participant 12.0
2025-03-28 19:21:31,818 - INFO - Participant 12.0: LL=-0.0407, BIC=0.8320, Params=11, Val trials=60
2025-03-28 19:21:31,818 - INFO - Processing participant 13.0...
2025-03-28 19:21:31,819 - INFO - Fitting SINDy model for participant 13.0
2025-03-28 19:21:33,352 - INFO - Participant 13.0: LL=-0.6952, BIC=2.0728, Params=10, Val trials=60
2025-03-28 19:21:33,352 - INFO - Processing participant 14.0...
2025-03-28 19:21:33,353 - INFO - Fitting SINDy model for participant 14.0
2025-03-28 19:21:34,814 - INFO - Participant 14.0: LL=-0.7119, BIC=2.1744, Params=11, Val trials=60
2025-03-28 19:21:34,815 - INFO - Processing participant 15.0...
2025-03-28 19:21:34,815 - INFO - Fitting SINDy model for participant 15.0
2025-03-28 19:21:36,351 - INFO - Participant 15.0: LL=-0.4495, BIC=1.4450, Params=8, Val trials=60
2025-03-28 19:21:36,351 - INFO - Processing participant 16.0...
2025-03-28 19:21:36,351 - INFO - Fitting SINDy model for participant 16.0
2025-03-28 19:21:37,871 - INFO - Participant 16.0: LL=-0.1754, BIC=1.1697, Params=12, Val trials=60
2025-03-28 19:21:37,872 - INFO - Processing participant 17.0...
2025-03-28 19:21:37,872 - INFO - Fitting SINDy model for participant 17.0
2025-03-28 19:21:39,402 - INFO - Participant 17.0: LL=-0.1410, BIC=1.0326, Params=11, Val trials=60
2025-03-28 19:21:39,402 - INFO - Processing participant 18.0...
2025-03-28 19:21:39,402 - INFO - Fitting SINDy model for participant 18.0
2025-03-28 19:21:40,895 - INFO - Participant 18.0: LL=-0.7581, BIC=2.2669, Params=11, Val trials=60
2025-03-28 19:21:40,895 - INFO - Processing participant 19.0...
2025-03-28 19:21:40,896 - INFO - Fitting SINDy model for participant 19.0
2025-03-28 19:21:42,545 - INFO - Participant 19.0: LL=-0.1719, BIC=1.2308, Params=13, Val trials=60
2025-03-28 19:21:42,545 - INFO - Processing participant 20.0...
2025-03-28 19:21:42,545 - INFO - Fitting SINDy model for participant 20.0
2025-03-28 19:21:44,197 - INFO - Participant 20.0: LL=-1.3526, BIC=3.4558, Params=11, Val trials=60
2025-03-28 19:21:44,197 - INFO - Processing participant 21.0...
2025-03-28 19:21:44,198 - INFO - Fitting SINDy model for participant 21.0
2025-03-28 19:21:45,855 - INFO - Participant 21.0: LL=-0.0253, BIC=0.7330, Params=10, Val trials=60
2025-03-28 19:21:45,855 - INFO - Processing participant 22.0...
2025-03-28 19:21:45,855 - INFO - Fitting SINDy model for participant 22.0
2025-03-28 19:21:47,444 - INFO - Participant 22.0: LL=-0.3886, BIC=1.6642, Params=13, Val trials=60
2025-03-28 19:21:47,444 - INFO - Processing participant 23.0...
2025-03-28 19:21:47,444 - INFO - Fitting SINDy model for participant 23.0
2025-03-28 19:21:49,079 - INFO - Participant 23.0: LL=-0.6931, BIC=2.1369, Params=11, Val trials=60
2025-03-28 19:21:49,079 - INFO - Processing participant 24.0...
2025-03-28 19:21:49,079 - INFO - Fitting SINDy model for participant 24.0
2025-03-28 19:21:50,731 - INFO - Participant 24.0: LL=-0.8123, BIC=2.3753, Params=11, Val trials=60
2025-03-28 19:21:50,731 - INFO - Processing participant 25.0...
2025-03-28 19:21:50,732 - INFO - Fitting SINDy model for participant 25.0
2025-03-28 19:21:52,296 - INFO - Participant 25.0: LL=-0.5111, BIC=1.7046, Params=10, Val trials=60
2025-03-28 19:21:52,296 - INFO - Processing participant 26.0...
2025-03-28 19:21:52,297 - INFO - Fitting SINDy model for participant 26.0
2025-03-28 19:21:53,749 - INFO - Participant 26.0: LL=-0.6595, BIC=2.0695, Params=11, Val trials=60
2025-03-28 19:21:53,749 - INFO - Processing participant 27.0...
2025-03-28 19:21:53,750 - INFO - Fitting SINDy model for participant 27.0
2025-03-28 19:21:55,296 - INFO - Participant 27.0: LL=-0.0259, BIC=0.7342, Params=10, Val trials=60
2025-03-28 19:21:55,296 - INFO - Processing participant 28.0...
2025-03-28 19:21:55,297 - INFO - Fitting SINDy model for participant 28.0
2025-03-28 19:21:56,924 - INFO - Participant 28.0: LL=-0.0201, BIC=0.8591, Params=12, Val trials=60
2025-03-28 19:21:56,924 - INFO - Processing participant 29.0...
2025-03-28 19:21:56,925 - INFO - Fitting SINDy model for participant 29.0
2025-03-28 19:21:58,574 - INFO - Participant 29.0: LL=-0.7727, BIC=2.2960, Params=11, Val trials=60
2025-03-28 19:21:58,574 - INFO - Processing participant 30.0...
2025-03-28 19:21:58,574 - INFO - Fitting SINDy model for participant 30.0
2025-03-28 19:22:00,133 - INFO - Participant 30.0: LL=-0.1622, BIC=1.0069, Params=10, Val trials=60
2025-03-28 19:22:00,133 - INFO - Processing participant 31.0...
2025-03-28 19:22:00,134 - INFO - Fitting SINDy model for participant 31.0
2025-03-28 19:22:01,655 - INFO - Participant 31.0: LL=-2.0493, BIC=4.7811, Params=10, Val trials=60
2025-03-28 19:22:01,655 - INFO - Processing participant 32.0...
2025-03-28 19:22:01,656 - INFO - Fitting SINDy model for participant 32.0
2025-03-28 19:22:03,249 - INFO - Participant 32.0: LL=-0.6931, BIC=2.0687, Params=10, Val trials=60
2025-03-28 19:22:03,249 - INFO - Processing participant 33.0...
2025-03-28 19:22:03,249 - INFO - Fitting SINDy model for participant 33.0
2025-03-28 19:22:04,692 - INFO - Participant 33.0: LL=-0.4898, BIC=1.6620, Params=10, Val trials=60
2025-03-28 19:22:04,692 - INFO - Processing participant 34.0...
2025-03-28 19:22:04,693 - INFO - Fitting SINDy model for participant 34.0
2025-03-28 19:22:06,236 - INFO - Participant 34.0: LL=-0.1507, BIC=0.8473, Params=8, Val trials=60
2025-03-28 19:22:06,236 - INFO - Processing participant 35.0...
2025-03-28 19:22:06,237 - INFO - Fitting SINDy model for participant 35.0
2025-03-28 19:22:07,851 - INFO - Participant 35.0: LL=-0.6869, BIC=2.3291, Params=14, Val trials=60
2025-03-28 19:22:07,851 - INFO - Processing participant 36.0...
2025-03-28 19:22:07,851 - INFO - Fitting SINDy model for participant 36.0
2025-03-28 19:22:09,484 - INFO - Participant 36.0: LL=-0.7099, BIC=2.1021, Params=10, Val trials=60
2025-03-28 19:22:09,485 - INFO - Processing participant 37.0...
2025-03-28 19:22:09,485 - INFO - Fitting SINDy model for participant 37.0
2025-03-28 19:22:11,139 - INFO - Participant 37.0: LL=-0.0231, BIC=0.7969, Params=11, Val trials=60
2025-03-28 19:22:11,139 - INFO - Processing participant 38.0...
2025-03-28 19:22:11,140 - INFO - Fitting SINDy model for participant 38.0
2025-03-28 19:22:12,685 - INFO - Participant 38.0: LL=-0.1648, BIC=1.0803, Params=11, Val trials=60
2025-03-28 19:22:12,685 - INFO - Processing participant 39.0...
2025-03-28 19:22:12,686 - INFO - Fitting SINDy model for participant 39.0
2025-03-28 19:22:14,219 - INFO - Participant 39.0: LL=-0.0162, BIC=0.7830, Params=11, Val trials=60
2025-03-28 19:22:14,219 - INFO - Processing participant 40.0...
2025-03-28 19:22:14,220 - INFO - Fitting SINDy model for participant 40.0
2025-03-28 19:22:15,857 - INFO - Participant 40.0: LL=-0.5445, BIC=1.8397, Params=11, Val trials=60
2025-03-28 19:22:15,857 - INFO - Processing participant 41.0...
2025-03-28 19:22:15,858 - INFO - Fitting SINDy model for participant 41.0
2025-03-28 19:22:17,389 - INFO - Participant 41.0: LL=-4.8994, BIC=10.6176, Params=12, Val trials=60
2025-03-28 19:22:17,389 - INFO - Processing participant 42.0...
2025-03-28 19:22:17,389 - INFO - Fitting SINDy model for participant 42.0
2025-03-28 19:22:18,942 - INFO - Participant 42.0: LL=-7.0909, BIC=15.0690, Params=13, Val trials=60
2025-03-28 19:22:18,942 - INFO - Processing participant 43.0...
2025-03-28 19:22:18,943 - INFO - Fitting SINDy model for participant 43.0
2025-03-28 19:22:20,575 - INFO - Participant 43.0: LL=-4.1239, BIC=8.9985, Params=11, Val trials=60
2025-03-28 19:22:20,575 - INFO - Processing participant 44.0...
2025-03-28 19:22:20,576 - INFO - Fitting SINDy model for participant 44.0
2025-03-28 19:22:22,178 - INFO - Participant 44.0: LL=-0.0178, BIC=0.7863, Params=11, Val trials=60
2025-03-28 19:22:22,178 - INFO - Processing participant 45.0...
2025-03-28 19:22:22,179 - INFO - Fitting SINDy model for participant 45.0
2025-03-28 19:22:23,669 - INFO - Participant 45.0: LL=-1.1236, BIC=3.1343, Params=13, Val trials=60
2025-03-28 19:22:23,669 - INFO - Processing participant 46.0...
2025-03-28 19:22:23,669 - INFO - Fitting SINDy model for participant 46.0
2025-03-28 19:22:25,127 - INFO - Participant 46.0: LL=-0.3135, BIC=1.4459, Params=12, Val trials=60
2025-03-28 19:22:25,127 - INFO - Processing participant 47.0...
2025-03-28 19:22:25,127 - INFO - Fitting SINDy model for participant 47.0
2025-03-28 19:22:26,641 - INFO - Participant 47.0: LL=-0.6500, BIC=1.9823, Params=10, Val trials=60
2025-03-28 19:22:26,641 - INFO - Processing participant 48.0...
2025-03-28 19:22:26,642 - INFO - Fitting SINDy model for participant 48.0
2025-03-28 19:22:28,246 - INFO - Participant 48.0: LL=-0.7017, BIC=2.2223, Params=12, Val trials=60
2025-03-28 19:22:28,247 - INFO - Processing participant 49.0...
2025-03-28 19:22:28,247 - INFO - Fitting SINDy model for participant 49.0
2025-03-28 19:22:29,794 - INFO - Participant 49.0: LL=-0.6931, BIC=2.2734, Params=13, Val trials=60
2025-03-28 19:22:29,794 - INFO - Processing participant 50.0...
2025-03-28 19:22:29,795 - INFO - Fitting SINDy model for participant 50.0
2025-03-28 19:22:31,364 - INFO - Participant 50.0: LL=-0.2372, BIC=1.2251, Params=11, Val trials=60
2025-03-28 19:22:31,364 - INFO - Processing participant 51.0...
2025-03-28 19:22:31,364 - INFO - Fitting SINDy model for participant 51.0
2025-03-28 19:22:32,895 - INFO - Participant 51.0: LL=-0.0322, BIC=0.8151, Params=11, Val trials=60
2025-03-28 19:22:32,895 - INFO - Processing participant 52.0...
2025-03-28 19:22:32,896 - INFO - Fitting SINDy model for participant 52.0
2025-03-28 19:22:34,398 - INFO - Participant 52.0: LL=-0.6097, BIC=1.9018, Params=10, Val trials=60
2025-03-28 19:22:34,398 - INFO - Processing participant 53.0...
2025-03-28 19:22:34,399 - INFO - Fitting SINDy model for participant 53.0
2025-03-28 19:22:35,908 - INFO - Participant 53.0: LL=-0.2363, BIC=1.2914, Params=12, Val trials=60
2025-03-28 19:22:35,908 - INFO - Processing participant 54.0...
2025-03-28 19:22:35,909 - INFO - Fitting SINDy model for participant 54.0
2025-03-28 19:22:37,344 - INFO - Participant 54.0: LL=-6.1769, BIC=13.2409, Params=13, Val trials=60
2025-03-28 19:22:37,344 - INFO - Processing participant 55.0...
2025-03-28 19:22:37,345 - INFO - Fitting SINDy model for participant 55.0
2025-03-28 19:22:38,872 - INFO - Participant 55.0: LL=-0.2450, BIC=1.1723, Params=10, Val trials=60
2025-03-28 19:22:38,872 - INFO - Processing participant 56.0...
2025-03-28 19:22:38,872 - INFO - Fitting SINDy model for participant 56.0
2025-03-28 19:22:40,459 - INFO - Participant 56.0: LL=-0.4119, BIC=1.5062, Params=10, Val trials=60
2025-03-28 19:22:40,459 - INFO - Processing participant 57.0...
2025-03-28 19:22:40,460 - INFO - Fitting SINDy model for participant 57.0
2025-03-28 19:22:41,994 - INFO - Participant 57.0: LL=-0.6931, BIC=2.2052, Params=12, Val trials=60
2025-03-28 19:22:41,994 - INFO - Processing participant 58.0...
2025-03-28 19:22:41,995 - INFO - Fitting SINDy model for participant 58.0
2025-03-28 19:22:43,490 - INFO - Participant 58.0: LL=-0.1710, BIC=1.0244, Params=10, Val trials=60
2025-03-28 19:22:43,490 - INFO - Processing participant 59.0...
2025-03-28 19:22:43,490 - INFO - Fitting SINDy model for participant 59.0
2025-03-28 19:22:44,999 - INFO - Participant 59.0: LL=-0.6880, BIC=1.8536, Params=7, Val trials=60
2025-03-28 19:22:44,999 - INFO - Processing participant 60.0...
2025-03-28 19:22:44,999 - INFO - Fitting SINDy model for participant 60.0
2025-03-28 19:22:46,584 - INFO - Participant 60.0: LL=-0.1614, BIC=1.0735, Params=11, Val trials=60
2025-03-28 19:22:46,584 - INFO - Processing participant 61.0...
2025-03-28 19:22:46,584 - INFO - Fitting SINDy model for participant 61.0
2025-03-28 19:22:48,234 - INFO - Participant 61.0: LL=-0.6267, BIC=1.9358, Params=10, Val trials=60
2025-03-28 19:22:48,235 - INFO - Processing participant 62.0...
2025-03-28 19:22:48,235 - INFO - Fitting SINDy model for participant 62.0
2025-03-28 19:22:49,818 - INFO - Participant 62.0: LL=-3.5640, BIC=7.9469, Params=12, Val trials=60
2025-03-28 19:22:49,818 - INFO - Processing participant 63.0...
2025-03-28 19:22:49,819 - INFO - Fitting SINDy model for participant 63.0
2025-03-28 19:22:51,508 - INFO - Participant 63.0: LL=-0.0383, BIC=0.7589, Params=10, Val trials=60
2025-03-28 19:22:51,508 - INFO - Processing participant 64.0...
2025-03-28 19:22:51,509 - INFO - Fitting SINDy model for participant 64.0
2025-03-28 19:22:53,129 - INFO - Participant 64.0: LL=-0.9672, BIC=2.6168, Params=10, Val trials=60
2025-03-28 19:22:53,129 - INFO - Processing participant 65.0...
2025-03-28 19:22:53,130 - INFO - Fitting SINDy model for participant 65.0
2025-03-28 19:22:54,771 - INFO - Participant 65.0: LL=-0.3890, BIC=1.4605, Params=10, Val trials=60
2025-03-28 19:22:54,771 - INFO - Processing participant 66.0...
2025-03-28 19:22:54,771 - INFO - Fitting SINDy model for participant 66.0
2025-03-28 19:22:56,351 - INFO - Participant 66.0: LL=-0.2633, BIC=1.2090, Params=10, Val trials=60
2025-03-28 19:22:56,352 - INFO - Processing participant 67.0...
2025-03-28 19:22:56,352 - INFO - Fitting SINDy model for participant 67.0
2025-03-28 19:22:57,988 - INFO - Participant 67.0: LL=-0.5257, BIC=1.7338, Params=10, Val trials=60
2025-03-28 19:22:57,988 - INFO - Processing participant 68.0...
2025-03-28 19:22:57,988 - INFO - Fitting SINDy model for participant 68.0
2025-03-28 19:22:59,617 - INFO - Participant 68.0: LL=-0.0227, BIC=0.5913, Params=8, Val trials=60
2025-03-28 19:22:59,617 - INFO - Processing participant 69.0...
2025-03-28 19:22:59,618 - INFO - Fitting SINDy model for participant 69.0
2025-03-28 19:23:01,252 - INFO - Participant 69.0: LL=-0.2680, BIC=1.2866, Params=11, Val trials=60
2025-03-28 19:23:01,252 - INFO - Processing participant 70.0...
2025-03-28 19:23:01,253 - INFO - Fitting SINDy model for participant 70.0
2025-03-28 19:23:02,820 - INFO - Participant 70.0: LL=-0.4741, BIC=1.6988, Params=11, Val trials=60
2025-03-28 19:23:02,820 - INFO - Processing participant 71.0...
2025-03-28 19:23:02,821 - INFO - Fitting SINDy model for participant 71.0
2025-03-28 19:23:04,414 - INFO - Participant 71.0: LL=-0.0354, BIC=0.8214, Params=11, Val trials=60
2025-03-28 19:23:04,414 - INFO - Processing participant 72.0...
2025-03-28 19:23:04,415 - INFO - Fitting SINDy model for participant 72.0
2025-03-28 19:23:05,909 - INFO - Participant 72.0: LL=-0.0142, BIC=0.7108, Params=10, Val trials=60
2025-03-28 19:23:05,909 - INFO - Processing participant 73.0...
2025-03-28 19:23:05,910 - INFO - Fitting SINDy model for participant 73.0
2025-03-28 19:23:07,419 - INFO - Participant 73.0: LL=-0.7514, BIC=2.1851, Params=10, Val trials=60
2025-03-28 19:23:07,419 - INFO - Processing participant 74.0...
2025-03-28 19:23:07,420 - INFO - Fitting SINDy model for participant 74.0
2025-03-28 19:23:08,858 - INFO - Participant 74.0: LL=-0.7146, BIC=2.2482, Params=12, Val trials=60
2025-03-28 19:23:08,858 - INFO - Processing participant 75.0...
2025-03-28 19:23:08,858 - INFO - Fitting SINDy model for participant 75.0
2025-03-28 19:23:10,369 - INFO - Participant 75.0: LL=-0.2490, BIC=1.4533, Params=14, Val trials=60
2025-03-28 19:23:10,369 - INFO - Processing participant 76.0...
2025-03-28 19:23:10,370 - INFO - Fitting SINDy model for participant 76.0
2025-03-28 19:23:11,965 - INFO - Participant 76.0: LL=-0.1431, BIC=0.7639, Params=7, Val trials=60
2025-03-28 19:23:11,965 - INFO - Processing participant 77.0...
2025-03-28 19:23:11,965 - INFO - Fitting SINDy model for participant 77.0
2025-03-28 19:23:13,451 - INFO - Participant 77.0: LL=-0.1896, BIC=0.9251, Params=8, Val trials=60
2025-03-28 19:23:13,451 - INFO - Processing participant 78.0...
2025-03-28 19:23:13,451 - INFO - Fitting SINDy model for participant 78.0
2025-03-28 19:23:14,897 - INFO - Participant 78.0: LL=-0.7376, BIC=2.2259, Params=11, Val trials=60
2025-03-28 19:23:14,898 - INFO - Processing participant 79.0...
2025-03-28 19:23:14,898 - INFO - Fitting SINDy model for participant 79.0
2025-03-28 19:23:16,404 - INFO - Participant 79.0: LL=-0.4886, BIC=1.7279, Params=11, Val trials=60
2025-03-28 19:23:16,404 - INFO - Processing participant 80.0...
2025-03-28 19:23:16,405 - INFO - Fitting SINDy model for participant 80.0
2025-03-28 19:23:17,957 - INFO - Participant 80.0: LL=-3.6271, BIC=8.0048, Params=11, Val trials=60
2025-03-28 19:23:17,957 - INFO - Processing participant 81.0...
2025-03-28 19:23:17,958 - INFO - Fitting SINDy model for participant 81.0
2025-03-28 19:23:19,514 - INFO - Participant 81.0: LL=-0.0144, BIC=0.7111, Params=10, Val trials=60
2025-03-28 19:23:19,514 - INFO - Processing participant 82.0...
2025-03-28 19:23:19,514 - INFO - Fitting SINDy model for participant 82.0
2025-03-28 19:23:21,147 - INFO - Participant 82.0: LL=-1.1117, BIC=2.9058, Params=10, Val trials=60
2025-03-28 19:23:21,147 - INFO - Processing participant 83.0...
2025-03-28 19:23:21,147 - INFO - Fitting SINDy model for participant 83.0
2025-03-28 19:23:22,792 - INFO - Participant 83.0: LL=-0.1630, BIC=1.1449, Params=12, Val trials=60
2025-03-28 19:23:22,793 - INFO - Processing participant 84.0...
2025-03-28 19:23:22,793 - INFO - Fitting SINDy model for participant 84.0
2025-03-28 19:23:24,429 - INFO - Participant 84.0: LL=-0.9036, BIC=2.5579, Params=11, Val trials=60
2025-03-28 19:23:24,429 - INFO - Processing participant 85.0...
2025-03-28 19:23:24,429 - INFO - Fitting SINDy model for participant 85.0
2025-03-28 19:23:26,118 - INFO - Participant 85.0: LL=-0.0515, BIC=0.9218, Params=12, Val trials=60
2025-03-28 19:23:26,118 - INFO - Processing participant 86.0...
2025-03-28 19:23:26,119 - INFO - Fitting SINDy model for participant 86.0
2025-03-28 19:23:27,688 - INFO - Participant 86.0: LL=-0.4895, BIC=1.6613, Params=10, Val trials=60
2025-03-28 19:23:27,688 - INFO - Processing participant 87.0...
2025-03-28 19:23:27,689 - INFO - Fitting SINDy model for participant 87.0
2025-03-28 19:23:29,324 - INFO - Participant 87.0: LL=-0.2217, BIC=1.3305, Params=13, Val trials=60
2025-03-28 19:23:29,324 - INFO - Processing participant 88.0...
2025-03-28 19:23:29,325 - INFO - Fitting SINDy model for participant 88.0
2025-03-28 19:23:30,967 - INFO - Participant 88.0: LL=-0.7066, BIC=2.0956, Params=10, Val trials=60
2025-03-28 19:23:30,967 - INFO - Processing participant 89.0...
2025-03-28 19:23:30,967 - INFO - Fitting SINDy model for participant 89.0
2025-03-28 19:23:32,609 - INFO - Participant 89.0: LL=-0.6931, BIC=2.2734, Params=13, Val trials=60
2025-03-28 19:23:32,609 - INFO - Processing participant 90.0...
2025-03-28 19:23:32,610 - INFO - Fitting SINDy model for participant 90.0
2025-03-28 19:23:34,174 - INFO - Participant 90.0: LL=-0.1323, BIC=0.9470, Params=10, Val trials=60
2025-03-28 19:23:34,174 - INFO - Processing participant 91.0...
2025-03-28 19:23:34,175 - INFO - Fitting SINDy model for participant 91.0
2025-03-28 19:23:35,793 - INFO - Participant 91.0: LL=-0.1799, BIC=1.1104, Params=11, Val trials=60
2025-03-28 19:23:35,793 - INFO - Processing participant 92.0...
2025-03-28 19:23:35,794 - INFO - Fitting SINDy model for participant 92.0
2025-03-28 19:23:37,382 - INFO - Participant 92.0: LL=-0.6869, BIC=2.1244, Params=11, Val trials=60
2025-03-28 19:23:37,382 - INFO - Processing participant 93.0...
2025-03-28 19:23:37,383 - INFO - Fitting SINDy model for participant 93.0
2025-03-28 19:23:38,953 - INFO - Participant 93.0: LL=-0.4593, BIC=1.6693, Params=11, Val trials=60
2025-03-28 19:23:38,953 - INFO - Processing participant 94.0...
2025-03-28 19:23:38,954 - INFO - Fitting SINDy model for participant 94.0
2025-03-28 19:23:40,488 - INFO - Participant 94.0: LL=-0.5467, BIC=1.5711, Params=7, Val trials=60
2025-03-28 19:23:40,488 - INFO - Processing participant 95.0...
2025-03-28 19:23:40,488 - INFO - Fitting SINDy model for participant 95.0
2025-03-28 19:23:41,984 - INFO - Participant 95.0: LL=-0.2963, BIC=1.4115, Params=12, Val trials=60
2025-03-28 19:23:41,984 - INFO - Processing participant 96.0...
2025-03-28 19:23:41,984 - INFO - Fitting SINDy model for participant 96.0
2025-03-28 19:23:43,491 - INFO - Participant 96.0: LL=-0.5750, BIC=1.9689, Params=12, Val trials=60
2025-03-28 19:23:43,491 - INFO - Processing participant 97.0...
2025-03-28 19:23:43,492 - INFO - Fitting SINDy model for participant 97.0
2025-03-28 19:23:45,029 - INFO - Participant 97.0: LL=-0.6777, BIC=2.0378, Params=10, Val trials=60
2025-03-28 19:23:45,029 - INFO - Processing participant 98.0...
2025-03-28 19:23:45,030 - INFO - Fitting SINDy model for participant 98.0
2025-03-28 19:23:46,459 - INFO - Participant 98.0: LL=-0.1624, BIC=1.1438, Params=12, Val trials=60
2025-03-28 19:23:46,459 - INFO - Processing participant 99.0...
2025-03-28 19:23:46,460 - INFO - Fitting SINDy model for participant 99.0
2025-03-28 19:23:47,957 - INFO - Participant 99.0: LL=-0.3131, BIC=1.3768, Params=11, Val trials=60
2025-03-28 19:23:47,957 - INFO - Processing participant 100.0...
2025-03-28 19:23:47,957 - INFO - Fitting SINDy model for participant 100.0
2025-03-28 19:23:49,461 - INFO - Participant 100.0: LL=-0.0247, BIC=0.8000, Params=11, Val trials=60
2025-03-28 19:23:49,461 - INFO - Processing participant 101.0...
2025-03-28 19:23:49,462 - INFO - Fitting SINDy model for participant 101.0
2025-03-28 19:23:51,019 - INFO - Participant 101.0: LL=-0.0141, BIC=0.7105, Params=10, Val trials=60
2025-03-28 19:23:51,019 - INFO - Processing participant 102.0...
2025-03-28 19:23:51,019 - INFO - Fitting SINDy model for participant 102.0
2025-03-28 19:23:52,457 - INFO - Participant 102.0: LL=-0.6002, BIC=1.6780, Params=7, Val trials=60
2025-03-28 19:23:52,458 - INFO - Processing participant 103.0...
2025-03-28 19:23:52,458 - INFO - Fitting SINDy model for participant 103.0
2025-03-28 19:23:53,980 - INFO - Participant 103.0: LL=-0.2463, BIC=1.0386, Params=8, Val trials=60
2025-03-28 19:23:53,980 - INFO - Processing participant 104.0...
2025-03-28 19:23:53,980 - INFO - Fitting SINDy model for participant 104.0
2025-03-28 19:23:55,596 - INFO - Participant 104.0: LL=-0.5428, BIC=1.6315, Params=8, Val trials=60
2025-03-28 19:23:55,596 - INFO - Processing participant 105.0...
2025-03-28 19:23:55,596 - INFO - Fitting SINDy model for participant 105.0
2025-03-28 19:23:57,127 - INFO - Participant 105.0: LL=-2.9055, BIC=6.6298, Params=12, Val trials=60
2025-03-28 19:23:57,128 - INFO - Processing participant 106.0...
2025-03-28 19:23:57,128 - INFO - Fitting SINDy model for participant 106.0
2025-03-28 19:23:58,631 - INFO - Participant 106.0: LL=-0.6886, BIC=2.1279, Params=11, Val trials=60
2025-03-28 19:23:58,631 - INFO - Processing participant 107.0...
2025-03-28 19:23:58,631 - INFO - Fitting SINDy model for participant 107.0
2025-03-28 19:24:00,149 - INFO - Participant 107.0: LL=-0.7061, BIC=2.0946, Params=10, Val trials=60
2025-03-28 19:24:00,149 - INFO - Processing participant 108.0...
2025-03-28 19:24:00,149 - INFO - Fitting SINDy model for participant 108.0
2025-03-28 19:24:01,645 - INFO - Participant 108.0: LL=-0.1889, BIC=1.1284, Params=11, Val trials=60
2025-03-28 19:24:01,645 - INFO - Processing participant 109.0...
2025-03-28 19:24:01,645 - INFO - Fitting SINDy model for participant 109.0
2025-03-28 19:24:03,147 - INFO - Participant 109.0: LL=-0.7731, BIC=2.4333, Params=13, Val trials=60
2025-03-28 19:24:03,147 - INFO - Processing participant 110.0...
2025-03-28 19:24:03,148 - INFO - Fitting SINDy model for participant 110.0
2025-03-28 19:24:04,583 - INFO - Participant 110.0: LL=-0.1889, BIC=1.1285, Params=11, Val trials=60
2025-03-28 19:24:04,584 - INFO - Processing participant 111.0...
2025-03-28 19:24:04,584 - INFO - Fitting SINDy model for participant 111.0
2025-03-28 19:24:06,146 - INFO - Participant 111.0: LL=-0.1290, BIC=0.9404, Params=10, Val trials=60
2025-03-28 19:24:06,146 - INFO - Processing participant 112.0...
2025-03-28 19:24:06,147 - INFO - Fitting SINDy model for participant 112.0
2025-03-28 19:24:07,656 - INFO - Participant 112.0: LL=-0.6934, BIC=2.0692, Params=10, Val trials=60
2025-03-28 19:24:07,656 - INFO - Processing participant 113.0...
2025-03-28 19:24:07,657 - INFO - Fitting SINDy model for participant 113.0
2025-03-28 19:24:09,143 - INFO - Participant 113.0: LL=-0.1700, BIC=1.0224, Params=10, Val trials=60
2025-03-28 19:24:09,143 - INFO - Processing participant 114.0...
2025-03-28 19:24:09,144 - INFO - Fitting SINDy model for participant 114.0
2025-03-28 19:24:10,585 - INFO - Participant 114.0: LL=-0.8315, BIC=2.4136, Params=11, Val trials=60
2025-03-28 19:24:10,585 - INFO - Processing participant 115.0...
2025-03-28 19:24:10,586 - INFO - Fitting SINDy model for participant 115.0
2025-03-28 19:24:12,099 - INFO - Participant 115.0: LL=-8.6282, BIC=18.1435, Params=13, Val trials=60
2025-03-28 19:24:12,099 - INFO - Processing participant 116.0...
2025-03-28 19:24:12,100 - INFO - Fitting SINDy model for participant 116.0
2025-03-28 19:24:13,731 - INFO - Participant 116.0: LL=-9.2288, BIC=19.3447, Params=13, Val trials=60
2025-03-28 19:24:13,731 - INFO - Processing participant 117.0...
2025-03-28 19:24:13,731 - INFO - Fitting SINDy model for participant 117.0
2025-03-28 19:24:15,353 - INFO - Participant 117.0: LL=-0.7034, BIC=2.1575, Params=11, Val trials=60
2025-03-28 19:24:15,353 - INFO - Processing participant 118.0...
2025-03-28 19:24:15,353 - INFO - Fitting SINDy model for participant 118.0
2025-03-28 19:24:16,932 - INFO - Participant 118.0: LL=-0.6931, BIC=2.0687, Params=10, Val trials=60
2025-03-28 19:24:16,933 - INFO - Processing participant 119.0...
2025-03-28 19:24:16,933 - INFO - Fitting SINDy model for participant 119.0
2025-03-28 19:24:18,560 - INFO - Participant 119.0: LL=-0.5039, BIC=1.6902, Params=10, Val trials=60
2025-03-28 19:24:18,560 - INFO - Processing participant 120.0...
2025-03-28 19:24:18,561 - INFO - Fitting SINDy model for participant 120.0
2025-03-28 19:24:20,094 - INFO - Participant 120.0: LL=-0.1939, BIC=1.0702, Params=10, Val trials=60
2025-03-28 19:24:20,095 - INFO - Processing participant 121.0...
2025-03-28 19:24:20,095 - INFO - Fitting SINDy model for participant 121.0
2025-03-28 19:24:21,582 - INFO - Participant 121.0: LL=-1.5375, BIC=3.8256, Params=11, Val trials=60
2025-03-28 19:24:21,582 - INFO - Processing participant 122.0...
2025-03-28 19:24:21,582 - INFO - Fitting SINDy model for participant 122.0
2025-03-28 19:24:23,059 - INFO - Participant 122.0: LL=-0.6931, BIC=1.8640, Params=7, Val trials=60
2025-03-28 19:24:23,059 - INFO - Processing participant 123.0...
2025-03-28 19:24:23,060 - INFO - Fitting SINDy model for participant 123.0
2025-03-28 19:24:24,563 - INFO - Participant 123.0: LL=-0.1655, BIC=1.1499, Params=12, Val trials=60
2025-03-28 19:24:24,563 - INFO - Processing participant 124.0...
2025-03-28 19:24:24,564 - INFO - Fitting SINDy model for participant 124.0
2025-03-28 19:24:26,132 - INFO - Participant 124.0: LL=-0.6931, BIC=2.1369, Params=11, Val trials=60
2025-03-28 19:24:26,133 - INFO - Processing participant 125.0...
2025-03-28 19:24:26,133 - INFO - Fitting SINDy model for participant 125.0
2025-03-28 19:24:27,587 - INFO - Participant 125.0: LL=-0.0133, BIC=0.7090, Params=10, Val trials=60
2025-03-28 19:24:27,587 - INFO - Processing participant 126.0...
2025-03-28 19:24:27,588 - INFO - Fitting SINDy model for participant 126.0
2025-03-28 19:24:29,216 - INFO - Participant 126.0: LL=-0.3859, BIC=1.5223, Params=11, Val trials=60
2025-03-28 19:24:29,216 - INFO - Processing participant 127.0...
2025-03-28 19:24:29,217 - INFO - Fitting SINDy model for participant 127.0
2025-03-28 19:24:30,865 - INFO - Participant 127.0: LL=-0.6563, BIC=1.9951, Params=10, Val trials=60
2025-03-28 19:24:30,865 - INFO - Number of participants with valid BIC metrics: 128/128
2025-03-28 19:24:30,865 - INFO - Average SINDy BIC: 2.3330
2025-03-28 19:24:30,865 - INFO - Average SINDy LL: -0.8010
2025-03-28 19:24:30,876 - INFO - Completed processing dataset: data_128p_0.csv
2025-03-28 19:24:31,918 - INFO - Created violin plots with 128 participant data points
