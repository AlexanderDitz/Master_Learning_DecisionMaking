{"cells":[{"cell_type":"markdown","metadata":{"id":"LwfT57-uJIt9"},"source":["## Installation and imports"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","id":"zDN04KYnHMmI"},"outputs":[{"name":"stdout","output_type":"stream","text":["Not on Google Colab. Assuming you already installed the required packages.\n"]}],"source":["#@title Install required packages.\n","try:\n","    from google.colab import files  # checks if you are on google colab\n","    !rm -rf CogModelingRNNsTutorial\n","    !git clone https://github.com/whyhardt/CogModelingRNN.git\n","    %pip install -e CogModelingRNN/CogModelingRNNsTutorial\n","    !cp CogModelingRNN/CogModelingRNNsTutorial/*py CogModelingRNN\n","    %pip install pysindy\n","    _ON_COLAB = True\n","except:\n","    print('Not on Google Colab. Assuming you already installed the required packages.')"]},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","id":"lVdDzYwVHbdb"},"outputs":[],"source":["#@title Import libraries\n","import sys\n","import os\n","import warnings\n","from typing import Callable, Tuple, Iterable, Union\n","\n","import matplotlib.pyplot as plt\n","from sympy.parsing.sympy_parser import parse_expr\n","import numpy as np\n","import pandas as pd\n","import scipy.stats as st\n","import pickle\n","\n","# deepmind related libraries\n","import haiku as hk\n","import jax\n","import jax.numpy as jnp\n","import optax\n","\n","import pysindy as ps\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# RL libraries\n","sys.path.append('resources')  # add source directoy to path\n","from resources import bandits, disrnn, hybrnn, hybrnn_forget, plotting, rat_data, rnn_utils"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"0_eVhrNccDV7"},"outputs":[],"source":["#@title make update rule of Q-/SINDyNetwork-Agents adjustable and make values of RNN-Agent visible\n","\n","class AgentQuadQ(bandits.AgentQ):\n","  \n","  def __init__(\n","      self,\n","      alpha: float=0.2,\n","      beta: float=3.,\n","      n_actions: int=2,\n","      forgetting_rate: float=0.,\n","      perseveration_bias: float=0.,\n","      ):\n","    super().__init__(alpha, beta, n_actions, forgetting_rate, perseveration_bias)\n","  \n","  def update(self,\n","            choice: int,\n","            reward: float):\n","    \"\"\"Update the agent after one step of the task.\n","\n","    Args:\n","      choice: The choice made by the agent. 0 or 1\n","      reward: The reward received by the agent. 0 or 1\n","    \"\"\"\n","    \n","    # Decay q-values toward the initial value.\n","    self._q = (1-self._forgetting_rate) * self._q + self._forgetting_rate * self._q_init\n","\n","    # Update chosen q for chosen action with observed reward.\n","    self._q[choice] = self._q[choice] - self._alpha * self._q[choice]**2 + self._alpha * reward\n","\n","\n","class AgentSindy(bandits.AgentQ):\n","\n","  def __init__(\n","      self,\n","      alpha: float=0.2,\n","      beta: float=3.,\n","      n_actions: int=2,\n","      forgetting_rate: float=0.,\n","      perservation_bias: float=0.,):\n","    super().__init__(alpha, beta, n_actions, forgetting_rate, perservation_bias)\n","\n","    self._update_rule = lambda q, choice, reward: (1 - self._alpha) * q[choice] + self._alpha * reward\n","    self._update_rule_formula = None\n","\n","  def set_update_rule(self, update_rule: callable, update_rule_formula: str=None):\n","    self._update_rule=update_rule\n","    self._update_rule_formula=update_rule_formula\n","\n","  @property\n","  def update_rule(self):\n","    if self._update_rule_formula is not None:\n","      return self._update_rule_formula\n","    else:\n","      return f'{self._update_rule}'\n","\n","  def update(self, choice: int, reward: int):\n","\n","    for c in range(self._n_actions):\n","      self._q[c] = self._update_rule(self._q[c], int(c==choice), reward)\n","\n","\n","class AgentNetwork_VisibleState(bandits.AgentNetwork):\n","\n","  def __init__(self,\n","               make_network: Callable[[], hk.RNNCore],\n","               params: hk.Params,\n","               n_actions: int = 2,\n","               state_to_numpy: bool = False,\n","               habit=False):\n","    super().__init__(make_network=make_network, params=params, n_actions=n_actions, state_to_numpy=state_to_numpy)\n","    self.habit = habit\n","\n","  @property\n","  def q(self):\n","    if self.habit:\n","      return self._state[2], self._state[3]\n","    else:\n","      return self._state[3].reshape(-1)\n","\n","dict_agents = {\n","    'basic': lambda alpha, beta, n_actions, forgetting_rate, perseveration_bias: bandits.AgentQ(alpha, beta, n_actions, forgetting_rate, perseveration_bias),\n","    'quad_q': lambda alpha, beta, n_actions, forgetting_rate, perseveration_bias: AgentQuadQ(alpha, beta, n_actions, forgetting_rate, perseveration_bias)\n","}"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def get_q(experiment: bandits.BanditSession, agent: Union[bandits.AgentQ, bandits.AgentNetwork, AgentSindy]):\n","  \"\"\"Compute Q-Values of a specific agent for a specific experiment.\n","\n","  Args:\n","      experiment (bandits.BanditSession): _description_\n","      agent (_type_): _description_\n","\n","  Returns:\n","      _type_: _description_\n","  \"\"\"\n","  \n","  choices = np.expand_dims(experiment.choices, 1)\n","  rewards = np.expand_dims(experiment.rewards, 1)\n","  qs = np.zeros((experiment.choices.shape[0], agent._n_actions))\n","  choice_probs = np.zeros((experiment.choices.shape[0], agent._n_actions))\n","  \n","  agent.new_sess()\n","  \n","  for trial in range(experiment.choices.shape[0]):\n","    qs[trial] = agent.q\n","    choice_probs[trial] = agent.get_choice_probs()\n","    agent.update(int(choices[trial]), float(rewards[trial]))\n","    \n","  return qs, choice_probs\n","\n","\n","def parse_equation_for_sympy(eq):\n","    # replace all blank spaces with '*' where necessary\n","    # only between number and letter in exactly this order\n","    blanks = [i for i, ltr in enumerate(eq) if ltr == ' ']\n","    for blank in blanks:\n","        if (eq[blank+1].isalpha() or eq[blank-1].isdigit()) and (eq[blank+1].isalpha() or eq[blank+1].isdigit()):\n","            eq = eq[:blank] + '*' + eq[blank+1:]\n","    \n","    # replace all '^' with '**'\n","    eq = eq.replace('^', '**')\n","    \n","    # remove all [k]\n","    eq = eq.replace('[k]', '')\n","\n","    return eq\n","\n","def make_sindy_data(\n","    dataset,\n","    agent: bandits.AgentQ,\n","    sessions=-1,\n","    get_choices=True,\n","    # keep_sessions=False,\n","    ):\n","\n","  # Get training data for SINDy\n","  # put all relevant signals in x_train\n","\n","  if not isinstance(sessions, Iterable) and sessions == -1:\n","    # use all sessions\n","    sessions = np.arange(len(dataset))\n","  else:\n","    # use only the specified sessions\n","    sessions = np.array(sessions)\n","    \n","  if get_choices:\n","    n_control = 2\n","  else:\n","    n_control = 1\n","  \n","  # if keep_sessions:\n","  #   # concatenate all sessions along the trial dimensinon -> shape: (n_trials, n_sessions, n_features)\n","  #   choices = np.expand_dims(np.stack([dataset[i].choices for i in sessions], axis=1), -1)\n","  #   rewards = np.expand_dims(np.stack([dataset[i].rewards for i in sessions], axis=1), -1)\n","  #   qs = np.stack([dataset[i].q for i in sessions], axis=1)\n","  # else:\n","  # concatenate all sessions along the trial dimensinon -> shape: (n_trials*n_sessions, n_features)\n","  # choices = np.expand_dims(np.concatenate([dataset[i].choices for i in sessions], axis=0), -1)\n","  # rewards = np.expand_dims(np.concatenate([dataset[i].rewards for i in sessions], axis=0), -1)\n","  # qs = np.concatenate([dataset[i].q for i in sessions], axis=0)\n","  \n","  choices = np.stack([dataset[i].choices for i in sessions], axis=0)\n","  rewards = np.stack([dataset[i].rewards for i in sessions], axis=0)\n","  qs = np.stack([dataset[i].q for i in sessions], axis=0)\n","  \n","  if not get_choices:\n","    raise NotImplementedError('Only get_choices=True is implemented right now.')\n","    n_sessions = qs.shape[0]\n","    n_trials = qs.shape[1]*qs.shape[2]\n","    qs_all = np.zeros((n_sessions, n_trials))\n","    r_all = np.zeros((n_sessions, n_trials))\n","    c_all = None\n","    # concatenate the data of all arms into one array for more training data\n","    index_end_last_arm = 0\n","    for index_arm in range(agent._n_actions):\n","      index = np.where(choices==index_arm)[0]\n","      r_all[index_end_last_arm:index_end_last_arm+len(index)] = rewards[index]\n","      qs_all[index_end_last_arm:index_end_last_arm+len(index)] = qs[index, index_arm].reshape(-1, 1)\n","      index_end_last_arm += len(index)\n","  else:\n","    choices_oh = np.zeros((len(sessions), choices.shape[1], agent._n_actions))\n","    for sess in sessions:\n","      # one-hot encode choices\n","      choices_oh[sess] = np.eye(agent._n_actions)[choices[sess]]\n","      # add choices as control parameter; no sorting required then\n","      # qs_all = np.concatenate([qs[sess, :, i] for i in range(agent._n_actions)], axis=1)\n","      # c_all = np.concatenate([choices[:, sess, i] for i in range(agent._n_actions)], axis=1)\n","      # r_all = np.concatenate([rewards for _ in range(agent._n_actions)], axis=1)\n","      # concatenate all qs values of one sessions along the trial dimension\n","      qs_all = np.concatenate([np.stack([np.expand_dims(qs_sess[:, i], axis=-1) for i in range(agent._n_actions)], axis=0) for qs_sess in qs], axis=0)\n","      c_all = np.concatenate([np.stack([c_sess[:, i] for i in range(agent._n_actions)], axis=0) for c_sess in choices_oh], axis=0)\n","      r_all = np.concatenate([np.stack([r_sess for _ in range(agent._n_actions)], axis=0) for r_sess in rewards], axis=0)\n","  \n","  # get observed dynamics\n","  x_train = qs_all\n","  feature_names = ['q']\n","\n","  # get control\n","  control_names = []\n","  control = np.zeros((*x_train.shape[:-1], n_control))\n","  if get_choices:\n","    control[:, :, 0] = c_all\n","    control_names += ['c']\n","  control[:, :, n_control-1] = r_all\n","  control_names += ['r']\n","  \n","  feature_names += control_names\n","  \n","  print(f'Shape of Q-Values is: {x_train.shape}')\n","  print(f'Shape of control parameters is: {control.shape}')\n","  print(f'Feature names are: {feature_names}')\n","  \n","  # make x_train and control sequences instead of arrays\n","  x_train = [x_train_sess for x_train_sess in x_train]\n","  control = [control_sess for control_sess in control]\n"," \n","  return x_train, control, feature_names\n"]},{"cell_type":"markdown","metadata":{"id":"rCHCHSQbcJjU"},"source":["# RNN Reinforcement Learning"]},{"cell_type":"markdown","metadata":{"id":"Ca6uMC-Pglux"},"source":["## Set up agent and generate training data"]},{"cell_type":"code","execution_count":7,"metadata":{"cellView":"form","id":"hgqxccJZhT6d"},"outputs":[],"source":["#@title Select dataset type.\n","#@markdown ## Select dataset:\n","\n","dataset_type = 'synt'  #@param ['synt', 'real']\n","\n","#@markdown Set up parameters for synthetic data generation:\n","if dataset_type == 'synt':\n","    # agent parameters\n","    agent_kw = 'basic'  #@param ['basic', 'quad_q'] \n","    gen_alpha = .25 #@param\n","    gen_beta = 1 #@param\n","    forgetting_rate = 0.1 #@param\n","    perseveration_bias = 0.  #@param\n","    # environment parameters\n","    non_binary_reward = False #@param\n","    n_actions = 2 #@param\n","    sigma = .1  #@param\n","    \n","    # experiement parameters\n","    n_trials_per_session = 200  #@param\n","    n_sessions = 220  #@param\n","\n","#@markdown Set up parameters for loading rat data from Miller et al 2019.\n","elif dataset_type == 'real':\n","    # TODO: ys are not the rewards but the following choices!!!!\n","    raise NotImplementedError('This is not implemented yet.')\n","\n","    path = 'data/bahrami_100.csv'\n","    data = pd.read_csv(path)\n","    xs = data['action'].values\n","    ys = data['reward'].values\n","    episodes = np.unique(data['participant_id'].values)\n","    # reshape xs and ys to be (n_trials_per_episode, n_episodes, 1). Take the variable episodes as the index for the dim 'n_episodes'\n","    train_test_ratio = 0.8\n","    n_episodes_train = int(len(episodes)*train_test_ratio)\n","    n_episodes_test = len(episodes) - n_episodes_train\n","\n","    xs = xs.reshape(-1, len(episodes), 1)\n","    ys = ys.reshape(-1, len(episodes), 1)\n","    \n","    # one-hot encode xs\n","    xs = jax.nn.one_hot(xs[:, :, 0], num_classes=int(np.max(np.unique(xs[:, 0, 0])+1)))\n","    # delay xs by one time step to have previous choices\n","    xs = np.concatenate((np.zeros((1, *xs.shape[1:])), xs[:-1, :, :]), axis=0)\n","    # add one-time-step delayed reward as feature to xs\n","    reward_delayed = np.concatenate((np.zeros((1, *ys.shape[1:])), ys[:-1, :, :]), axis=0)\n","    xs = np.concatenate((xs, reward_delayed), axis=-1)\n","    \n","    xs_train = xs[:, :n_episodes_train]\n","    ys_train = ys[:, :n_episodes_train]\n","    xs_test = xs[:, n_episodes_train:]\n","    ys_test = ys[:, n_episodes_train:]\n","    \n","    n_actions = xs.shape[-1]# - 1  # -1 because of the delayed reward \n","    n_trials_per_session = xs.shape[0] \n","    n_sessions = xs_train.shape[1]\n","    \n","    dataset_train = rnn_utils.DatasetRNN(xs_train, ys_train)\n","    dataset_test = rnn_utils.DatasetRNN(xs_test, ys_test)\n","    \n","    experiment_list_train = None\n","    experiment_list_test = None\n","\n","else:\n","  raise NotImplementedError(\n","      (f'dataset_type {dataset_type} not implemented. '\n","       'Please select from drop-down list.'))"]},{"cell_type":"markdown","metadata":{},"source":["For the values $f=0.5$, $\\alpha=0.25$ and $Q_0=0.5$ the discovered model should be equal to\n","$$Q_\\text{k+1}=0.9 Q_\\text{k} + 0.05 - 0.225 c Q_\\text{k} -  0.0125 c + 0.25 c r$$"]},{"cell_type":"markdown","metadata":{"id":"5aYKermb0BJe"},"source":["## Fit a hybrid RNN and train SINDy on RNN dynamics"]},{"cell_type":"code","execution_count":8,"metadata":{"cellView":"form","id":"lkBYYdpXcO59"},"outputs":[],"source":["#@title Set up Hybrid RNN.\n","\n","#@markdown Is the model recurrent (ie can it see the hidden state from the previous step)\n","use_hidden_state = False  #@param ['True', 'False']\n","\n","#@markdown Is the model recurrent (ie can it see the hidden state from the previous step)\n","use_previous_values = False  #@param ['True', 'False']\n","\n","#@markdown If True, learn a value for the forgetting term\n","fit_forget = False  #@param ['True', 'False']\n","\n","#@markdown Learn a reward-independent term that depends on past choices.\n","habit_weight = \"0\"  #@param [0, 1]\n","habit_weight = float(habit_weight)\n","\n","value_weight = 1.  # This is needed for it to be doing RL\n","\n","rnn_rl_params = {\n","    's': use_hidden_state,\n","    'o': use_previous_values,\n","    'fit_forget': fit_forget,\n","    'forget': 0.,\n","    'w_h': habit_weight,\n","    'w_v': value_weight}\n","network_params = {'n_actions': n_actions, 'hidden_size': 16}\n","\n","def make_hybrnn():\n","  # model = hybrnn.BiRNN(rl_params=rnn_rl_params, network_params=network_params)\n","  model = hybrnn_forget.BiRNN(rl_params=rnn_rl_params, network_params=network_params)\n","  return model\n","\n","optimizer_rnn = optax.adam(learning_rate=1e-3)"]},{"cell_type":"code","execution_count":13,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":95493,"status":"ok","timestamp":1703173698779,"user":{"displayName":"Daniel W","userId":"06430346412716090550"},"user_tz":-60},"id":"catb-Attg4XL","outputId":"67fc93c8-c51c-41bb-87ba-963fee64c698"},"outputs":[{"name":"stdout","output_type":"stream","text":["Beta: 1 -- Model: 1\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6814393; Time: 12.4s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 0.0003s.\n","Step 500 of 500; Loss: 0.6813739; Time: 13.2s)\n","Model not yet converged (convergence_value = 9.595322e-05) - Running more steps of gradient descent. Time elapsed = 7e-05s.\n","Step 500 of 500; Loss: 0.6813708; Time: 13.3s)\n","Model Converged! Time elapsed = 0.0004s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=0.9344863891601562, min=-0.7147908210754395\n","Beta: 1 -- Model: 2\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6840516; Time: 12.6s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.6840174; Time: 13.4s)\n","Model not yet converged (convergence_value = 5.010246e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6840057; Time: 12.0s)\n","Model not yet converged (convergence_value = 1.699212e-05) - Running more steps of gradient descent. Time elapsed = 0.0004s.\n","Step 500 of 500; Loss: 0.6839871; Time: 12.7s)\n","Model not yet converged (convergence_value = 2.7275e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6839485; Time: 12.1s)\n","Model not yet converged (convergence_value = 5.646862e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6838109; Time: 11.9s)\n","Model not yet converged (convergence_value = 0.0002010501) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6837984; Time: 12.3s)\n","Model not yet converged (convergence_value = 1.830473e-05) - Running more steps of gradient descent. Time elapsed = 0.0004s.\n","Step 500 of 500; Loss: 0.6837986; Time: 12.6s)\n","Model Converged! Time elapsed = 3e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=0.8087758421897888, min=0.046055424958467484\n","Beta: 1 -- Model: 3\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6834574; Time: 13.0s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.6833997; Time: 12.3s)\n","Model not yet converged (convergence_value = 8.441974e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6833930; Time: 13.6s)\n","Model Converged! Time elapsed = 4e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=0.6519295573234558, min=-0.9826641082763672\n","Beta: 1 -- Model: 4\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6824414; Time: 12.4s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 0.0004s.\n","Step 500 of 500; Loss: 0.6823796; Time: 13.2s)\n","Model not yet converged (convergence_value = 9.05719e-05) - Running more steps of gradient descent. Time elapsed = 6e-05s.\n","Step 500 of 500; Loss: 0.6823774; Time: 13.1s)\n","Model Converged! Time elapsed = 0.0004s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=0.718461275100708, min=-0.7836455702781677\n","Beta: 1 -- Model: 5\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6835675; Time: 12.1s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 0.0004s.\n","Step 500 of 500; Loss: 0.6835014; Time: 12.3s)\n","Model not yet converged (convergence_value = 9.661365e-05) - Running more steps of gradient descent. Time elapsed = 7e-05s.\n","Step 500 of 500; Loss: 0.6834809; Time: 12.1s)\n","Model not yet converged (convergence_value = 2.999847e-05) - Running more steps of gradient descent. Time elapsed = 0.0001s.\n","Step 500 of 500; Loss: 0.6834616; Time: 12.9s)\n","Model not yet converged (convergence_value = 2.825522e-05) - Running more steps of gradient descent. Time elapsed = 6e-05s.\n","Step 500 of 500; Loss: 0.6834452; Time: 13.2s)\n","Model not yet converged (convergence_value = 2.406994e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6834358; Time: 12.7s)\n","Model not yet converged (convergence_value = 1.369229e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6834307; Time: 12.8s)\n","Model Converged! Time elapsed = 0.0004s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=0.5, min=-0.749557614326477\n","Beta: 2 -- Model: 1\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6540025; Time: 11.1s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6538904; Time: 12.1s)\n","Model not yet converged (convergence_value = 0.000171431) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.6538681; Time: 11.9s)\n","Model not yet converged (convergence_value = 3.41827e-05) - Running more steps of gradient descent. Time elapsed = 0.0005s.\n","Step 500 of 500; Loss: 0.6538333; Time: 12.5s)\n","Model not yet converged (convergence_value = 5.314452e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6537747; Time: 11.3s)\n","Model not yet converged (convergence_value = 8.961208e-05) - Running more steps of gradient descent. Time elapsed = 6e-05s.\n","Step 500 of 500; Loss: 0.6535864; Time: 12.3s)\n","Model not yet converged (convergence_value = 0.000288006) - Running more steps of gradient descent. Time elapsed = 0.0003s.\n","Step 500 of 500; Loss: 0.6528365; Time: 12.2s)\n","Model not yet converged (convergence_value = 0.001147431) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6528354; Time: 12.7s)\n","Model Converged! Time elapsed = 3e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=1.0059655904769897, min=-0.6969730854034424\n","Beta: 2 -- Model: 2\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6588653; Time: 13.1s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 7e-05s.\n","Step 500 of 500; Loss: 0.6587320; Time: 12.1s)\n","Model not yet converged (convergence_value = 0.0002022811) - Running more steps of gradient descent. Time elapsed = 0.0003s.\n","Step 500 of 500; Loss: 0.6587193; Time: 13.2s)\n","Model not yet converged (convergence_value = 1.927307e-05) - Running more steps of gradient descent. Time elapsed = 6e-05s.\n","Step 500 of 500; Loss: 0.6586982; Time: 13.0s)\n","Model not yet converged (convergence_value = 3.203192e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6586614; Time: 13.7s)\n","Model not yet converged (convergence_value = 5.592192e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6585990; Time: 12.5s)\n","Model not yet converged (convergence_value = 9.474681e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6583859; Time: 12.0s)\n","Model not yet converged (convergence_value = 0.0003234548) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6577117; Time: 12.8s)\n","Model not yet converged (convergence_value = 0.001024092) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6577115; Time: 12.2s)\n","Model Converged! Time elapsed = 5e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=1.2363908290863037, min=-0.29217422008514404\n","Beta: 2 -- Model: 3\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6570830; Time: 12.0s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 0.0003s.\n","Step 500 of 500; Loss: 0.6569796; Time: 12.6s)\n","Model not yet converged (convergence_value = 0.0001572929) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6569225; Time: 12.3s)\n","Model not yet converged (convergence_value = 8.700552e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6567929; Time: 12.2s)\n","Model not yet converged (convergence_value = 0.0001972539) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6563076; Time: 12.3s)\n","Model not yet converged (convergence_value = 0.0007388043) - Running more steps of gradient descent. Time elapsed = 6e-05s.\n","Step 500 of 500; Loss: 0.6555730; Time: 12.1s)\n","Model not yet converged (convergence_value = 0.001119334) - Running more steps of gradient descent. Time elapsed = 0.0004s.\n","Step 500 of 500; Loss: 0.6555728; Time: 12.2s)\n","Model Converged! Time elapsed = 0.0003s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=1.162140965461731, min=-0.403197318315506\n","Beta: 2 -- Model: 4\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6585362; Time: 12.5s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.6584007; Time: 13.2s)\n","Model not yet converged (convergence_value = 0.0002057311) - Running more steps of gradient descent. Time elapsed = 6e-05s.\n","Step 500 of 500; Loss: 0.6583942; Time: 12.4s)\n","Model Converged! Time elapsed = 8e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=1.316934585571289, min=-1.8244444131851196\n","Beta: 2 -- Model: 5\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6561685; Time: 12.4s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.6560267; Time: 12.5s)\n","Model not yet converged (convergence_value = 0.0002161022) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6560061; Time: 12.2s)\n","Model not yet converged (convergence_value = 3.143654e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6559730; Time: 12.1s)\n","Model not yet converged (convergence_value = 5.042724e-05) - Running more steps of gradient descent. Time elapsed = 0.0006s.\n","Step 500 of 500; Loss: 0.6559077; Time: 13.3s)\n","Model not yet converged (convergence_value = 9.958747e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6556913; Time: 12.9s)\n","Model not yet converged (convergence_value = 0.0003299618) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6550509; Time: 12.6s)\n","Model not yet converged (convergence_value = 0.0009765765) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6550500; Time: 11.2s)\n","Model Converged! Time elapsed = 2e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=1.2932668924331665, min=-0.4537697732448578\n","Beta: 3 -- Model: 1\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6184928; Time: 12.8s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6183369; Time: 13.1s)\n","Model not yet converged (convergence_value = 0.0002522024) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6182861; Time: 12.4s)\n","Model not yet converged (convergence_value = 8.212863e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6181927; Time: 12.5s)\n","Model not yet converged (convergence_value = 0.0001509671) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6179493; Time: 12.7s)\n","Model not yet converged (convergence_value = 0.0003937694) - Running more steps of gradient descent. Time elapsed = 7e-05s.\n","Step 500 of 500; Loss: 0.6162151; Time: 12.5s)\n","Model not yet converged (convergence_value = 0.002806374) - Running more steps of gradient descent. Time elapsed = 0.0005s.\n","Step 500 of 500; Loss: 0.6154853; Time: 12.9s)\n","Model not yet converged (convergence_value = 0.001184326) - Running more steps of gradient descent. Time elapsed = 7e-05s.\n","Step 500 of 500; Loss: 0.6154854; Time: 13.3s)\n","Model Converged! Time elapsed = 4e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=2.0194194316864014, min=-0.6943217515945435\n","Beta: 3 -- Model: 2\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6186435; Time: 12.6s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 0.0004s.\n","Step 500 of 500; Loss: 0.6185653; Time: 12.9s)\n","Model not yet converged (convergence_value = 0.0001264077) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6185501; Time: 11.5s)\n","Model not yet converged (convergence_value = 2.457167e-05) - Running more steps of gradient descent. Time elapsed = 0.0003s.\n","Step 500 of 500; Loss: 0.6185266; Time: 12.8s)\n","Model not yet converged (convergence_value = 3.796658e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6184858; Time: 12.5s)\n","Model not yet converged (convergence_value = 6.601039e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6183612; Time: 13.4s)\n","Model not yet converged (convergence_value = 0.0002014172) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6167438; Time: 11.9s)\n","Model not yet converged (convergence_value = 0.002615674) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.6161155; Time: 12.2s)\n","Model not yet converged (convergence_value = 0.001018822) - Running more steps of gradient descent. Time elapsed = 0.0003s.\n","Step 500 of 500; Loss: 0.6161150; Time: 12.8s)\n","Model Converged! Time elapsed = 3e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=1.7906889915466309, min=-0.6436865925788879\n","Beta: 3 -- Model: 3\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6194893; Time: 12.4s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.6193168; Time: 13.2s)\n","Model not yet converged (convergence_value = 0.0002785447) - Running more steps of gradient descent. Time elapsed = 0.0001s.\n","Step 500 of 500; Loss: 0.6192123; Time: 12.2s)\n","Model not yet converged (convergence_value = 0.0001687132) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6189681; Time: 13.0s)\n","Model not yet converged (convergence_value = 0.0003942761) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6180605; Time: 12.1s)\n","Model not yet converged (convergence_value = 0.001466408) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6167451; Time: 10.6s)\n","Model not yet converged (convergence_value = 0.002128295) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6167154; Time: 10.6s)\n","Model not yet converged (convergence_value = 4.812866e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6167137; Time: 10.4s)\n","Model Converged! Time elapsed = 2e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=1.5519784688949585, min=-0.5672804713249207\n","Beta: 3 -- Model: 4\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6182290; Time: 10.2s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.6180855; Time: 10.5s)\n","Model not yet converged (convergence_value = 0.0002320635) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.6180589; Time: 10.4s)\n","Model not yet converged (convergence_value = 4.310613e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6180251; Time: 10.2s)\n","Model not yet converged (convergence_value = 5.458417e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6179628; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0001007837) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6177769; Time: 10.6s)\n","Model not yet converged (convergence_value = 0.0003009347) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.6165641; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.001963129) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6160981; Time: 10.4s)\n","Model not yet converged (convergence_value = 0.0007557837) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6160976; Time: 10.3s)\n","Model Converged! Time elapsed = 2e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=1.8452874422073364, min=-0.6562837958335876\n","Beta: 3 -- Model: 5\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.6193682; Time: 10.1s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.6192442; Time: 10.4s)\n","Model not yet converged (convergence_value = 0.0002001679) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.6192124; Time: 10.4s)\n","Model not yet converged (convergence_value = 5.130331e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6191576; Time: 10.3s)\n","Model not yet converged (convergence_value = 8.855809e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6190445; Time: 10.4s)\n","Model not yet converged (convergence_value = 0.0001827154) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.6186508; Time: 10.4s)\n","Model not yet converged (convergence_value = 0.0006359619) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6168618; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.002891734) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.6168028; Time: 10.4s)\n","Model not yet converged (convergence_value = 9.565935e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.6168027; Time: 10.3s)\n","Model Converged! Time elapsed = 2e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=1.8942954540252686, min=-0.6924291253089905\n","Beta: 4 -- Model: 1\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.5782553; Time: 10.5s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.5781435; Time: 10.5s)\n","Model not yet converged (convergence_value = 0.0001933719) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5780984; Time: 11.0s)\n","Model not yet converged (convergence_value = 7.794105e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.5780263; Time: 10.8s)\n","Model not yet converged (convergence_value = 0.0001247566) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5779074; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0002057195) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5775895; Time: 10.5s)\n","Model not yet converged (convergence_value = 0.0005501421) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5751165; Time: 10.4s)\n","Model not yet converged (convergence_value = 0.004281479) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5749255; Time: 10.1s)\n","Model not yet converged (convergence_value = 0.0003321638) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5749180; Time: 10.2s)\n","Model not yet converged (convergence_value = 1.295921e-05) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5749179; Time: 10.3s)\n","Model Converged! Time elapsed = 2e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=1.8107059001922607, min=-1.0994577407836914\n","Beta: 4 -- Model: 2\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.5706694; Time: 10.3s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.5704919; Time: 10.1s)\n","Model not yet converged (convergence_value = 0.0003109384) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5704353; Time: 10.2s)\n","Model not yet converged (convergence_value = 9.925542e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5703632; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0001263281) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5702639; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.0001742064) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5700701; Time: 10.4s)\n","Model not yet converged (convergence_value = 0.0003396938) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5675319; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.004452442) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5669410; Time: 10.1s)\n","Model not yet converged (convergence_value = 0.001041316) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5669382; Time: 9.9s)\n","Model Converged! Time elapsed = 2e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=2.2671568393707275, min=-0.9096769094467163\n","Beta: 4 -- Model: 3\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.5768049; Time: 10.0s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.5766696; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0002346758) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5766379; Time: 10.3s)\n","Model not yet converged (convergence_value = 5.498759e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5765900; Time: 10.1s)\n","Model not yet converged (convergence_value = 8.300275e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5765164; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0001276674) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5763587; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.0002734602) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5736678; Time: 10.0s)\n","Model not yet converged (convergence_value = 0.004668813) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5726135; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0018378) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5726022; Time: 10.2s)\n","Model not yet converged (convergence_value = 1.988162e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5726020; Time: 10.0s)\n","Model Converged! Time elapsed = 2e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=1.901469349861145, min=-1.15785813331604\n","Beta: 4 -- Model: 4\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.5763853; Time: 10.5s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.5762556; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0002250226) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5762068; Time: 10.5s)\n","Model not yet converged (convergence_value = 8.460933e-05) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5761271; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.0001384069) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5759710; Time: 10.1s)\n","Model not yet converged (convergence_value = 0.0002708516) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5749505; Time: 10.4s)\n","Model not yet converged (convergence_value = 0.001771879) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5722547; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.004688646) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5722322; Time: 10.2s)\n","Model not yet converged (convergence_value = 3.926739e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5722321; Time: 10.3s)\n","Model Converged! Time elapsed = 2e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=2.032902479171753, min=-1.0358657836914062\n","Beta: 4 -- Model: 5\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.5840850; Time: 10.0s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.5839731; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.0001915439) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5839105; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0001072729) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5837898; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0002066067) - Running more steps of gradient descent. Time elapsed = 0.0003s.\n","Step 500 of 500; Loss: 0.5834367; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.0006048374) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5807984; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.004522067) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5804784; Time: 10.4s)\n","Model not yet converged (convergence_value = 0.0005508929) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5804733; Time: 10.1s)\n","Model Converged! Time elapsed = 2e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=1.8637186288833618, min=-1.2971341609954834\n","Beta: 5 -- Model: 1\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.5320981; Time: 10.2s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.5319075; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.0003581221) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5318715; Time: 10.2s)\n","Model not yet converged (convergence_value = 6.768321e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.5318173; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.0001019799) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5317255; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.000172599) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5312501; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.0008940829) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5271577; Time: 10.1s)\n","Model not yet converged (convergence_value = 0.007703219) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5270621; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.000181361) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5270582; Time: 10.3s)\n","Model Converged! Time elapsed = 0.0003s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=2.271656036376953, min=-1.6268318891525269\n","Beta: 5 -- Model: 2\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.5318966; Time: 10.3s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.5316828; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.0004018493) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5316236; Time: 10.6s)\n","Model not yet converged (convergence_value = 0.000111433) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5315453; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0001473232) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5314336; Time: 10.5s)\n","Model not yet converged (convergence_value = 0.0002100282) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5310448; Time: 10.4s)\n","Model not yet converged (convergence_value = 0.000731608) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5267752; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.008039999) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5267348; Time: 10.3s)\n","Model not yet converged (convergence_value = 7.671573e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5267333; Time: 10.3s)\n","Model Converged! Time elapsed = 3e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=2.769498586654663, min=-1.2678711414337158\n","Beta: 5 -- Model: 3\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.5345427; Time: 10.3s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.5344575; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0001594534) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5344219; Time: 10.3s)\n","Model not yet converged (convergence_value = 6.669113e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5343615; Time: 10.5s)\n","Model not yet converged (convergence_value = 0.0001128694) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5342382; Time: 10.1s)\n","Model not yet converged (convergence_value = 0.0002308954) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5334242; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.001523592) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5299951; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.006428383) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5298468; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0002799195) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5298395; Time: 10.3s)\n","Model not yet converged (convergence_value = 1.383678e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5298389; Time: 10.3s)\n","Model Converged! Time elapsed = 2e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=2.6201508045196533, min=-1.345253825187683\n","Beta: 5 -- Model: 4\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.5358767; Time: 10.4s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.5357253; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.0002825198) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5356753; Time: 10.3s)\n","Model not yet converged (convergence_value = 9.323564e-05) - Running more steps of gradient descent. Time elapsed = 5e-05s.\n","Step 500 of 500; Loss: 0.5356021; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0001367509) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5354953; Time: 10.4s)\n","Model not yet converged (convergence_value = 0.0001994233) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5352178; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.0005182478) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5303304; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.009131503) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5301997; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0002464746) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5301971; Time: 10.3s)\n","Model Converged! Time elapsed = 2e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=2.5840377807617188, min=-1.3732308149337769\n","Beta: 5 -- Model: 5\n","Training the hybrid RNN...\n","Step 500 of 500; Loss: 0.5360751; Time: 10.2s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.5358920; Time: 10.3s)\n","Model not yet converged (convergence_value = 0.0003415668) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5358166; Time: 10.1s)\n","Model not yet converged (convergence_value = 0.000140811) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5357051; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.0002080202) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5355530; Time: 10.1s)\n","Model not yet converged (convergence_value = 0.0002838342) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5351882; Time: 10.5s)\n","Model not yet converged (convergence_value = 0.0006812398) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5310501; Time: 10.2s)\n","Model not yet converged (convergence_value = 0.007731958) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5308729; Time: 10.7s)\n","Model not yet converged (convergence_value = 0.0003336871) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.5308661; Time: 10.1s)\n","Model not yet converged (convergence_value = 1.291182e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n","Step 500 of 500; Loss: 0.5308663; Time: 10.1s)\n","Model Converged! Time elapsed = 3e-05s.\n","Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","Dataset characteristics: max=2.5475826263427734, min=-1.1749248504638672\n"]}],"source":["train = True\n","load = False  # only relevant if train is True --> Determines whether to load trained parameters and continue training or start new training\n","\n","\n","for beta in range(1, 6):\n","  for i in range(1,6):\n","    print('Beta:', beta, '-- Model:', i)\n","    # params_path = 'params/params_rnn_forget_f01.pkl'\n","    params_path = 'params/params_rnn_forget_f01_b'+str(beta)+'_model'+str(i)+'.pkl'\n","\n","    if train:\n","      # set up env and agent\n","      environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_rewards=non_binary_reward)\n","      agent = dict_agents[agent_kw](gen_alpha, beta, n_actions, forgetting_rate, perseveration_bias)  \n","      dataset_train, experiment_list_train = bandits.create_dataset(\n","            agent=agent,\n","            environment=environment,\n","            n_trials_per_session=n_trials_per_session,\n","            n_sessions=n_sessions)\n","      \n","      if load:\n","        with open(params_path, 'rb') as f:\n","          rnn_params = pickle.load(f)\n","        opt_state = rnn_params[1]\n","        rnn_params = rnn_params[0]\n","        print('Loaded parameters.')\n","      else:\n","        opt_state = None\n","        rnn_params = None\n","\n","      # with jax.disable_jit():\n","      #@title Fit the hybrid RNN\n","      print('Training the hybrid RNN...')\n","      rnn_params, opt_state, _ = rnn_utils.fit_model(\n","          model_fun=make_hybrnn,\n","          dataset=dataset_train,\n","          optimizer=optimizer_rnn,\n","          optimizer_state=opt_state,\n","          model_params=rnn_params,\n","          loss_fun='categorical',  # penalized_categorical, categorical\n","          convergence_thresh=1e-5,\n","          n_steps_max=10000,\n","      )\n","\n","      # save trained parameters\n","      params = (rnn_params, opt_state)\n","      with open(params_path, 'wb') as f:\n","        pickle.dump(params, f)\n","        \n","    else:\n","      # load trained parameters\n","      with open(params_path, 'rb') as f:\n","        rnn_params = pickle.load(f)[0]\n","      print('Loaded parameters.')\n","      \n","    #@title Synthesize a dataset using the fitted network\n","    hybrnn_agent = AgentNetwork_VisibleState(make_hybrnn, rnn_params, habit=habit_weight==1, n_actions=n_actions)\n","    dataset_hybrnn, experiment_list_hybrnn = bandits.create_dataset(hybrnn_agent, environment, n_trials_per_session, int(n_sessions*1e0))\n","\n","    #@title Fit SINDy to RNN data and synthesize new dataset\n","\n","    threshold = 0.015\n","    poly_order = 3\n","    dt = 1\n","\n","    x_train, control, feature_names = make_sindy_data(experiment_list_hybrnn, hybrnn_agent, get_choices=True)\n","    # x_train, control, feature_names = make_sindy_data(experiment_list_train, agent, get_choices=get_choices)\n","    # scale q-values between 0 and 1 for more realistic dynamics\n","    x_max = np.max(np.stack(x_train, axis=0))\n","    x_min = np.min(np.stack(x_train, axis=0))\n","    print(f'Dataset characteristics: max={x_max}, min={x_min}')\n","    x_train = [(x - x_min) / (x_max - x_min) for x in x_train]\n","\n","    # library_rnnsindy = ps.CustomLibrary(\n","    #     library_functions=custom_lib_functions,\n","    #     function_names=custom_lib_names,\n","    #     include_bias=True,\n","    # )\n","\n","    library_rnnsindy = ps.PolynomialLibrary(poly_order)\n","\n","    rnnsindy = ps.SINDy(\n","        optimizer=ps.STLSQ(threshold=threshold, verbose=False, alpha=0.1),\n","        feature_library=library_rnnsindy,\n","        discrete_time=True,\n","        feature_names=feature_names,\n","    )\n","\n","    rnnsindy.fit(x_train, t=dt, u=control, ensemble=True, library_ensemble=False, multiple_trajectories=True)\n","\n","    # groundtruth coefficients for model w/ and w/o forgetting; for polynomial order 3 library\n","    groundtruth_coeffs = [forgetting_rate * 0.5, 1-forgetting_rate, -0.5*gen_alpha*forgetting_rate, 0, 0, -(1-forgetting_rate)*gen_alpha, 0, 0, gen_alpha, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","    sindy_coeffs = rnnsindy.coefficients().reshape(-1).copy()\n","    # post-processing of sindy coefficients\n","    # sum up all coefficients that encode the same term if their values are equal\n","    equal_terms = {'c': ['c', 'c^2', 'c^3'], 'r': ['r', 'r^2', 'r^3'], 'c r': ['c r', 'c^2 r', 'c r^2'], 'q c': ['q c', 'q c^2'], 'q r': ['q r', 'q r^2']}\n","    sindy_terms = rnnsindy.get_feature_names()\n","    if not non_binary_reward:\n","        for term in equal_terms.keys():\n","            for equal_term in equal_terms[term]:\n","                if equal_term in sindy_terms:\n","                    if equal_term != term:\n","                        sindy_coeffs[sindy_terms.index(term)] += sindy_coeffs[sindy_terms.index(equal_term)]\n","                        sindy_coeffs[sindy_terms.index(equal_term)] = 0\n","\n","    # filter all remaining coeffs which are lower than threshold\n","    sindy_coeffs[np.abs(sindy_coeffs) < threshold] = 0\n","\n","    list_coeffs = [[sindy_terms[i], groundtruth_coeffs[i], np.round(sindy_coeffs[i], 2)] for i in range(len(sindy_terms))]\n","    list_features = ['term', 'groundtruth', 'sindy']\n","        \n","    import pandas as pd\n","\n","    pd.DataFrame(list_coeffs, columns=list_features).to_csv('params/params_recovery/recovered_coeffs_beta'+str(beta)+'model'+str(i)+'.csv', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNwCLLvTmMqZJNfKuTxnPyw","collapsed_sections":["LwfT57-uJIt9","Eq7jeg9mIx-f","Ca6uMC-Pglux","5aYKermb0BJe"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
